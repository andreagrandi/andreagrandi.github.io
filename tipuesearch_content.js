var tipuesearch = {"pages":[{"title":"About","text":"My name is Andrea Grandi and I live in Pavia (Italy) . I work as Python/Django developer for LaterPay a German company with a fully distributed and remote team. In my spare time I like to work on opensource projects (I'm learning Go language at the moment and developing Django/Python applications), attend local meetups and building stuff with Arduino and RaspberryPi . You can contact me at this address: me [at] andreagrandi.it - Note: I do not authorise anyone to use this email address for advertisement nor to contact me with unsolicited services (recruiters: I'm talking to you!).","tags":"pages","url":"https://www.andreagrandi.it/about/","loc":"https://www.andreagrandi.it/about/"},{"title":"Curriculum","text":"Profile Name: Andrea Grandi Where I live: Pavia, Italy e-mail: a.grandi [AT] gmail [dot] com GitHub: https://github.com/andreagrandi LinkedIn: https://uk.linkedin.com/in/andreagrandi In my 15 years' experience in professional software development, I started with .Net/C# language, continued my career in mobile development (Nokia platforms, Qt/C++) to finally become a Python/Django backend developer. During these years I also became an expert user and administrator of Linux systems. I am constantly striving to learn new technologies and to improve my skills. My ideal working place is an Agile environment where Test Driven Development and Continuous Integration are the norm and where I can balance my work between writing code, pairing and mentoring junior developers. Current position: Backend Software Engineer at LaterPay (remote) Skills languages: Python, Go, C#, Java, C++ frameworks: Django, Django Rest Framework, Flask databases: PostgreSQL, MySQL, MS-SQL and MongoDB other technologies: RabbitMQ methodologies: Test Driven Development, Agile (Sprint, Kanban) cloud and PaaS: Amazon AWS, Heroku, CloudFoundry, Docker automation: Ansible Professional Experience January 2019 / present - Backend Software Engineer at LaterPay (remote): I'm working as Python/Django backend developer for LaterPay, a company with a fully distributed and remote team. In my current role I have the opportunity to work on a backend service which uses Django, Django Rest Framework and it's based on a PostgreSQL database. November 2016 / December 2018 - Software Developer at Government Digital Service (London): I worked in the Data division of GDS as Software Developer in a team of data scientists. My role was to help the team to deliver well structured Python applications, mentor other developers and bootstrap new projects. During the last year I've improved my data science skills and helped my team to deliver a couple of Machine Learning based projects. I then moved to Data Ops team for other Python related work and finally moved to Cyber Security team to help the development of a Python/AWS based application to detect and report misconfigurations with potential security implications. February 2016 / November 2016 - Software Engineer at Marks & Spencer (London): Working in the \"Quick Order\" team to deliver a Python/Django based tool used internally by the customer care. I'm also working on the Android version of Quick Store used by staff in stores. The aim of Quick Order was to build an end to end journey on top of APIs and help the API team to build a reliable platform that is now being used by customer facing products. June 2015 / February 2016 - Python/Django developer at Plentific (London): I worked on the Python/Django backend of the website plentific.com, a property service market partner of Zoopla and Prime Location. We used Django Rest Framework for the API and PostgreSQL for the database. March 2015 / May 2015 - Python/Django, Go Platform Engineer at Yoyo (London): As a Platform Engineer, I worked on the backend implementation of the product, developing the API with Python and using Go to write complementary micro services. April 2013 / March 2015 - Python/Django backend developer at Glow (London): I helped maintaining the backend code of our main product \"Glow Machine\" and played an important role in the development of a new application, developing the rest API and interacting with other API services. All these products were mainly developed in Python/Django (with an ExtJS frontend) and using both PostgreSQL and MongoDB as databases. At Glow I also maintained the infrastrastructure (Debian server, PostgreSQL, MongoDB, Django, Nginx) where we deployed our web application and leaded the migration to Docker containers. June 2012 / September 2012 - Software Engineer in Nokia (Tampere): I worked in Nokia with a 3 months contract as software engineer in the \"Nokia Developer Forum\". My role was writing examples in Qt/C++, working on some Qt libraries and helping developers on Nokia Forum. During this period I worked to SocialConnect, a Qt library to connect to Facebook, Twitter and Instagram and QGoogleAuth, a Qt library that implements 2-steps Google authentication. June 2009 / September 2009 - Software Developer for Igalia: During a 3 months Internship at Igalia I developed a Python binding for MAFW (a multimedia framework for Maemo OS). November 2006 / December 2006 - Software Developer for Develer: I developed an embedded software in C language that manages employees badge and doors alarm. July 2005 / October 2006 - Software Architect and QA for Kyklos: I joined the company as Quality Assurance for some softwares they were developing, then I developed some parts of applications in C# (.Net) language, then I wrote the architecture of some .Net class for Kyklos programmers team in Romania. January 2004 / July 2005 - Software Developer for Megamente: I developed applications in C# and Vb.Net languages. The kind of application I developed are web applications, desktop applications and embedded applications (with .Net Compact Framework). August 2003 / January 2004 - Software Developer for Orange Informatica: I developed applications in Visual Basic 6 and Visual Basic.Net, Microsoft Access applications and a little of PHP/MySQL. August 2002 / July 2003 - Software Developer for Levon Italia: I developed database applications in Vb.Net and MsSql Server and I was a System Administrator for their Linux server. June 2001 / September 2001 - Software Developer for Softec: I've been a software developer at Softec S.r.l. for the Audiotex customer (an important local Call Center). Projects and Open Source Contributions I've been a strong contributor to open source project for almost a decade and I'm currently working on some Python related libraries and experimenting with MicroPython. In the past years I've fixed bugs for Django, Django Rest Framework and contributed to Ubuntu Unity 2D. I founded and managed the Linux User Group of my home town (Pistoia) for 12 years and I've been involved in Ubuntu Community, Maemo/MeeGo Community and recently in the Python Community. All open source projects I've contributed to are available on my GitHub profile. Other roles Between 2005 and 2008 I worked as a system administrator consultant (Linux systems), I managed the Pistoia Wireless project, I taught programming at a local school and I wrote articles for an italian Linux magazine. Conferences and Talks April 2018 - Practical Machine Learning with Python and scikit-learn (PyCon Italy) April 2017 - Getting Started with requests HTTP library (PyCon Italy) September 2016 - Getting Started with requests HTTP library (PyCon UK) April 2016 - Getting Started with BBC micro:bit (PyCon Italy) January 2016 - Django ligthning talks (FOSDEM) January 2012 - QtDay Italy: Introduction to QtAmbassador program May 2010 - PySide: Python Bindings for the Qt Framework (PyCon Italy) October 2009 - python-mafw: MAFW framework for Python developers (Maemo Summit) September 2008 - ESBox and Pluthon Eclipse plugins: how to use Eclipse to develop Maemo applications (Maemo Summit) May 2008 - PyMaemo: Python for Nokia Internet Tablet (PyCon Italy) Languages Knowledge Italian: native English: fluent Spanish: basic","tags":"pages","url":"https://www.andreagrandi.it/curriculum/","loc":"https://www.andreagrandi.it/curriculum/"},{"title":"PGP Key","text":"7D4C 4090 DB50 1693 4614 F6FC 6206 9DE9 2240 402E -----BEGIN PGP PUBLIC KEY BLOCK----- mQINBFnJP4gBEAC/AktYcEGSdJfdgx+gmKLBaExJuGW74NK/BUv8NNqFOuPzCbRH NpKiokkBAQPxoNb1ll+Cfn1rzVb2M8H9GWsVpPL30gvCWu5biwqADse/6i1N8ClI Duwj2SnWNOpHAUMWDzAGT4oAD9BxlgqEYkN0BCMsxKtn7SUwMqy46WWM0iDUBLaK 81SUcf5VM/AEhgomksrYWASMU7szL9M46NOA6KZ4mcor6Snu7rFc/IBnZrEtY56N ozr4tKJd9o6rnUgcIr8u+AAEAyxEJaakpr1Bvlcy8+w3HaXTtoAcaXGMSJBwD+OH qGEiHuuoS4+v6Gba2UG49p74bXR9G00sBRdwXOv7ZtE2Hlx/7h1Ed9KCsYyvHpDv 41xZhF/MvvkLSx5PuGMj1BrM3a3js3ap4xhs45C4S9eK+zMwS5rgvMThmkTt1ILS 8VDWwNdl3fdaWRsEkd50IlPjKBO2bBKWhzz6xHLDUiVFNt5Bj12tAar8JHgBbHOH ddV6qGDwpcLz9OMQSy2Hq74/ownafn+TwwJnzdLSztxDPbrE1AL0TtdD7x5pz1bB HCyPPbT8tW3QhtJb8IjxT5eVfCvN0EsODqAmUhdK4sFd7m9GJ046giSrFAvejdWJ 8TVY0zw7tR8toGueEZLnmBBz/ezO7JotQgv8IFZC1yngauivikpUWZad0QARAQAB tCJBbmRyZWEgR3JhbmRpIDxhLmdyYW5kaUBnbWFpbC5jb20+iQJpBBMBCgBTAhsB BQkDwmcABwsJCAcDAgEGFQgCCQoLBBYCAwECHgECF4AFAlnJRNgpGGh0dHBzOi8v d3d3LmFuZHJlYWdyYW5kaS5pdC8yMjQwNDAyRS5hc2MACgkQYgad6SJAQC4QFRAA vRnir9mPrKtFoINHhomlTsJ5lRCfskOhIwgZeSGg8pogN1Kya3oU+Qh+0I3oamQ3 jK9rW6JJJqYqxTYI911UbGhJbilSZ8XDj+7giQoJRuMcI7BVfthf9/G43Z8mzUYm IbJ56t0i4gvyfQPO4FY0OVUtiZ/lzzZncuFg3nfzTIIjS7QOb+jXOlaf02d0pvGi sVlvrV+USJL1Z0j/ztsjtvAxEvg29u5uLCtRMvP8zzg5w2wvVi6HPn7vlcZ2FF0L oFc6PpdO2pViKb5xXLNGpyAgm+gUTFdj92MimKBQ1p6cOBQ4XdNUwBeavTlW8pcS RO2fhpLpo+LBcInBUMc+c5Vkt63GuTW8HMFo+UEcEu0PYH1Zo4VrnYMtODRA+p8I CK7NYUkZ+iYjBhOJbWCPFOwd+oVq4lAqwbdcOXe/e3dUul6i6hUkD0JZisQftbl6 IAzfR9zxEeKc3GClcGXEfcJDSEXA5MEEqW5omhCgc5+ftDhgYY6W8/Q6e+rHBu+R 6LhiwanaPge4vB7+ibdSFjVZA/zwLoBo54Nh5bXTDhF/PxRQpDx5NONOj5CCN5Pn qs9ylM6ZaZiElKBtmMlxTyq+zsWyC8RequTbcEr/p4GWi+J/u/Gv+QaCPR8SalQc T86cMT+yR1iWXp+Ts+/I867rw0KwoouXAI8XyICFQ6u5Ag0EWclA/AEQAL4x7W/y BMRZxgDqi1hA7S805yYLbuPtkaw4vzF4SZys/6bpp+VoKfA8q/+L7Vn8/JwIrT6x dghfW7d+1SnDc74hYUg9VznZjq3iQVWgA+UqtwXtRZhrT8SdgCGCFXPaQr5yOd2x /vPU+geOUAa7PhRVoG4/j+fTShDBPnTJo7UqfF12JZVrDtXNuqBvQNRCHdmiD/CN J+zM2GI0tZ+zCzcPZqvDUR8gOkqzpkDqHB86SxJskdQMEqMR2MycgkXuCMjsWNu7 w4TV62GApU8vdKZBaXy/C/i5WqJl0DsycB4KgFAW1VXD54Bhf9yFjVB7WnneC7K1 LZ8R4tVUlqxHBNAbbBx6sgBOEYd6HSrl48t0UFIkj9xlY5Zs6qdgVemqWCFrBo2X EBERSUROp/DEI1V1QSpA3gwflykcF22XE5/2YOfqyVBiEq3HIGl7RLT8ywCwpK2j wXrCz6KQtj7WL4ZSO3EGbywG7x5PQYN+MmicETDIdAUSCUZ0f5N7B6KDZ40bLKny Ob5yUOyDKEN3X1jdorO/Op9l7IRUdeJGG/FBDOSqq2c1BrYBXi/tmCsG79CojopS hvpRBs3yD7M98nBtFI4vilxeRzhsfkJlt52LPL8to2/xqdePyxOkenVTQO7GAbPl hoxw1W3xvEEbVsMxpzvVxsRcaNudG/sXmpyBABEBAAGJBEQEGAEKAA8FAlnJQPwC GwIFCQPCZwACKQkQYgad6SJAQC7BXSAEGQEKAAYFAlnJQPwACgkQVXsOkNOcea16 wQ/+NZ/RZRU9lOh23qJAGnvlnq+9I7XNlnPc4g01bZpnBDuW3DrT0CYSXrRL12bI F6JpxegdCYyJ2+x15doX1Q8eGp/Pu2gS+JpQ4DEAZnoceVVeDyfmXQgPIjxD6Pk2 bCOwALaZTU+6pUVCfSkK+SVWvqkQp2bJ1ibPlnMXHGPbZv2JXEgclwY4BgrW+s8O jqGd6hrejFSz52gbkji3htui0L7G8tGoZGhWj7Wm9abd+QIE5HBqMxXYXjD738mA vIo+wqKYwugP/kcTgyPZSsboWf7sFagDvp197qQghV6trBgizoYUFrMgRAkkyPMK RfZ9qzZd4tHC6B0ZtwycCh6f6/4CN+FSDNMKLxRTfZQp6DLLtDSS26Pa+yMw4E6D N0Ap4x+Lm9W6v+nfl8SP+ktZJ6vbUVBSQ5i6Q/Gb6gZVS3XfdGoFq0+xtLu7Clp+ 0/zjHbxZDQH6dr2Y45e7iyLJRDJFEW1TRi2HRlIuuKoIKTFCTfQzbQTG/L5v/Y2c Hd1LTiootyvRTyw553q9cVjBarILY7zgmint0pCKExmttD/zWJfVOVmaQPK5ctr9 Fz3zFprUSzhP3+240cdB0B16Ky9nYVLwXXQXiz6wzMbPPlkgFiQYlsfQjrr4JAc+ I9lq+5jSDQJJG2N3PNnkrJxBa6FKRfreKULwrpF0ti4SjKw0Hw//cCS5ROCmJHdu hHw1lTf62esmPhzO4y1cG9ku44ZVMRGnpjocs4foUVsP+CPy+b9pLSJvKNexjDeY 776gGua1BdVqcFJpUKLzydVdlWSCFFVSU+Wjvh7JJZ1UZPrN7049bgHj9fqtImmo NmtOcynJHNUJ0uEBtUpxYIRSNDUW+PgTvYgIPPYsUPw+LNEXnyRgvaz8n113BXJQ 60kP1ga2R2FUJy4Z8QgtDyPuM5sI6NM9Pl2goI/gpoOtsob1ng/COsXBsxzFlSCb 9vmsEm5LUUBlYDMDxiZLguUbUnhNBWvvKc3ea2u8q9CgiT7OYUmStJWrEoZiqAHW OMNePG7+VBiGq77FFkwrSeWvGieZRGBpXZhkFRfdLMjDj/9yRUROeXofUK/s4g2i 7doYKEdrU8spkw+WxJcVbJcWBS2ochtQrwbm50VdPGJVaQgofoTdoJwMzcY2hrkX PrBdtPu0vxtxK4W1eD7YJz2eXK7MCNs2VFNJ0Yp0wl3KaWqlJ7LtB0n10qoUzNEa Xw0xI2e+L/LA9KL9DFhv0PuJZDNoulk1ih1KxuVxg2iHye/jOZa+EuiBSM0lRNEn FgMQPLmg3GZo577YlW3oJiyYqzgu5OepZHMMsfHOAafYnbjETP3ZqB2ZNlATVKZS dmuzKCI6YFfHY0xr6DQuLsHYdmPfUja5Ag0EWclBHQEQANntPsy2UhDdhAff64B/ iMdrjlX4doLryO1kO6OjiM40xOpcTXviAqqdXaUMsmv/WJwgGBwMPE4UJScjFO8k ByssJ+A7+r4nfegCSDyjGy+5Y/aqqHC6bn/WNiGfGN0enmvy4kFBGr3sikJs06KI Z8e5kwxgu8AFzVxWTTLc/qjsl5JgU2R7LSeXSXFAm+5NYNoVpljIWY32idl+zckO XDbwQeFD9zYinekdBsPgCvQlnvqwyDEKvXG+Mw9su1xWSrxIguNp8P5EcKY743Nz Z8pd15SGvqZEXfpEzQtvxvuZJlWcyuJyM9dp1kO25NHef+KoFwdFLmKI1RGFYu04 9VaeS6Kps2at6ZTst4ARAM1JtrltfSqUIVDHLXhomzwlcXqKVpu80JGCHIoevUWr rBjcgdu7gKWUNAsHwW+1CvVeKB//+aFRG3/B/4ZMJac42ERED9tJKyithH141nys CE0nATCZVO+aCiUGjXJuBaBw0Q7KL8uBbUSyD8RTpuid+uS1EXLLTVx1z83pE6LP +5DKGlYn0dzWVE+fDY5bZnTnTT5RksnuawxLEGZ901DCQ7JZUuiVymrRJwcGKW10 3rBe3Os6ud2KCF2KCq3vUG5zKkLeVWkID3hnEvuJ3srn5zsUJ60Z/gz6kYEsp96A l2DdxLV4seQDqZbbISwhyWUhABEBAAGJAiUEGAEKAA8FAlnJQR0CGwwFCQPCZwAA CgkQYgad6SJAQC7Cag//SZDavOyWQ0KpEKnh1tZOdEDvzzRLXsrfHxWrf4Y5vfTY zp2eKrxsxLfymt+NOyR+g2FHo3sMP3H2/+vD5k5SL14cN3Er1l78GyYkk25JFoER MtK5sEOWjshlJxpLQUM2r9rYDNP4FdxEItUb06mF3DBNn9TeVq23iVQIdehWWIPV 20gUeNNt26QB4/jB4sfCZt5+U37hSt/MJLY1aOB4y7+he6GSPdspGCZv31gjSPXd zcMgLHzTnG5lQQNmdxc7Ox6FbtdJaW3pXyVtRxBcKOkXAP0UNYfQJHqOuilRMgVZ WWn5GJ6fsEebM5d5CY8Z18B4RSDPQQaB7bqBkUOuNW0buE9WhVoIn1jrAcuxGEHY /WTlG7rTxU39A9ZRmTrN6XtvxPCzgshH+TvLxTEm5jvsYibiggnGxDyvCsR8/RGX wg0CUmLRRwVkjzqxJ3zoTXmSYZjDbFa0mYH516AmHfH0Ei3P+FOJ/pPUii0Qqm+G TGBgUMhgYpyN2DKXQGWOAonk5Be9v6M0Pd18vOIph8SI3AOcudNP1SPxxt3JvDs/ huaUldYCI9zonPVD25CDK1uTGSRZ0pc56BKcU4d9Ng4ZRQsoguiidGlrWjSsyX1k 8Hkpr3ER0Z27mImej+1bGx2mWBYvUPsoj2TQcXI8lAE03xpCytaWhbSy8ifbdci5 Ag0EWclB7QEQAMXIDdHZalffCHZtyEfsy86wqoWnJCD0azrXTTuWztuAbYF8QxNx pMtR3GRojb+ipdbpO0kcDcqybXBz16ASV9dhIHTW/9GOBtN4U5ZP53mVmAziII/U MvXwain/u6aCaINK/bC25R6oPGlSnJzhwv0M/DnhC8+YIqA2//Ci7AhOp5YPVC4k dDtT1V37454LV8cZgALzC4jCpcwVAtDPUoc6c6M92anPmWZku99NbjZ2QWzC7USk N+kJ3WfgnePVw+5Z4AqlYe7+tCHHT4jS/LnnniGHDYAoQuSxD+SqPEtodMDzjgZD SMEpHODXg/d3tOJtaEc/mFy9SdIhrl5t5ANHKTznKNN58JH2V6fyTzdCyhIWzh+G RBGqMnExAQAlJFS/dQ3td1Q7c7+t+cn5yzVJ4jsPDYds8CBeptd6QLADrTZxXVOt hmWEBl/hB6d5KCowB99uZVz4NAAKLHGb9lhR7SiFRTHUrYnX7ItVpM/b4ip6i4Yo dQGmQmBQT4tEtSsts/TIGYrBoF0PhxPB5jZ00mUpjjMV1XNhhT/EYkqLV+uvR22J 63M7h19q4N19foym3owsRm7g2ToCT+XM40zJGEzi0mySpbWAFGLq4HBSBQwL2T4s ObcvKlL55ETabfoUtdji2R9aPEOuxEOroLgebYg8jicLgvEZyDrDZWMNABEBAAGJ BEQEGAEKAA8FAlnJQe0CGwIFCQPCZwACKQkQYgad6SJAQC7BXSAEGQEKAAYFAlnJ Qe0ACgkQDeE2tHcbBVSLqQ//aByu0OxNOJm1wXG3IStGAU4aHroyFKJgUa9nVxhW NjMSxRMcl4S++/yv8THo8TrzJ3lYZtRt8159MtTSs2Og4ycAdD8RRztkKdcoZsbM IO8isnEqraqy6rIdWoyNMUt0MirpPvXHnwtcjb2h50mCk2GZzw80v++lqBik0U17 04XOb4zcwpT9CFzcBF4pv1ZLDRcW/qou5htTlh+z9EvTk6XMb+QvSFIS/lmROtb4 Sw5i47Yi/CWhW2DdjGBcroFc/8yVI7r6skYkJLbqiT9KDs9c9TPKw8CuDx4hwxf+ WBlnohmOjqzDvCQbDnQYj2JS+70tu28l1A55GpTsaKN56mBAJmnx2SX0GT73Yhz0 7dN/N7r1cOyhbeO4XzUV7CQp2LftIDuGN1flBoDqrBIsPqxrezM6Ufx3W5cF7Toa Z1bw1g+7BJE5B/CbOI1hg7uCTyDGNdrCm0S+9g3JhJ3AqMSrsh6/niLzU4pE2suU QbHdohDJbCwT7fa3Se+TptCzg09uJ1O6Fj3ehR3rTsA88LCMHIjc+y/X6UKX71us lfhzd6EHQ4SGKOIth9/2VpPSaukn3uDwe5Cf7Nn3/aDPQ7SvSU09Ni7D2tcyckVy 2VBwIfkC1zZbe+yUAUwxf8QfhWBYLQ26YQMagr64wKzGA8UoqPUKahR+M62bYhuL MGd9jw/9FRoGArfBioHSSt7nMlOuzcxDi3GXQWVtLP0xs5o6uqtuvlQevlQBGSt2 SXtyGqutu1u58KteRhv9Pq4DVROIdEdMUXlzsohzV0UikKbFXCm5FsznNsdPKUap 9q6RBR8YwEftsWgQ41/yZ/EpEEyk0ibfwavd5aZCuS5EBRyPd2/xz2BFwxUXYsjA r5F51vQ3PEAuJc40++55FHTfKQyw9TD+Mo0bNQ1yFoXF0SP0n7c6BaFUBocJNJI+ K/ub7FFljwqMdAOAwJ0NwAeBSovkB1Z2ioMr9fBdGrHySTGbVumrv5OmTtbeiyg2 fJkpfgvTVnFLCw7l5uk8r7lDY/ATa1nDiHK5qB0fKK0Qkmx7Va3exBZtN/a+foGW J9GIF7Bbzotc6v7ZkFbWMyUK1a0W1Vg65xUl2w6TCq4Sbzam2qdJByjXG4R6WMrX vj/HgqpzCNiKh7M4z1WHkr8z3+XhVkyc9SfdPDK6BSsCdH9oIfLuAM+mOduNDrS1 de3uyzM0brtYKz/eI/t9P8h5t637/bhBRqgkGaH1tlg8tvWJkhEIzbUqFObW6+QF wg9Tg/JTBm+BR4c7hg4Q5TxzTmGXNDiInknD4mXpuG0rAGfSla8ESlba4ktK0nhK +8UOIi2lOfar5vUPcwh0ADV573ZpCu6+KTKksGW5zjwuL9KcVt25Ag0EWclC6QEQ ALuyhEarKdK+k5PDEuZjCCmAp7AnUmiNQo/6aWZNZ0cPtAyrxd+iMWUJ9lxInShe o/NLC9KZvaYf4yuVDaMacCCBTVZBsph6S1pWgUtmgLkxF0vpleKoSm9diOpuzyT0 szWYTL5KUVz34viGwb5f91XPoZJf1/JlWlSIiYM3k3/yBEtLyEnkJtaFsP6/4BKT DLGJnLqH26X6M/Chp/Q9HmyO7RqtiQMcKG4AIAG108hWN1Tfck1Q6cV7WWt21w3E 7PHdY0zFo5VGAkoUKEzNscL0ywxYgI21AyAOi59BL8PXnpBNuWrMtHENUb7dx9fv FuJD3MU9OynytfOoOMWkn7gishomp24zKYEm/ZLWh/RIDtfYlmE846G0rG/Oa5el iViemtrYKknJ1/QCClal5pmV+CIScKQhardWJoG55bGjJT8erxAstmEK4iTXtcUC TuwvMcRqb8HK+TU50uNkbNee9oqXxPhBWO0gMuxMi7+opTyCqKapVieamnZAiyR5 ij498xWFyJmU0wITQwqQW9cLjAsb3coQxIxvtoeJ8uTVwGLI38CjrtJn7Z19x1pA vSsjzacS4fXJuxJ/jAts0MLGmZ3W7mDcVA5PDvyYD7T5RzPAFQjLt7zxNUXH8XWJ G2179HJcOfamDkKe59r6hsT6dPDCmwZpxiV9ScidxHXdABEBAAGJAiUEGAEKAA8F AlnJQukCGyAFCQPCZwAACgkQYgad6SJAQC7Qrw//YBHl25J+RVHtNp6DjUn7cYsr 9s6HgA30MHhtOjIbOxsAqBTWr4pN0SsP8u4pQ7uEI5zlmv8EnM/e4LI67FSPg2Gm 0/LHwYFsFJV/iCAx4EhEmPL1FX0jU+4RsQ0iY/f4TS9593eVNX+A2xm8UhmP47WH CeSNZAg7STCz9GHigE9pDDbBhnKYBLCw3ekyuQObpyMkssF4d9Rf9uNw+vieBKqu ddU0TDN4w9ClC6i1lrj3+/oE4UVTUrztKPheU0+c5P11/rHIoVnjKy2thSejjeQ3 ATfyhQ3rxzuT/9Fneod7T025v/XxouyZYHWlGYCll7fQfZ0XJrhvPmC5YKNQcBuY Ofjz5zv0QRDW1lBG0/c2zECfgVP+MpwRQtSMf3FzvPI6SUvO+d0zIDCrrqNf6VB4 qbCQABmXkfLoaUP1lLTlHYmPPI2TWH72su2xrOKgoKeNTQrQxwArLwkSHSEhoPR6 cOFxFovELHUDJcglEwiCTThnT0PezC167XGe/xxPXW5rjvXEP8z+MIirE2/cTsd/ kpQuRZHfw3no2rV0iTWh5yClY+xMUviDm+oeQzp4ggwWFGL71x5L7nq7Y3rzP4JR Qw++qq37ZnIaUp5VkuoBMIh+eoa9ht5Bjmno0mXlaGMIObDgM3NJcCoAHH/BdSIa 3dFZvA35ULuczzVhDNE= =6OmL -----END PGP PUBLIC KEY BLOCK----- You can download it from here: https://www.andreagrandi.it/2240402E.asc","tags":"pages","url":"https://www.andreagrandi.it/pgp-key/","loc":"https://www.andreagrandi.it/pgp-key/"},{"title":"Python 3.9 introduces removeprefix and removesuffix","text":"Python 3.9.0 has introduced two new methods to work with strings: removeprefix and removesuffix . As their names suggest, one is used to remove a prefix from a string while the other one is used to remove a suffix. removeprefix Given a string and a prefix, if the string begins with the prefix, the prefix is being removed, otherwise a copy of the original string is being returned: In [ 5 ]: 'MyStringExample' . removeprefix ( 'My' ) Out [ 5 ]: 'StringExample' In [ 6 ]: 'MyStringExample' . removeprefix ( 'Foo' ) Out [ 6 ]: 'MyStringExample' removesuffix Given a string and a suffix, if the string ends with the suffix, the suffix is being removed, otherwise a copy of the original string is being returned: In [ 7 ]: 'ThisIsATest' . removesuffix ( 'Test' ) Out [ 7 ]: 'ThisIsA' In [ 8 ]: 'ThisIsATest' . removesuffix ( 'Foo' ) Out [ 8 ]: 'ThisIsATest' Of course these are not the only features which have been added to Python 3.9.0 , so I may cover more in the next days. If in the mean time you have any preferences, please leave a comment below and thanks for reading. References https://docs.python.org/3/library/stdtypes.html#str.removeprefix https://docs.python.org/3/library/stdtypes.html#str.removesuffix","tags":"Development","url":"https://www.andreagrandi.it/2020/10/11/python39-introduces-removeprefix-removesuffix/","loc":"https://www.andreagrandi.it/2020/10/11/python39-introduces-removeprefix-removesuffix/"},{"title":"Using pyenv to install Python and create a virtual environment","text":"A few days ago Python 3.9.0 has been released and I really wanted to test ist latest features (maybe I will do a separate post to talk about them) without messing my system with another Python version. To manage my Python versions I've been using pyenv for a while and once configured, it's very easy to install a new Python version. Make sure your pyenv is updated You should have at least pyenv 1.2.21 if you want to test Python 3.9.0 In case you haven't updated it and you are using MacOS, you can do it with this command: brew update && brew upgrade pyenv once installed you should see the latest version: pyenv --version pyenv 1 .2.21 Install Python 3.9.0 To install Python 3.9.0 you only need pyenv install 3.9.0 : pyenv install 3 .9.0 python-build: use openssl@1.1 from homebrew python-build: use readline from homebrew Downloading Python-3.9.0.tar.xz... -> https://www.python.org/ftp/python/3.9.0/Python-3.9.0.tar.xz Installing Python-3.9.0... python-build: use readline from homebrew python-build: use zlib from xcode sdk Installed Python-3.9.0 to /Users/andrea/.pyenv/versions/3.9.0 Set Python 3.9.0 as the local version Now that the version you want has been installed, you need to tell pyenv you want to use it: pyenv local 3 .9.0 pyenv which python /Users/andrea/.pyenv/versions/3.9.0/bin/python Install virtualenvwrapper for pyenv pyenv needs its own installation of virtualenvwrapper to manage virtualenvs. You can configure it using pyenv virtualenvwrapper : pyenv virtualenvwrapper Collecting virtualenvwrapper Using cached virtualenvwrapper-4.8.4.tar.gz ( 334 kB ) Collecting virtualenv Downloading virtualenv-20.0.33-py2.py3-none-any.whl ( 4 .9 MB ) | ████████████████████████████████ | 4 .9 MB 4 .1 MB/s Collecting virtualenv-clone Using cached virtualenv_clone-0.5.4-py2.py3-none-any.whl ( 6 .6 kB ) Collecting stevedore Downloading stevedore-3.2.2-py3-none-any.whl ( 42 kB ) | ████████████████████████████████ | 42 kB 2 .7 MB/s Collecting six< 2 ,> = 1 .9.0 Using cached six-1.15.0-py2.py3-none-any.whl ( 10 kB ) Collecting filelock< 4 ,> = 3 .0.0 Using cached filelock-3.0.12-py3-none-any.whl ( 7 .6 kB ) Collecting distlib< 1 ,> = 0 .3.1 Using cached distlib-0.3.1-py2.py3-none-any.whl ( 335 kB ) Collecting appdirs< 2 ,> = 1 .4.3 Using cached appdirs-1.4.4-py2.py3-none-any.whl ( 9 .6 kB ) Collecting pbr! = 2 .1.0,> = 2 .0.0 Using cached pbr-5.5.0-py2.py3-none-any.whl ( 106 kB ) Using legacy 'setup.py install' for virtualenvwrapper, since package 'wheel' is not installed. Installing collected packages: six, filelock, distlib, appdirs, virtualenv, virtualenv-clone, pbr, stevedore, virtualenvwrapper Running setup.py install for virtualenvwrapper ... done Successfully installed appdirs-1.4.4 distlib-0.3.1 filelock-3.0.12 pbr-5.5.0 six-1.15.0 stevedore-3.2.2 virtualenv-20.0.33 virtualenv-clone-0.5.4 virtualenvwrapper-4.8.4 Create a virtual environment using Python from pyenv At this point you can create the virtual environment based on Python 3.9.0 using this command mkvirtualenv -p $(pyenv which python) py39-test : mkvirtualenv -p $( pyenv which python ) py39-test created virtual environment CPython3.9.0.final.0-64 in 1394ms creator CPython3Posix ( dest = /Users/andrea/.virtualenvs/py39-test, clear = False, global = False ) seeder FromAppData ( download = False, pip = bundle, setuptools = bundle, wheel = bundle, via = copy, app_data_dir = /Users/andrea/Library/Application Support/virtualenv ) added seed packages: pip == 20 .2.3, setuptools == 50 .3.0, wheel == 0 .35.1 activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/py39-test/bin/predeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/py39-test/bin/postdeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/py39-test/bin/preactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/py39-test/bin/postactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/py39-test/bin/get_env_details Check you are using the correct Python version ( py39-test ) ➜ ~ python --version Python 3 .9.0 As you can see from the above output, we have created a new virtualenv using Python 3.9.0 which has been installed through pyenv .","tags":"Development","url":"https://www.andreagrandi.it/2020/10/10/install-python-with-pyenv-create-virtual-environment-with-specific-python-version/","loc":"https://www.andreagrandi.it/2020/10/10/install-python-with-pyenv-create-virtual-environment-with-specific-python-version/"},{"title":"Contact Tracing: non e' solo un problema di privacy o di sicurezza","text":"Contact Tracing in Italia Negli ultimi giorni non si fa che parlare di Immuni , la app che il Governo Italiano avrebbe scelto, come soluzione di contact tracing per il COVID-19 , e vengono sollevati molti dubbi (si va da quelli legittimi a quelli che rasentano il complottismo) al riguardo. Per \"contact tracing\" si intende una soluzione che, mediante l'uso della tecnologia, ci permetta di creare una traccia di tutti i nostri contatti e fare in modo che quando uno di essi dichiarera' di essere positivo al COVID-19, le persone che sono entrate in contatto con lui/lei ricevano una notifica. Prima che proseguiate nella lettura, mi sento in dovere di fare una doverosa premessa : da oltre 20 anni mi occupo di sviluppo software ed ho esperienza di utilizzo di svariate tecnologie anche in ambiti in cui di solito e' l'uomo a prendere una decisione. La cosa piu' importante pero' e' che non sono ne' un virologo, ne' un epidemiologo, ne' un medico . Mi limitero' quindi ad un'analisi dei fatti, rimanendo nell'ambito delle mie competenze. La mia personale opinione (tuttavia irrilevante) e' che una soluzione tecnologica possa essere di aiuto nelle prossime fasi della pandemia, ma dovra' essere accompagnata da un'accurata verifica manuale dei risultati. I dubbi al momento I maggiori dubbi al momento riguardando l'efficacia della soluzione scelta, la sicurezza dei dati sensibili che verranno raccolti e quelli sulla privacy delle persone. Ritengo tutti questi punti molto importanti, ma sono dell'idea che prima di tutto questo si debba fare un punto sulla trasparenza . Il Governo e la task force Alcune settimane fa il Governo ha annunciato la creazione di una task force di tecnici , che avrebbe dovuto produrre un report con suggerimenti e linee guida, in modo che il governo potesse effettuare una scelta ragionata. Molti di questi nomi sono noti a chi e' del settore (ne conosco personalmente alcuni) e ritengo personalmente che fosse un ottimo punto di partenza. Il problema pero' e' che l'intera task force e' stata messa sotto Non Disclosure Agreement , che tradotto in termini semplici significa che a nessuno di loro e' permesso di rilasciare commenti o dichiarazioni in pubblico, ne' di rivelare alcuna informazione su quanto prodotto. Il report della task force Il report , ad oggi, non e' stato reso pubblico : in che modo possiamo valutare i criteri utilizzati per scegliere la soluzione, se non ci e' permesso di leggere il report? Come facciamo a verificare che il Governo abbia effettivamente seguito le indicazioni dei tecnici o se abbia preferito fare di testa propria? La soluzione scelta: quali criteri? Al momento non esiste un \"white paper\" che ci descriva la soluzione proposta e adottata. In base a quali criteri e' stata scelta proprio questa soluzione? Quali conseguenze dopo una notifica? Supponiamo di ricevere una notifica che ci avvisa che il giorno X siamo stati per un certo periodo di tempo vicini ad un'altra persona che si e' poi dichiarata positiva. Quale sara' la diretta conseguenza? A) Qualcuno verra' a farci un tampone di verifica il prima possibile B) Ci verra' imposto un periodo di quarantena senza alcuna verifica C) Potremo ignorare la notifica Se le conseguenze di questa importante notifica non vengono stabilite a priori, molti non vorranno rischiare di essere costretti in casa, magari per un falso negativo. Nota : le possibilita' di un falso positivo sono davvero molte. Basandosi sul raggio di azione del Bluetooth, in teoria potremmo essere a 1 metro di distanza da una persona infetta, ma essere nella stanza accanto (e quindi in totale sicurezza). Oppure potremmo passare accanto ad una persona infetta mentre siamo in macchina con il finestrino chiuso. Per non parlare poi degli operatori sanitari: in alcuni casi, loro hanno la certezza di trovarsi nei paraggi di persone infette. Verrebbero considerati infetti anche loro? E quando la sera tornano a casa dai loro coniugi e familiari, sarebbero anche essi considerati positivi dalla app? Closed Source Nonostante le raccomandazioni della commissione Europea, pare che il codice sorgente della app non sara' pubblico (ma verra' rilasciato solo al Governo Italiano). Questo significa che non sara' possibile un controllo da parte di terze parti, e non ci sara' alcuna garanzia su quello che la app possa fare con i nostri dati (ne' sara' facile scovare e segnalare bug di sicurezza). Aggiornamento (21/04/2020): il governo ha annunciato in un aggiornamento , che la app verra' rilasciata sotto licenza Open Source (MPL 2.0) . Conclusioni Qualsiasi strada si decida di prendere, e' fondamentale che il processo decisionale che ha portato a tale scelta sia quanto piu' trasparente possibile. Solo in questo modo si potra' ottenere la fiducia del maggior numero di persone e cercare di raggiungere l'effetto desiderato. Per il momento, tutta questa trasparenza non c'e' stata.","tags":"Privacy","url":"https://www.andreagrandi.it/2020/04/20/contact-tracing-non-solo-un-problema-di-privacy/","loc":"https://www.andreagrandi.it/2020/04/20/contact-tracing-non-solo-un-problema-di-privacy/"},{"title":"covid-api - a free and open source API service for COVID-19 data","text":"Introduction In this period of COVID-19 emergency, many countries are publishing COVID related data that is being used by many existing projects and researchers. The main problem with these data is that they are being released in CSV format on some GitHub repository. While we fully appreciate the opennes of this format, unfortunataly it can introduce an additional work to be done (downloading the data, cleaning it, importing the data into a database, keeping it updated etc...) before someone can consume and analyse the data. covid-api covid-api project is a free and open source API service which automatically imports the data from various sources (at the moment we support the John Hopkins CSSE data source) and makes it available as a REST API. The service is still under development, but an initial version (with regularly updated data) is already available at https://api.covid19data.cloud . How to use the data To consume the API you don't need an account nor you need to authenticate in any way. You just need to request the right endpoint using the supported parameters. Here is an example for Python language: In [ 1 ]: import requests In [ 2 ]: response = requests . get ( 'https://api.covid19data.cloud/v1/jh/daily-reports?last_update_from=2020-04-01&last_update_to=2020-04-03&country=Italy' ) In [ 3 ]: response . json () Out [ 3 ]: [{ 'id' : 35343 , 'country_region' : 'Italy' , 'province_state' : None , 'fips' : None , 'admin2' : None , 'last_update' : '2020-04-01T21:58:34' , 'confirmed' : 110574 , 'deaths' : 13155 , 'recovered' : 16847 }, { 'id' : 37895 , 'country_region' : 'Italy' , 'province_state' : None , 'fips' : None , 'admin2' : None , 'last_update' : '2020-04-02T23:25:14' , 'confirmed' : 115242 , 'deaths' : 13915 , 'recovered' : 18278 }] Further API documentation is available at https://api.covid19data.cloud/docs Next steps While we keep polishing the code and improving the existing data import procedure, we are planning to support additional data sources. The next one we are going to support is the Italian Protezione Civile . If you are aware of an additional data source that you would like to see covered, please let us know (creating a new Issue on GitHub) or send us a pull request. Contribute to the project If you are a Python developer and would like to contribute to the project, my advice is to first have a look at the main documentation available in the README . Then I suggest to have a look at the existing Issues and see where help is needed or in alternative you can open a new Issue or send a pull request with fixes and improvements. I also recommend to become familiar with our Code of Conduct before sending any contribution. Sponsors and Thanks I want to thank Heroku for accepting to sponsor the hosting of this service. I also want to thank all the volunteers involved in the project for their help and contributions. Disclaimer We are doing our best to keep the available data updated, clean (removing duplicates), and to provide a reliable service, but we are not in any way responsible for the accuracy of the data nor for the availability of the service itself. Please use it at your own risk . Abuse notice : we are currently not requiring any registration or authentication to use this service because we would like to keep it as simple as possible. Please do not abuse the service or you will force us to require a registration (subject to approval) to continue using it.","tags":"Development","url":"https://www.andreagrandi.it/2020/04/10/covid-api-free-and-open-source-api-service-for-covid19-data/","loc":"https://www.andreagrandi.it/2020/04/10/covid-api-free-and-open-source-api-service-for-covid19-data/"},{"title":"Google is moving some EU citizens data to US","text":"What is going on As you may have heard already, because of brexit , Google is moving UK citizens data from the Northern Ireland data controller to the US one (Google LLC). Leaving the EU, UK citizens are not protected anymore by GDPR, and while this may be unfair, Google is legally allowed to do it. The problem Even if I'm an Italian citizen and I live in Italy, a few days ago I received this email from them: What's wrong with it? The point is that I'm an Italian citizen , living in Italy . I have nothing to do with UK (even if I lived there for a few years in the past, my account was created from Italy). Why do they mention \"UK leaving EU\" to me, if I don't live in UK? I tried to contact them multiple times on their @Google account on Twitter, but I got no reply at all. I tried to search online and it looks like I'm not alone, they are doing this to many other people: https://support.google.com/accounts/thread/29317992?hl=en&authuser=1 Looking for help What should I do? Is this legally allowed? If there was an easy way to complain with them, I would have done it already, but I've tried to search on their website (even googling it... no pun intended) but I couldn't find a single contact form to report this issue and of course they are ignoring both Twitter and that forum I linked previously. Should I report them to the Privacy Authority ? If yes, how? Full text of the email Here is the full text of the email I received: We're improving our Terms of Service and making them easier for you to understand. The changes will take effect on 31 March 2020, and they won't impact the way that you use Google services. And, because the United Kingdom (UK) is leaving the European Union (EU), Google LLC will now be the service provider and the data controller responsible for your information and for complying with applicable privacy laws for UK consumer users. For more details, we've provided a summary of the key changes and Frequently asked questions. And the next time that you visit Google, you'll have the chance to review and accept the new Terms. At a glance, here's what this update means for you: • Improved readability: While our Terms remain a legal document, we've done our best to make them easier to understand, including by adding links to useful information and providing definitions. • Better communication: We've clearly explained when we'll make changes to our services (like adding or removing a feature) and when we'll restrict or end a user's access. And we'll do more to notify you when a change negatively impacts your experience on our services. • Adding Google Chrome, Google Chrome OS and Google Drive to the Terms: Our improved Terms now cover Google Chrome, Google Chrome OS and Google Drive, which also have service-specific terms and policies to help you understand what's unique to those services. • Your service provider and data controller is now Google LLC: Because the UK is leaving the EU, we've updated our Terms so that a United States-based company, Google LLC, is now your service provider instead of Google Ireland Limited. Google LLC will also become the data controller responsible for your information and complying with applicable privacy laws. We're making similar changes to the Terms of Service for YouTube, YouTube Paid Services and Google Play. These changes to our Terms and privacy policy don't affect your privacy settings or the way that we treat your information (see the privacy policy for details). As a reminder, you can always visit your Google Account to review your privacy settings and manage how your data is used. If you're the guardian of a child under the age required to manage their own Google Account and you use Family Link to manage their use of Google services, please note that when you accept our new Terms, you do so on their behalf as well, and you may want to discuss these changes with them. And of course, if you don't agree to our new Terms and what we can expect from each other as you use our services, you can find more information about your options in our Frequently asked questions. Thank you for using Google's services. Your Google team","tags":"Privacy","url":"https://www.andreagrandi.it/2020/02/25/google-is-moving-eu-citizens-data-to-us/","loc":"https://www.andreagrandi.it/2020/02/25/google-is-moving-eu-citizens-data-to-us/"},{"title":"How to deploy a static website to Github Pages using CircleCI","text":"Since I created my blog with a static pages generator, I've been using TravisCI to automate the pages build and deployment. My desire to learn something new (we are using CircleCI at work, but I never configured it from scratch) and the recent news about TravisCI acquisition and employees layoff , led me to think about moving to a different service. Github Pages Every account on Github can use a special repository to publish static pages. In my case, since I have github.com/andreagrandi , my special repository is named github.com/andreagrandi.github.io . Once I publish my pages there, they will be accessible from https://andreagrandi.github.io . You will need to use the master branch of the special repository directly and not the gh-pages branch which is available to each repository. CircleCI CircleCI is a very flexible and powerful continuous integration tool, which is also free for open source projects. As long as your static website is located on a public repository on Github, you won't have to pay anything to use it. In my case, the surce code of this website is available at https://github.com/andreagrandi/andreagrandi.it Configuration You can find the complete configuration at this address . The only value you won't find is GH_TOKEN . You need to generate this token on Github, at this address: https://github.com/settings/tokens . Give it a nice description like \"CircleCI deployment token\", select repo scope and finally click Generate token button. This token will be used to git push... your pages once they are built. Please remember to keep this token secret and not to publish it anywhere. In my configuration you may notice that I'm using Pelican static websites generator, but apart from a few changes, the structure of the configuration should be very similar even if you use Jekill, Hugo etc... it doesn't really matter how you generate the pages, the deployment phase will be the same . Deployment script You will notice that there is a complete bash script embedded in the CircleCI configuration. This script configures git, fetches the existing andreagrandi.github.io repository, and sync the built pages with the existing ones (this avoid creating a commit which contains all the pages so it will contain just the added content). Once the commit is made, the script will finally push the changes to the repository. Please note: regardless of CircleCI settings, the deployment will only happens if we are pushing (or merging a pull request) to master ( if [ \"${CIRCLE_BRANCH}\" = \"master\" ]; then ) and it will actually commit and push pages only if there is something new to commit ( if git commit -m \"CircleCI build $CIRCLE_BUILD_NUM pushed to Github Pages\" ; then ). For example if I'm just updating something in the CircleCI configuration, which doesn't change anything in the content, the pages won't be deployed again. Conclusion My first impression of CircleCI is that is faster than TravisCI and this means that I can publish my content more quickly. The possibility of using Docker containers as base image is really powerful and in more complex scenarios we can reproduce the building environment locally on our machine. If you have any advices about how to improve my build script, feel free to leave a comment here.","tags":"Web","url":"https://www.andreagrandi.it/2019/02/24/how-to-deploy-static-website-github-pages-circleci/","loc":"https://www.andreagrandi.it/2019/02/24/how-to-deploy-static-website-github-pages-circleci/"},{"title":"Skipping tests depending on the Python version","text":"Sometimes we want to run certain tests only on a specific version of Python. Suppose you are migrating a large project from Python 2 to Python 3 and you know in advance that certain tests won't run under Python 3. Chances are that during the migration you are already using the six library. The six libraries have two boolean properties which are initialised to True depending on the Python version which is being used: PY2 when running under Python 2 and PY3 when running under Python 3. This library, combined with the skipIf method of unittest library can be used to easily skip tests when using Python 3: import six import unittest class MyTestCase ( unittest . TestCase ): @unittest . skipIf ( six . PY3 , \"not compatible with Python 3\" ) def test_example ( self ): # This test won't run under Python 3 pass Credits Thanks to my colleague Nicola for giving me the inspiration to write this post.","tags":"Python","url":"https://www.andreagrandi.it/2019/02/21/skipping-tests-depending-python-version/","loc":"https://www.andreagrandi.it/2019/02/21/skipping-tests-depending-python-version/"},{"title":"Installing Python and virtualenv on OSX","text":"Every time I need to install Python on OSX or whenever a colleague asks for help, I have to search fo the most updated instructions on Google, and every time I find different ways of doing the exact same thing. Tired of this, I decided to write down my own notes. Please note that I don't claim this to be the best way of installing Python on OSX. It works fine for me so use it at your own risk. Requirements To follow these instructions you need to at least have installed brew on OSX. Please follow the instructions on the official website: https://brew.sh Installing Python 3.7.x and Python 2.7.x Even if I strongly suggest to start every new project with Python 3 (since Python 2 will only be supported until the end of 2019), there may be use cases when version 2 is still required, so I will give you the instructions to install both. Installing Python 3.7.x brew install python This will install Python 3 by default. Installing Python 2.7.x brew install python@2 This will install version 2 of Python. Add the Python locations to PATH Edit your .bashrc or .zshrc and add this: export PATH=\"/usr/local/opt/python/libexec/bin:/usr/local/bin:$PATH\" You will need to close your terminal and reopen it for the changes to be applied. Once you have done it, you can verify if Python 3 and Python 2 have been installed correctly: python --version Python 3.7.1 and python2 --version Python 2.7.15 Install virtualenv and virtualenvwrapper When working with Python, it's a good thing not to install packages system wide, but confine them in virtual environments. A good and well tested way of doing that is to use virtualenv (and its companion virtualenvwrapper ) which makes the most common operations easier. pip install virtualenv pip install virtualenvwrapper Those (and only those) two packages will be installed system wide, because we will need them to be available outside of a virtual environment. Configure virtualenv Edit again your .bashrc (or .zshrc ) and add these lines: export WORKON_HOME=~/.virtualenvs [ -f /usr/local/bin/virtualenvwrapper.sh ] && source /usr/local/bin/virtualenvwrapper.sh This will configure the default location where to store your virtual environments and will run a command every time you open a new terminal, to make sure virtualenvwrapper can work correctly. Test if the installed tools are working To make sure everything has been configured correctly, please close and reopen your terminal and let's try to create a new virtual environment: mkvirtualenv test which should output something like this: Using base prefix '/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7' New python executable in /Users/andrea/.virtualenvs/test/bin/python3.7 Also creating executable in /Users/andrea/.virtualenvs/test/bin/python Installing setuptools, pip, wheel... done. virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/predeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/postdeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/preactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/postactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/get_env_details (test) ➜ ~ If you see something similar, it means that the virtual environment has been created correctly. Please note that by default this command will create an environment base on Python 3. Do you need to create one for Python 2? No problem, you just need to do the following: mkvirtualenv -p /usr/local/bin/python2 test which should output this: Running virtualenv with interpreter /usr/local/bin/python2 New python executable in /Users/andrea/.virtualenvs/test/bin/python2.7 Also creating executable in /Users/andrea/.virtualenvs/test/bin/python Installing setuptools, pip, wheel... done. virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/predeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/postdeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/preactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/postactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/get_env_details (test) ➜ ~ Conclusion That's all you have to do to install and configure Python and virtualenv on OSX. If you have problems, comments or questions, feel free to leave a comment on this post.","tags":"Python","url":"https://www.andreagrandi.it/2018/12/19/installing-python-and-virtualenv-on-osx/","loc":"https://www.andreagrandi.it/2018/12/19/installing-python-and-virtualenv-on-osx/"},{"title":"Why I mentor on Exercism.io","text":"Exercism ( https://exercism.io ) is a platform that has been created to help people improving their coding skills, thanks to the volunteers mentoring the students. There are tracks for almost all the popular languages and each track has coding tests that the students can download, solve offline using their preferred editor, and test the solution against the provided unit tests. Once the solution is ready to be reviewed (or even if it's not complete but the student needs help), it can be submitted to the website and it will go in a queue where the first available mentor will pick it and start mentoring. The service is free to use for all the students and the mentors are all volunteers (this doesn't mean that the platform doesn't have any costs. If you are curious about the resources needed to keep the platform alive, you can give a look at this answer on Reddit . When I found out about the platform, I decided to use it (as student) to improve my Go coding skills . I must say that I've been learning a lot from the mentors and some of them are putting a lot of effort to give you all the possible advices to improve your coding style. In a single exercise once, I learnt at least five things about Go I didn't know before! I've been a Python developer (professionally) for the last 5 years, but I've never considered myself an \"expert\". I decided to give it a try with mentoring, because I felt I wanted to give something back to the community , so I registered as mentor too and started mentoring in the Python track. The first surprise has been that mentoring other students, I was probably learning more than how much I was teaching. First of all, once you already know how to solve a problem, it's always interesting to look at other possible solutions. I've found sometimes that students were providing better (more concise and readable) solutions than mine. Last but not least, before advising someone about conding style or a more idiomatic solution, I always double check things from different sources. There is nothing wrong making mistakes, especially if you are learning... but it would be damaging for the student if I was teaching them something wrong, so I need to be sure about what I say. This of course makes me study, even the basic things, again and again and at the end of the day, my skills are better too. Once you join the mentors group, you are invited to a private Slack where you can count on the help of other mentors (we have channels for each track/language) or ask questions. So, if you are not sure about something, you can always ask around. If my story and experience convinced you, Exercism is looking for more mentors! The more we have available, the less time the students have to wait in a queue to be mentored. You can find all the instructions at this address https://mentoring.exercism.io","tags":"Python","url":"https://www.andreagrandi.it/2018/11/04/why-i-mentor-on-exercism/","loc":"https://www.andreagrandi.it/2018/11/04/why-i-mentor-on-exercism/"},{"title":"Using ipdb with Python 3.7.x breakpoint","text":"Python 3.7.x introduced a new method to insert a breakpoint in the code. Before Python 3.7.x to insert a debugging point we had to write import pdb; pdb.set_trace() which honestly I could never remember (and I also created a snippet on VS Code to auto complete it). Now you can just write breakpoint() that's it! Now... the only problem is that by default that command will use pdb which is not exactly the best debugger you can have. I usually use ipdb but there wasn't an intuitive way of using it... and no, just installing it in your virtual environment, it won't be used by default. How to use it then? It's very simple. The new debugging command will read an environment variable named PYTHONBREAKPOINT . If you set it properly, you will be able to use ipdb instead of pdb. export PYTHONBREAKPOINT=ipdb.set_trace At this point, any time you use breakpoint() in your code, ipdb will be used instead of pdb . References https://hackernoon.com/python-3-7s-new-builtin-breakpoint-a-quick-tour-4f1aebc444c","tags":"Python","url":"https://www.andreagrandi.it/2018/10/16/using-ipdb-with-python-37-breakpoint/","loc":"https://www.andreagrandi.it/2018/10/16/using-ipdb-with-python-37-breakpoint/"},{"title":"Machine Learning: Pima Indians Diabetes","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } pre { line-height: 125%; margin: 0; } td.linenos pre { color: #000000; background-color: #f0f0f0; padding: 0 5px 0 5px; } span.linenos { color: #000000; background-color: #f0f0f0; padding: 0 5px 0 5px; } td.linenos pre.special { color: #000000; background-color: #ffffc0; padding: 0 5px 0 5px; } span.linenos.special { color: #000000; background-color: #ffffc0; padding: 0 5px 0 5px; } .highlight pre .hll { background-color: #ffffcc } .highlight pre { background: #f8f8f8; } .highlight pre .c { color: #408080; font-style: italic } /* Comment */ .highlight pre .err { border: 1px solid #FF0000 } /* Error */ .highlight pre .k { color: #008000; font-weight: bold } /* Keyword */ .highlight pre .o { color: #666666 } /* Operator */ .highlight pre .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight pre .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight pre .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight pre .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight pre .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight pre .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight pre .gd { color: #A00000 } /* Generic.Deleted */ .highlight pre .ge { font-style: italic } /* Generic.Emph */ .highlight pre .gr { color: #FF0000 } /* Generic.Error */ .highlight pre .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight pre .gi { color: #00A000 } /* Generic.Inserted */ .highlight pre .go { color: #888888 } /* Generic.Output */ .highlight pre .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight pre .gs { font-weight: bold } /* Generic.Strong */ .highlight pre .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight pre .gt { color: #0044DD } /* Generic.Traceback */ .highlight pre .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight pre .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight pre .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight pre .kp { color: #008000 } /* Keyword.Pseudo */ .highlight pre .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight pre .kt { color: #B00040 } /* Keyword.Type */ .highlight pre .m { color: #666666 } /* Literal.Number */ .highlight pre .s { color: #BA2121 } /* Literal.String */ .highlight pre .na { color: #7D9029 } /* Name.Attribute */ .highlight pre .nb { color: #008000 } /* Name.Builtin */ .highlight pre .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight pre .no { color: #880000 } /* Name.Constant */ .highlight pre .nd { color: #AA22FF } /* Name.Decorator */ .highlight pre .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight pre .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight pre .nf { color: #0000FF } /* Name.Function */ .highlight pre .nl { color: #A0A000 } /* Name.Label */ .highlight pre .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight pre .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight pre .nv { color: #19177C } /* Name.Variable */ .highlight pre .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight pre .w { color: #bbbbbb } /* Text.Whitespace */ .highlight pre .mb { color: #666666 } /* Literal.Number.Bin */ .highlight pre .mf { color: #666666 } /* Literal.Number.Float */ .highlight pre .mh { color: #666666 } /* Literal.Number.Hex */ .highlight pre .mi { color: #666666 } /* Literal.Number.Integer */ .highlight pre .mo { color: #666666 } /* Literal.Number.Oct */ .highlight pre .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight pre .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight pre .sc { color: #BA2121 } /* Literal.String.Char */ .highlight pre .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight pre .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight pre .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight pre .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight pre .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight pre .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight pre .sx { color: #008000 } /* Literal.String.Other */ .highlight pre .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight pre .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight pre .ss { color: #19177C } /* Literal.String.Symbol */ .highlight pre .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight pre .fm { color: #0000FF } /* Name.Function.Magic */ .highlight pre .vc { color: #19177C } /* Name.Variable.Class */ .highlight pre .vg { color: #19177C } /* Name.Variable.Global */ .highlight pre .vi { color: #19177C } /* Name.Variable.Instance */ .highlight pre .vm { color: #19177C } /* Name.Variable.Magic */ .highlight pre .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } Introduction The Pima are a group of Native Americans living in Arizona. A genetic predisposition allowed this group to survive normally to a diet poor of carbohydrates for years. In the recent years, because of a sudden shift from traditional agricultural crops to processed foods, together with a decline in physical activity, made them develop the highest prevalence of type 2 diabetes and for this reason they have been subject of many studies. Dataset The dataset includes data from 768 women with 8 characteristics, in particular: Number of times pregnant Plasma glucose concentration a 2 hours in an oral glucose tolerance test Diastolic blood pressure (mm Hg) Triceps skin fold thickness (mm) 2-Hour serum insulin (mu U/ml) Body mass index (weight in kg/(height in m)&#94;2) Diabetes pedigree function Age (years) The last column of the dataset indicates if the person has been diagnosed with diabetes (1) or not (0) Source The original dataset is available at UCI Machine Learning Repository and can be downloaded from this address: http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes The problem The type of dataset and problem is a classic supervised binary classification . Given a number of elements all with certain characteristics (features), we want to build a machine learning model to identify people affected by type 2 diabetes. To solve the problem we will have to analyse the data, do any required transformation and normalisation, apply a machine learning algorithm, train a model, check the performance of the trained model and iterate with other algorithms until we find the most performant for our type of dataset. Imports and configuration In [82]: # We import the libraries needed to read the dataset import os import pandas as pd import numpy as np In [83]: # We placed the dataset under datasets/ sub folder DATASET_PATH = 'datasets/' Load the dataset In [84]: # We read the data from the CSV file data_path = os . path . join ( DATASET_PATH , 'pima-indians-diabetes.csv' ) dataset = pd . read_csv ( data_path , header = None ) # Because thr CSV doesn't contain any header, we add column names # using the description from the original dataset website dataset . columns = [ \"NumTimesPrg\" , \"PlGlcConc\" , \"BloodP\" , \"SkinThick\" , \"TwoHourSerIns\" , \"BMI\" , \"DiPedFunc\" , \"Age\" , \"HasDiabetes\" ] Inspect the Dataset In [85]: # Check the shape of the data: we have 768 rows and 9 columns: # the first 8 columns are features while the last one # is the supervised label (1 = has diabetes, 0 = no diabetes) dataset . shape Out[85]: (768, 9) In [86]: # Visualise a table with the first rows of the dataset, to # better understand the data format dataset . head () Out[86]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } NumTimesPrg PlGlcConc BloodP SkinThick TwoHourSerIns BMI DiPedFunc Age HasDiabetes 0 6 148 72 35 0 33.6 0.627 50 1 1 1 85 66 29 0 26.6 0.351 31 0 2 8 183 64 0 0 23.3 0.672 32 1 3 1 89 66 23 94 28.1 0.167 21 0 4 0 137 40 35 168 43.1 2.288 33 1 Data correlation matrix The correlation matrix is an important tool to understand the correlation between the different characteristics. The values range from -1 to 1 and the closer a value is to 1 the bettere correlation there is between two characteristics. Let's calculate the correlation matrix for our dataset. In [87]: corr = dataset . corr () corr Out[87]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } NumTimesPrg PlGlcConc BloodP SkinThick TwoHourSerIns BMI DiPedFunc Age HasDiabetes NumTimesPrg 1.000000 0.129459 0.141282 -0.081672 -0.073535 0.017683 -0.033523 0.544341 0.221898 PlGlcConc 0.129459 1.000000 0.152590 0.057328 0.331357 0.221071 0.137337 0.263514 0.466581 BloodP 0.141282 0.152590 1.000000 0.207371 0.088933 0.281805 0.041265 0.239528 0.065068 SkinThick -0.081672 0.057328 0.207371 1.000000 0.436783 0.392573 0.183928 -0.113970 0.074752 TwoHourSerIns -0.073535 0.331357 0.088933 0.436783 1.000000 0.197859 0.185071 -0.042163 0.130548 BMI 0.017683 0.221071 0.281805 0.392573 0.197859 1.000000 0.140647 0.036242 0.292695 DiPedFunc -0.033523 0.137337 0.041265 0.183928 0.185071 0.140647 1.000000 0.033561 0.173844 Age 0.544341 0.263514 0.239528 -0.113970 -0.042163 0.036242 0.033561 1.000000 0.238356 HasDiabetes 0.221898 0.466581 0.065068 0.074752 0.130548 0.292695 0.173844 0.238356 1.000000 I'm not a doctor and I don't have any knowledge of medicine, but from the data I can guess that the greater the age or the BMI of a patient is, the greater probabilities are the patient can develop type 2 diabetes . In [88]: % matplotlib inline import seaborn as sns sns . heatmap ( corr , annot = True ) Out[88]: <matplotlib.axes._subplots.AxesSubplot at 0x10bc93d68> Visualise the Dataset Visualising the data is an important step of the data analysis. With a graphical visualisation of the data we have a better understanding of the various features values distribution: for example we can understand what's the average age of the people or the average BMI etc... We could of course limit our inspection to the table visualisation, but we could miss important things that may affect our model precision. In [89]: import matplotlib.pyplot as plt dataset . hist ( bins = 50 , figsize = ( 20 , 15 )) plt . show () An important thing I notice in the dataset (and that wasn't obvious at the beginning) is the fact that some people have null (zero) values for some of the features: it's not quite possible to have 0 as BMI or for the blood pressure. How can we deal with similar values? We will see it later during the data transformation phase. Data cleaning and transformation We have noticed from the previous analysis that some patients have missing data for some of the features. Machine learning algorithms don't work very well when the data is missing so we have to find a solution to \"clean\" the data we have. The easiest option could be to eliminate all those patients with null/zero values, but in this way we would eliminate a lot of important data. Another option is to calculate the median value for a specific column and substitute that value everywhere (in the same column) we have zero or null. Let's see how to apply this second method. In [90]: # Calculate the median value for BMI median_bmi = dataset [ 'BMI' ] . median () # Substitute it in the BMI column of the # dataset where values are 0 dataset [ 'BMI' ] = dataset [ 'BMI' ] . replace ( to_replace = 0 , value = median_bmi ) In [91]: # Calculate the median value for BloodP median_bloodp = dataset [ 'BloodP' ] . median () # Substitute it in the BloodP column of the # dataset where values are 0 dataset [ 'BloodP' ] = dataset [ 'BloodP' ] . replace ( to_replace = 0 , value = median_bloodp ) In [92]: # Calculate the median value for PlGlcConc median_plglcconc = dataset [ 'PlGlcConc' ] . median () # Substitute it in the PlGlcConc column of the # dataset where values are 0 dataset [ 'PlGlcConc' ] = dataset [ 'PlGlcConc' ] . replace ( to_replace = 0 , value = median_plglcconc ) In [93]: # Calculate the median value for SkinThick median_skinthick = dataset [ 'SkinThick' ] . median () # Substitute it in the SkinThick column of the # dataset where values are 0 dataset [ 'SkinThick' ] = dataset [ 'SkinThick' ] . replace ( to_replace = 0 , value = median_skinthick ) In [94]: # Calculate the median value for TwoHourSerIns median_twohourserins = dataset [ 'TwoHourSerIns' ] . median () # Substitute it in the TwoHourSerIns column of the # dataset where values are 0 dataset [ 'TwoHourSerIns' ] = dataset [ 'TwoHourSerIns' ] . replace ( to_replace = 0 , value = median_twohourserins ) I haven't transformed all the columns, because for some values can make sense to be zero (like \"Number of times pregnant\"). Splitting the Dataset Now that we have transformed the data we need to split the dataset in two parts: a training dataset and a test dataset. Splitting the dataset is a very important step for supervised machine learning models. Basically we are going to use the first part to train the model (ignoring the column with the pre assigned label), then we use the trained model to make predictions on new data (which is the test dataset, not part of the training set) and compare the predicted value with the pre assigned label. In [95]: # Split the training dataset in 80% / 20% from sklearn.model_selection import train_test_split train_set , test_set = train_test_split ( dataset , test_size = 0.2 , random_state = 42 ) In [96]: # Separate labels from the rest of the dataset train_set_labels = train_set [ \"HasDiabetes\" ] . copy () train_set = train_set . drop ( \"HasDiabetes\" , axis = 1 ) test_set_labels = test_set [ \"HasDiabetes\" ] . copy () test_set = test_set . drop ( \"HasDiabetes\" , axis = 1 ) Feature Scaling One of the most important data transformations we need to apply is the features scaling . Basically most of the machine learning algorithms don't work very well if the features have a different set of values . In our case for example the Age ranges from 20 to 80 years old, while the number of times a patient has been pregnant ranges from 0 to 17. For this reason we need to apply a proper transformation. In [97]: # Apply a scaler from sklearn.preprocessing import MinMaxScaler as Scaler scaler = Scaler () scaler . fit ( train_set ) train_set_scaled = scaler . transform ( train_set ) test_set_scaled = scaler . transform ( test_set ) Scaled Values In [98]: df = pd . DataFrame ( data = train_set_scaled ) df . head () Out[98]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 5 6 7 0 0.117647 0.258065 0.489796 0.272727 0.019832 0.282209 0.096499 0.000000 1 0.529412 0.438710 0.591837 0.290909 0.019832 0.204499 0.514091 0.483333 2 0.058824 0.612903 0.224490 0.200000 0.082933 0.214724 0.245944 0.016667 3 0.000000 0.754839 0.265306 0.272727 0.019832 0.075665 0.075149 0.733333 4 0.352941 0.580645 0.571429 0.527273 0.427885 0.572597 0.068318 0.416667 Select and train a model It's not possible to know in advance which algorithm will work better with our dataset. We need to compare a few and select the one with the \"best score\". Comparing multiple algorithms To compare multiple algorithms with the same dataset, there is a very nice utility in sklearn called model_selection . We create a list of algorithms and then we score them using the same comparison method. At the end we pick the one with the best score. In [99]: # Import all the algorithms we want to test from sklearn.linear_model import LogisticRegression from sklearn.neighbors import KNeighborsClassifier from sklearn.naive_bayes import GaussianNB from sklearn.svm import SVC from sklearn.svm import LinearSVC from sklearn.ensemble import RandomForestClassifier from sklearn.tree import DecisionTreeRegressor In [100]: # Import the slearn utility to compare algorithms from sklearn import model_selection In [101]: # Prepare an array with all the algorithms models = [] models . append (( 'LR' , LogisticRegression ())) models . append (( 'KNN' , KNeighborsClassifier ())) models . append (( 'NB' , GaussianNB ())) models . append (( 'SVC' , SVC ())) models . append (( 'LSVC' , LinearSVC ())) models . append (( 'RFC' , RandomForestClassifier ())) models . append (( 'DTR' , DecisionTreeRegressor ())) In [102]: # Prepare the configuration to run the test seed = 7 results = [] names = [] X = train_set_scaled Y = train_set_labels In [103]: # Every algorithm is tested and results are # collected and printed for name , model in models : kfold = model_selection . KFold ( n_splits = 10 , random_state = seed ) cv_results = model_selection . cross_val_score ( model , X , Y , cv = kfold , scoring = 'accuracy' ) results . append ( cv_results ) names . append ( name ) msg = \" %s : %f ( %f )\" % ( name , cv_results . mean (), cv_results . std ()) print ( msg ) LR: 0.755632 (0.045675) KNN: 0.740984 (0.049627) NB: 0.739450 (0.062140) SVC: 0.757271 (0.037642) LSVC: 0.763802 (0.042701) RFC: 0.747541 (0.054909) DTR: 0.723030 (0.053026) In [104]: # boxplot algorithm comparison fig = plt . figure () fig . suptitle ( 'Algorithm Comparison' ) ax = fig . add_subplot ( 111 ) plt . boxplot ( results ) ax . set_xticklabels ( names ) plt . show () It looks like that using this comparison method, the most performant algorithm is SVC . Find the best parameters for SVC The default parameters for an algorithm are rarely the best ones for our dataset. Using sklearn we can easily build a parameters grid and try all the possible combinations. At the end we inspect the best_estimator_ property and get the best ones for our dataset. In [105]: from sklearn.model_selection import GridSearchCV param_grid = { 'C' : [ 1.0 , 10.0 , 50.0 ], 'kernel' : [ 'linear' , 'rbf' , 'poly' , 'sigmoid' ], 'shrinking' : [ True , False ], 'gamma' : [ 'auto' , 1 , 0.1 ], 'coef0' : [ 0.0 , 0.1 , 0.5 ] } model_svc = SVC () grid_search = GridSearchCV ( model_svc , param_grid , cv = 10 , scoring = 'accuracy' ) grid_search . fit ( train_set_scaled , train_set_labels ) Out[105]: GridSearchCV(cv=10, error_score='raise', estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False), fit_params=None, iid=True, n_jobs=1, param_grid={'C': [1.0, 10.0, 50.0], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], 'shrinking': [True, False], 'gamma': ['auto', 1, 0.1], 'coef0': [0.0, 0.1, 0.5]}, pre_dispatch='2*n_jobs', refit=True, return_train_score='warn', scoring='accuracy', verbose=0) In [106]: # Print the bext score found grid_search . best_score_ Out[106]: 0.76872964169381108 Apply the parameters to the model and train it In [107]: # Create an instance of the algorithm using parameters # from best_estimator_ property svc = grid_search . best_estimator_ # Use the whole dataset to train the model X = np . append ( train_set_scaled , test_set_scaled , axis = 0 ) Y = np . append ( train_set_labels , test_set_labels , axis = 0 ) # Train the model svc . fit ( X , Y ) Out[107]: SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) Make a Prediction In [114]: # We create a new (fake) person having the three most correated values high new_df = pd . DataFrame ([[ 6 , 168 , 72 , 35 , 0 , 43.6 , 0.627 , 65 ]]) # We scale those values like the others new_df_scaled = scaler . transform ( new_df ) In [115]: # We predict the outcome prediction = svc . predict ( new_df_scaled ) In [117]: # A value of \"1\" means that this person is likley to have type 2 diabetes prediction Out[117]: array([1]) Conclusion We finally find a score of 76% using SVC algorithm and parameters optimisation. Please note that there may be still space for further analysis and optimisation, for example trying different data transformations or trying algorithms that haven't been tested yet. Once again I want to repeat that training a machine learning model to solve a problem with a specific dataset is a try / fail / improve process. Credits First of all I need to thank my wife Dr Daniela Ceccarelli Ceccarelli for helping me to validate this experiment and for checking I didn't write anything wrong from a medical point of view. Then I want to thank Dr. Jason Brownlee for his fantastic blog which has helped me a lot to understand many concepts used here. I strongly advise you to have a look at his blog: https://machinelearningmastery.com if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Development","url":"https://www.andreagrandi.it/2018/04/14/machine-learning-pima-indians-diabetes/","loc":"https://www.andreagrandi.it/2018/04/14/machine-learning-pima-indians-diabetes/"},{"title":"Keybase: PGP encryption made easy","text":"Using PGP can be quite hard, even if you have a lot of experience with computers. By the way encryption is what gives us privacy and permits us to safely transmit information and for this reason it should be easy to use, for everyone. Keybase really makes encryption easy to use. PGP identity When Keybase was launched it was mainly a wrapper for PGP commands to encrypt and decrypt a message for a certain user, but it also introduced a very nice chain of trust. In Keybase it's possible to either generate a new PGP key or import an existing one but the most important thing is being able to verify our own identity using multiple proofs. Many of us have a personal blog, a Twitter or Facebook accounts, a GitHub account etc... All these accounts combined together make our online identity. Every Keybase account can be verified by other online identities. In Keybase you don't just say \"I'm Andrea Grandi, this is my PGP key...\". In Keybase you can link your existing online accounts to your Keybase account and show additional proofs of your identity. Unless an attacker controls all your social accounts, they cannot impersonate and verify themselves as if they were you. Once you are on Keybase, other users can look for you even using your GitHub or Twitter username without having to know your email address or Keybase username. This concept can be very useful in some situations, we will see it later. Encrypted Filesystem One of the first features launched by Keybase was their encrypted filesystem. There is a virtual folder located at /keybase (on OSX/Linux or k:\\keybase on Windows) where you will find at least three other folders: public , private , team . Public folders Anything you place inside the /public folder can be accessed by any Keybase user and it's automatically signed. Every user public folder/file can be accessed using their Keybase username, like for example /keybase/public/andreagrandi/hello.txt but you can also use any other identity like /keybase/public/andreagrandi@github/hello.txt or /keybase/public/andreagrandi@twitter/hello.txt Note: This is very useful if you only know a person on Twitter (or GitHub etc...) and you want to share a file with them (or send a message, as we will see later) but you don't follow each other and you can't reach them privately. This is a public folder example of one of the Keybase developers: You can put whatever you want in these folders: your public PGP key, your official avatar, your Signal fingerprint etc... the other users will access these files with the assurance they haven't been changed by anyone else in the middle. Note: please keep in mind that Keybase doesn't work like Dropbox or similar. Files are not synced between your devices and Keybase servers. Files are streamed on demand, so you won't be able to access these files without a working Internet connection . Private folders Hey but... where is the encryption here?! Whatever you put inside your private folder can only be read by you and only you. Not even Keybase employees can access the content of your files , because they are encrypted before leaving your devices and decrypted on demand when you want to access them. Do you want to share files with anotheruser ? No problem. Just create a file inside /keybase/private/andreagrandi,anotheruser (the folder andreagrandi,anotheruser will implicitely exist already) and that file will only be readable by you and anotheruser . Security and other information Keybase employes only have access to: 1) your top level folder names (like: \"andreagrandi,anotheruser\"), 2) when and for how long you are reading/writing, 3) how much space you are using. They won't be able to access the content of your files and not even the files or folders names. Every user initially had 10GB quota available, but a few hints (including one of their recent screenshots ) say that now users have 250GB available to store their files. You can find more technical information about Keybase encrypted folders in this article: https://keybase.io/docs/kbfs Encrypted Chat A few months ago Keybase introduced the encrypted chat. Messages between users are end to end encrypted and cannot be read by anyone else, not even having access to Keybase servers. A better address book When we use services like WhatsApp or Signal, we are forced to share our telephone number if we want the other person to be able to contact us. On Keybase I don't need to share my telephone number. Anyone can reach me using one of my online identities: andreagrandi@twitter , andreagrandi@github etc... You can even send a message to a person who is not on Keybase yet : if you send a message to randomuser@twitter, when randomuser joins Keybase and verify their Twitter account, the message will be encrypted for them and will be safely delivered. Security Keybase doesn't use PGP to encrypt chat or files. Transmitting the key across all devices wouldn't be safe so each message is encrypted using the public key of every device connected to the account. Command line Keybase works from the command line too. There is no need to use the graphic client to send a message to another user, you can do something like this: keybase chat send andreagrandi \"Hello mate!\" You can integrate messages in any script and it's even available a JSON API: keybase chat help api For more details you can have a look a this blog post on their website: https://keybase.io/blog/keybase-chat Teams Keybase has recently introduced Teams feature. The Chat becomes more similar to Slack, but with the difference that only team members can read the content of messages and files: the server only knows about team names and users, nobody else can access the content. It's important to mention that in Keybase there aren't private channels like there are in Slack: if a team wants to have channels accessible only from a restricted group of users, the admin needs to create a sub team. For example if you have a team called keybaselovers you can create a sub team for admins only called keybaselovers.admins Teams have a dedicated encrypter folder that you will find under /keybase/team/keybaselovers At the moment the features available from the UI are quite limited and are only available from the command line. In the next weeks these features will be available from the UI too. In the mean time you can have a look at the commandline help: keybase team --help # for admin'ing teams keybase chat --help # for admin'ing chat channels Create a Team keybase team create keybaselovers Add a user to a Team keybase team add-member keybaselovers --user = alice --role = writer For more information you can have a look at the official announcement page: https://keybase.io/blog/introducing-keybase-teams Git Sometimes we have the need to store private information in a safe way and we want to be sure that nobody else is able to access these information. Latest feature that has been added to Keybase is encrypted Git repositories . They are like normal GitHub repositories, but their content is stored in a safer way. Privacy and Security What is the difference with GitHub private repositories? In GitHub a private repository is used to store information that only our account can access, but the files are accessible in plain text by GitHub employees. With encrypted Git repositories instead, the information are encrypted before they leave our device and they are stored encrypted. Nobody, without having our private key can read them, not even Keybase employees. Teams and Quota Encrypted Git repositories are of course available for teams too. Creating a team repository, it will be available to all the members of the team. Both teams and single users have 100GB of space available (which is separate from Folders quota). Usage If I create my personal repository called documents all I have to do to clone it and use it is: git clone keybase://private/andreagrandi/documents and I can use it as a normal git repository. Every time I commit and push something, the content will be signed and encrypted and only available to the repository owner (which is me) or to the whole team if it's a team repository. For more information, please have a look at the official announcement here: https://keybase.io/blog/encrypted-git-for-everyone Conclusion Keybase is still in continuous development but it already offers a few interesting features which can help people in their every day life. I strongly advise anyone to get an account , play with the available features and report any bug so the developers will be able to fix them and build an even better product. I can't wait to see the features they will announce in the next months!","tags":"HowTo","url":"https://www.andreagrandi.it/2017/10/21/keybase-pgp-encryption-made-easy/","loc":"https://www.andreagrandi.it/2017/10/21/keybase-pgp-encryption-made-easy/"},{"title":"Configuring an offline GnuPG master key and subkeys on YubiKey","text":"I've recently bought a YubiKey 4 and decided to use it for GnuPG too, other than using it as hardware 2FA. I've also decided to make my GnuPG configuration much more safe, generating the master key on an offline computer (in my case a simple RaspberryPi not connected to Internet) and generating a subkey that will be moved to my YubiKey . Disclaimer Always think about what your threat model is before deciding something is 100% safe for you. I'm not claiming this setup/configuration is bullet proof. If you want to protect your GnuPG key from most of the hackers, keyloggers and if you want to use it on different computers without ever compromising your secret key, this setup can be what you are looking for. If you think you may be victim of a targeted state sponsored attack, I'm not sure this setup could be enough. Why keeping offline the master key? If you only use your master key on a computer that never connects to Internet (I reckon you will want to update/patch it from time to time, that's why we are going to keep the master key on an external USB key) you are at least safe from remote attacks. Why using subkeys? Your GnuPG master key is also your \"identity\" among every PGP user. If you loose your master key or if your key is compromised you need to rebuild your identity and reputation from scratch. Instead, if a subkey is compromised, you can revoke the subkey (using your master key) and generate a new subkey. How a YubiKey makes things safer? If you always use your subkey from a YubiKey , it's very unlikely that your private key can be stolen: it's impossible to read it from the YubiKey and if you loose your YubiKey or if it's physically stolen, the attacker will still need your passphrase and your YubiKey PIN. Requirements 1 YubiKey 4 2 USB keys (in theory you only need one, but I strongly suggest you have another one as backup) 1 offline computer (a simple RaspberryPi with no Internet connection will be fine) Initial setup From now on, I will assume that you have prepared a computer for offline use (in my case I'm using a RaspberryPi 2 with Raspbian) and you will type the next commands there and only there. Plug one of the USB key (you can format it with VFAT for simplicity) in the offline computer and wait for the system to mount it. At this point it should be mounted in a path like this: /media/AABB-BAAC Now set the GnuPG working directory and create it: user@debian:~$ export GNUPGHOME=/media/AABB-BAAC/gnupghome user@debian:~$ mkdir $GNUPGHOME Second disclaimer If you think your threat model doesn't include someone can hack your computer from remote, you can ignore my advice and type these commands on your main laptop (at your own risk). Note For my own convenience, to write this tutorial I reproduced all these steps on my MacBook because it was easier to copy/paste commands and outputs but I've tested it with the exact setup I'm describing, and it should be compatible with OSX and Linux. When you see something has been masked it's just to hide (from spam) things like my email or to protect the serial number of my YubiKey . Last but not least, the output shown here could not match exactly the one you get on your own PC and this also depends on the GnuPG version you are using. Generating the master key The master key must be generated using the advanced mode, because by default when a new master key is generated, also a new subkey is created with all the capabilities (Authentication + Signing + Encryption), while we want something different. Note: PGP keys up to 4096 bits are only supported in YubiKey 4 models. If you have a YubiKey NEO you must use a 2048 bits key because it's the maximum size supported. Here you will create a PGP key with only the Authentication capability . If your GnuPG version doesn't allow this, choose \"sign only\", just don't create the encryption capability at this time. user@debian:~$ gpg --expert --gen-key gpg (GnuPG) 2.0.30; Copyright (C) 2015 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. gpg: directory `/media/AABB-BAAC/gnupghome' created gpg: new configuration file `/media/AABB-BAAC/gnupghome/gpg.conf' created gpg: WARNING: options in `/media/AABB-BAAC/gnupghome/gpg.conf' are not yet active during this run gpg: keyring `/media/AABB-BAAC/gnupghome/secring.gpg' created gpg: keyring `/media/AABB-BAAC/gnupghome/pubring.gpg' created Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) (7) DSA (set your own capabilities) (8) RSA (set your own capabilities) Your selection? 8 Possible actions for a RSA key: Sign Certify Encrypt Authenticate Current allowed actions: Sign Certify Encrypt (S) Toggle the sign capability (E) Toggle the encrypt capability (A) Toggle the authenticate capability (Q) Finished Your selection? s Possible actions for a RSA key: Sign Certify Encrypt Authenticate Current allowed actions: Certify Encrypt (S) Toggle the sign capability (E) Toggle the encrypt capability (A) Toggle the authenticate capability (Q) Finished Your selection? e Possible actions for a RSA key: Sign Certify Encrypt Authenticate Current allowed actions: Certify (S) Toggle the sign capability (E) Toggle the encrypt capability (A) Toggle the authenticate capability (Q) Finished Your selection? q RSA keys may be between 1024 and 4096 bits long. What keysize do you want? (2048) 4096 Requested keysize is 4096 bits Please specify how long the key should be valid. 0 = key does not expire <n> = key expires in n days <n>w = key expires in n weeks <n>m = key expires in n months <n>y = key expires in n years Key is valid for? (0) 2y Key expires at Wed 25 Sep 18:39:49 2019 BST Is this correct? (y/N) y GnuPG needs to construct a user ID to identify your key. Real name: Andrea Grandi Email address: user@email.com Comment: You selected this USER-ID: \"Andrea Grandi <user@email.com>\" Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? o You need a Passphrase to protect your secret key. We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. gpg: /media/AABB-BAAC/gnupghome/trustdb.gpg: trustdb created gpg: key 2240402E marked as ultimately trusted public and secret key created and signed. gpg: checking the trustdb gpg: 3 marginal(s) needed, 1 complete(s) needed, PGP trust model gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u gpg: next trustdb check due at 2019-09-25 pub 4096R/2240402E 2017-09-25 [expires: 2019-09-25] Key fingerprint = 7D4C 4090 DB50 1693 4614 F6FC 6206 9DE9 2240 402E uid [ultimate] Andrea Grandi <user@email.com> Note: please remember to save your passphrase in a safe place. Choose something you can remember because you will need it every time you need to sign, encrypt or decrypt something. Creating a revocation certificate It's very important to create a revocation certificate to be used if and when in the future you want to change your master key and revoke the existing one: user@debian:~$ gpg --gen-revoke 2240402E > 2240402E-revocation-certificate.asc sec 4096R/2240402E 2017-09-25 Andrea Grandi <user@email.com> Create a revocation certificate for this key? (y/N) y Please select the reason for the revocation: 0 = No reason specified 1 = Key has been compromised 2 = Key is superseded 3 = Key is no longer used Q = Cancel (Probably you want to select 1 here) Your decision? 3 Enter an optional description; end it with an empty line: > Reason for revocation: Key is no longer used (No description given) Is this okay? (y/N) y You need a passphrase to unlock the secret key for user: \"Andrea Grandi <user@email.com>\" 4096-bit RSA key, ID 2240402E, created 2017-09-25 ASCII armored output forced. Revocation certificate created. Please move it to a medium which you can hide away; if Mallory gets access to this certificate he can use it to make your key unusable. It is smart to print this certificate and store it away, just in case your media become unreadable. But have some caution: The print system of your machine might store the data and make it available to others! Creating Encryption subkey To create a subkey we need to edit the existing key (please note that 2240402E is the last 8 chars from the fingerprint of the previously generated master key) and specify we want to create an Encryption only key. user@debian:~$ gpg --edit-key 2240402E gpg (GnuPG) 2.0.30; Copyright (C) 2015 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Secret key is available. pub 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 usage: C trust: ultimate validity: ultimate [ultimate] (1). Andrea Grandi <user@email.com> gpg> addkey Key is protected. You need a passphrase to unlock the secret key for user: \"Andrea Grandi <user@email.com>\" 4096-bit RSA key, ID 2240402E, created 2017-09-25 Please select what kind of key you want: (3) DSA (sign only) (4) RSA (sign only) (5) Elgamal (encrypt only) (6) RSA (encrypt only) Your selection? 6 RSA keys may be between 1024 and 4096 bits long. What keysize do you want? (2048) 4096 Requested keysize is 4096 bits Please specify how long the key should be valid. 0 = key does not expire <n> = key expires in n days <n>w = key expires in n weeks <n>m = key expires in n months <n>y = key expires in n years Key is valid for? (0) 2y Key expires at Wed 25 Sep 18:47:21 2019 BST Is this correct? (y/N) y Really create? (y/N) y We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. pub 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 usage: C trust: ultimate validity: ultimate sub 4096R/01731555 created: 2017-09-25 expires: 2019-09-25 usage: E [ultimate] (1). Andrea Grandi <user@email.com> gpg> save Export a backup of the secret keys It's very important to export a backup of the secret keys at this point. Writing the secret subkey to the YubiKey is a destructive process: keys are moved to the YubiKey , they are not copied. user@debian:~$ gpg --export-secret-key 2240402E > 2240402E-secret.pgp Note: this backup includes both the secret master key and the secret subkey. Please remember to save a backup of this key on a couple of separate USB keys: you will need this keys to generate future subkeys and/or to revoke the existing ones. Programming the YubiKey with all GnuPG keys We have previously created the master key and the encryption subkey . Now we will create the authentication and signing keys directly on the YubiKey (we don't need to have a copy of these keys) and we will move the secret encryption key to the YubiKey . user@debian:~$ gpg --edit-key 2240402E gpg (GnuPG) 2.0.30; Copyright (C) 2015 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Secret key is available. pub 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 usage: C trust: ultimate validity: ultimate sub 4096R/01731555 created: 2017-09-25 expires: 2019-09-25 usage: E [ultimate] (1). Andrea Grandi <user@email.com> gpg> addcardkey Signature key ....: [none] Encryption key....: [none] Authentication key: [none] Please select the type of key to generate: (1) Signature key (2) Encryption key (3) Authentication key Your selection? 1 What keysize do you want for the Signature key? (4096) Key is protected. You need a passphrase to unlock the secret key for user: \"Andrea Grandi <user@email.com>\" 4096-bit RSA key, ID 2240402E, created 2017-09-25 Please specify how long the key should be valid. 0 = key does not expire <n> = key expires in n days <n>w = key expires in n weeks <n>m = key expires in n months <n>y = key expires in n years Key is valid for? (0) 2y Key expires at Wed 25 Sep 18:50:42 2019 BST Is this correct? (y/N) y Really create? (y/N) y pub 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 usage: C trust: ultimate validity: ultimate sub 4096R/01731555 created: 2017-09-25 expires: 2019-09-25 usage: E sub 4096R/771B0554 created: 2017-09-25 expires: 2019-09-25 usage: S [ultimate] (1). Andrea Grandi <user@email.com> gpg> addcardkey Signature key ....: 6FAB DC46 1847 3550 3769 2D32 0DE1 36B4 771B 0554 Encryption key....: [none] Authentication key: [none] Please select the type of key to generate: (1) Signature key (2) Encryption key (3) Authentication key Your selection? 3 What keysize do you want for the Authentication key? (4096) Key is protected. You need a passphrase to unlock the secret key for user: \"Andrea Grandi <user@email.com>\" 4096-bit RSA key, ID 2240402E, created 2017-09-25 Please specify how long the key should be valid. 0 = key does not expire <n> = key expires in n days <n>w = key expires in n weeks <n>m = key expires in n months <n>y = key expires in n years Key is valid for? (0) 2y Key expires at Wed 25 Sep 18:54:51 2019 BST Is this correct? (y/N) y Really create? (y/N) y pub 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 usage: C trust: ultimate validity: ultimate sub 4096R/01731555 created: 2017-09-25 expires: 2019-09-25 usage: E sub 4096R/771B0554 created: 2017-09-25 expires: 2019-09-25 usage: S sub 4096R/A9B5334C created: 2017-09-25 expires: 2019-09-25 usage: A [ultimate] (1). Andrea Grandi <user@email.com> gpg> toggle sec 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 ssb 4096R/01731555 created: 2017-09-25 expires: never ssb 4096R/771B0554 created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 ssb 4096R/A9B5334C created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 (1) Andrea Grandi <user@email.com> gpg> key 1 sec 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 ssb* 4096R/01731555 created: 2017-09-25 expires: never ssb 4096R/771B0554 created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 ssb 4096R/A9B5334C created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 (1) Andrea Grandi <user@email.com> gpg> keytocard Signature key ....: 6FAB DC46 1847 3550 3769 2D32 0DE1 36B4 771B 0554 Encryption key....: [none] Authentication key: BD26 3AD8 985E CAB0 9F32 7307 DF7C F7C0 A9B5 334C Please select where to store the key: (2) Encryption key Your selection? 2 You need a passphrase to unlock the secret key for user: \"Andrea Grandi <user@email.com>\" 4096-bit RSA key, ID 01731555, created 2017-09-25 sec 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 ssb* 4096R/01731555 created: 2017-09-25 expires: never card-no: 0006 05672181 ssb 4096R/771B0554 created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 ssb 4096R/A9B5334C created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 (1) Andrea Grandi <user@email.com> gpg> save Check public keys Just to verify everything has been created correctly, we check the public keys. We should see one pub key and three sub : user@debian:~$ gpg -k /media/AABB-BAAC/gnupghome/pubring.gpg -------------------------------- pub 4096R/2240402E 2017-09-25 [expires: 2019-09-25] uid [ultimate] Andrea Grandi <user@email.com> sub 4096R/01731555 2017-09-25 [expires: 2019-09-25] sub 4096R/771B0554 2017-09-25 [expires: 2019-09-25] sub 4096R/A9B5334C 2017-09-25 [expires: 2019-09-25] Check private keys When we check the private keys we should see that one key is still local, marked as sec (it's the private key of the master key), while three other keys are marked as ssb> which means they have been moved to the YubiKey : user@debian:~$ gpg -K /media/AABB-BAAC/gnupghome/secring.gpg -------------------------------- sec 4096R/2240402E 2017-09-25 [expires: 2019-09-25] uid Andrea Grandi <user@email.com> ssb> 4096R/01731555 2017-09-25 ssb> 4096R/771B0554 2017-09-25 ssb> 4096R/A9B5334C 2017-09-25 Import back secret keys from backup (only for multiple YubiKeys) As previously said, when we write the encryption subkey to the YubiKey , the key is moved and not just copied, so we need to import back the secret key into the keyring. It's important to have a backup of the subkey too, not because we need it in case the key is compromised etc... but because we need it in case we want to write multiple YubiKeys with the same encryption key, so that we have a backup key to use. user@debian:~$ gpg --import < 2240402E-secret.pgp Completely remove secret keys from laptop Once you have programmed the YubiKey and you are sure the secret keys are backed up on a couple of USB keys, you are ready to remove the secret keys from your laptop. Note: you don't need to remove anything if you have conducted the whole setup on a spare offline PC (or on a RaspberryPi) because that's not your every day computer. user@debian:~$ gpg --delete-secret-key 2240402E Exporting the public PGP key As you know, PGP keys are composed by a secret part and a public one. The public one must be distributed publicly and it's the one people will use to encrypt messages directed to you. user@debian:~$ gpg --armor --export 2240402E > 2240402E.asc If you have a personal blog/website I suggest to upload it there (for example mine can be found here https://www.andreagrandi.it/2240402E.asc ) Change YubiKey PINs and complete configuration Every YubiKey is sold with a certain default configuration: there is a user PIN that is required every time we need to use the key to sign/decrypt something (in addition to our passphrase) and there is an admin PIN that is required every time we change certain settings on the YubiKey . The default values are: user PIN: 123456 admin PIN: 12345678 I strongly recommend you to change them following this example: user@debian:~$ gpg --card-edit Reader ...........: Yubico Yubikey 4 OTP U2F CCID Application ID ...: D000000000000000000000000000000000 Version ..........: 2.1 Manufacturer .....: Yubico Serial number ....: 012345678 Name of cardholder: [not set] Language prefs ...: [not set] Sex ..............: unspecified URL of public key : [not set] Login data .......: [not set] Signature PIN ....: not forced Key attributes ...: rsa4096 rsa4096 rsa4096 Max. PIN lengths .: 127 127 127 PIN retry counter : 3 0 3 Signature counter : 3 Signature key ....: 6FAB DC46 1847 3550 3769 2D32 0DE1 36B4 771B 0554 created ....: 2017-09-25 17:50:37 Encryption key....: FC6F 40BC 4173 8D13 2D7C E958 BCDC EA84 0173 1555 created ....: 2017-09-25 17:47:09 Authentication key: BD26 3AD8 985E CAB0 9F32 7307 DF7C F7C0 A9B5 334C created ....: 2017-09-25 17:54:49 General key info..: sub rsa4096/0DE136B4771B0554 2017-09-25 Andrea Grandi <user@email.com> sec# rsa4096/62069DE92240402E created: 2017-09-25 expires: 2019-09-25 ssb> rsa4096/BCDCEA8401731555 created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 ssb> rsa4096/0DE136B4771B0554 created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 ssb> rsa4096/DF7CF7C0A9B5334C created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 gpg/card> admin Admin commands are allowed # Change the PIN and Admin PINs gpg/card> passwd gpg: OpenPGP card no. D000000000000000000000000000000000 detected 1 - change PIN 2 - unblock PIN 3 - change Admin PIN 4 - set the Reset Code Q - quit Your selection? 1 PIN changed. 1 - change PIN 2 - unblock PIN 3 - change Admin PIN 4 - set the Reset Code Q - quit Your selection? 3 PIN changed. 1 - change PIN 2 - unblock PIN 3 - change Admin PIN 4 - set the Reset Code Q - quit Your selection? q # Make sure the PIN is entered before signing gpg/card> forcesig # Set the URL where the OpenPGP public key can be found. gpg/card> url URL to retrieve public key: https://www.andreagrandi.it/2240402E.asc # Fetch the public key into the local keyring gpg/card> fetch gpg/card> quit Note: when you want to use your YubiKey on any computer (for example your work laptop) you need to at least import your public PGP key into the keyring. If the key is not read automatically, you may need to give it a refresh using this command: user@debian:~$ gpg --card-status Careful with PINs Please remember that you can only digit a wrong user PIN for a maximum of three times. After three time you will need to edit the YubiKey (with gpg --card-edit ) become admin and use the unblock PIN option. If you digit the wrong admin PIN for three time, you will have to follow a quite complicated procedure (explained at this address: https://developers.yubico.com/ykneo-openpgp/ResetApplet.html ) and your YubiKey will be reset with factory settings, deleting your PGP keys from it. References To write this tutorial I originally followed other articles online. The main ones are: https://www.esev.com/blog/post/2015-01-pgp-ssh-key-on-yubikey-neo/ https://blog.josefsson.org/2014/06/23/offline-gnupg-master-key-and-subkeys-on-yubikey-neo-smartcard/ https://wiki.debian.org/Subkeys https://www.paulfurley.com/gpg-for-humans-preparing-an-offline-machine/ https://spin.atomicobject.com/2013/11/24/secure-gpg-keys-guide/ https://rnorth.org/gpg-and-ssh-with-yubikey-for-mac Amazon Association disclaimer I'm trying a little experiment with the Amazon Association program. Basically, if you click on any of the YubiKey links and decide to buy it, I will get a little commission from it. I've never tried this before and I've no idea if it works or not. I'm writing this here just for the sake of transparency.","tags":"HowTo","url":"https://www.andreagrandi.it/2017/09/30/configuring-offline-gnupg-masterkey-subkeys-on-yubikey/","loc":"https://www.andreagrandi.it/2017/09/30/configuring-offline-gnupg-masterkey-subkeys-on-yubikey/"},{"title":"Getting latest Ubuntu AMI with Terraform","text":"When we need to create an EC2 resource on AWS using Terraform, we need to specify the AMI id to get the correct image. The id is not easy to memorise and it changes depending on the zone we are working one. On every new release the id changes again. So, how can we be sure to get the correct ID for our region, of the latest image available for a given Linux distribution? Getting latest Ubuntu AMI id In this example I will show how to get the ID for the latest version of Ubuntu 16.04 server, for the London region and create an EC2 instance using that ID. variable \"aws_region\" { default = \"eu-west-2\" } # London provider \"aws\" { region = \"${var.aws_region}\" access_key = \"youraccesskey\" secret_key = \"yoursecretkey\" } data \"aws_ami\" \"ubuntu\" { most_recent = true filter { name = \"name\" values = [ \"ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-*\" ] } filter { name = \"virtualization-type\" values = [ \"hvm\" ] } owners = [ \"099720109477\" ] # Canonical } resource \"aws_instance\" \"web\" { ami = \"${data.aws_ami.ubuntu.id}\" instance_type = \"t2.micro\" tags { Name = \"HelloUbuntu\" } } output \"image_id\" { value = \"${data.aws_ami.ubuntu.id}\" } After we have initialised our script using terraform init if we run it, we will get the AMI id and the instance will be created: ➜ example1$ : terraform apply data . aws_ami . ubuntu : Refreshing state ... aws_instance . web : Creating ... ami : \"\" => \"ami-03998867\" associate_public_ip_address : \"\" => \"<computed>\" availability_zone : \"\" => \"<computed>\" ebs_block_device . # : \"\" => \"<computed>\" ephemeral_block_device . # : \"\" => \"<computed>\" instance_state : \"\" => \"<computed>\" instance_type : \"\" => \"t2.micro\" ipv6_address_count : \"\" => \"<computed>\" ipv6_addresses . # : \"\" => \"<computed>\" key_name : \"\" => \"<computed>\" network_interface . # : \"\" => \"<computed>\" network_interface_id : \"\" => \"<computed>\" placement_group : \"\" => \"<computed>\" primary_network_interface_id : \"\" => \"<computed>\" private_dns : \"\" => \"<computed>\" private_ip : \"\" => \"<computed>\" public_dns : \"\" => \"<computed>\" public_ip : \"\" => \"<computed>\" root_block_device . # : \"\" => \"<computed>\" security_groups . # : \"\" => \"<computed>\" source_dest_check : \"\" => \"true\" subnet_id : \"\" => \"<computed>\" tags . % : \"\" => \"1\" tags . Name : \"\" => \"HelloUbuntu\" tenancy : \"\" => \"<computed>\" volume_tags . % : \"\" => \"<computed>\" vpc_security_group_ids . # : \"\" => \"<computed>\" aws_instance . web : Still creating ... ( 10 s elapsed ) aws_instance . web : Still creating ... ( 20 s elapsed ) aws_instance . web : Still creating ... ( 30 s elapsed ) aws_instance . web : Creation complete ( ID : i - 0 f58f8bd55b3a7e38 ) Apply complete ! Resources : 1 added , 0 changed , 0 destroyed . Outputs : image_id = ami - 03998867 That's all we need to spin up an EC2 instance on AWS using latest Ubuntu image available.","tags":"Development","url":"https://www.andreagrandi.it/2017/08/25/getting-latest-ubuntu-ami-with-terraform/","loc":"https://www.andreagrandi.it/2017/08/25/getting-latest-ubuntu-ami-with-terraform/"},{"title":"Creating a production ready API with Python and Django Rest Framework – part 4","text":"In the previous part of the tutorial we implemented details management, relations between models, nested APIs and a different level of permissions. Our API is basically complete but it is working properly? Is the source code free of bugs? Would you feel confident to refactor the code without breaking something? The answer to all our question is probably no. I can't be sure if the code behaves properly nor I would feel confident refactoring anything without having some tests coverage . As I mentioned previously, we should have written tests since the beginning, but I really didn't want to mix too many concepts together and I wanted to let the user concentrate on the Rest Framework instead. Test structure and configuration Before beginning the fourth part of this tutorial, make sure you have grabbed the latest source code from https://github.com/andreagrandi/drf-tutorial and you have checked out the previous git tag: git checkout tutorial-1.14 Django has an integrated test runner but my personal choice is to use pytest , so as first thing let's install the needed libraries: pip install pytest pytest-django As long as we respect a minimum of conventions (test files must start with test_ prefix), tests can be placed anywhere in the code. My advice is to put them all together in a separate folder and divide them according to app names. In our case we are going to create a folder named \" tests \" at the same level of manage.py file. Inside this folder we need to create a __init__.py file and another folder called catalog with an additional __init__.py inside. Now, still at the same level of manage.py create a file called pytest.ini with this content: [ pytest ] DJANGO_SETTINGS_MODULE = drftutorial . settings Are you feeling confused? No problem. You can checkout the source code containing these changes. git checkout tutorial-1.15 You can check if you have done everything correctly going inside the drftutorial folder (the one containing manage.py ) and launching pytest . If you see something like this, you did your changes correctly: ( drf-tutorial ) ➜ drftutorial git: ( master ) pytest ============================================================================================================================= test session starts ============================================================================================================================== platform darwin -- Python 2 .7.13, pytest-3.0.6, py-1.4.32, pluggy-0.4.0 Django settings: drftutorial.settings ( from ini file ) rootdir: /Users/andrea/Projects/drf-tutorial/drftutorial, inifile: pytest.ini plugins: django-3.1.2 collected 0 items ========================================================================================================================= no tests ran in 0 .01 seconds ========================================================================================================================= ( drf-tutorial ) ➜ drftutorial git: ( master ) Writing the first test To begin with, I will show you how to write a simple test that will verify if the API can return the products list. If you remember we implemented this API in the first part of the tutorial. First of all create a file called test_views.py under the folder drftutorial/tests/catalog/ and add this code: import pytest from django.urls import reverse from rest_framework import status from rest_framework.test import APITestCase class TestProductList ( APITestCase ): @pytest . mark . django_db def test_can_get_product_list ( self ): url = reverse ( 'product-list' ) response = self . client . get ( url ) self . assertEqual ( response . status_code , status . HTTP_200_OK ) self . assertEqual ( len ( response . json ()), 8 ) before being able to run this test we need to change a little thing in the catalog/urls.py file, something we should have done since the beginning. Please change the first url in this way, adding the name parameter: urlpatterns = [ url ( r '&#94;products/$' , views . ProductList . as_view (), name = 'product-list' ), ... at this point we are able to run our test suite again and verify the test is passing: ( drf-tutorial ) ➜ drftutorial git: ( test-productlist ) ✗ pytest -v ============================================================================================================================= test session starts ============================================================================================================================== platform darwin -- Python 2 .7.13, pytest-3.0.6, py-1.4.32, pluggy-0.4.0 -- /Users/andrea/.virtualenvs/drf-tutorial/bin/python2.7 cachedir: .cache Django settings: drftutorial.settings ( from ini file ) rootdir: /Users/andrea/Projects/drf-tutorial/drftutorial, inifile: pytest.ini plugins: django-3.1.2 collected 1 items tests/catalog/test_views.py::TestProductList::test_can_get_product_list PASSED =========================================================================================================================== 1 passed in 0 .98 seconds =========================================================================================================================== To checkout the source code at this point: git checkout tutorial-1.16 Explaining the test code When we implement a test, the first thing to do is to create a test_* file and import the minimum necessary to write a test class and method. Each test class must inherit from APITestCase and have a name that start with Test , like TestProductList . Since we use pytest , we need to mark our method with @pytest.mark.django_db decorator , to tell the test suite our code will explicitly access the database. We are going to use the client object that is integrated in APITestCase to perform the request. Before doing that we first get the local url using Django's reverse function. At this point we do the call using the client: response = self . client . get ( url ) and then we assert a couple of things that we expect to be true: self . assertEqual ( response . status_code , status . HTTP_200_OK ) self . assertEqual ( len ( response . json ()), 8 ) We check that our API returns the 200 status code and that in the returned JSON there are 8 elements. It's normally a good practice to create test data inside the tests, but in our case we previously created a data migration that creates test data. Migrations are run every time we run tests so when we call our API, the data will be already there. Wrapping up I've written a few tests for all the views we have implemented until now and they are available if you checkout this version of the code: git checkout tutorial-1.17 I've only tested the views but it would be nice to test even the permission class, for example. Please remember to write your tests first, if possible: implementing the code will be much more natural once the tests are already in place.","tags":"Development","url":"https://www.andreagrandi.it/2017/08/17/creating-a-production-ready-api-with-python-and-django-rest-framework-part-4/","loc":"https://www.andreagrandi.it/2017/08/17/creating-a-production-ready-api-with-python-and-django-rest-framework-part-4/"},{"title":"Migrating from WordPress to a static generated website","text":"As you may have noticed, my website looks very different compared to a few days ago. It's just a different theme or template, I completely changed how the pages are generated and I'm hosting it in a completely different way. A brief history When I started this blog 10 years ago, I was hosting it on a shared hosting service and it was based on WordPress . I then decided to keep WordPress as backend (I don't like PHP very much but I wasn't even good at front end development at the time, so using a tool that allowed me to concentrate on the content rather than on design was a natural choice for me) but to move my website to a VPS on DigitalOcean , where I've self-hosted Nginx + PHP + MySQL and even Postfix for email aliases until a few days ago. Why moving to a static website? In these three or four years I've been using a VPS, I must say I've been good enough (or maybe lucky?) at keeping \"bad people\" out of my server, but it's true that maintaining a VPS can be very time consuming and you can never be sure that your website is always safe. I've heard about static website before, but I was a bit skeptic because I had not spent enough time investigating all the possibilities (search and comments are still possible, thanks to external services and plugins). Another advantage of a static website is that I can perfectly \"run\" (preview) on my local computer without publishing it online. Pages can be rendered locally and will appear in the browser exactly as they will appear once published online. If you use a tool like WordPress, you need to be constantly connected to Internet to write any change. With static pages I can write my content offline (so I can do it while commuting on the train or while I'm flying somewhere) and publish it once I'm back online. Pelican The tool that I'm using to generate this website is called Pelican . There are many static website generators , the reason why I chose Pelican is because it's written in Python , so if I need to do any change I can do them and because its templates use Jinja2 which I'm already familiar with. It can also import posts from WordPress (and I had over 180 posts to import from my previous website) so if you are migrating from it it's a good choice. Please note that the import script is not perfect and that you may have to adjust some formatting here and there. A new deployment pipeline When you use WordPress your website is already online and all you have to do is to login, use the integrated editor, write content and finally publish it. A static website doesn't have any admin tool, it's just static pages. How do you publish content then? There are of course multiple solutions available. In my case my website source code is hosted in a repository on GitHub . When I commit on master branch there is a webhook that triggers a build job on TravisCI . TravisCI fetches the latest source code, installs Pelican on the CI and builds the static pages. Once the build is finished, a bash script is used to publish the generated pages on the static website hosting service. Hosting a static website The good thing about hosting a static website is that you don't need a database so you can host it almost anywhere at a cheaper price or even for free. In my case I've decided to use GitHub pages , mainly for simplicity. Every GitHub user can have a static website hosted at <yourusername>.github.io for free. To start using it, you just have to create a repository named <yourusername>.github.io under your GitHub account. In my case the repository is https://github.com/andreagrandi/andreagrandi.github.io . My deploy script simply takes the generated content that is in the output/ folder and git push it on this repository. Once the website has been pushed to git, it's immediately available at https://andreagrandi.github.io CloudFlare GitHub Pages service has a little limitation: you can either have your website served from a URL similar to the one I've just mentioned, including SSL support or you can use your own domain, but you can't have both things (SSL + custom domain). To workaround this, you can instruct your domain registrar (in my case is Gandi.net ) to let CloudFlare manage your domain and just enabling \"Full SSL\" support will do the trick. I won't repeat here how to use CloudFlare since they have a very nice tutorial explaining how to configure their service to be used with GitHub Pages: https://blog.cloudflare.com/secure-and-fast-github-pages-with-cloudflare/ . Remember to include a CNAME file containing your domain name and let your static generetor put it on the root of your website, otherwise GitHub pages won't serve the pages correctly. Why not Amazon S3? While I was looking for instructions about how to host a static websites, I found many examples of websites using Amazon S3. There is nothing wrong with using this service (just keep in mind that it's not free, Amazon charges you for space usage and requests, so keep an eye on the AWS bill) but the way these websites were using it was completely wrong. The most common error I noticed was the fact they were enabling the flexible SSL option on CloudFlare: this means that the connection between the visitor and CloudFlare was encrypted (and visitor could see the the SSL enabled) but the connection between CloudFlare and Amazon S3 was being served with HTTP only , meaning that potentially the pages could have been modified before being served. Infact Amazon doesn't serve the S3 website buckets with SSL, they use plain HTTP (Why are you doing this Amazon?!). To use the S3 bucket correctly one should also configure Route 53 (to manage DNS) and CloudFront (the Amazon equivalent of CloudFlare service, beware because this is also charged separately depending on usage/traffic), making the whole setup a bit more complicated. Conclusion I finally moved away from my VPS and from now on I will be able to concentrate my time on content only instead of spending part of it to maintain my server. Last but not least, the possibility to write my content offline, will hopefully allow me to write from places (train, airplane) where I've never written from before. If you have any suggestion or if if you notice any error, feel free to leave a comment here below. In alternative, since now this blog is completely open source and on GitHub, you can fork it and make a pull request!","tags":"Development","url":"https://www.andreagrandi.it/2017/07/02/migrating-from-wordpress-to-static-generated-website/","loc":"https://www.andreagrandi.it/2017/07/02/migrating-from-wordpress-to-static-generated-website/"},{"title":"Creating a production ready API with Python and Django Rest Framework – part 3","text":"In the previous part we implemented authentication, permissions and the possibility to POST new products for admins. In this new episode we will see how to implement details management, relations between models, nested APIs and a different level of permissions. If you haven't completed the previous parts or if you want to begin from this one, checkout the right code first: git checkout tutorial-1.10 Handling Product Details Our current API methods allow us to list all the products we have in our catalog and to create a new one (if we have admin permissions), but what if we wanted to delete or update a single one? What if we wanted to get only a specific product? We need to handle details. As first thing we need to change the ProductSerializer to return the id of the product. Edit catalog/serializers.py and change the class in this way: class ProductSerializer ( serializers . ModelSerializer ): class Meta : model = Product fields = ( 'id' , 'name' , 'description' , 'price' ) After changing the serializer we need to implement a new view called ProductDetail . Edit catalog/views.py and add the following imports: from django.http import Http404 from rest_framework.response import Response from rest_framework.views import APIView from rest_framework import status and the following class: class ProductDetail ( APIView ): def get_object ( self , pk ): try : return Product . objects . get ( pk = pk ) except Product . DoesNotExist : raise Http404 def get ( self , request , pk , format = None ): product = self . get_object ( pk ) serializer = ProductSerializer ( product ) return Response ( serializer . data ) def put ( self , request , pk , format = None ): product = self . get_object ( pk ) serializer = ProductSerializer ( product , data = request . data ) if serializer . is_valid (): serializer . save () return Response ( serializer . data ) return Response ( serializer . errors , status = status . HTTP_400_BAD_REQUEST ) def delete ( self , request , pk , format = None ): product = self . get_object ( pk ) product . delete () return Response ( status = status . HTTP_204_NO_CONTENT ) let's connect the new view to the urls, editing catalog/urls.py and changing the code in this way: urlpatterns = [ url ( r '&#94;products/$' , views . ProductList . as_view ()), url ( r '&#94;products/(?P<pk>[0-9]+)/$' , views . ProductDetail . as_view ()), ] If we try to PUT , DELETE or GET a product like /products/1/ we can now update, delete or retrieve an existing item, but there is a little problem: we haven't set any permission on this class, so anyone can do it. The previous view was also more compact, why don't we use a generic view to perform these basic operations? Let's refactor ProductDetail with a RetrieveUpdateDestroyAPIView generic class. Open catalog/views.py and change the class code in this way: class ProductDetail ( generics . RetrieveUpdateDestroyAPIView ): queryset = Product . objects . all () serializer_class = ProductSerializer permission_classes = ( IsAdminOrReadOnly , ) That's it! With just three lines of code we have now implemented the same feature of the previous class, plus we have set the correct permissions. To checkout the code at this point: git checkout tutorial-1.12 Reviews - Relations between models As many online catalogs already have, it would be nice if our API had an endpoint where it is possible to leave a review for a product and get a list of reviews for a specific product. To implement this feature we need to add a new model to our application. Edit catalog/models.py adding this import: from django.contrib.auth.models import User and this Django model: class Review ( models . Model ): product = models . ForeignKey ( Product , related_name = 'reviews' ) title = models . CharField ( max_length = 255 ) review = models . TextField () rating = models . IntegerField () created_by = models . ForeignKey ( User ) after creating the model, please remember to create the related DB migration : $ ./manage.py makemigrations catalog When the model is ready, we have to do some changes to the serializers. First of all we need to write a new one, for our new Review model. Then we have to change our ProductSerializer so that it will return its related reviews. Each Product can have multiple Review. And each Review will be always linked to a specific Product. Edit catalog/serializers.py and change it in this way: from .models import Product , Review from rest_framework import serializers class ReviewSerializer ( serializers . ModelSerializer ): created_by = serializers . ReadOnlyField ( source = 'created_by.username' ) class Meta : model = Review fields = ( 'id' , 'title' , 'review' , 'rating' , 'created_by' ) class ProductSerializer ( serializers . ModelSerializer ): reviews = ReviewSerializer ( many = True , read_only = True ) class Meta : model = Product fields = ( 'id' , 'name' , 'description' , 'price' , 'reviews' ) Note: in ReviewSerializer when we serialise the user contained in created_by field, return the username instead of the id (to make it more human readable). Another important thing to notice is that the value of the related_name we have set in the Review model must match with the field name we have added in ProductSerializer fields property. In this case we have set it to reviews . At this point we need to add a new view. Edit catalog/views.py and add the following imports: from rest_framework.permissions import IsAuthenticatedOrReadOnly from .models import Product , Review from .serializers import ProductSerializer , ReviewSerializer then add this class: class ReviewList ( generics . ListCreateAPIView ): queryset = Review . objects . all () serializer_class = ReviewSerializer permission_classes = ( IsAuthenticatedOrReadOnly , ) def perform_create ( self , serializer ): serializer . save ( created_by = self . request . user , product_id = self . kwargs [ 'pk' ]) As you can notice, I had to customise the perform_create method because the default one doesn't know anything about the fact we want to set the created_by and product_id fields. Finally we need to bind this new view to a specific url, so we need to edit catalog/urls.py and add this: ... url ( r '&#94;products/(?P<pk>[0-9]+)/reviews/$' , views . ReviewList . as_view ()), ] At this point any authenticated user should be able to POST a review for a product and anyone should be able to get the list of reviews for each product. If you have any problem with the code and want to move to this point, please checkout this: git checkout tutorial-1.13 Nested APIs details To complete our API endpoints for Review, we need to add an additional feature that will let users to edit/delete their own review. Before implementing the new view, we need a little bit of refactoring and a new permission class. Edit catalog/permissions.py and add this new class: class IsOwnerOrReadOnly ( BasePermission ): def has_object_permission ( self , request , view , obj ): if request . method in SAFE_METHODS : return True return obj . created_by == request . user Basically this will permit changes to the review only to its author. Now we are going to add new urls and doing some refactoring at the same time. Edit catalog/urls.py and change the urls in this way: urlpatterns = [ url ( r '&#94;products/$' , views . ProductList . as_view ()), url ( r '&#94;products/(?P<product_id>[0-9]+)/$' , views . ProductDetail . as_view ()), url ( r '&#94;products/(?P<product_id>[0-9]+)/reviews/$' , views . ReviewList . as_view () ), url ( r '&#94;products/(?P<product_id>[0-9]+)/reviews/(?P<review_id>[0-9]+)/$' , views . ReviewDetail . as_view () ), ] You may have noticed that I substituted pk with product_id . In the latest url I added, we need to be able to identify two primary keys: the one for the product and the one for the review. I renamed the previous ones for consistency. Now it's time to add the new view for Review details. Edit catalog/view.py and add this class: class ReviewDetail ( generics . RetrieveUpdateDestroyAPIView ): serializer_class = ReviewSerializer permission_classes = ( IsAuthenticatedOrReadOnly , IsOwnerOrReadOnly ) lookup_url_kwarg = 'review_id' def get_queryset ( self ): review = self . kwargs [ 'review_id' ] return Review . objects . filter ( id = review ) What are we doing here? You may have noticed that we set a new property called lookup_url_kwarg . That property is being used to determine the keyword in urls.py to be used for the primary key lookup. You will also need to do some refactoring to the other views, to adapt them to the changes we just did to the urls. I suggest you to have a look at the diffs here: https://github.com/andreagrandi/drf-tutorial/compare/tutorial-1.13...tutorial-1.14 or you can have a look at the whole file here https://github.com/andreagrandi/drf-tutorial/blob/541bf31c11fd1dbf2bcc1d31312086995e3e5b48/drftutorial/catalog/views.py In alternative, you can fetch the whole source code at this point: git checkout tutorial-1.14 Wrapping Up In this third part of the tutorial you learned how to handle model details in the API and how relations between different model work. In the next part of the tutorial we will do something we should have done since the beginning: adding tests to our code and learn how to properly test the API. Feedback Please If you enjoyed this tutorial, please leave me some feedback! I really want to improve my work, based on the users feedback so any little advice will be appreciated, thanks!","tags":"Development","url":"https://www.andreagrandi.it/2017/03/12/creating-a-production-ready-api-with-python-and-django-rest-framework-part-3/","loc":"https://www.andreagrandi.it/2017/03/12/creating-a-production-ready-api-with-python-and-django-rest-framework-part-3/"},{"title":"Creating a production ready API with Python and Django Rest Framework – part 2","text":"In the first part of this tutorial we have seen how to create a basic API using Django Rest Framework . This second part will explain how to implement POST methods and add different levels of permissions and authentication . If you are starting from part 2, you may want to checkout the source code at this exact point: git checkout tutorial-1.4 A step back Before showing how easy it is to implement a POST method for our existing API, I want to do a step back and show you the \"manual way\", using just the APIView class. Edit the file catalog/views.py and change the code in this way: from django.http import HttpResponse from rest_framework.response import Response from rest_framework.views import APIView from .models import Product from .serializers import ProductSerializer class ProductList ( APIView ): def get ( self , request , format = None ): products = Product . objects . all () serializer = ProductSerializer ( products , many = True ) return Response ( serializer . data ) If we try to use the API again (from the browser of from the http client), it will still work in the same way. The difference here is that we are using the very basic APIView class and we have explicitly defined the GET method for it. Implementing a POST method with APIView An API is not being used at its full potential if it's read only. We are going to implement a POST method for the existing view and testing it with httpie client again. First of all we need to add an import to catalog/views.py from rest_framework import status then we add this method to our ProductList class: def post ( self , request , format = None ): serializer = ProductSerializer ( data = request . data ) if serializer . is_valid (): serializer . save () return Response ( serializer . data , status = status . HTTP_201_CREATED ) return Response ( serializer . errors , status = status . HTTP_400_BAD_REQUEST ) Now let's test our POST method we just implemented: $ http --json POST http://127.0.0.1:8000/products/ name = \"Salamino\" description = \"Salamino Piccante\" price = \"10.50\" HTTP/1.0 201 Created Allow: GET, POST, HEAD, OPTIONS Content-Type: application/json Date: Thu, 29 Sep 2016 11 :48:48 GMT Server: WSGIServer/0.1 Python/2.7.10 Vary: Accept, Cookie X-Frame-Options: SAMEORIGIN { \"description\" : \"Salamino Piccante\" , \"name\" : \"Salamino\" , \"price\" : \"10.50\" } It works! In case something doesn't work, try to fetch the source code at this point: git checkout tutorial-1.7 Implementing a POST method with ListCreateAPIView Do you remember when I mentioned at the beginning that there is an easy way to do the same thing? I wasn't cheating. Let's change again our old code in catalog/views.py but this time we will use a different base class: from django.http import HttpResponse from rest_framework import generics from rest_framework.response import Response from .models import Product from .serializers import ProductSerializer class ProductList ( generics . ListCreateAPIView ): queryset = Product . objects . all () serializer_class = ProductSerializer let's test this again with httpie : $ http --json POST http://127.0.0.1:8000/products/ name = \"Pecorino\" description = \"Pecorino Sardo\" price = \"7.00\" HTTP/1.0 201 Created Allow: GET, POST, HEAD, OPTIONS Content-Type: application/json Date: Thu, 29 Sep 2016 15 :21:20 GMT Server: WSGIServer/0.1 Python/2.7.10 Vary: Accept, Cookie X-Frame-Options: SAMEORIGIN { \"description\" : \"Pecorino Sardo\" , \"name\" : \"Pecorino\" , \"price\" : \"7.00\" } We just POSTed some data on the API! How can it work? Well, we have changed the base class from ListAPIView to ListCreateAPIView . This particular class implements a generic POST method that will accept and validate all the fields through the specified serializer. Authentication Now our API let us add products to the catalog, amazing! But... is it exactly what we want? In a real scenario we don't want any random user to be able to add products in our database, so we are going to protect the POST method allowing only Admin users. Before digging into Django Rest Framework permissions, we need to setup an authentication system. For simplicity we will implement TokenAuthentication . As first step we need to edit settings.py and insert rest_framework.authtoken in the INSTALLED_APPS : ... 'rest_framework' , 'rest_framework.authtoken' , 'catalog' , ] after this, we need to add TokenAuthentication as default authentication class (append this in settings.py at the end): REST_FRAMEWORK = { 'DEFAULT_AUTHENTICATION_CLASSES' : ( 'rest_framework.authentication.TokenAuthentication' , ) } Finally we need to add a particular URL to the project so that clients will be able to call an endpoint passing username and password to get a token back. Edit drftutorial/urls.py and make it's like this: from django.conf.urls import url , include from django.contrib import admin from rest_framework.authtoken.views import obtain_auth_token urlpatterns = [ url ( r '&#94;admin/' , admin . site . urls ), url ( r '&#94;' , include ( 'catalog.urls' )), url ( r '&#94;api-token-auth/' , obtain_auth_token ), ] Don't forget to re-run the migrations , because TokenAuthorization needs to change a couple of tables: $ ./manage.py migrate Operations to perform: Apply all migrations: admin, auth, authtoken, catalog, contenttypes, sessions Running migrations: Applying authtoken.0001_initial... OK Applying authtoken.0002_auto_20160226_1747... OK In case you had any problem changing the code up to this point, you can always fetch the related git tag: git checkout tutorial-1.9 Testing the Authentication Before testing the authentication, make sure you created at least the Django superuser with: $ ./manage.py createsuperuser now let's try to obtain the token we will need later for our API calls: $ http --json POST http://127.0.0.1:8000/api-token-auth/ username = \"yourusername\" password = \"yourpassword\" HTTP/1.0 200 OK Allow: POST, OPTIONS Content-Type: application/json Date: Fri, 30 Sep 2016 08 :55:07 GMT Server: WSGIServer/0.1 Python/2.7.11 X-Frame-Options: SAMEORIGIN { \"token\" : \"bc9514f0892368cfd0ea792a977aff55d53e3634\" } We will need to pass this token in every API call we want to be authenticated. The token is being passed through the \"Authentication\" header parameter. API Permissions Authentication is something that identify the user with a particular system. Permissions instead are the level of things that are allowed or not allowed for a particular user. In our case we said we want to let Admin users to be able to POST new products and we want to let even anonymous users to GET the product list. Django Rest Framework has some built-in classes that we can apply to our views to define the level of permissions. We could have used the IsAdminUser class, but it would not allow anonymous users to perform the GET request. Or we could have used IsAuthenticatedOrReadOnly class, but this would allow any registered user to add products (and we want to let only admins). Or...we can define our own permission class and have exactly what we want. Create a new file catalog/permissions.py from rest_framework.permissions import BasePermission , SAFE_METHODS class IsAdminOrReadOnly ( BasePermission ): def has_permission ( self , request , view ): if request . method in SAFE_METHODS : return True else : return request . user . is_staff Just as a side note, SAFE_METHODS are GET , HEAD and OPTIONS . These method are considered \"safe\" because they don't change any existing data. Open catalog/views.py again, import this at the beginning: from .permissions import IsAdminOrReadOnly and set this as permission_classes to ProductList : ... serializer_class = ProductSerializer permission_classes = ( IsAdminOrReadOnly , ) Let's now try to add a new product using the token we got before (you will have to use your own token of course, mine only works on my local db): $ http --json POST http://127.0.0.1:8000/products/ name = \"Lardo\" description = \"Lardo di Colonnata\" price = \"8.50\" 'Authorization: Token bc9514f0892368cfd0ea792a977aff55d53e3634' HTTP/1.0 201 Created Allow: GET, POST, HEAD, OPTIONS Content-Type: application/json Date: Fri, 30 Sep 2016 13 :04:13 GMT Server: WSGIServer/0.1 Python/2.7.11 Vary: Accept X-Frame-Options: SAMEORIGIN { \"description\" : \"Lardo di Colonnata\" , \"name\" : \"Lardo\" , \"price\" : \"8.50\" } It worked! We have now protected our API so that not admin people can't create any product. If you have any problem with the code, you can check it out with this tag: git checkout tutorial-1.10 Wrapping Up We have now implemented the POST method to add new products to our catalog. In the next episode we will see how to implement endpoints to get a single product, to update or delete products and finally we will allow registered users to send a review for a specific product. Feedback Please I know, this blog doesn't have any \"comment\" feature (I was tired of dealing with spam), but if you want to provide some feedback you can still do it by email. Just visit my About page, you will find my email there.","tags":"Development","url":"https://www.andreagrandi.it/2016/10/01/creating-a-production-ready-api-with-python-and-django-rest-framework-part-2/","loc":"https://www.andreagrandi.it/2016/10/01/creating-a-production-ready-api-with-python-and-django-rest-framework-part-2/"},{"title":"Creating a production ready API with Python and Django Rest Framework - part 1","text":"The aim if this tutorial is to show how to create a production ready solution for a REST API , using Python and Django Rest Framework . I will show you how to first create a very basic API, how to handle the authentication and permissions and I will cover deployment and hosting of images. The full source code of the tutorial is available at: https://github.com/andreagrandi/drf-tutorial Summary of the complete tutorial Create the basic structure for the API Add Authentication and POST methods Handling details and changes to existing data Testing the API Switching from Sqlite to PostgreSQL Hosting the API on Heroku Add an Image field and save images to S3 Create the basic structure for the API For this tutorial I will assume you have correctly installed at least Python (I will use Python 2.7.x), virtualenv and virtualenvwrapper on your system and I will explain how to create everything else step by step. Note: at the time of writing, the tutorial has been based on Django 1.10.1 and Django Rest Framework 3.4.7 Creating the main project structure mkdir drf-tutorial mkvirtualenv drf-tutorial cd drf-tutorial pip install django djangorestframework django-admin.py startproject drftutorial . cd drftutorial django-admin.py startapp catalog Data Model We will create the API for a generic products catalog, using a very simple structure (to keep things simple). Edit the file catalog/models.py adding these lines: from __future__ import unicode_literals from django.db import models class Product ( models . Model ): name = models . CharField ( max_length = 255 ) description = models . TextField () price = models . DecimalField ( decimal_places = 2 , max_digits = 20 ) after creating the model, we need to add 'catalog' application to INSTALLED_APPS . Edit settings.py and add the app at the end of the list: INSTALLED_APPS = [ 'django.contrib.admin' , 'django.contrib.auth' , 'django.contrib.contenttypes' , 'django.contrib.sessions' , 'django.contrib.messages' , 'django.contrib.staticfiles' , 'catalog' , ] at this point the Django application will be recognised by the project and we can create and apply the schema migration: ( drf-tutorial ) ➜ drftutorial git: ( 235dfcc ) ✗ ./manage.py makemigrations Migrations for 'catalog' : catalog/migrations/0001_initial.py: - Create model Product ( drf-tutorial ) ➜ drftutorial git: ( 235dfcc ) ✗ ./manage.py migrate Operations to perform: Apply all migrations: admin, auth, catalog, contenttypes, sessions Running migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying catalog.0001_initial... OK Applying sessions.0001_initial... OK API Serializer Serializers are those components used to convert the received data from JSON format to the relative Django model and viceversa. Create the new file catalog/serializers.py and place this code inside: from .models import Product from rest_framework import serializers class ProductSerializer ( serializers . ModelSerializer ): class Meta : model = Product fields = ( 'name' , 'description' , 'price' ) In this case we are using a ModelSerializer . We need to create a new class from it, and specify the model attribute, that's it. In this case we also specify the fields we want to return. API View The serializer alone is not able to respond to an API request, that's why we need to implement a view. In this first version of the view (that we will improve soon) we will \"manually\" transform the data available in the serializer dictionary to a JSON response. In catalog/views.py add this code: from django.http import HttpResponse from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from .models import Product from .serializers import ProductSerializer class JSONResponse ( HttpResponse ): \"\"\" An HttpResponse that renders its content into JSON. \"\"\" def __init__ ( self , data , ** kwargs ): content = JSONRenderer () . render ( data ) kwargs [ 'content_type' ] = 'application/json' super ( JSONResponse , self ) . __init__ ( content , ** kwargs ) def product_list ( request ): if request . method == 'GET' : products = Product . objects . all () serializer = ProductSerializer ( products , many = True ) return JSONResponse ( serializer . data ) At this point we need to tell our Django app to use this API view when a certain URL is requested. We first need to add this code in catalog/urls.py from django.conf.urls import url from . import views urlpatterns = [ url ( r '&#94;products/$' , views . product_list ), ] and finally we need to add this to drftutorial/urls.py from django.conf.urls import url , include from django.contrib import admin urlpatterns = [ url ( r '&#94;admin/' , admin . site . urls ), url ( r '&#94;' , include ( 'catalog.urls' )), ] Testing our work At this point we should be able to start our Django app: ./manage.py runserver Let's install a tool that will help us to test the API: pip install httpie now we can use it to call our URL: $ http http://127.0.0.1:8000/products/ HTTP/1.0 200 OK Content-Type: application/json Date: Wed, 28 Sep 2016 09 :54:50 GMT Server: WSGIServer/0.1 Python/2.7.11 X-Frame-Options: SAMEORIGIN [] It works! It's an empty response of course, because we still don't have any data to show, but we will see later how to load some example data in our database. If you have been able to follow the tutorial up to this point, that's good. If not, don't worry. You can checkout the code at exactly this point of the tutorial doing: git checkout tutorial-1.0 Improving the API View There is a quicker and more efficient way of implementing the same API view we have seen before. We can use a class based view, in particular the APIView class and also have the JSON response implemented automatically. Change the code inside catalog/views.py with this one: from django.http import HttpResponse from rest_framework.views import APIView from rest_framework.response import Response from .models import Product from .serializers import ProductSerializer class ProductList ( APIView ): def get ( self , request , format = None ): products = Product . objects . all () serializer = ProductSerializer ( products , many = True ) return Response ( serializer . data ) You will also have to change catalog/urls.py in this way: urlpatterns = [ url ( r '&#94;products/$' , views . ProductList . as_view ()), ] You can check the source code for this step of the tutorial with: git checkout tutorial - 1.1 There is also another way of writing the same view. Let's try it with ListAPIView . Edit catalog/views.py again and substitute the code with this one: from django.http import HttpResponse from rest_framework import generics from rest_framework.response import Response from .models import Product from .serializers import ProductSerializer class ProductList ( generics . ListAPIView ): queryset = Product . objects . all () serializer_class = ProductSerializer With a ListAPIView we are basically creating a read-only API that is supposed to return a list of items. We need to specify a queryset and the serializer_class parameters. Once again, you can get up to this point, checking out the related git tag: git checkout tutorial-1.2 Creating Initial Data An API that doesn't return any data is not very useful, right? Also, at the moment we haven't implemented yet any feature that let us insert any data. That's why I've created a data migration for you that will insert some data for you. You may notice that the example data contains some Italian products... out of the scope of this tutorial, I strongly advise you to google this products and if you ever happen to visit Italy, try them. You won't regret! Going back to our data migration, you first have to create an empty one with: ./manage.py makemigrations --empty catalog and then open the file that has been created under catalog/migrations/ named 0002_..... (your name will be different from mine, so just edit the one starting with 0002 and you will be fine) and fill it with this code: from __future__ import unicode_literals from django.db import migrations def create_initial_products ( apps , schema_editor ): Product = apps . get_model ( 'catalog' , 'Product' ) Product ( name = 'Salame' , description = 'Salame Toscano' , price = 12 ) . save () Product ( name = 'Olio Balsamico' , description = 'Olio balsamico di Modena' , price = 10 ) . save () Product ( name = 'Parmigiano' , description = 'Parmigiano Reggiano' , price = 8.50 ) . save () Product ( name = 'Olio' , description = 'Olio Oliva Toscano' , price = 13 ) . save () Product ( name = 'Porchetta' , description = 'Porchetta toscana cotta a legna' , price = 7.50 ) . save () Product ( name = 'Cantucci' , description = 'Cantucci di Prato' , price = 4 ) . save () Product ( name = 'Vino Rosso' , description = 'Vino Rosso del Chianti' , price = 9.50 ) . save () Product ( name = 'Brigidini' , description = 'Brigidini di Lamporecchio' , price = 3.50 ) . save () class Migration ( migrations . Migration ): dependencies = [ ( 'catalog' , '0001_initial' ), ] operations = [ migrations . RunPython ( create_initial_products ), ] to apply the migration we just created, just do: ./manage.py migrate If you try to test the API again from the command line, you will get these products back: $ http http://127.0.0.1:8000/products/ HTTP/1.0 200 OK Allow: GET, HEAD, OPTIONS Content-Type: application/json Date: Wed, 28 Sep 2016 12 :29:36 GMT Server: WSGIServer/0.1 Python/2.7.11 Vary: Accept, Cookie X-Frame-Options: SAMEORIGIN [ { \"description\" : \"Salame Toscano\" , \"name\" : \"Salame\" , \"price\" : \"12.00\" } , { \"description\" : \"Olio balsamico di Modena\" , \"name\" : \"Olio Balsamico\" , \"price\" : \"10.00\" } , { \"description\" : \"Parmigiano Reggiano\" , \"name\" : \"Parmigiano\" , \"price\" : \"8.50\" } , { \"description\" : \"Olio Oliva Toscano\" , \"name\" : \"Olio\" , \"price\" : \"13.00\" } , { \"description\" : \"Porchetta toscana cotta a legna\" , \"name\" : \"Porchetta\" , \"price\" : \"7.50\" } , { \"description\" : \"Cantucci di Prato\" , \"name\" : \"Cantucci\" , \"price\" : \"4.00\" } , { \"description\" : \"Vino Rosso del Chianti\" , \"name\" : \"Vino Rosso\" , \"price\" : \"9.50\" } , { \"description\" : \"Brigidini di Lamporecchio\" , \"name\" : \"Brigidini\" , \"price\" : \"3.50\" } ] Again, you can get up to this point with: git checkout tutorial-1.3 One more thing... No, we are not going to present a new amazing device, I'm sorry, but I want to show you a nice Django Rest Framework feature you can have without much additional work. Edit settings.py and add rest_framework to the list of INSTALLED_APPS : INSTALLED_APPS = [ 'django.contrib.admin' , 'django.contrib.auth' , 'django.contrib.contenttypes' , 'django.contrib.sessions' , 'django.contrib.messages' , 'django.contrib.staticfiles' , 'rest_framework' , 'catalog' , ] Now, if you are still running the Django app, try to visit this url from your browser: http://127.0.0.1:8000/products/ That's very nice, isn't it? You can have browsable APIs at no cost. Wrapping Up I've mentioned at the beginning that this is just the first part of my API tutorial. In the next part I will show you how to let the consumer of your API add some products and leave reviews (we will introduce a new model for this). Also, we will see how to set proper permissions to these new API methods so that only admin users will be able to add products while normal users will be able to add reviews. So, if you feel ready, you can begin to follow the second part of this tutorial References Some parts of this tutorial and a few examples have been taken directly from the original Django Rest Framework tutorial .","tags":"Development","url":"https://www.andreagrandi.it/2016/09/28/creating-production-ready-api-python-django-rest-framework-part-1/","loc":"https://www.andreagrandi.it/2016/09/28/creating-production-ready-api-python-django-rest-framework-part-1/"},{"title":"Using Python ipdb from Jupyter","text":"If we try to use the usual ipdb commands from a Jupyter (IPython notebook) import ipdb ; ipdb . set_trace () we will get a similar error: -------------------------------------------------------------------------- MultipleInstanceError Traceback ( most recent call last ) < ipython - input - 1 - f2b356251c56 > in < module > () 1 a = 4 ----> 2 import ipdb ; ipdb . set_trace () 3 b = 5 4 print a 5 print b / home / nnn / anaconda / lib / python2 . 7 / site - packages / ipdb / __init__ . py in < module > () 14 # You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/. 15 ---> 16 from ipdb.__main__ import set_trace , post_mortem , pm , run , runcall , runeval , launch_ipdb_on_exception 17 18 pm # please pyflakes / home / nnn / anaconda / lib / python2 . 7 / site - packages / ipdb / __main__ . py in < module > () 71 # the instance method will create a new one without loading the config. 72 # i.e: if we are in an embed instance we do not want to load the config. ---> 73 ipapp = TerminalIPythonApp . instance () 74 shell = get_ipython () 75 def_colors = shell . colors / home / nnn / anaconda / lib / python2 . 7 / site - packages / traitlets / config / configurable . pyc in instance ( cls , * args , ** kwargs ) 413 raise MultipleInstanceError ( 414 'Multiple incompatible subclass instances of ' --> 415 ' %s are being created.' % cls . __name__ 416 ) 417 MultipleInstanceError : Multiple incompatible subclass instances of TerminalIPythonApp are being created . The solution is to use Tracer instead: from IPython.core.debugger import Tracer Tracer ()() Source: http://stackoverflow.com/questions/35613249/using-ipdb-to-debug-python-code-in-one-cell-jupyter-or-ipython","tags":"Development","url":"https://www.andreagrandi.it/2016/05/10/using-python-ipdb-from-jupyter/","loc":"https://www.andreagrandi.it/2016/05/10/using-python-ipdb-from-jupyter/"},{"title":"How to publish a Python package to PyPI","text":"PyPI is the Python Package Index , that archive that let you install a package using pip, for example: pip install Flask In the past days I started writing a Python API client for Toshl expense manager and I decided to publish the library on PyPI. You can have a look at my library here https://github.com/andreagrandi/toshl-python (please note: it's still in development and Toshl API is not even public yet) in case you are not sure how to structure it. I found a nice guide but it wasn't complete (for example it didn't say how to sign packages) so I decided to rewrite it adding more information. Create PyPI accounts To publish packages on PyPI you need to create two accounts: one for the production server and another one for the test server . When you register, please specify (if you have one, but I really hope you do) the PGP id of your public key. Once the accounts are created, you need to create a file named .pypirc in your \\$HOME folder containing the following configuration: [ distutils ] index-servers = pypi pypitest [ pypi ] repository = https://pypi.python.org/pypi username = your_username password = your_password [ pypitest ] repository = https://testpypi.python.org/pypi username = your_username password = your_password Please substitute your_username and your_password with the details you sent during the registration. Preparing the package I assume you have structured your library in the proper way and have included a setup.py with all the configuration (it's not something specific to PyPI so you should have done it already). If you haven't I remember you can give a look at my library here https://github.com/andreagrandi/toshl-python in particular to the setup.py : from setuptools import setup , find_packages setup ( name = 'toshl' , version = '0.0.3' , url = 'https://github.com/andreagrandi/toshl-python' , download_url = 'https://github.com/andreagrandi/toshl-python/tarball/0.0.3' , author = 'Andrea Grandi' , author_email = 'a.grandi@gmail.com' , description = 'Python client library for Toshl API.' , packages = find_packages ( exclude = [ 'tests' ]), zip_safe = False , include_package_data = True , platforms = 'any' , license = 'MIT' , install_requires = [ 'requests==2.9.1' , ], ) Upload the package to PyPI Test server The first time you upload the package you will need to register it: python setup.py register -r pypitest and then you will need to build the package and upload it (please note I'm using the --sign to sign the package with PGP): python setup.py sdist upload --sign -r pypitest Upload the package to PyPI production server Once you have verified that you are able to build and upload the package to the test server (without getting any errors), you should upload it to the production server: python setup.py register -r pypi python setup.py sdist upload --sign -r pypi This is everything you need to do if you want to publish a Python package on PyPI. Happy coding!","tags":"Development","url":"https://www.andreagrandi.it/2016/04/10/how-to-publish-a-python-package-to-pypi/","loc":"https://www.andreagrandi.it/2016/04/10/how-to-publish-a-python-package-to-pypi/"},{"title":"Using a light sensor with BBC micro:bit and MicroPython","text":"A light sensor is a small component with a particular characteristic: it is basically a resistor and its resistance decreases if the light is more intense. To use it with micro:bit we need to use one of the analogic ports . To build this circuit you will need a breadboard , 3 jumper wires , a 10k resistance and possibly a Kitronik breadboard kit . The project I wanted to realise a simple project where, depending on the light intensity captured by the light sensor, the micro:bit shows an image of the Sun if the light is intense and an image of the Moon if the light is less intense. Here is the complete circuit scheme : \"Image Copyright © Kitronik\" and here is a picture of the finished project I created: The source code I needed is available here: and as a demo I realised this small video :","tags":"Development","url":"https://www.andreagrandi.it/2016/02/08/using-a-light-sensor-with-bbc-microbit-and-micropython/","loc":"https://www.andreagrandi.it/2016/02/08/using-a-light-sensor-with-bbc-microbit-and-micropython/"},{"title":"Prototyping BBC micro:bit projects with Kitronik breadboard kit","text":"BBC micro:bit has a few IO pins that can be used to interact with external devices. The problem with the board is that it's not easy to connect the classic jumper wires (those that we normally connect to a breadboard) to the micro:bit , unless using a crocodile clip and being limited to just 3 pins. Kitronik breadboard kit solves this problem, offering an interface where the micro:bit can be plugged and all the pins are easily connectable to the breadboard using normal male/female jumper wires . I've built a very simple circuit following an example you can find on this manual https://www.kitronik.co.uk/pdf/5603_inventors_kit_for_the_bbc_microbit_tutorial_book.pdf To build the circuit you also need 4 male/female jumper wires and two buttons . All this circuit does is to connect the buttons to the micro:bit pins that relate to those buttons. Basically pressing those buttons is the same as pressing button A or button B on the micro:bit board. Here you can see the schema in detail: \"Image Copyright © Kitronik\" I've also made a short video so that you can see it in action: And of course the source code is available too:","tags":"Development","url":"https://www.andreagrandi.it/2016/02/07/prototyping-bbc-microbit-projects-with-kitronik-breadboard-kit/","loc":"https://www.andreagrandi.it/2016/02/07/prototyping-bbc-microbit-projects-with-kitronik-breadboard-kit/"},{"title":"Using BBC MicroBit accelerometer with Python","text":"In these days I'm having a bit of fun with BBC MicroBit board and I'm learning how to use the different sensors available. The latest one I wanted to try was the accelerometer. The board can \"sense\" if you are moving it in any of the 3 dimensional axes: X, Y, Z. According to the documentation there are four methods available that can be used to get these values: microbit.accelerometer.get_values() will return you a tuple with all the 3 values, while microbit.accelerometer.get_x() , microbit.accelerometer.get_y() , microbit.accelerometer.get_z() will give you the single values. The documentation on the official website doesn't explain much and for example I didn't even know what was the range of the values I can get back from these methods (by the way it's between -1024 and 1024 ), so I decided to play with the code directly and write a very simple example. The small example I wrote, shows a smile on the board display if you keep it straight and shows a sad face if you bend it. This is the result: and this is all the needed code of the application: In the next days I will try to play with more sensors and to publish other examples.","tags":"Development","url":"https://www.andreagrandi.it/2016/01/26/using-bbc-microbit-accelerometer-with-python/","loc":"https://www.andreagrandi.it/2016/01/26/using-bbc-microbit-accelerometer-with-python/"},{"title":"Using Python PyPy in a virtual environment","text":"Sometimes we need to test if our code also works with PyPy implementation of Python . Assuming you have already installed it in your system, first find out where it is installed: which pypy /usr/local/bin/pypy then you need mkvirtualenv to create a virtual environment that will use this runtime: mkvirtualenv -p /usr/local/bin/pypy pypy-test Running virtualenv with interpreter /usr/local/bin/pypy New pypy executable in pypy-test/bin/pypy Installing setuptools, pip, wheel...done. ( pypy-test ) ➜ ~ python Python 2 .7.10 ( f3ad1e1e1d6215e20d34bb65ab85ff9188c9f559, Sep 01 2015 , 06 :26:30 ) [ PyPy 2 .6.1 with GCC 4 .2.1 Compatible Apple LLVM 6 .1.0 ( clang-602.0.53 )] on darwin Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. >>>> That's it! You can now use this virtual environment to run your Python application using PyPy environment.","tags":"HowTo, Python","url":"https://www.andreagrandi.it/2015/12/18/using-python-pypy-in-a-virtual-environment/","loc":"https://www.andreagrandi.it/2015/12/18/using-python-pypy-in-a-virtual-environment/"},{"title":"Getting started with BBC MicroBit and Python","text":"A few days ago I had the great opportunity to attend an event organised in collaboration with Python Software Foundation , a few primary school teachers and hosted by Computing at School , in London . The meeting was organised by Yvonne Walker (from CAS) and Nicholas Tollervey (PSF). The aim of the meeting was for teachers and developers to meet and discuss the opportunities offered by MicroPython on the BBC micro:bit . During the event a BBC micro:bit board was loaned to each person for the purpose of developing Python scripts, MicroPython itself or educational resources for the BBC micro:bit . Nicholas made it very clear that there is an NDA in place until the device is delivered to the kids and explained what we could or couldn't do. The Board The board is a 4 x 5 cm device with an ARM Cortex-M0 processor, accelerometer and magnetometer sensors, Bluetooth and USB connectivity , a display consisting of 25 LEDs, two programmable buttons , and can be powered by either USB or an external battery pack (source: https://en.wikipedia.org/wiki/Micro_Bit ). Flashing the firmware Once you get a new board, it probably doesn't have a proper firmware and application flashed. I suggest you to download the Python MicroBit REPL from this repository: https://github.com/ntoll/microrepl All you need to do is to connect the board to your computer, using a micro-USB cable . The device will be mounted as a volume. At this point, drag & drop the file called firmware.hex into the mounted volume. The firmware will be flashed and during the operation you will see a yellow led flashing. Using MicroPython micro:bit REPL To start writing some Python code on micro:bit you first need to clone this repository git clone git@github.com:ntoll/microrepl.git once you have cloned the repository, you need to install the Python dependencies (I suggest you to do it from inside a virtualenv ) pip install -r requirements.txt start the MicroPython REPL python microrepl.py and the Python shell will open, so you can start writing commands, like this one ( microbit ) ➜ microrepl git: ( master ) python microrepl.py Quit: Ctrl+ ] | Stop program: Ctrl+C | Reset: Ctrl+D Type 'help()' ( without the quotes ) then press ENTER. >>> import this The Zen of MicroPython, by Nicholas H.Tollervey Code, Hack it, Less is more, Keep it simple, Small is beautiful, Be brave! Break things! Learn and have fun! Express yourself with MicroPython. Happy hacking! :- ) >>> BBC micro:bit MicroPython Editor Typing all the Python commands directly into the shell can be a bit difficult. You can use a very nice and dedicated editor to write code and produce the compiled application for the micro:bit. All you need to do is clone this repository git clone git@github.com:ntoll/upyed.git Open the file named editor.html with your browser and start writing your code. When your code is done, you can generate the .hex file clicking on Download button. To load the compiled application you just need to drag & drop the .hex file to the mounted device, exactly like you did the first time to flash it. If you need a reference for all the methods and libraries available, you can consult the official documentation here http://microbit-micropython.readthedocs.org/en/latest/index.html References https://github.com/ntoll/microrepl https://github.com/ntoll/upyed https://www.microbit.co.uk/ http://microbit-micropython.readthedocs.org/en/latest/index.html","tags":"HowTo, Microbit, Python","url":"https://www.andreagrandi.it/2015/12/10/getting-started-with-bbc-microbit-and-python/","loc":"https://www.andreagrandi.it/2015/12/10/getting-started-with-bbc-microbit-and-python/"},{"title":"Fix encfs under OSX after upgrading to 10.11.2","text":"After having upgraded OSX to 10.11.2 on my MacBook, I noticed that my encfs volume didn't mount after reboot. I tried to run the script manually and all I got was this error: dyld: Symbol not found: __ZN5boost7archive17xml_iarchive_implINS0_12xml_iarchiveEE13load_overrideERNS0_15class_name_typeEi Referenced from: /usr/local/Cellar/encfs/1.8.1/lib/libencfs.6.dylib Expected in: /usr/local/lib/libboost_serialization-mt.dylib in /usr/local/Cellar/encfs/1.8.1/lib/libencfs.6.dylib I quickly found that was a common problem caused by a new version of Boost being installed: https://github.com/Homebrew/homebrew/issues/46254 To fix it, you just need to reinstall encfs using this command brew reinstall -s encfs","tags":"HowTo, OSX","url":"https://www.andreagrandi.it/2015/12/09/fix-encfs-under-osx-after-upgrading-to-10-11-2/","loc":"https://www.andreagrandi.it/2015/12/09/fix-encfs-under-osx-after-upgrading-to-10-11-2/"},{"title":"Getting a free SSL certificate from Letsencrypt and configuring it on Nginx with automatic renewal","text":"Finally Letsencrypt went to public beta and I really couldn't wait to use it on my VPS (where this blog is hosted). Until few days ago I was using a free SSL certificate from StartSSL . The service is nice and I'm grateful to them for this important resource they are providing for free, but it must be said that their renewal procedure isn't one of the most user friendly. For people who don't know the service yet, Letsencrypt not only gives free SSL certificates , they also provide a command line tool that people can use to request a new certificate or to renew an existing one. This means that you don't have to worry anymore if/when your certificate expires, you can set a crontab command and have the certificate automatically renewed for you. Client installation To request a SSL certificate you need to install their command line utility. Unless it has already been packaged for your distribution, for the moment it's much easier to get it from git as they explain in their installation instructions : git clone https://github.com/letsencrypt/letsencrypt cd letsencrypt ./letsencrypt-auto Getting the SSL certificate There are a few different options available to request a certificate, but the easiest one is to use the --webroot option, specifying the document root of your website so that the client will be able to put there a verification (temporary) file that will be served to the remote service and used as verification method. In my case I only needed this command: ./letsencrypt-auto certonly --webroot -w /var/www/andreagrandi.it/ -d www.andreagrandi.it -d andreagrandi.it --email myemail@myprovider.com --renew-by-default --agree-tos Please note that I had to specify both www.andreagrandi.it and andreagrandi.it as domains, otherwise it would have been invalid when requesting just andreagrandi.it resources. Configuration files and certificates installation The command above will save all the configuration under /etc/letsencrypt/ and all the generated certificates under /etc/letsencrypt/live/www.andreagrandi.it/*.pem (all the *.pem files here are symbolic links to the current certificate). If you are using Nginx the only files you need are fullchain.pem and privkey.pem and you can set them in your Nginx configuration using these two parameters: ssl_certificate /etc/letsencrypt/live/www.andreagrandi.it/fullchain.pem ; ssl_certificate_key /etc/letsencrypt/live/www.andreagrandi.it/privkey.pem ; In case you want to have a look at my full Nginx configuration file, as reference, you can find it here https://gist.github.com/andreagrandi/8b194c99cd3e77fdb5a8 Automatic renewal The last thing to be configured is a crontab rule to call the script every... 2 months. Why 2 months? Letsencrypt SSL certificates expire in 3 months . Usually SSL certificates are valid at least for 1 year, but Letsencrypt decided to make it 3 months to incentivate the automation of the renewal. I set it to 2 months, so if anything goes wrong I still have plenty of time to do it manually. To edit crontab for root user execute crontab -e and add this line: 0 3 1 */2 * /root/letsencrypt/letsencrypt-auto certonly --webroot -w /var/www/andreagrandi.it/ -d www.andreagrandi.it -d andreagrandi.it --email email@domain.com --renew-by-default --agree-tos && service nginx reload Just a final note. You may have noticed that this website presents an SSL certificate issued by COMODO. That's because I have CloudFlare in front of my website and that's how their SSL strict option works (at least for free plans).","tags":"DevOps, HowTo, Linux","url":"https://www.andreagrandi.it/2015/12/06/getting-a-free-ssl-certificate-from-letsencrypt-and-configuring-it-on-nginx-with-automatic-renewal/","loc":"https://www.andreagrandi.it/2015/12/06/getting-a-free-ssl-certificate-from-letsencrypt-and-configuring-it-on-nginx-with-automatic-renewal/"},{"title":"Reversing a List in Python","text":"Sometimes we need to reverse the order of the elements in a Python list. While there can be many different ways of implementing this task, I found three in particular that I appreciate for different reasons. Let's define first a list of integers that we will reverse later. l = [ 1 , 2 , 3 , 4 , 5 , 6 ] List slicing This method can be a bit obscure at first read, but basically it slices the whole list proceding in the reverse order: [ input ]: print l [:: - 1 ] [ output ]: [ 6 , 5 , 4 , 3 , 2 , 1 ] Reversed method We use the reversed method that returns an iterable object and a list comprehension to generate the new list [ input ]: print [ x for x in reversed ( l )] [ output ]: [ 6 , 5 , 4 , 3 , 2 , 1 ] Swapping values in place This last method is more verbose and it basically divides the list in two parts and swaps the first with sixth, the second with fifth, etc... [ input ]: for i in range ( 0 , len ( l ) / 2 ): l [ i ], l [ len ( l ) - 1 - i ] = l [ len ( l ) - 1 - i ], l [ i ] print l [ output ]: [ 6 , 5 , 4 , 3 , 2 , 1 ]","tags":"Development","url":"https://www.andreagrandi.it/2015/10/11/reversing-a-list-in-python/","loc":"https://www.andreagrandi.it/2015/10/11/reversing-a-list-in-python/"},{"title":"How to configure EncFS on OSX 10.10 (Yosemite)","text":"With EncFS it's possible to keep our data in almost any cloud (Dropbox, OneDrive, etc...), having a good level of privacy and security. Infact EncFS encrypt and decrypt our data automatically. It's available for Linux as well and using a commercial solution (that is currently unsupported) even on Windows. Installing EncFS EncFS can be installed from brew . If you don't have brew package manager installed on OSX you can install it using this command: ruby -e \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install ) \" After brew, you need to install OSXFuse from this website http://osxfuse.github.io Finally you can install encfs using this command: brew install homebrew/fuse/encfs Configuring the encrypted folder Now that EncFS is installed, you can either mount an existing EncFS volume or create a new one. In both cases the command is the same: encfs ~/Dropbox/Private ~/Private If you are mounting an existing encrypted volume, you will be prompted for the password. If you are creating a new encrypted volume you will be asked some questions about EncFS parameters. Note: if it's important for you to keep compatibility with BoxCryptor Classic (in case you want to use the same volume under Windows), please refer to this other article I wrote: https://www.andreagrandi.it/2014/09/12/create-an-encfs-volume-compatible-with-boxcryptor-classic/ Mount the encrypted volume on startup First of all you need to save the volume's password inside the OSX keychain. Open the app Keychain Access and create a new entry with name encfs and account value encfs , then write your password and click Add : Once the password is saved, open a text editor and paste this script and save it as encfs_mount.sh inside your \\$HOME folder: #!/bin/bash # Secure EncFS Dropbox mounter by Daniel Widerin <daniel@widerin.net> SOURCE = ~/Dropbox/Private TARGET = ~/Private VOLUME_TITLE = Private KEYCHAIN_PASSWORD = 'encfs' ENCFS = /usr/local/bin/encfs mount | grep $TARGET >/dev/null [[ \" $? \" -eq \"0\" ]] && /usr/sbin/diskutil unmount $TARGET if [ ! -d $TARGET ] ; then echo \"Create new mountpoint $TARGET \" mkdir $TARGET chmod 0700 $TARGET fi $ENCFS $SOURCE $TARGET --extpass = \"security 2>&1 >/dev/null find-generic-password -gl ' $KEYCHAIN_PASSWORD ' |grep password|cut -d \\\\\\\" -f 2\" -ovolname = $VOLUME_TITLE Make it executable : chmod +x ~/encfs_mount.sh Open AppleScript editor and paste this text inside and save as an app in the \\$HOME folder: do shell script \" $HOME /encfs_mount.sh\" Finally, open \" System Preferences \" -> \" Users & Groups \" and add the previously saved application. Final notes At this point encfs is configured to be mounted at startup and to save the encrypted files inside Dropbox. Please note: do not save anything directly on ~/Dropbox/Private , only read and save your files from ~/Private References https://www.maketecheasier.com/install-encfs-mac/ http://ninjatips.com/encrypt-dropbox-using-encfs/","tags":"HowTo, OSX, Sicurezza","url":"https://www.andreagrandi.it/2015/10/11/how-to-configure-encfs-on-osx-10-10-yosemite/","loc":"https://www.andreagrandi.it/2015/10/11/how-to-configure-encfs-on-osx-10-10-yosemite/"},{"title":"Understanding Python decorators optimizing a recursive Fibonacci implementation","text":"A decorator is a Python function that takes a function object as an argument and returns a function as a value . Here is an example of decorator definition: def foo ( function ): # make a new function def new_function (): # some code return new_function To apply a decorator to an existing function, you just need to put @*decorator_name * in the line before its definition, like this example: @foo def hello (): print 'Hello World' This decorator doesn't do anything, so let's think about a more concrete problem we could solve using decorators. Fibonacci sequence By definition, the first two numbers in the Fibonacci sequence are either 1 and 1 or 0 and 1. All the other numbers are the sum of the previous two numbers of the sequence. Example: 0, 1: the third number is 1 0, 1, 1: the fourth number is 2 0, 1, 1, 2: the fifth number is 3 0, 1, 1, 2, 3: the sixth number is 5 etc... If we wanted to give a math definition of the sequence, we could describe it in this way: F(0): 0 F(1): 1 F(n): F(n-1) + F(n-2) In Python we could have a recursive function like the following one: def fib ( n ): if n < 2 : return n else : return fib ( n - 1 ) + fib ( n - 2 ) What's the problem with this implementation? The code works as expected, but it's very inefficient . The next picture will explain what happens when we will try, for example, to calculate the 5th number of the sequence: Fib(5) is Fib(4) + Fib(3), but Fib(4) itself is Fib(3) + Fib(2), and... the picture just tell us that we have calculated Fib(3) 2 times, Fib(2) 3 times, Fib(1) 5 times! Why are we repeating the same operation every time if we already calculated the result? Memoization In computing, memoization is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again. We need to store values of the sequence we have already calculated and get them later when we need them. Let's implement a simple memoization decorator: def memoize ( function ): cache = {} def decorated_function ( * args ): if args in cache : return cache [ args ] else : val = function ( * args ) cache [ args ] = val return val return decorated_function The decorator defines a dict at the beginning that is used as a cache. When we want to find the n number of the sequence, it first checks if the value was already calculated and that value is returned instead of being calculated again. If the value is not found, then the original function is being called and then the value is store in the cache, then returned to the caller. Using the memoize decorator How much this decorator can speed up our fib method? Let's try to benchmark the execution using Python timeit module. # First example, not using the memoize decorator import timeit def fib ( n ): if n < 2 : return n else : return fib ( n - 1 ) + fib ( n - 2 ) t1 = timeit . Timer ( \"fib(35)\" , \"from __main__ import fib\" ) print t1 . timeit ( 1 ) The required time to calculate the 35th number of the Fibonacci sequence on my laptop is: 4.73480010033 # Second example, using the memoize decorator import timeit from memoize import memoize # For convenience I put my decorator # in a module named memoize.py @memoize def fib ( n ): if n < 2 : return n else : return fib ( n - 1 ) + fib ( n - 2 ) t1 = timeit . Timer ( \"fib(35)\" , \"from __main__ import fib\" ) print t1 . timeit ( 1 ) The required time to calculate the 35th number of the Fibonacci sequence on my laptop is: 0.000133037567139 Quite faster, don't you think? I will let you try how long does it take to calculate the 60th number of the sequence with and without using the decorator. Hint: grab a cup of coffee before beginning!","tags":"Programmazione, Python","url":"https://www.andreagrandi.it/2015/08/31/understanding-python-decorators-optimizing-a-recursive-fibonacci-implementation/","loc":"https://www.andreagrandi.it/2015/08/31/understanding-python-decorators-optimizing-a-recursive-fibonacci-implementation/"},{"title":"Django Notes: read values from settings in a safe way","text":"Working on Django projects I find very often that many developers access the values that are defined in settings in this way from django.conf import settings my_value = settings . MY_SETTING What happens if MY_SETTING has not been defined in settings.py ? The code will raise an error and crash, of course. How can we make the code more reliable? We could try/except the code block that tries to read the value and maybe set a value if we get an exception, but this would not be a clean way to do this job. A cleaner way to do it is to use getattr in this way: from django.conf import settings my_value = getattr ( settings , 'MY_SETTING' , 'my-default-value' ) getattr will try to read MY_SETTING value from settings.py , if the value doesn't exist my_value will be assigned with 'my-default-value'","tags":"Django, HowTo, Programmazione, Python","url":"https://www.andreagrandi.it/2015/08/29/django-notes-read-values-from-settings-in-a-safe-way/","loc":"https://www.andreagrandi.it/2015/08/29/django-notes-read-values-from-settings-in-a-safe-way/"},{"title":"How to write a custom Django Middleware","text":"To understand how a Django Middleware works we need to remember that the basic architecture of Django is composed by a request and a response . A middleware is something that stays in the middle. Let's give a look to the next diagram, taken from official Django documentation: Important things to know There are four important things to know about middlewares: You need to write a class that just inherit from object The order where you place your middleware in settings.py is important: middlewares are processed from top to bottom during a request and from bottom to top during a response. You don't need to implement all the available methods of a middleware. For example you can just implement process_request and process_template_response If you implement process_request and you decide to return an HttpResponse , all the other middlewares, views etc... will be ignored and only your response will be returned Writing a middleware In my example I wanted to implement a feature that saves the time when a request is made and the time when a request has been processed, then calculates the time delta and exposes this value in the context so that is accessible from our templates. How to implement a similar feature using a middleware? Here is my example: from datetime import datetime class BenchmarkMiddleware ( object ): def process_request ( self , request ): request . _request_time = datetime . now () def process_template_response ( self , request , response ): response_time = request . _request_time - datetime . now () response . context_data [ 'response_time' ] = abs ( response_time ) return response Please don't care about how I calculated the time. I'm aware that there are better ways to do it, but I just wanted to keep it simple and show how to implement a simple middleware. If you want to see a complete example of a project that includes and uses this middleware, here you can find the complete source code: https://github.com/andreagrandi/benchmark-middleware-example References https://docs.djangoproject.com/en/1.8/topics/http/middleware/ http://agiliq.com/blog/2015/07/understanding-django-middlewares/ http://code.runnable.com/UrSGolK00ygpAAAQ/creating-a-custom-middleware-for-python-and-django","tags":"Development","url":"https://www.andreagrandi.it/2015/08/23/how-to-write-a-custom-django-middleware/","loc":"https://www.andreagrandi.it/2015/08/23/how-to-write-a-custom-django-middleware/"},{"title":"Why I completely switched this website to HTTPS (and why you should do the same)","text":"I must admit it, there was a time when I was not using HTTPS , not even to protect the admin section of the website. This means that anyone could have intercepted the password and published (or deleted) things in my name. Since a couple of years ago I started protecting my admin sectio using an SSL certificate. I haven't done it before for a couple of reason: my hosting was on a provider that required a lot of money (something like 100\\$/year) to enable SSL support, plus an SSL certificated costed at least 100-120\\$/year. When I migrated my website on my own VPS on DigitalOcean I finally discovered that StartSSL was giving free class 1 certificates and I immediately got one. I made the mistake to just serve the admin pages using HTTPS, not all the website. I regretted about this decision after readin a couple of articles that were explaining how some internet providers where changing served HTTP pages injecting their own ads or banner. That was unacceptable to me and I swicthed the whole website to HTTPS. Basically, if you don't serve even your personal website using HTTPS, someone could change the page while it's being transfered to the requester. Imagine if you have (like me) a page on your blog that let people download your public PGP key. Users could be served with a different key, so someone else would be able to decrypt a message intended for you only. Scary, isn't it? If you need more informations about how to request a StartSSL certificate and how to install it on Nginx/Apache, I can suggest this nice tutorial: https://konklone.com/post/switch-to-https-now-for-free If you need to serve a WordPress website, that configuration is not enough. In that case you may want to have a look at my own Nginx configuration, available at this address: https://gist.github.com/andreagrandi/5de9dc9c4eb7e732764c p.s: if you are you curious to try how Digital Ocean VPS works and fancy 10\\$ credit (enough for 2 months if you choose the basic droplet) for free, u se this link and enjoy it https://www.digitalocean.com/?refcode=cc8349e328a5","tags":"Sicurezza","url":"https://www.andreagrandi.it/2015/08/22/why-i-completely-switched-this-website-to-https-and-why-you-should-do-the-same/","loc":"https://www.andreagrandi.it/2015/08/22/why-i-completely-switched-this-website-to-https-and-why-you-should-do-the-same/"},{"title":"Django Notes: tests, setUp method and db data","text":"This won't be a full post, but just a quick note (probably the first one of a serie) about development with Django. When we write a TestCase test, if we have defined a setUp method, it will be called before the execution of each test. One could think that the database is completely reset after each test, but this is not true (not like I was thinking). After each test, whatever we wrote on the database is rolled back. If we create a \"Client\" row (assuming we have a model called Clients) in our setUp, when we call it the second time the ID won't be 1 as someone (me included) could expect. It will be 2 instead, because the database has not completely deleted and created from scratch. This means that we can't assume that our Client ID will always be 1 for each test and we should rather reference to it in a dinamic way like: self.client.id This could be a trivial thing for many people but I was not 100% sure about this so I asked for a confirmation on #django IRC room and people (expecially apollo13 ) was kind enough to explain me how it works.","tags":"Django, Python","url":"https://www.andreagrandi.it/2015/07/23/django-notes-tests-setup-method-and-db-data/","loc":"https://www.andreagrandi.it/2015/07/23/django-notes-tests-setup-method-and-db-data/"},{"title":"Soma.fm + Spotify + import.io + Python mashup: automatically create a Spotify playlist with Soma.fm tracks","text":"I'm a big fan of Soma.fm (a 25+ channels streaming radio based in San Francisco) and during the years I've been writing clients for this radio for different mobile platforms (Maemo, MeeGo, Harmattan, Windows Phone, BlackBerry 10, Jolla). I love in particular their \" Indie Pop Rock \" channel that during these years made me discover some very good artists. When Spotify finally was available in Italy (I'm still using it right now that I live in the UK), something that I always missed was a radio with the same good music. Why not just listening to Soma.fm? Because I like to listen to the music while I commute and in the London Underground it's nearly impossible to have signal. So I was thinking: it would be nice to have a Spotify playlist with Soma.fm tracks . Wait a moment.... I can do it! Soma.fm publishes the tracks history with all the tracks streamed during the last hour http://somafm.com/indiepop/songhistory.html so I just needed something to parse this list for me and return me a well formatted version. Thanks to import.io (it's a service that takes a web page as input, parse the data and generates a RESTful API to access this data) I was able to easily get the data I needed. At this point I only needed to be able to loop through the list, search each track on Spotify and add it to my playlist. The source code is fully available here https://github.com/andreagrandi/spotisoma Note: you can't just get the code and run it. You will need to get your own import.io api key , generate your import.io api url, get a Spotify application key (the old/deprecated one, since it was nearly impossible for me to use oauth in a simple Python script due to the fact I didn't have an endpoint to receive the token back. You can get more informations here: https://pyspotify.mopidy.com/en/latest/quickstart/#application-keys ) and set your env variables with your Spotify username and password. Last but not least: the old Spotify library only works with Premium accounts.","tags":"Python","url":"https://www.andreagrandi.it/2015/07/12/soma-fm-spotify-import-io-python-mashup/","loc":"https://www.andreagrandi.it/2015/07/12/soma-fm-spotify-import-io-python-mashup/"},{"title":"Goenv - Go Environment Manager","text":"To briefly explain what Goenv is, I will assume you have previously worked with Python . Basically it's what Virtualenv is for Python. Goenv (and it's wrapper goof ) creates a folder for a new project and set the $GOPATH env variable to that folder path. At this point every time you do go get , the libraries will be installed in that specific $GOPATH . It's very important to use separate $GOPATH for each project, because this allow us to use different library versions for each project and avoid version conflicts . Installation git clone https://bitbucket.org/ymotongpoo/goenv cd goenv go build -o goenv *.go chmod +x goenv sudo cp goenv /usr/bin Goenv is now installed, we will now install its wrapper goof : sudo cp shellscripts/goenvwrapper.sh /usr/bin Edit .bashrc (or .zshrc if you use zsh) and append these lines: export GOENVHOME = $HOME /goenvs source /usr/bin/goenvwrapper.sh How to use it To create a new go environment use make : goof make go-test Do you want to create all parental directory of '/Users/andrea/goenvs/go-test' ? [ y/N ] : y Environment /Users/andrea/goenvs/go-test created! ( go:go-test ) ➜ go-test To exit the go environment use deactivate : ( go:go-test ) ➜ go-test deactivate go-test To use an environment use workon : go-test goof workon go-test ( go:go-test ) ➜ go-test To show available environments use show : ( go:go-test ) ➜ go-test goof show go-test Goenv itself is not enough to manage Go packages. It would be like using Virtualenv only and not using pip and requirements . In a future post I will explain how to use Godep .","tags":"Go, HowTo, Programmazione","url":"https://www.andreagrandi.it/2015/04/19/goenv-go-environment-manager/","loc":"https://www.andreagrandi.it/2015/04/19/goenv-go-environment-manager/"},{"title":"Go: defining methods on struct types","text":"In Go it's possible to define methods on struct types . The syntax needed for it can be a bit strange for people that are used to define classes and methods in Java, C# etc... but once you learn it it's quite easy to use. In my case for example I needed something that could contain a Timer object, a string and a method that could start the timer and call a method at the end of the Timer execution. I implemented it in this way: type DeviceTimer struct { DeviceID string DeviceTimer * time . Timer } func ( timer DeviceTimer ) startTimer () { <- timer . DeviceTimer . C notifyDeviceTimerExpired ( timer . DeviceID ) } The key point is row 6 func (timer DeviceTimer) startTimer() { ... } where I defined a method called startTimer and I specify timer DeviceTimer inside the func definition. This basically \"extends\" the struct DeviceTimer adding that method to it. This means that I can call that method in this way: timer := time . NewTimer ( time . Millisecond * 300 ) device_timer := DeviceTimer { \"abc123\" , timer } go device_timer . startTimer () This is all you need to do. If you want to read more about this subject, I can suggest to read these two articles: Go by Example: Methods https://gobyexample.com/methods Inheritance and subclassing in Go - or its near likeness http://golangtutorials.blogspot.co.uk/2011/06/inheritance-and-subclassing-in-go-or.html Note: I'm not a Go expert and these are just my personal notes I'm taking during my learning experience. I'm very keen to share my notes with everyone, but please don't take them as notes from an expert Go developer.","tags":"Go","url":"https://www.andreagrandi.it/2015/03/16/go-defining-methods-on-struct-types/","loc":"https://www.andreagrandi.it/2015/03/16/go-defining-methods-on-struct-types/"},{"title":"How to create a Docker image for PostgreSQL and persist data","text":"Before I start, let me confirm to you that official Docker images for PostgreSQL already exist and are available here: https://registry.hub.docker.com/_/postgres/ so this howto wants to be a guide to explain how to create these images and talk about some of the Docker features. I will assume that you have already installed Docker on your machine. I have tested these instructions both on Ubuntu Linux and OSX (OSX users will need to install boot2docker , instructions are not available in this guide). Dockerfile To create a Docker image we need to create a text file named Dockerfile and use the available commands and syntax to declare how the image will be built. At the beginning of the file we need to specify the base image we are going to use and our contact informations: FROM ubuntu:14.04 MAINTAINER Andrea Grandi <nospamthanks@gmail.com> In our case we are using Ubuntu 14.04 as base image. After these instructions we need to add PostgreSQL package repository and GnuPG public key: RUN apt-key adv --keyserver keyserver.ubuntu.com --recv-keys B97B0AFCAA1A47F044F244A07FCC7D46ACCC4CF8 RUN echo \"deb http://apt.postgresql.org/pub/repos/apt/ precise-pgdg main\" > /etc/apt/sources.list.d/pgdg.list then we need to update the packages available in Ubuntu and install PostgreSQL: RUN apt-get update && apt-get -y -q install python-software-properties software-properties-common && apt-get -y -q install postgresql-9.3 postgresql-client-9.3 postgresql-contrib-9.3 We are installing version 9.3 of PostgreSQL, instructions would be very similar for any other version of the database. Note: it's important to have apt-get update and apt-get install commands in the same RUN line, else they would be considered two different layers by Docker and in case an updated package is available it won't be installed when the image is rebuilt. At this point we switch to postgres user to execute the next commands: USER postgres RUN /etc/init.d/postgresql start && psql --command \"CREATE USER pguser WITH SUPERUSER PASSWORD 'pguser';\" && createdb -O pguser pgdb We switch to root user and we complete the configuration: USER root RUN echo \"host all all 0.0.0.0/0 md5\" >> /etc/postgresql/9.3/main/pg_hba.conf RUN echo \"listen_addresses='*'\" >> /etc/postgresql/9.3/main/postgresql.conf We expose the port where PostgreSQL will listen to: EXPOSE 5432 We setup the data and shared folders that we will use later: RUN mkdir -p /var/run/postgresql && chown -R postgres /var/run/postgresql VOLUME [ \"/etc/postgresql\" , \"/var/log/postgresql\" , \"/var/lib/postgresql\" ] Finally we switch again to the postgres user and we define the entry command for this image: USER postgres CMD [ \"/usr/lib/postgresql/9.3/bin/postgres\" , \"-D\" , \"/var/lib/postgresql/9.3/main\" , \"-c\" , \"config_file=/etc/postgresql/9.3/main/postgresql.conf\" ] The full Dockerfile is available here https://github.com/andreagrandi/postgresql-docker/blob/master/Dockerfile Building Docker image Once the Dockerfile is ready, we need to build the image before running it in a container. Please customize the tag name using your own docker.io hub account (or you won't be able to push it to the hub): docker build --rm = true -t andreagrandi/postgresql:9.3 . Running the PostgreSQL Docker container To run the container, once the image is built, you just need to use this command: docker run -i -t -p 5432 :5432 andreagrandi/postgresql:9.3 Testing the running PostgreSQL To test the running container we can use any client, even the commandline one: psql -h localhost -p 5432 -U pguser -W pgdb When you are prompted for password, type: pguser Please note that localhost is only valid if you are running Docker on Ubuntu. If you are an OSX user, you need to discover the correct ip using: boot2docker ip Persisting data You may have noticed that once you stop the container, if you previously wrote some data on the DB, that data is lost. This is because by default Docker containers are not persistent. We can resolve this problem using a data container. My only suggestion is not to do it manually and use a tool like fig to orchestrate this. Fig is a tool to orchestrate containers and its features are being rewritten in Go language and integrated into Docker itself. So if you prepare a fig.yml configuration file now, you will be able, hopefully, to reuse it once this feature will be integrated into Docker. Please refer to fig website for the instructions to install it (briefly: under Ubuntu you can use pip install fig and under OSX you can use brew install fig ). dbdata : image : andreagrandi/postgresql:9.3 volumes : - /var/lib/postgresql command : true db : image : andreagrandi/postgresql:9.3 volumes_from : - dbdata ports : - \"5432:5432\" Save this file as fig.yml in the same folder of the Dockerfile and spin up the container using this command: fig up andreas-air:postgresql-docker andrea [ master ] $ fig up Recreating postgresqldocker_dbdata_1... Recreating postgresqldocker_db_1... Attaching to postgresqldocker_db_1 db_1 | 2015 -02-21 19 :01:07 UTC [ 6 -1 ] LOG: database system was interrupted ; last known up at 2015 -02-21 17 :46:10 UTC db_1 | 2015 -02-21 19 :01:07 UTC [ 6 -2 ] LOG: database system was not properly shut down ; automatic recovery in progress db_1 | 2015 -02-21 19 :01:07 UTC [ 6 -3 ] LOG: redo starts at 0 /1782F68 db_1 | 2015 -02-21 19 :01:07 UTC [ 6 -4 ] LOG: record with zero length at 0 /1782FA8 db_1 | 2015 -02-21 19 :01:07 UTC [ 6 -5 ] LOG: redo done at 0 /1782F68 db_1 | 2015 -02-21 19 :01:07 UTC [ 6 -6 ] LOG: last completed transaction was at log time 2015 -02-21 17 :46:10.61746+00 db_1 | 2015 -02-21 19 :01:07 UTC [ 1 -1 ] LOG: database system is ready to accept connections db_1 | 2015 -02-21 19 :01:07 UTC [ 10 -1 ] LOG: autovacuum launcher started If you try to write some data on the database and then you stop (CTRL+C) the running containers and spin up them again, you will see that your data is still there. Conclusion This is just an example of how to prepare a Docker container for a specific service. The difficoult part is when you have to spin up multiple services (for example a Django web application using PostgreSQL, RabbitMQ, MongoDB etc...), connect them all together and orchestrate the solution. I will maybe talk about this in one of the next posts. You can find the full source code of my PostgreSQL Docker image, including the fig.yml file in this repository https://github.com/andreagrandi/postgresql-docker","tags":"Development","url":"https://www.andreagrandi.it/2015/02/21/how-to-create-a-docker-image-for-postgresql-and-persist-data/","loc":"https://www.andreagrandi.it/2015/02/21/how-to-create-a-docker-image-for-postgresql-and-persist-data/"},{"title":"Moving away from Google Talk to a real Jabber/XMPP service","text":"I've been recently concerned about the future of Google Talk service and all the implications related to recent changes to the existing service. What has been a nice implementation of the Jabber/XMPP protocol once, now is just a closed and proprietary service. The main problem with these changes are: Jabber/XMPP users of other services won't be able to talk anymore to Google Talk users Google is killing some of their native clients (like the Windows one) and forcing users to Chrome or Android/iOS versions Google has disabled the possibility to turn off chat recording (you can still do it individually, for each contact) So, what are the alternatives to Google Talk? Luckly you have at least three options. Using an existing Jabber/XMPP service This is surely the easiest way to get a Jabber/XMPP account. There is a list of free services available here: https://xmpp.net/directory.php registering a new account is usually very easy. Most of the clients have an option that let you register the account while you are configuring it. For example if you are using Pidgin and you want to register an account with DukGo service, you can configure it in this way: Using an hosted Jabber/XMPP service with your domain A service called HostedIM offer a very nice service. Basically if you already have a domain, you can register an account on hosted.im , setup your DNS following their instructions and create an account directly on their dashboard. You can create up to 5 accounts for free . If you need more, they offer a paid service for that. In my case all I had to do was updating my DNS with the following configuration: _xmpp-client._tcp.andreagrandi.it. IN SRV 10 0 5222 xmpp1.hosted.im. _xmpp-client._tcp.andreagrandi.it. IN SRV 20 0 5222 xmpp2.hosted.im. _xmpp-server._tcp.andreagrandi.it. IN SRV 20 0 5269 xmpp2.hosted.im. _xmpp-server._tcp.andreagrandi.it. IN SRV 10 0 5269 xmpp1.hosted.im. _jabber._tcp.andreagrandi.it. IN SRV 20 0 5269 xmpp2.hosted.im. _jabber._tcp.andreagrandi.it. IN SRV 10 0 5269 xmpp1.hosted.im. Hosting your own Jabber/XMPP service If you have a VPS and some syasdmin skills, why not hosting your own XMPP server? There are different options available, but I can suggest you three in particular: OpenFire ejabberd Prosody I haven't tried any of these personally, because for the moment I'm using the service offered by hosted.im. I'm curious anyway to configure at least one of them and when I will do it I will publish a dedicated tutorial about it. Conclusion Given the recent changes that Google is doing to all their services, I'm more than happy when I can abandon one of them, because I personally don't like to rely (and bind myself) to a single company, expecially if that company closes a service whenever they want and try to lock you inside their ecosystem.","tags":"HowTo, Linux","url":"https://www.andreagrandi.it/2015/02/20/moving-away-from-google-talk-to-a-real-jabberxmpp-service/","loc":"https://www.andreagrandi.it/2015/02/20/moving-away-from-google-talk-to-a-real-jabberxmpp-service/"},{"title":"Automatically pull updated Docker images and restart containers with docker-puller","text":"If you use docker.io (or any similar service) to build your Docker containers, it may be possible that, once the new image is generated, you want your Docker host to automatically pull it and restart the container. Docker.io gives you the possibility to set a web hook after a successful build. Basically it does a POST on a defined URL and send some informations in JSON format. docker-puller listens to these web hooks and can be configured to run a particular script, given a specific hook. It's a very simple service I wrote using Python/Flask. It's also my first Flask application, so if you want to improve it, feel free to send me a pull request on GitHub. Note: this is not the only existing service that is able to do this task. I took inspiration from this article http://nathanleclaire.com/blog/2014/08/17/automagical-deploys-from-docker-hub/ and I really tried to customize https://github.com/cpuguy83/dockerhub-webhook-listener for my own needs, but the problem is that dockerhub-webhook-listener is not ready to be used as is (you have to customize it) and I'm not very good with Golang (yet) to be able to do it in little time. This is why I rewrote the service in Python (that is my daily language). I want to thank Brian Goff for the idea and all the people in #docker @ FreeNode for the support. How to use docker-puller Setting up the service should be quite easy. After you clone the repository from https://github.com/glowdigitalmedia/docker-puller there is a config.json file where you define the host , port , a token and a list of hooks you want to react to. For example: { \"host\" : \"localhost\" , \"port\" : 8000 , \"token\" : \"abc123\" , \"hooks\" : { \"hello\" : \"scripts/hello.sh\" } } Create a bash script (in this case it was called hello.sh) and put it under script folder and write the instructions to be executed to pull the new image and restart the container (example): docker pull andreagrandi/test:latest docker stop test docker rm test docker run --name test -d -p 8000 :80 andreagrandi/test:latest Once configured, I suggest you to setup a Nginx entry (instructions not covered here) that for example redirect yourhost.com/dockerpuller to localhost:8000 (I would advise to enable SSL too, or people could be able to sniff your token). The service can be started with: \" python app.py \" (or you can setup a Supervisor script). At this point docker-puller is up and running. Go to docker.io automatic build settings and setup a webhook like this: http://yourhost.com/dockerpuller?token=abc123&hook=hello Every time docker.io finishes building and pushing your image to the docker registry, it will POST on that URL. docker-puller will catch the POST, check for a valid token, get the hook name and will execute the relative script. That's all! I hope this very simple service can be useful to other people and once again, if you want to improve it, I will be glad to accept your pull requests on GitHub.","tags":"HowTo","url":"https://www.andreagrandi.it/2014/10/25/automatically-pull-updated-docker-images-and-restart-containers-with-docker-puller/","loc":"https://www.andreagrandi.it/2014/10/25/automatically-pull-updated-docker-images-and-restart-containers-with-docker-puller/"},{"title":"Create an EncFS volume compatible with BoxCryptor Classic","text":"If you are planning to share an encrypted volume between Linux/OSX and Windows (I will assume you are sharing it on Dropbox, but you could use any similar service) and you are using EncFS under Linux/OSX and BoxCryptor under Windows, there are some specifig settings to use when you create the EncFS volume. Infact even if BoxCryptor claims to be \"encfs compatible\", it's not 100%. Suppose you want to create an encrypted volume located at $HOME/.TestTmpEncrypted and mounted at $HOME/TestTmp you need the following command: encfs ~/.TestTmpEncrypted ~/TestTmp answer \"Y\" when you are asked if you want to create the folders: The directory \"/home/andrea/.TestTmpEncrypted/\" does not exist. Should it be created? ( y,n ) y The directory \"/home/andrea/TestTmp\" does not exist. Should it be created? ( y,n ) y At this point you will need to select between default paranoia mode or advanced mode. Please choose the advanced one (x): Creating new encrypted volume. Please choose from one of the following options: enter \"x\" for expert configuration mode, enter \"p\" for pre-configured paranoia mode, anything else , or an empty line will select standard mode. ?> x Manual configuration mode selected. Select AES as cypher algorithm: The following cypher algorithms are available: 1 . AES : 16 byte block cipher -- Supports key lengths of 128 to 256 bits -- Supports block sizes of 64 to 4096 bytes 2 . Blowfish : 8 byte block cypher -- Supports key lengths of 128 to 256 bits -- Supports block sizes of 64 to 4096 bytes Enter the number corresponding to your choice: 1 Selected algorithm \"AES\" Select 256 as key size: Please select a key size in bits. The cypher you have chosen supports sizes from 128 to 256 bits in increments of 64 bits. For example: 128 , 192 , 256 Selected key size: 256 Using key size of 256 bits Choose 1024 as block size: Select a block size in bytes. The cypher you have chosen supports sizes from 64 to 4096 bytes in increments of 16 . Alternatively, just press enter for the default ( 1024 bytes ) filesystem block size: Using filesystem block size of 1024 bytes Select Stream as filename encoding: The following filename encoding algorithms are available: 1 . Block : Block encoding, hides file name size somewhat 2 . Null : No encryption of filenames 3 . Stream : Stream encoding, keeps filenames as short as possible Enter the number corresponding to your choice: 3 Selected algorithm \"Stream\"\" Do NOT enable filename initialization vector chaining : Enable filename initialization vector chaining? This makes filename encoding dependent on the complete path, rather then encoding each path element individually. The default here is Yes. Any response that does not begin with 'n' will mean Yes: no Do NOT enable per-file initialization vectors : Enable per-file initialization vectors? This adds about 8 bytes per file to the storage requirements. It should not affect performance except possibly with applications which rely on block-aligned file io for performance. The default here is Yes. Any response that does not begin with 'n' will mean Yes: no Do NOT enable external chained IV : External chained IV disabled, as both 'IV chaining' and 'unique IV' features are required for this option. Enable block authentication code headers on every block in a file? This adds about 12 bytes per block to the storage requirements for a file, and significantly affects performance but it also means [ almost ] any modifications or errors within a block will be caught and will cause a read error. The default here is No. Any response that does not begin with 'y' will mean No: no Do NOT enable random bytes to each block header : Add random bytes to each block header? This adds a performance penalty, but ensures that blocks have different authentication codes. Note that you can have the same benefits by enabling per-file initialisation vectors, which does not come with as great a performance penalty. Select a number of bytes, from 0 ( no random bytes ) to 8 : 0 Enable file-hole pass-through : Enable file-hole pass-through? This avoids writing encrypted blocks when file holes are created. The default here is Yes. Any response that does not begin with 'n' will mean Yes: yes Finally you will see: Configuration finished. The filesystem to be created has the following properties: Filesystem cypher: \"ssl/aes\" , version 3 :0:2 Filename encoding: \"nameio/stream\" , version 2 :1:2 Key Size: 256 bits Block Size: 1024 bytes File holes passed through to ciphertext. At this point set a passphrase for your new volume: Now you will need to enter a password for your filesystem. You will need to remember this password, as there is absolutely no recovery mechanism. However, the password can be changed later using encfsctl. New Encfs Password: Verify Encfs Password: You should be able to mount this volume using BoxCryptor.","tags":"HowTo, Linux, Sicurezza","url":"https://www.andreagrandi.it/2014/09/12/create-an-encfs-volume-compatible-with-boxcryptor-classic/","loc":"https://www.andreagrandi.it/2014/09/12/create-an-encfs-volume-compatible-with-boxcryptor-classic/"},{"title":"How to configure Edimax EW-7811UN Wifi dongle on Raspbian","text":"If you want to connect your RaspberryPi to your home network and you want to avoid cables, I suggest you to use the Edimax wifi adapter . This device is quite cheap (around £8 on Amazon ) and it's very easy to configure on Raspbian (I assume you are using a recent version of Raspbian. I'm using the one released on 20/06/2014). Configure the wifi adapter Edit /etc/network/interfaces and insert these configuration values: auto lo iface lo inet loopback iface eth0 inet dhcp allow-hotplug wlan0 auto wlan0 iface wlan0 inet dhcp wpa-ssid YOURESSID wpa-psk YOURWPAPASSWORD Power management issue There is a known \"issue\" with this adapter default configuration that makes it to turn off if the wlan interface is not in use for some minutes. To avoid this you have to customize the parameters used to load the kernel module. First check that your adapter is using 8192cu module: sudo lsmod | grep 8192 8192cu 551136 0 Create the file /etc/modprobe.d/8192cu.conf and insert the following lines inside: # prevent power down of wireless when idle options 8192cu rtw_power_mgnt = 0 rtw_enusbss = 0 I also suggest to create a little entry in crontab to make the RaspberryPi ping your router every minute. This will ensure that your wifi connection will stay alive. To edit crontab just type (from pi user, you don't need to be root): crontab -e and insert this line at the end: */1 * * * * ping -c 1 192 .168.0.1 where 192.168.0.1 is the IP of your router (of course substitute this value with the ip of your router). Keep Alive Script I created a further script to keep my WIFI alive. This script will ping the router (change the IP using the one of your router) every 5 minutes and if the ping fails it brings down the wlan0 interface, the kernel module for the wifi and bring them up again. Just put this script in /root/wifi_recover.sh and then execute from root user: chmod +x wifi_recover.sh crontab -e Insert this line inside the crontab editor: */5 * * * * /root/wifi_recover.sh Conclusion The configuration is done. Just reboot your RaspberryPi and enjoy your wifi connection.","tags":"HowTo","url":"https://www.andreagrandi.it/2014/09/02/how-to-configure-edimax-ew-7811un-wifi-dongle-on-raspbian/","loc":"https://www.andreagrandi.it/2014/09/02/how-to-configure-edimax-ew-7811un-wifi-dongle-on-raspbian/"},{"title":"Configuring ddclient to update your dynamic DNS at noip.com","text":"noip.com is one of the few dynamic DNS free services that are reliable to use. If you have, like in my situation, a RaspberryPi connected to your home DSL and you want it to be always reachable without knowing the current IP address (the IP could change if you have a normal DSL service at home), you need a dynamic DNS service. To update the noip.com one you just need ddclient a tool that is available in Raspbian/Debian repository. You can install it with this command: sudo apt-get install ddclient then you just need to edit /etc/ddclient.conf protocol = dyndns2 use = web, web = checkip.dyndns.com/, web-skip = 'IP Address' server = dynupdate.no-ip.com login = yourusername password = yourpassword yourhostname.no-ip.org and restart the client: sudo /etc/init.d/ddclient restart That's all! Please remember that noip.com free accounts have a limitation : they need to be confirmed every 30 days (you will receive an email and you need to click on the link contained to update your DNS).","tags":"HowTo","url":"https://www.andreagrandi.it/2014/09/02/configuring-ddclient-to-update-your-dynamic-dns-at-noip-com/","loc":"https://www.andreagrandi.it/2014/09/02/configuring-ddclient-to-update-your-dynamic-dns-at-noip-com/"},{"title":"Getting started with Digital Ocean VPS: configuring DNS and Postfix for email forwarding","text":"I have recently migrated my website from a shared hosting to a dedicated VPS on Digital Ocean. Having a VPS surely gives you unlimited possibilities, compared to a shared hosting, but of course you have to manage some services by yourself. In my case I only needed: SSH access, LEMP configuration (Nginx + MySQL + PHP) to serve my WordPress blog and Postfix to use email forwarding from my aliases to my personal email. Configuring DNS on Digital Ocean Understanding how to properly configure the DNS entries in the panel could be a bit tricky if it's not your daily bread. In particular there is a Digital Ocean configuration that assumes certain things about your droplet, so it's better to configure it properly. For example the droplet name should not be casual, but it should match your domain name: I initially called my host \"andreagrandi\" and I had to rename it to \"andreagrandi.it\" to have the proper PTR values. You will need to create at least a \"mail\" record, pointing to your IP and an \"MX\" record pointing to mail.yourdomain.com. (please note the dot at the end of the domain name). Here is the configuration of my own droplet (you will notice also a CNAME record. You need it if you want www.yourdomain.com to correctly point to your ip. Configuring Postfix In my case I only needed some aliases that I use to forward emails to my GMail account, so the configuration is quite easy. First you need to install Postfix: sudo apt-get install postfix Then you need to edit /etc/postfix/main.cf customizing myhostname with your domain name and add virtual_alias_maps and virtual_alias_domains parameters. Please also check that mynetworks is configured exactly as I did, or you will make your mail server vulnerable to spam bots. You can see my complete configuration here: Add your email aliases Edit /etc/postfix/virtual file and add your aliases, one per line, like in this example: info@yourdomain.com youremail@gmail.com sales@yourdomain.com youremail@gmail.com At this point update the alias map and reload Postfix configuration: sudo postmap /etc/postfix/virtual sudo /etc/init.d/postfix reload Conclusion As you can see, configuring Postfix is quite easy, you just need to be careful when you configure the DNS records in the control panel. Are you curious to try how Digital Ocean VPS works? Fancy 10\\$ credit (enough for 2 months if you choose the basic droplet) for free ? Use this link and enjoy it https://www.digitalocean.com/?refcode=cc8349e328a5","tags":"HowTo","url":"https://www.andreagrandi.it/2014/08/31/getting-started-with-digital-ocean-vps-configuring-dns-and-postfix-for-email-forwarding/","loc":"https://www.andreagrandi.it/2014/08/31/getting-started-with-digital-ocean-vps-configuring-dns-and-postfix-for-email-forwarding/"},{"title":"Travis-ci.org and Coveralls.io: Continuous Integration and QA made easy","text":"Developing a large web application or before deploying some code is very important to verify the quality of the code itself, check if we have introduced any regression or bug and have something that tell us if we are increasing or decreasing the quality of the code. Suppose we are in an organization or a company where the basic rule is: master branch is always ready/stable to be deployed. In a team usually people work on personal branches, then when the code is stable it's merged with master. How do we check if the code is stable and ready to be merged? First of all we need to cover all our code with proper tests (I won't go in details about unit testing here, I assume that the reader knows what I'm talking about), then we need to actually run them, possibly in an isolated environment that is similar to the production one, and check if they all pass. If they do, we are quite safe to merge our code with master branch. How can we ensure that all the developers remember to run tests when they push some new code? To make things a bit more real, let's take the example of a Python/Django product (or even a library) that currently supports Python 2.6, 2.7, 3.3 and Django 1.4.x, 1.5.x, 1.6.x . The whole matrix consists of 9 possible combinations . Do we have to manually run tests on 9 configurations? No, we don't. Travis-ci.org Travis is a continuous integration tool that, once configured, takes care of these tasks and let us save lot of time (that we can use to actually write code). Travis-ci.org is an online service that works with GitHub (it requires we use GitHub as repository for our code), and once we have connected the two accounts and configured a very simple file in our projects, it's automatically triggered when we push on our GitHub repository. The configuration consists of adding a file named .travis.yml in the root of our project. A working example is available here https://github.com/andreagrandi/workshopvenues/blob/master/.travis.yml (all the env variables I set are not required normally, but that's where I save the values of my configuration, so they need to be initialized before I can run tests). The service supports most of the languages that are commonly used and even a good number of PAAS, making it very easy to automatically deploy our code. If it should not be enough for your needs, they also expose a public API . I suggest you to give a look at the official documentation that will explain everything in details http://docs.travis-ci.com Once everything is configured, we will have something like this on our console https://travis-ci.org/andreagrandi/workshopvenues/jobs/19882128 If something goes wrong (if tests don't pass for example) we receive a notification with all the informations about the failing build, and if we had configured an automatic deployment of course the code would not be deployed in case of a failing build. Travis-ci.org is completly free for opensource projects and has also a paid version for private repositories. Coveralls.io There is a nice tool available for Python called coverage . Basically it runs tests and checks the percentage of the source code that is covered by tests, producing a nice report that shows us the percentage for every single file/module and even the lines of code that have been tested. Thanks to Coveralls.io and the use of Travis, even these tasks are completly automatized and the results are available online like in this example https://coveralls.io/builds/560853 The configuration is quite easy. We need to connect our Coveralls.io profile with GitHub, like we did for Travis-ci.org and then enable the repository. To trigger Coveralls after a successful Travis build, we need to have these lines at the end of our .travis.yml file after_success : - coveralls Even Coveralls.io is completly free for opensource projects and offers a paid version for private repositories. Heroku I use Heroku to host and run my web application. Normally to deploy on Heroku you so something like this: git push heroku master Adding these settings to the .travis.yaml file, I can automatically deploy the application on Heroku, if the build was successful: deploy : provider : heroku api_key : secure : R4LFkVu1/io9wSb/FvVL6UEaKU7Y4vfen/gCDe0OnEwsH+VyOwcT5tyINAg05jWXhRhsgjYT9AuyB84uCuNZg+lO7HwV5Q4WnHo5IVcCrv0PUq/CbRPUS4C2kDD7zbA1ByCd224tcfBmUtu+DPzyouk23oJH+lUwa/FeUk0Yl+I= app : workshopvenues on : repo : andreagrandi/workshopvenues run : - \"python workshopvenues/manage.py syncdb\" - \"python workshopvenues/manage.py migrate\" Not only the code is deployed, after deployment the South migrations are executed. Conclusion These two tools are saving me lot of time and are ensuring that the code I release for a project I'm working on ( WorkshopVenues ) is always tested when I push it on my repository.","tags":"Linux, Programmazione, Python","url":"https://www.andreagrandi.it/2014/03/02/travis-ci-org-and-coveralls-io-qa-made-easy/","loc":"https://www.andreagrandi.it/2014/03/02/travis-ci-org-and-coveralls-io-qa-made-easy/"},{"title":"Factoryboy: Creating data for unit tests in an easy way","text":"I recently prepared a presentation about Factoryboy , a Python library that automates lot of the work when a developer needs to create some data for unit testing. I've been using this library since a couple of months, both in the company where I work and on a personal open source project I'm working on. I will give a presentation about this library in an internal workshop in my company and I'm available to give it in any Python/Django related event around London , if anyone is interested. The slides are already available:","tags":"Programmazione, Python","url":"https://www.andreagrandi.it/2014/01/30/factoryboy-creating-data-for-unit-tests-in-an-easy-way/","loc":"https://www.andreagrandi.it/2014/01/30/factoryboy-creating-data-for-unit-tests-in-an-easy-way/"},{"title":"How to fix encfs installation on OSX 10.9 (Mavericks) and brew","text":"After upgrading from OSX 10.8.x to 10.9 (Mavericks), encfs recipe is broken. First of all you have to fix a problem with a library header: sudo ln -s /usr/include/sys/_endian.h /usr/include/sys/endian.h then you can install encfs using this remote brew recipe: brew reinstall https://gist.github.com/ghibble/7297078/raw/cae1ff000a5e1cfc670f5b7a611279ed494b63af/encfs.rb It's also possible that you have to fix fuse4x installation before being able to use encfs (I had to do it): sudo /bin/cp -rfX /usr/local/Cellar/fuse4x-kext/0.9.2/Library/Extensions/fuse4x.kext /Library/Extensions sudo chmod +s /Library/Extensions/fuse4x.kext/Support/load_fuse4x That's it! Please note that this is just a workaround (thanks to Giovanni Bajo for suggesting me the symlink fix). Please also note that this recipe uses fuse4x library and not the most updated osxfuse (but it works, anyway). Some other users reported me that there is a fix for the original brew recipe, and this one uses osxfuse. You can find it here https://gist.github.com/defunctzombie/7324625 but I haven't tested it yet. Update: to fully integrate encfs with OSX, I also suggest to follow this nice guide http://www.maketecheasier.com/install-encfs-mac/","tags":"HowTo, OSX, Sicurezza","url":"https://www.andreagrandi.it/2013/11/08/how-to-fix-encfs-installation-on-osx-10-9-mavericks-and-brew/","loc":"https://www.andreagrandi.it/2013/11/08/how-to-fix-encfs-installation-on-osx-10-9-mavericks-and-brew/"},{"title":"How to make subwoofer work in Ubuntu","text":"Using the same computer with Windows 8 and Ubuntu I noticed that the sound was worse in Ubuntu and I discovered why soon: subwoofer doesn't work out of the box! How to fix it The fix is quite easy to apply (but it was not easy to find the right one!). First of all edit /etc/pulse/default.pa and add this line at the end: load-module module-combine channels = 6 channel_map = front-left,front-right,rear-left,rear-right,front-center,lfe then edit /etc/pulse/daemon.conf , modify the line enable-lfe-remixing: no to enable-lfe-remixing: yes , then uncomment it (remove the semicolon in front of it). Reboot your PC and enjoy the subwoofer! References http://forums.gentoo.org/viewtopic-t-859769.html http://askubuntu.com/questions/53802/subwoofer-sound-preferences-problem","tags":"HowTo","url":"https://www.andreagrandi.it/2013/06/22/how-to-make-subwoofer-work-in-ubuntu/","loc":"https://www.andreagrandi.it/2013/06/22/how-to-make-subwoofer-work-in-ubuntu/"},{"title":"How to fix a WordPress website hacked by \"zend_framework\" malware","text":"I admit. This website , like thousands of others, has been hacked ! I still have to identify the precise source of the attack, but I've found out that is very common. I was able to discover about the attack just because the dashboard of WordPress stopped working. I decided to investigate and I found this strind on top of every .php file http://pastebin.com/k0iQymRy Just googling I discovered that I was not alone http://stackoverflow.com/questions/16963818/server-hacked-on-wordpress-files How to fix this? The best solution would be to restore the files with a valid backup, but sometimes this is not possible. Here comes an handy bash solution (note: you need to be able to access your hosting with a SSH shell to execute this command): http://pastebin.com/V3nFwwtZ","tags":"HowTo, Linux, Sicurezza, Ubuntu (EN), WordPress","url":"https://www.andreagrandi.it/2013/06/22/how-to-fix-a-wordpress-websitet-hacked-by-zend_framework-malware/","loc":"https://www.andreagrandi.it/2013/06/22/how-to-fix-a-wordpress-websitet-hacked-by-zend_framework-malware/"},{"title":"How to fix pip under Debian 6.0 (squeeze): ImportError: cannot import name parser","text":"The pip utility distributed with Debian 6.0 has a bug once you upgrade it with pip install -U pip . You will easily get this error when you try to install a new package with it: root@worker2:~# pip install setproctitle Traceback ( most recent call last ) : File \"/usr/bin/pip\" , line 8 , in from pip.baseparser import parser ImportError: cannot import name parser Luckly there is a very easy workaround: easy_install pip rm /usr/bin/pip ln -sv /usr/local/bin/pip-2.6 /usr/bin/pip pip install pip --upgrade Reference: http://blog.102web.ru/tag/virtualenvs/","tags":"HowTo, Linux, Programmazione, Python, Ubuntu (EN)","url":"https://www.andreagrandi.it/2013/05/02/how-to-fix-pip-under-debian-6-0-squeeze-importerror-cannot-import-name-parser/","loc":"https://www.andreagrandi.it/2013/05/02/how-to-fix-pip-under-debian-6-0-squeeze-importerror-cannot-import-name-parser/"},{"title":"Using virtualenv to manage multiple Python/Django environments in the same machine","text":"Developing Python applications sometimes it's useful to be able to test the code with different environments, for example a particular version of Python or a specific Django version etc... Setting up many different virtual machines would be really too much work and even using a chroot environment is not what you need in some cases. Thanks to virtualenv is it possible to create a self contained Python environment with all the specific libraries you may need. Using virtualenv is very easy: Creating the virtual environment: virtualenvmyenv --no-site-packages Entering the virtual environment: source myenv/bin/activate Deactivating the virtual environment: deactivate That's it! Once you're inside the virtual environment you will be using the Python libraries inside it. I suggest you to install all the Python libraries you need using pip .","tags":"HowTo, Linux, Programmazione, Python, Ubuntu (EN)","url":"https://www.andreagrandi.it/2013/04/25/using-virtualenv-to-manage-multiple-pythondjango-environments-in-the-same-machine/","loc":"https://www.andreagrandi.it/2013/04/25/using-virtualenv-to-manage-multiple-pythondjango-environments-in-the-same-machine/"},{"title":"UDS happening online only: pros and cons","text":"When last week Canonical announced the usual UDS was not going to happen I was a bit shocked and disappointed: starting from the next UDS (that is going to happen tomorrow!) the event will be online only and every 3 months . During these days I've been thinking a lot about this move and I will tell you what are the pros and cons, in my opinion, followed by some final thoughts. Pros Having 4 UDS every year, instead of 2, is surely a better thing. I'm a big fan of Scrum methodology, so I think that iterating more often is better than iterating less. If there are any mistakes you can correct them and iterating again before releasing the final product. Potentially more people can partecipate to the event (even the opposite is true and I will explain why). People won't need to move from home, travel, pay any expense etc... they just need a computer and a good Internet connection. It's cheaper for everyone : I can just imagine how expensive could be for Canonical to organize a similar event. Booking a big hotel, paying travel and expenses to near one houndred of community people. People who didn't get any sponsorization had to pay all the travel expenses to attend the event. Cons Potentially less people can partecipate to the event. Yes, like I said before even this sentence is true and I will explain why. First of all, using Google+ there are at least three countries that will be cut out: China , Thailand and Vietnam . Google+ is not available in those countries. Are you sure that special people will be able to follow the event? For example blind people won't be able to chat or to ask question in the chat. Only 10 people will be able to talk. In normal UDS sessions more people could raise the hand and ask a question or interact with the track leaders. Who will choose the 10 people with audio+video streaming rights? We will completly miss the social aspect of the UDS. If you think this was only a secondary part, please go on. I felt more committed to work and collaborate with people I met in person than with someone I've never met before. Announcing an event, even if online, just one week before it happens. Really? Some people had already taken vacation from work, booked flights etc... not counting many people that can't take 2 days off from work just with 1 week notice period. It's also almost impossible that community members have the time to schedule a blueprint and be able to discuss about a subject. Final thoughts From a cutting costs point of view I really can't say anything. Organizing UDS was surely very expensive for Canonical and nobody can blame them if they decided to spend those money in a different way. What really concerns me: is UDS still useful? My opinion is that at least since latest 2 or 3 UDS the presence of the Community was not so relevant, because I had the clear sensation that the most important decisions were made by Canonical before the UDS and then there was just some details tuning. Another proof of my thoughts is the today announcement: despite the fact that I 100% agree with Unity switching to Qt/QML (I already proposed this 2 years ago during Budapest UDS, but nobody listened to me) I completly disagree with the way the decision was made : not a single involvement or discussion with the community. I would apreaciate more openness and honesty from Canonical. Do you want to take all the decisions? That's fine, but at least state it clearly.","tags":"Ubuntu (EN), UDS","url":"https://www.andreagrandi.it/2013/03/05/uds-happening-online-only-pros-and-cons/","loc":"https://www.andreagrandi.it/2013/03/05/uds-happening-online-only-pros-and-cons/"},{"title":"Using Twitter Bootstrap with Node.js, Express and Jade","text":"I've decided to write this post as a note to myself. I'm still learning Node.js and digging into Express/Jade, but I've read many people using the nice Twitter Bootstrap and I was wondering if there was a way to integrate all these technologies. The short answer is: yes, we can! Note: once again, I'm not a Node.js expert and surely there are other ways to achieve this task (for example there is a Node.js module called twitter-bootstrap , but I haven't tried it). This tutorial is based on another tutorial I found, but it was not very updated and it had a more complicated way to install Bootstrap, so I decided to write a new one basing it on the original http://www.rs.au.com/31/how-to-install-bootstrap-v2-0-2-in-expressjs-v3-0-0 Preparing the environment I will assume that you're running any Linux distribution (in my case I'm using Ubuntu 12.10, but feel free to use your own distribution). Be sure to have installed a recent version of nodejs and npm packages (I'm using Node.js 0.8.20 and npm 1.2.11). Create a project folder and install the required dependencies mkdir node-bootstrap cd node-bootstrap npm install express npm install jade Create the basic project structure with Express andrea@andrea-Inspiron-660:~/Documents/sviluppo/nodejs/node-bootstrap$ node_modules/express/bin/express nodebootstrap create : nodebootstrap create : nodebootstrap/package.json create : nodebootstrap/app.js create : nodebootstrap/public create : nodebootstrap/public/javascripts create : nodebootstrap/public/images create : nodebootstrap/public/stylesheets create : nodebootstrap/public/stylesheets/style.css create : nodebootstrap/routes create : nodebootstrap/routes/index.js create : nodebootstrap/routes/user.js create : nodebootstrap/views create : nodebootstrap/views/layout.jade create : nodebootstrap/views/index.jade install dependencies: $ cd nodebootstrap && npm install run the app: $ node app You should already have installed all the needed dependencies, even without executing npm install , anyway executing it won't hurt. Download and install Bootstrap Download Twitter Boostrap from the official website http://twitter.github.com/bootstrap/assets/bootstrap.zip and unzip it under the nodebootstrap/public folder. Bootstrap integration with Jade template system At this point you need to edit the views/layout.jade file and include the references to Bootsrap html head title = title link ( rel= 'stylesheet' , href= '/bootstrap/css/bootstrap.min.css' ) link ( rel= 'stylesheet' , href= '/bootstrap/css/bootstrap-responsive.min.css' ) link ( rel= 'stylesheet' , href= '/stylesheets/style.css' ) script ( src= 'https://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js' ) script ( src= '/bootstrap/js/bootstrap.min.js' ) body block content Test the Bootstrap integration At this point we will modify views/index.jade that is the default template used to render the index extends layout block content div .top form .form-horizontal ( method= \"post\" , id= \"loginForm\" ) label Username input .span3 ( id= \"username\" , type= \"text\" , name= \"User\" , placeholder= \"Enter your username\" ) label Password input .span3 ( id= \"password\" , type= \"password\" , name= \"Password\" ) input .btn ( type= \"submit\" , value= \"Log In\" ) div .container div .content table .table.table-striped thead tr th Table th Heading tbody tr td Blah td Test tr td Hello td World div .footer Now go back to the terminal and execute the app: andrea@andrea-Inspiron-660:~/Documents/sviluppo/nodejs/node-bootstrap/nodebootstrap$ node app.js Express server listening on port 3000 Open your favourite browse and visit http://localhost:3000 to see your first Bootstrap + Node.js application app and running.","tags":"HowTo","url":"https://www.andreagrandi.it/2013/02/24/using-twitter-bootstrap-with-node-js-express-and-jade/","loc":"https://www.andreagrandi.it/2013/02/24/using-twitter-bootstrap-with-node-js-express-and-jade/"},{"title":"Fundraising for CuteSoma (Soma.fm mobile client) development","text":"Developing CuteSoma and maintaining it for three different platforms (Nokia N9, Windows Phone, BlackBerry 10) is really taking me a lot of time. I've many features in mind to add but I can't dedicate much spare time to them and to do it I should take time from other paid projects. I've also discarded the idea to make CuteSoma a paid app, because it's been always free (except the Windows Phone one that was non-free for just a month, but only 6 people \"SIX\" bought the app). So I decided to open a fundraising campaign on Indiegogo that is a service like KickStarter , but it's available all around the world (not just in USA and UK like Kickstarter). What do I Need & What You Get I would like to raise at least 5.000€ to be able to keep maintaining the existing features and to implement new one. Developing for 3 different platforms really takes a lot of time. I also need to find a way to get a Windows Phone 8 device because at the moment I cannot test some features using just the emulator. What the application currently does: You can view the list of Soma.fm channels You can listen any channel Features I would like to add: Scrobbling song to Last.fm Write a new MediaSource for Windows Phone (the default one is quite bugged and I need to implement one from scratch) Port the BlackBerry10 version to the native CascadesUI The Impact Funding the development of CuteSoma you will make thousands of people really happy, because they will be able to listen to Soma.fm on their Nokia N9, Windows Phone and BlackBerry 10 devices. You will also make me feel apreciated for all the hours I'm spending to write the code :) Completly Opensource Yes. CuteSoma is completly opensource . I keep my source code on GitHub and BitBucket and it's always updated. All the CuteSoma versions are released under the GPL license . CuteSoma for Nokia N9 - source code: https://github.com/andreagrandi/CuteSoma CuteSoma for BlackBerry 10 - source code: https://github.com/andreagrandi/CuteSoma/tree/bb10 CuteSoma for Windows Phone - source code: https://bitbucket.org/andreagrandi/cutesoma/src Other Ways You Can Help If you want to contribute but you can't or you don't want to send money, you could help me in the following ways: 1) Download and use the application: Nokia N9 : http://store.ovi.com/content/205737 Windows Phone : http://www.windowsphone.com/en-us/store/app/cutesoma/387185ca-1328-4d1c-a4c2-45568cf06470 BlackBerry 10 : http://appworld.blackberry.com/webstore/content/20200430/ 2) Tweet/Blog about this fund raising campaign: http://www.indiegogo.com/projects/cutesoma-soma-fm-client/x/2353169","tags":"BlackBerry, Maemo (EN), MeeGo, Programmazione, Windows Phone","url":"https://www.andreagrandi.it/2013/02/10/fundraising-for-cutesoma-soma-fm-mobile-client-development/","loc":"https://www.andreagrandi.it/2013/02/10/fundraising-for-cutesoma-soma-fm-mobile-client-development/"},{"title":"How to install latest stable Node.js on Ubuntu","text":"If you develop with Node.js and you want to be sure to have the latest stable version, luckly there is a PPA for it. All you need is to follow these instructions: sudo apt-get install python-software-properties python g++ make sudo add-apt-repository ppa:chris-lea/node.js sudo apt-get update sudo apt-get install nodejs npm That's it! Reference: https://github.com/joyent/node/wiki/Installing-Node.js-via-package-manager","tags":"HowTo, Linux, Programmazione, Ubuntu (EN)","url":"https://www.andreagrandi.it/2013/02/08/how-to-install-latest-stable-node-js-on-ubuntu/","loc":"https://www.andreagrandi.it/2013/02/08/how-to-install-latest-stable-node-js-on-ubuntu/"},{"title":"The Windows Phone Emulator wasn't able to connect to the Windows Phone operating system: how to fix it","text":"This morning when I started my Windows Phone 8 emulator to test an application, the emulator refused to work, giving me this error \" The Windows Phone Emulator wasn't able to connect to the Windows Phone operating system \". Luckly it's very easy to fix. It's caused by the virtual network interface that has been disabled for some reason (well... in my case it must depend on the other day when I tryed to trick WP7 firmware upgrade and used the disconnect trick, but this is another story). I searched on Google for a solution and I landed on this page http://pauliom.com/2012/12/20/the-windows-phone-emulator-wasnt-able-to-connect-to-the-windows-phone-operating-system/ All you have to do is going to \" Network and Internet --> Network Connections \", right click on \" vEthernet (Internal Ethernet Port) Windows Phone Emulator \" and Enable it.","tags":"HowTo, Programmazione, Windows, Windows Phone","url":"https://www.andreagrandi.it/2013/02/03/the-windows-phone-emulator-wasnt-able-to-connect-to-the-windows-phone-operating-system-how-to-fix-it/","loc":"https://www.andreagrandi.it/2013/02/03/the-windows-phone-emulator-wasnt-able-to-connect-to-the-windows-phone-operating-system-how-to-fix-it/"},{"title":"Using QtCreator to deploy and run a Qt application to a remote Linux device","text":"QtCreator is a very flexible IDE and can really be adapted for a lot of things. I usually use it to develop mobile applications for Nokia N9 and BlackBerry 10, but it can be used for more generic tasks. In my case I wanted to be able to develop a Qt application using my desktop PC, deploy it and run on a remote (actually it's on the same desk) Linux machine running Xubuntu. Doing this is quite easy and you don't need any specific plugin on QtCreator, but be sure to have at least version 2.6.x. Other than QtCreator you also need two Linux based PC (I used Ubuntu 12.10 for my development machine and Xubuntu 12.10 for the remote netbook) and an SSH account on the remote PC. Add the remote device to QtCreator To add the remote Linux device on QtCreator, use the Tools->Options menu and click on \" Devices \" item. At this point click on \" Add \" button and fill the fields using values similar to the screenshot. In particular specify a name for the device, the IP of the remote machine and a username and password that must already exist (I just created the user \"andrea\" on the Xubuntu machine and used the same password). I also had to set the timeout to 20 seconds, because I had some connection problems and the connection kept dropping after 10 seconds trying. To verify if everything is working fine, just click on Test button. Add a specific Qt version To write your application you may need a specific Qt version that is different from the one distributed by your Linux distribution. There's no problem, QtCreator let you add different Qt versions without any conflict. In my case I installed the Qt5 version distributed by Canonical Qt5 Edgers Team : https://launchpad.net/~canonical-qt5-edgers Once it's installed, just click on \" Add \" button and select the qmake specific to the version you want to add (in my case it was in /opt/qt5/bin/qmake ). Add a Qt Kit QtCreator permits to add new Kit (development configurations) and these kits are used during project creation to specify what you want to target. In my example I added a new kit choosing an appropriate name \"Qt5 Ubuntu\", the device type , the actual device previously configured and finally the Qt version that we added before. With a kit I have a complete \"toolchain\" that allow me to write applications for a particular device, with a specific Qt version. Putting the pieces together At this point you just have to create a new \" Qt Quick 2 \" application, and select the new kit you just created instead of the \"Desktop\" one. Please note that there is a little problem that I haven't fixed yet (but I'm working on it): if you create, for example, a project named \"QtTest1\" it will be deployed to the folder /opt/QtTest1/ on the remote machine. By default your user doesn't have read+write permissions for that folder so I manualy created the folder and I gave a chmod 777 on it, just for testing. There are two possible ways to fix this: you could create a specific user that has read+write permissions on /opt/ or you could modify the deployment configuration to have the app deployed to the user /home (I will investigate on this possibility and I will write something in one of the next posts). Final thoughts What all of this could be useful for? Well, do 2+2 and you'll easily guess ;) In the next weeks I will post more specific informations and I will update everyone with my progresses. Any comment is welcome! If you want to contribute to this you're welcome too of course.","tags":"HowTo","url":"https://www.andreagrandi.it/2013/01/17/using-qtcreator-to-deploy-and-run-a-qt-application-to-a-remote-linux-device/","loc":"https://www.andreagrandi.it/2013/01/17/using-qtcreator-to-deploy-and-run-a-qt-application-to-a-remote-linux-device/"},{"title":"Spotify 0.8.8 for Linux crashes if it cannot connect to Internet: how to fix it","text":"If you upgrade Spotify for Linux to 0.8.8.x version and you have some network connection problems (for example you're behind a company firewall and need to set a proxy...) the application will crash/hang without letting you doing anything (neither setting Proxy informations) This is caused by a deadlock in the GUI and you can view the complete debugging informations here http://pastebin.com/zcKgXEqz To fix this, you just need to open this file ~/.config/spotify/prefs and add these two lines: network.proxy.addr=\"123.123.123.123:1234@https\" network.proxy.mode=2 of course substituting 123.123.123.123:1234 with your proxyip:proxyport .","tags":"HowTo, Linux, Ubuntu (EN)","url":"https://www.andreagrandi.it/2013/01/06/spotify-0-8-8-for-linux-crashes-if-it-cannot-connect-to-internet-how-to-fix-it/","loc":"https://www.andreagrandi.it/2013/01/06/spotify-0-8-8-for-linux-crashes-if-it-cannot-connect-to-internet-how-to-fix-it/"},{"title":"Using Cloud9 IDE to develop Django applications","text":"Django is becoming very popular for dynamic websites development (actually it already is) so I decided to start learning it, with the help of a good book . To develop Django web applications you need a good IDE and an environment that support at least Python and a database (SQL Lite, MySQL etc...). If you have multiple machines and you alternate from multiple operating systems, the best thing is using an environment that you can use everywhere, from your favourite browser. Here comes Cloud9 , a very nice service that you could define as the \"Google Docs\" for developers. C9 offers you a shared, always available on the cloud, environment to write your code. They also offer access to a Linux terminal (so you can install applications, like Django) and your websites are istantly available online for remote testing. Installing and using Django on C9 is very easy. You just need to open a new terminal tab (ALT+T) in C9 and execute these commands easy_install django python ./../bin/django-admin.py startproject myproject python ./myproject/manage.py runserver $OPENSHIFT_INTERNAL_IP : $PORT After these commands, your Django website will be live and accessible using http://projectname.username.c9.io (where projectname is the name of the project you just created and username is your C9 user name). source: http://support.cloud9ide.com/entries/21830983-django-development-in-c9","tags":"HowTo, Programmazione, Python, Ubuntu (EN)","url":"https://www.andreagrandi.it/2013/01/05/using-cloud9-ide-to-develop-django-applications/","loc":"https://www.andreagrandi.it/2013/01/05/using-cloud9-ide-to-develop-django-applications/"},{"title":"CuteSoma (Soma.fm client) ported to BlackBerry10","text":"During these Christmas holidays I've ported the N9 version of CuteSoma to BlackBerry10 platform, thanks to the BB10 Alpha device that RIM gave to me and thanks in particular to my friend Cornelius Hald that helped me with porting. The porting itself was quite easy after all: if you have a Qt application that uses MeeGo Qt components, you have to switch to Symbian components (they're more portable and support higher resolutions) and to do it I suggest you follow the informations on this blog post http://www.johanpaul.com/blog/2011/12/porting-meego-qt-components-apps-to-symbian/ If you need more detailed informations about Symbian Qt Components, you can also read this nice blog post from Cornelius Hald http://kodira.de/2012/12/qt-components-on-blackberry-10/ How does it look So, what's the result of my porting? Well, first of all a couple of screenshots Source Code And finally the source code: https://github.com/andreagrandi/CuteSoma/tree/bb10 The application will be published soon in the BlackBerry App World and you will have it available in time for the BlackBerry 10 launch!","tags":"BlackBerry, Programmazione, Qt","url":"https://www.andreagrandi.it/2013/01/03/cutesoma-soma-fm-client-ported-to-blackberry10/","loc":"https://www.andreagrandi.it/2013/01/03/cutesoma-soma-fm-client-ported-to-blackberry10/"},{"title":"CuteSoma (Soma.fm client) for Windows Phone available","text":"It's a pleasure for me to announce the first public release of CuteSoma for Windows Phone (WP7 and WP8). CuteSoma is a mobile client for the amazing Soma.fm radio a listener-supported, commercial-free, underground, alternative radio broadcasting over 20 unique channels from San Francisco. This is my first application for WP platform, and unlike the N9 version that was completly free of charge, I've decided to release this version in two ways: a free trial version with just 3 (and other 3 coming with the next imminent upgrade) radio channels available and a full version with all Soma.fm channels for just 0.99 €. I don't think it's too expensive, right? Consider all the time I've spent coding it and if you like the trial version, please support the development of this application and purchase the full one. Install CuteSoma Press Search button on your Nokia Lumia (or any other Windows Phone) and tap vision button Scan the following QrCode 3. Tap on the link when it appears on the screen 4. Install the application from the Windows Phone Store 5. Enjoy! Please consider also donating to Soma.fm if you like their music: Soma.fm is donation supported and they need your \"love\" to pay their bills :)","tags":"Windows Phone","url":"https://www.andreagrandi.it/2012/12/14/cutesoma-soma-fm-client-for-windows-phone-available/","loc":"https://www.andreagrandi.it/2012/12/14/cutesoma-soma-fm-client-for-windows-phone-available/"},{"title":"Leaving Finland (and Nokia), coming back to Italy!","text":"After a very pleasant experience in Finland (Tampere) , I've finally come back to Italy. I had the opportunity to work for three months in Nokia as \" Qt Expert \" in \" Nokia Developer Forum \" and it's been an amazing job! To be more precise I left Finland on August 31th, but I didn't have much time to blog about this. Finally I can use my desktop PC again and I'm not anymore limited to my small netbook. Trust me... spending 3 months with a 11'' netbook and pretending to work normally is really frustrating. Now I have more spare time (too much :\\ ) to contribute to Ubuntu and to play with some new technologies: I'm working on a project that uses Arduino , Android and some \"robotic\" parts, with people of Pistoia Linux User Group and it's really an amazing learning experience! Talking about Ubuntu, if you have never contributed to it and you would like to start with something easy, I suggest you this interesting initiative https://wiki.ubuntu.com/UbuntuDevelopment/BugFixingInitiative In the mean time I'm also looking for new opportunities and challenges (aka = looking for a new job), so if you think you may be interested in me, take a couple of minutes to give a look to my LinkedIn profile http://www.linkedin.com/in/andreagrandi I will attend next UDS in Copenaghen (99% sure) and I already have a couple of topics I would like to work with, but I will talk about these later, first I want to properly create a blueprint in Launchpad so we will have a starting point.","tags":"Maemo (EN), Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/09/13/leaving-finland-and-nokia-coming-back-to-italy/","loc":"https://www.andreagrandi.it/2012/09/13/leaving-finland-and-nokia-coming-back-to-italy/"},{"title":"Ubuntu Release Sprint: calling for feedback!","text":"During the last UDS party, I had an idea to improve Ubuntu development, but I didn't know if it could be a good idea or a stupid one, so I talked to Daniel Holbach and David Planella about it and they were happy to hear about it and Daniel told me to talk about this directly to Mark (and I did it). Let's explain the basic idea. From an UDS and the next one, it would be useful to have a development sprint where people can talk about assigned UDS blueprints, at which point they are on their tasks, if they have any problems and if they will finish them within the next UDS. Of course Canonical cannot organize another meeting, it would be very expensive, so the idea is: why don't we use Google Hangout to organize the sprint? I has a limit of 10 people, I know, but we could select (for example) 5 from the community and 5 from Canonical. There would be parallel meeting and tracks, we would use the same blueprints used during the last UDS and we would add further notes. The attendees would be able to listen and watch the stream and make questions through the available chat. I've also created a wiki page with more informations and you can find it here: https://wiki.ubuntu.com/UbuntuReleaseSprint What do you think about? I know that Canonical is already organizing sprints and this could be a way to involve more the Ubuntu Community. Maybe we should schedule a session at next UDS to talk about this? I hope to get some feedback from you.","tags":"Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/08/17/ubuntu-release-sprint-calling-for-feedback/","loc":"https://www.andreagrandi.it/2012/08/17/ubuntu-release-sprint-calling-for-feedback/"},{"title":"Social Connect QML plugin: access Facebook, Twitter from your Qt/QML applications","text":"Social Connect is a library written in Qt that allows applications to easily connect to services like Facebook and Twitter . Recently I had the opportunity to work on this library improving it and adding support for Instagram (work is still in progress but it's almost finished). The main features of this library are: Out-of-the-box support for Facebook and Twitter Integrated authentication implementation Simplified common interface for all supported services Provides interfaces for native API calls Design enabling easy addition of new services e.g. LinkedIn If you are writing an application that needs to access these services, this could be the library for you. It can be extended to support even other services like LinkedIn, Flickr etc... and I would like to invite people to contribute to the code. The library has been tested with Qt 4.8.1 on Ubuntu Linux 12.04 but it should be compatible with any other versions/platforms. For more informations about getting started with the library, I suggest you to give a look at this page https://projects.developer.nokia.com/socialconnect/wiki/GettingStarted","tags":"Maemo (EN), MeeGo, Programmazione, Qt, Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/08/13/social-connect-qml-plugin-access-facebook-twitter-from-your-qtqml-applications/","loc":"https://www.andreagrandi.it/2012/08/13/social-connect-qml-plugin-access-facebook-twitter-from-your-qtqml-applications/"},{"title":"Ubuntu Release Sprint: a proposal to improve Ubuntu development","text":"Yesterday, during the final UDS party, I had an idea to improve Ubuntu development, but I didn't know if it could be a good idea or a stupid one, so I talked to Daniel Holbach and David Planella about it and they were happy to hear about it and Daniel told me to talk about this directly to Mark (and I did it). Let's explain the basic idea. From an UDS and the next one, it would be useful to have a development sprint where people can talk about assigned UDS blueprints, at which point they are on their tasks, if they have any problems and if they will finish them within the next UDS. Of course Canonical cannot organize another meeting, it would be very expensive, so the idea is: why don't we use Google Hangout to organize the sprint? I has a limit of 10 people, I know, but we could select (for example) 5 from the community and 5 from Canonical. There would be parallel meeting and tracks, we would use the same blueprints used during the last UDS and we would add further notes. The attendees would be able to listen and watch the stream and make questions through the available chat. I don't want to write more details here because I don't think it's the right place (and probably it's not the moment to write a similar blog post, since I'm still in th SFO Airport), my idea is to create a wiki page to explain all the details, so everyone would be able to add more ideas and see if it's doable or not. So, what do you think about? I think we should try, it doesn't cost anything except some hours in the week we'll organize it. I wait for your comments then.","tags":"Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/05/12/ubuntu-release-sprint-a-proposal-to-improve-ubuntu-development/","loc":"https://www.andreagrandi.it/2012/05/12/ubuntu-release-sprint-a-proposal-to-improve-ubuntu-development/"},{"title":"Ubuntu 12.04, Nvidia 8800 GS and Nouveau drivers","text":"After upgrading my desktop PC to Ubuntu 12.04 (actually my main machine) I started experimenting many Xorg crashes and instability issues. I reported the bug , but I had to find a solution or I should have rolled back to Ubuntu 11.10. The problem (from my point of view) is of the new Nvidia 295.40 binary drivers. I also tried an older version (295.33) experiencing the same problems. I then decided to give the Nouveau opensource drivers a try. I must say that in over 24 hours I didn't have a single Xorg crash. My desktop is very stable and Nouveau drivers are pretty fast: I can watch a 1080p video on Youtube in full screen without having any problem. The only problem with my machine is that I'm using a VGA Switcher to share my monitor wit Xbox (see this old post ), so my monitor capabilities cannot be detected automatically and I had to do some manually tuning of the Xorg configuration. First of all I had to resolve a very annoying problem: the screen was blinking every 10 seconds and this really hurted my eyes. To fix this I had to add a kernel parameter: drm_kms_helper.poll=0 you need to add this string in /etc/default/grub to the GRUB_CMDLINE_LINUX_DEFAULT parameter. After this your line should look like this one: GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash drm_kms_helper.poll=0\" Don't forget to execute: sudo update-grub from the command line. Then I had to create a proper xorg.conf setting my resolution (1680x1050) manually: Section \"Monitor\" Identifier \"DVI-I-1\" VendorName \"Asus\" ModelName \"Ancor Communications Inc VW222\" Modeline \"1680x1050R\" 119 .00 1680 1728 1760 1840 1050 1053 1059 1080 +hsync -vsync Option \"PreferredMode\" \"1680x1050R\" EndSection Section \"Screen\" Identifier \"Screen0\" Monitor \"DVI-I-1\" EndSection How do you generate the Modeline line? It's very simple. Just execute: \" cvt -r 1680 1050 \" in the command line and you'll get a line similar to the one I added (of course substitute those numbers with the resolution you want). You have to save this file in /etc/X11/xorg.conf and reboot your system to use all the new settings. Now my system runs nicely and very fast! I'm really enjoying the new Ubuntu 12.04 Precise Pangolin . I just hope that Nvidia guys will fix the sta bility issues of their driver as soon as possible, so I'll be able to choose again between the opensource driver and the closed source one (faster with 3D stuff, but more unstable as you can see). A big thanks to everyone in #nouveau IRC channel on Freenode . They were very kind to help me configuring their opensource driver.","tags":"HowTo, Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/04/27/ubuntu-12-04-nvidia-8800-gs-and-nouveau-drivers/","loc":"https://www.andreagrandi.it/2012/04/27/ubuntu-12-04-nvidia-8800-gs-and-nouveau-drivers/"},{"title":"Using QML qt-components with QtQNX for BlackBerry PlayBook","text":"With BlackBerry PlayBook you can now use Qt libraries to develop your applications. The problem is that QML components are not available yet (they will be available with CascadesUI in the near future), but you can use Symbian qt-components to develop your application UI. This should also make the porting of an existing Symbian Qt application easier. We suppose you have already built and installed QtQNX under this directory: ~/QtQNX/ARM/ (please change it matching the folder where you installed it). At this point you have to get qt-components sources using this command: git clone git://gitorious.org/qt-components/qt-components.git qt-components Now enter the directory you just checked and compile the components: cd qt-components QTDIR = \\~ /QtQNX/ARM/ ./configure -symbian make Whend you complete all the previous operations, you'll have two directories inside qt-components/imports , please copy them inside the QtQNX installation directory: cp -R imports/Qt \\~ /QtQNX/ARM/imports/ cp -R imports/com \\~ /QtQNX/ARM/imports/ That's all for now. In the next posts I'll show you how to use these components, providing a small code example. In the mean time you can find more informations here http://supportforums.blackberry.com/t5/Native-SDK-for-BlackBerry-Tablet/QML-symbian-qt-components-for-PlayBook/td-p/1574275","tags":"HowTo, Programmazione, Qt","url":"https://www.andreagrandi.it/2012/03/30/using-qml-qt-components-with-qtqnx-for-blackberry-playbook/","loc":"https://www.andreagrandi.it/2012/03/30/using-qml-qt-components-with-qtqnx-for-blackberry-playbook/"},{"title":"Ubuntu Global Jam Italy (Pistoia): a quick review","text":"Yesterday in Pistoia (Italy) we had the Ubuntu Global Jam and about 15 people attended the event. We began with an introductive talk by Paolo Sammicheli about the Italian Ubuntu Community and how it is possible to contribute to Ubuntu. We divided in two small groups, one translating from English to Italian (coordinated on IRC by the people of the community) and another group leaded by Marco Trevisan , learning how to implement automatic tests in Unity code (in particular he introduced us Autopilot , more information here: https://wiki.ubuntu.com/Unity/QA/Autopilot ). Next time I would like to ask people to register to Launchpad and sign the Code of Conduct before attending the global jam. We wasted a lot of time with this task. At the end of the day me and the other people from Pistoia, took the other people for a quick tour around the city where we had the possibility to eat some tasty food. It was a very amazing day and people who started collaborating for the first time were very happy! I think this has been a successful day, at least for us. I hope the other LoCo are having a good Jam as well and I really can't wait for the next Ubuntu Global Jam.","tags":"Linux, Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/03/04/ubuntu-global-jam-italy-pistoia-a-quick-review/","loc":"https://www.andreagrandi.it/2012/03/04/ubuntu-global-jam-italy-pistoia-a-quick-review/"},{"title":"Sharing your PC monitor with your Xbox using a VGA Switcher","text":"Few days ago I decided to move my Xbox 360 from the room where is the TV to the room where I have my desktop PC. I wanted to avoid wasting precious space on my desk, so I decided to share my 22'' monitor with the Xbox and I bought a VGA Switcher . With this product you can easily switch the VGA signal between your PC and the Xbox and also the audio signal. The problem with this solution is the fact that your monitor is not anymore attached directly to your graphic card and this causes problems detecting the monitor capabilities. Please note that the switcher doesn't reduce the resolution you can have, it just make the graphic card impossible to detect the correct resolution. If you have an Nvidia graphic card you can use the nvidia-settings tool to manually set the configuration and to save it to a file, so during the next boot even if Ubuntu won't be able to detect the proper resolution for your monitor, it will simply apply the configuration found in xorg.conf Please remember to also set the refresh rate of the monitor (I was having a very bad resolution until I didn't choose 60 Hz in the settings window). If you don't have a Nvidia graphic card (and the proper tool) to generate a xorg.conf file or if you just want to give a look at my configuration here you have a copy: # nvidia-settings: X configuration file generated by nvidia-settings # nvidia-settings: version 280.13 (buildd@rothera) Thu Aug 11 17:28:49 UTC 2011 Section \"ServerLayout\" Identifier \"Layout0\" Screen 0 \"Screen0\" 0 0 InputDevice \"Keyboard0\" \"CoreKeyboard\" InputDevice \"Mouse0\" \"CorePointer\" Option \"Xinerama\" \"0\" EndSection Section \"Files\" EndSection Section \"InputDevice\" # generated from default Identifier \"Mouse0\" Driver \"mouse\" Option \"Protocol\" \"auto\" Option \"Device\" \"/dev/psaux\" Option \"Emulate3Buttons\" \"no\" Option \"ZAxisMapping\" \"4 5\" EndSection Section \"InputDevice\" # generated from default Identifier \"Keyboard0\" Driver \"kbd\" EndSection Section \"Monitor\" # HorizSync source: edid, VertRefresh source: edid Identifier \"Monitor0\" VendorName \"Unknown\" ModelName \"Ancor Communications Inc VW222\" HorizSync 31 .0 - 81 .0 VertRefresh 56 .0 - 75 .0 Option \"DPMS\" EndSection Section \"Device\" Identifier \"Device0\" Driver \"nvidia\" VendorName \"NVIDIA Corporation\" BoardName \"GeForce 8800 GS\" EndSection Section \"Screen\" Identifier \"Screen0\" Device \"Device0\" Monitor \"Monitor0\" DefaultDepth 24 Option \"TwinView\" \"0\" Option \"TwinViewXineramaInfoOrder\" \"CRT-0\" Option \"metamodes\" \"1680x1050\\_60 +0+0; nvidia-auto-select +0+0\" SubSection \"Display\" Depth 24 EndSubSection EndSection Remember to save the file in /etc/X11/xorg.conf and on next boot you will have the right resolution even with your VGA Switcher in use.","tags":"HowTo, Linux, Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/02/26/sharing-your-pc-monitor-with-your-xbox-using-a-vga-switcher/","loc":"https://www.andreagrandi.it/2012/02/26/sharing-your-pc-monitor-with-your-xbox-using-a-vga-switcher/"},{"title":"Ubuntu: synchronizing settings among multiple computers using Ubuntu One","text":"Using more than one computer, often it would be useful to have a way to synchronize settings among multiple computers. For example you change the desktop wallpaper on your office PC and you want to find the same wallpaper when you go back home on your personal PC or on your laptop. Language settings, online accounts, privacy settings ecc... are only few examples of settings you could want to have synchronized. Ubuntu One already gives you 5 Gb space for free and it's available for everyone activating it. It's a perfect place for storing a shared folder with all those settings. Of course not a simple folder, a special one. Applications use settings taken from usual \\~/.appName and a daemon takes care of synchronizing data once you're connected to Internet. Just like Ubuntu One does with your documents. How do I choose which settings to synchronize? First of all you have to activate an Ubuntu One account , if you don't have already done it, then you just have to choose the settings you want using this tool available in Ubuntu System Settings What? A mockup?! Isn't this tool available yet??!! Exactly :) This tool is not available yet , but I think it would be an interesting feature to talk about for the next (not precise, I mean 12.10) Ubuntu release. What do you think about?","tags":"Linux, Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/02/21/ubuntu-syncronizing-settings-among-multiple-pc-using-ubuntu-one/","loc":"https://www.andreagrandi.it/2012/02/21/ubuntu-syncronizing-settings-among-multiple-pc-using-ubuntu-one/"},{"title":"Ubuntu Global Jam - March 3rd 2012: Pistoia (Tuscany), Italy.","text":"Even this time Pistoia Linux User Group decided to join the international event \"Ubuntu Global Jam\" organizing it in collaboration with Ubuntu-it Community . The international event will be on March 2nd, 3rd and 4th and we have decided for March 3rd (saturday) from 15:00 CET to 19:00 CET . This event will be organized in a room made available by Circolo ARCI Bonelle . We'll have a room capable of about 100 people and a smaller one with 4 PC and a big table for people who want to bring their own laptop. Wifi internet connection will be available for everyone. The event will be introduced by a talk made by Paolo Sammicheli of the Ubuntu-it Community and then we will divide in some smaller groups that will dedicate to different tasks. One will be coordinated by Paolo Sammicheli and will be dedicated to testing and bug triaging. Another group will do some translations from english to italian and will collaborate directly with italian translation team talking with them on a dedicated IRC channel. The last group will be leaded by a very good Unity rockstar..... (suspance)...... Marco Trevisan ! People collaborating directly with him will try to help fixing some bugs or at least they will learn how to get started to bug fixing (probably we will pick a bitesize bug and we will fix it together). We've created an event on Facebook and invited all our friends to attend. We really hope that many people will partecipate to this opportunity to make the next Ubuntu version more... \" precise \"!","tags":"Linux, Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/02/19/ubuntu-global-jam-march-3rd-2012-pistoia-tuscany-italy/","loc":"https://www.andreagrandi.it/2012/02/19/ubuntu-global-jam-march-3rd-2012-pistoia-tuscany-italy/"},{"title":"CuteSoma - worldwide downloads statistic for Nokia N9","text":"CuteSoma (Soma.fm client for Nokia N9) has been available for 4 months now and it's the right time to publish some interesting statistics about downloads. First of all I didn't expect so much interest and I wasn't sure to have so many downloads, due to the fact that Nokia never advertised this device properly. But luckly lot of people don't care about advertising and buy a product anyway if they know it's one of the best available on the smartphone market. I'm really happy to notice that the number of downloads is growing each month, this motivates me to continue with development (well... when my N950 comes back from Nokia, since I had to send it because it was broken). I want to thank all the 3658 people that downloaded CuteSoma until now and all the people that are sending me their feedback, ideas and patches (yes Cornelius Hald , I'm talking about you :D ) you're giving me a big opportunity to learn C++/Qt/QML .","tags":"Maemo (EN), MeeGo, Qt","url":"https://www.andreagrandi.it/2012/02/03/cutesoma-worldwide-downloads-statistic-for-nokia-n9/","loc":"https://www.andreagrandi.it/2012/02/03/cutesoma-worldwide-downloads-statistic-for-nokia-n9/"},{"title":"Nokia QtSDK installer crash on Ubuntu: how to fix it","text":"If you try to install Nokia QtSDK on Ubuntu using the Nokia installer (that provides a newer version than the one distributed in Ubuntu Software Center) you could get an error like this: ( Qt_SDK_Lin32_offline_v1_1_3_en.run:3126 ) : Gtk-CRITICAL **: IA__gtk_widget_style_get: assertion ` GTK_IS_WIDGET ( widget ) ` failed to fix it, you need to run the installer with a specific parameter: ./Qt_SDK_Lin32_offline_v1_1_4_en.run -style cleanlooks and everything should work!","tags":"HowTo, Linux, Programmazione, Qt, Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/01/12/nokia-qtsdk-installer-crash-on-ubuntu-how-to-fix-it/","loc":"https://www.andreagrandi.it/2012/01/12/nokia-qtsdk-installer-crash-on-ubuntu-how-to-fix-it/"},{"title":"Backing up all your Flickr photos using Linux","text":"I've been a Flickr pro user for 4 years, but the pro account costs 24,95$/year and I was looking for something cheaper. Anyway I was thinking that after all, even if I don't renew my account, I can always access to all my pictures.... wrong! If you don't renew your pro Flickr account you can only access to the low resolution version of your own pictures. That's not acceptable for me, so I decided to download all my pictures and upload them somewhere else. Here comes the second disappointment: there is no automatic way to download all your pictures . I simply had no time to write an application by myself, so I started searching on Google to see if there was something available to do this simple task. At the beginning I only found abandoned tools (closed source, the API was expired ecc...), paid tools, Windows only tools ecc... but finally I found this post http://hivelogic.com/articles/backing-up-flickr/ There is a Python script that automatically downloads all your Flickr pictures getting the highest resolution available, you can download the script from here https://github.com/dan/hivelogic-flickrtouchr The usage is very simple mkdir FlickrBackupFolder python flickrtouchr.py FlickrBackupFolder A browser's window will be opened and you'll be prompted for authorization. After that, all you pictures will be downloaded.","tags":"HowTo, Linux, Python, Ubuntu (EN)","url":"https://www.andreagrandi.it/2012/01/05/backing-up-all-your-flickr-photos-using-linux/","loc":"https://www.andreagrandi.it/2012/01/05/backing-up-all-your-flickr-photos-using-linux/"},{"title":"ebook: valgono la pena rispetto ai libri cartacei? L'esempio Amazon Kindle","text":"In questo periodo diversi conoscenti mi stanno facendo domande su come siano gli ebook e se valga la pena farne uso rispetto ai normali libri cartacei. Recentemente ho avuto modo di acquistare il lettore Kindle di Amazon e devo ammettere di essere rimasto molto soddisfatto. Ho cercato di raccogliere le principali domande che mi sono state fatte al riguardo, sperando di fornire una panoramica completa sui libri in formato elettronico e sui relativi lettori. Non è scomodo leggere sul Kindke? Assolutamente no. Non dovete immaginare il Kindle come un tablet (anzi, chi cerca un qualcosa che funzioni anche come tablet ha proprio sbagliato prodotto. Kindle è fatto per leggere libri.), lo schermo infatti non è un normale LCD come quelli dei tablet o dei portatili, ma una speciale superficie dove le parole vengono disegnate tramite l' e-ink . Lo schermo del Kindle non è retroilluminato e per leggere, così come per un libro normale, c'è bisogno o della luce del sole o di stare vicino ad una lampada. Gli occhi quindi non si stancano ed è possibile andare avanti a leggere per ore, senza notare differenze rispetto alla lettura di un libro normale. Quanto costano i libri in formato elettronico? Di solito il costo è di 3-4€ in meno rispetto alla versione cartacea. Potrebbero costare molto meno se la legge italiana (ancora una volta cieca di fronte alle innovazioni) non equiparasse gli ebook a dei prodotti elettronici. L'IVA sugli ebook è infatti del 21% e non viene assolta come per i libri cartacei. Va detto anche che moltissimi libri, per i quali sono ormai scaduti i diritti di autore, sono disponibili gratuitamente. Volete leggere La Divina Commedia , Pirandello , I Promessi Sposi ecc...?! Benissimo. Questi e molti altri libri sono scaricabili gratuitamente. Kindle al momento offre \"soltanto\" 16.000 titoli in italiano, ma è ovviamente possibile accedere anche a tutti gli altri titoli disponibili in lingua straniera, per un totale di quasi un milione di libri a disposizione . Quali sono i vantaggi per chi scrive? Gli scrittori, grazie agli ebook, hanno un modo ancora piu' facile e redditizio per pubblicare i propri libri. Attualmente, se uno scrittore vuole pubblicare un libro, deve trovare un editore che lo reputi interessante e decida di investire per pubblicarlo. Visto che l'editore di assume un rischio molto alto, la maggior parte del compenso va a lui. Con Amazon invece è possibile pubblicare un proprio libro in modo economico e veloce. Non c'è necessità di stampare migliaia di copie di un libro, così come avviene per il cartaceo. I compensi inoltre sono molto alti: il 70% del ricavato va a chi scrive il libro , non all'editore. Su un libro da 10€ quindi, all'autore rimangono 7€. Riassumiamo i vantaggi degli ebook economici (costano 3-4€ in meno, molti sono persino gratuiti) ecologici (non c'è bisogno di stampare migliaia di copie) maggiori introiti per chi scrive i libri un e-reader è leggero, può contenere oltre 1000 libri, ottima autonomia con batterie che durano 1 mese comodità di poter acquistare un libro direttamente da casa ed averlo in pochi minuti nessun pericolo di acquistare un libro che non ci piace: con Kindle è possibile avere una copia dei primi capitoli del libro, senza spendere niente, in modo da valutare se il libro valga veramente la pena di essere letto Se posso aggiungere un vantaggio, del tutto soggettivo, ma che personalmente è il piu' importante: gli ebook mi hanno fatto tornare anche la voglia di leggere!","tags":"Review","url":"https://www.andreagrandi.it/2011/12/30/ebook-valgono-la-pena-rispetto-ai-libri-cartacei-lesempio-amazon-kindle/","loc":"https://www.andreagrandi.it/2011/12/30/ebook-valgono-la-pena-rispetto-ai-libri-cartacei-lesempio-amazon-kindle/"},{"title":"Ubuntu Oneiric 11.10 problems and regressions","text":"Tomorrow Ubuntu 11.10 (Oneiric Ocelot) will be released officially and I decided to test the RC (release candidate) version on my desktop PC. Being involved in Unity-2D development I used only that desktop environment on my development virtual machine so I didn't have much time to test Unity (3D version). I must admit that there have been a lot of improvements from 11.04 (Natty Narval) release, but also a lot of bugs and regressions have been introduced. I've noted all the problems I found in every day use and as soon as possible I'll also submit proper bug report on Launchpad for each of them. In the mean time you can give a look to the following list. Bugs and regressions Notifications broken: on Ubuntu Natty when an application wants to notify of a new message it popups an icon from the Launcher, then displays a small blue triangle in the top-left corner of the screen. Oneiric doesn't have the small blue triangle anymore. In this way, if the user is looking away when he gets a notification, he can miss it for hours. There's no way to know that there is a notify without manually going with mouse to the left and making the launcher to appear. Launcher visibility: on Ubuntu Natty when the user moves the mouse in the top-left corner the Launcher is shown. Oneiric doesn't show Launcher if you move the mouse in the top-left corner. You can't use the top 30-40 pixels (the height of the panel). Notify area icons: often in Oneiric when you click an icon in the notify area (for example the volume icon, the network manager icon ecc...) the popup is shown and suddenly hidden. You have to click a second time to view it. Notify icon - Empathy: in Oneiric you cannot open Empathy from the notify area. If you click on \"Chat\" Empathy is open and visible on the Launcher but not on the screen. You have to move to mouse to the launcher then click on it to view the application window. Empathy: \"Automatically connect on startup\" doesn't work. If you enable this option in Empathy it doesn't start anyway when the system start. Launcher doesn't work as expected: sometimes when you move the mouse on the left, Launcher is not shown. You can try it many times and it still doesn't appear. I've to SUPER+D a couple of times (to show/hide Desktop) to show view it. Even the opposite problem happens: sometime you cannot hide the Launcher. Boot failing: every time I boot Oneiric the first boot fails. I cannot know what happens because nothing is shown on video. I press CTRL+ALT+CANC, the system reboot and then boot normally. Showing Skype: on Natty you just need to double-click on Skype icon in the notify bar to show it, now you need to click once on the icon, choose \"Activate\" from menu and you show it. Why the need to complicate an easy thing? Webcam problems with Skype: with Natty I could use my webcam with Skype without any problem. Now I can still use it but if I activate the view of myself during a videcall, the video completly locks and it doesn't work anymore. Skype is always the same version, so probably there is a problem with the new driver used. Window manager: sometimes moving an application window doesn't work. You drag a window around the screen then suddenly the window stop moving and the mouse icon starts vibrating. You have to release and click again to move the window and stop mouse icon vibrating. Conclusion In the next days I'll work on checking for these bugs on Launchpad to see if they're already submitted and if not I'll submit them, hoping they will be fixed as soon as possible before end users start bothering about them.","tags":"Linux, Ubuntu (EN)","url":"https://www.andreagrandi.it/2011/10/12/ubuntu-oneiric-11-10-problems-and-regressions/","loc":"https://www.andreagrandi.it/2011/10/12/ubuntu-oneiric-11-10-problems-and-regressions/"},{"title":"CuteSoma: Soma.Fm client for Nokia N9/N950 now available on OVI Store","text":"CuteSoma is a client of Soma.Fm streaming radio that I wrote using Qt/QML for Nokia N9 and Nokia N950 . Previously it was available as a .deb only, now you can install it directly from the OVI Store . It's only a 0.1 version and even if it's quite stable it may contains some bugs: please report me any bug so I can try to fix them as soon as possible. CuteSoma is opensource and released under the GPL v.3 license. You can find the complete source code here: https://github.com/andreagrandi/CuteSoma There is a poll available to let the final users choose the new icon for this application, you can find it here: http://forum.meego.com/showthread.php?t=4619 I asked for help to design a new icon and I received two, so I'm letting the final users choose which one they like most. To get this application you need to search \"cutesoma\" on OVI Store client or visit this link http://store.ovi.com/content/205737 Please remember that CuteSoma is free , but if you want you can make me a donation or offer me a beer using the \"Donazione\" button on the right column.","tags":"Maemo (EN), MeeGo","url":"https://www.andreagrandi.it/2011/09/30/cutesoma-soma-fm-client-for-nokia-n9n950-now-available-on-ovi-store/","loc":"https://www.andreagrandi.it/2011/09/30/cutesoma-soma-fm-client-for-nokia-n9n950-now-available-on-ovi-store/"},{"title":"HowTo extend HTC Desire internal memory to 2Gb using CyanogenMod 7 and Data2SD","text":"Introduction Even if it's not a new model, the HTC Desire is still a very good Android device, thanks to its 1Ghz CPU and 512 Mb RAM , but one of the biggest problems of this phone is that it comes with only 148Mb available in the ROM. Once the operating system is installed (ROM I mean), after installing few useful applications you'll end the available space very soon. There are many apps available, like App2SD that move your applications to the SD card, but it's not enough because only the application is moved, not the data. To move the data to the SD card, there is a very nice utility called Data2SD . Please note that this procedure requires you to reflash your device and partition your SD card, so please do a complete backup before proceding. What you need a rooted HTC Desire (you need to have a rooted phone with a recovery already installed) a 4Gb (or bigger) microSD , at least class 4 (class 6 is even better while class 10 is reported not working with this phone) a microSD card reader CyanogenMod 7 : http://download.cyanogenmod.com/get/update-cm-7.0.3-Desire-signed.zip Data2SD : Data2SDInstallerX1.zip and Data2SDReInstallerX1.zip Google Apps : http://wiki.cyanogenmod.com/wiki/Latest_Version#Google_Apps GParted : you can use the version available on Ubuntu Linux or you can download a live Linux image with GParted installed: http://gparted.sourceforge.net/livecd.php Backup your data Before following these instructions, please do a complete backup of your microSD, of your original ROM (using Nandroid or similar) ecc... Prepare the microSD card Open GParted on your Ubuntu Linux or use the GParted Live CD/USB. Delete all partitions on this microSD Create the first one using FAT32 filesystem, leaving 2Gb ( 2047Mb ) available at the end. Create a second partition using ext4 filesystem. Confirm your changes Copy CyanogenMod7 rom, Data2SD installers and Google Apps on FAT32 partition CyanogenMod 7 installation Reboot your phone into Recovery (turn it off then press volume down + power) WIPE all data (userdata, cache ecc...) Choose \"Install from SD card\" and select CyanogenMod7 installation zip when finished reboot your phone Enter your Wifi settings, language ecc.... DO NOT enter your Google account settings. reboot your phone Data2SD installation Boot into Recovery again Choose \"Install from SD card\" and select Data2SDInstallerX1.zip (please note, you may have to turn off the signature verification in Other->Turn off ecc...) when finished reboot your phone now you should see 1,97Gb if you go in Settings->Storage->Internal Storage->Total space Google Apps installation Reboot your phone into Recovery Choose \"Install from SD card\" and select the Google Apps zip file reboot your phone Conclusion You now have 1,97Gb total space available instead of 148Mb. Enjoy your HTC Desire! Update Aug 1, 2012: since December 2011 I don't have an HTC Desire anymore. These informations could be still valid but in any other case I don't have the possibility to help you more.","tags":"HowTo","url":"https://www.andreagrandi.it/2011/08/13/howto-extend-htc-desire-internal-memory-to-2gb-using-cyanogenmod-7-and-data2sd/","loc":"https://www.andreagrandi.it/2011/08/13/howto-extend-htc-desire-internal-memory-to-2gb-using-cyanogenmod-7-and-data2sd/"},{"title":"UDS day-3","text":"Even this morning I didn't wake up early because I still felt sick (I already know this sore throath won't abandon me untile I go back home). I had a light breakfast at 10:30 and then I finishes uploading some pictures and published articles on my blog I already had written before. While waiting to attend a session, I found Mark Shuttleworth around and I congratulated with him for the effort he is putting into Ubuntu. Without a similar distribution, I'm pretty sure that Linux would not be so popular today. We had lunch at 13:00 as usual and after that I attended a couple of presentation. The first one on Eucalyptus, then \" Cooking Recipes \" for Ubuntu and another one dedicated to Wine . The Wine session was so funny! They had a little problem with video projector and all the images appeared with a blur effect so that you could think to be drunk ;) After these sessions I had to go back to my room since I didn't feel very well, but I was able to attend \" Unity's relations and dependancies on GNOME \" thanks to audio streaming, IRC for asking questions and etherpad to take notes. I attended also \" desktop-dx-o-unity-a11y \" where there was a discussion about the state of Unity and what can be improved before Oneiric release. Lot of work has to be done yet, in particular about accessibility. Last session of this day, a Q+A with Mark Shuttleworth . The session was very interesting! He replied to all questions coming from the public and from IRC.","tags":"Linux, Ubuntu (EN), UDS","url":"https://www.andreagrandi.it/2011/05/11/uds-day-3/","loc":"https://www.andreagrandi.it/2011/05/11/uds-day-3/"},{"title":"UDS day-2","text":"This day at UDS started a bit late for me, since i woke up pretty sick (damn air conditioned!!!). I did not follow any conferences in the morning. I relly wanted to follow the Wayland one, but when I arrived the room was already full and it was almost impossible to enter, so I decided not to enter. I attended \" What's wrong with UDS and how we can fix it \" session before having lunch. We discussed the possibility to improve all the session in general, for example giving them a proper order so that a team can first discuss some API interface, then another team can discuss how to design them. We had another wonderful and tasty lunch , even if I didn't eat so much, but food was very good anyway. During the afternoon I followed an interesting track: \" Recommend music based on current song playing or on users media library \". We discussed the possibilities to implement a music suggestion service, based on user's tastes. I spent the rest of theconference time writing these blog posts and uploading pictures. After the sessions we had the Linaro Showcase : lot of demo running on Linaro and ARM processors. I was really impressed by a robot with Kinect that was able to follow people recognizing their faces. During the showcase there was a very nice dinner. After dinner I went out with my friend Manrique Lopez who is here in Budapest for another conference, so we decided to meet for a good beer. Before coming back to the hotel me, Marco Trevisan and Andrea Azzarone had a nice talk with Jorge Castro . He really make us feel part of the Ubuntu family!","tags":"Ubuntu (EN), UDS","url":"https://www.andreagrandi.it/2011/05/11/uds-day-2/","loc":"https://www.andreagrandi.it/2011/05/11/uds-day-2/"},{"title":"UDS day-1","text":"My day started at 7:30 with a very nice breakfast! I was alone with just another guy this morning, in a very big breakbast room. After it I grabbed my badge to avoid queue later and went back to my room to wake up Marco Trevisan (he was still sleeping :P ). The keynote was opened by Jono Bacon (the Ubuntu Community manager), followed by Ubuntu founder Mark Shuttleworth . The most interesting (and tweeted) part of the keynote was \" how to prounounce Oneiric \" (Oeniric will be the next Ubuntu release). The keynote finished with a bit late, so all the other tracks were shifted forward. I followed \" Unity 2D Oneiric Improvements \", it was interesting because there were some Nokia/Qt guys and they looked very interested in helping the Unity 2D team and collaborating with them. Now following \" Shaping a strategy for Ubuntu user assistance \", I just had the possibility my involvement into helping people that require Ubuntu assistance. The lunch has been very tasty, I had the possibility to eat some local recipes, not bad at all. After lunch we had a short session on Qt . The version 4.8 is going to be released in a couple of months, while 5.0 is announced to be released in 1 year from now: it will be almost code-compatible with 4.x, it will have an improved support for Qt Quick and QML. As last track of the day I decided to follow \" Personal Cloud \". Not a perfect track, since the person who should have been here was only talking with us using Skype and it was more difficoult to hear what he said. At the end of this day there was the \" Meet & Greet \" party, sponsored by Freescale and Openstack. They offered a dinner and we had some good music after it.","tags":"Ubuntu (EN), UDS","url":"https://www.andreagrandi.it/2011/05/11/uds-day-1/","loc":"https://www.andreagrandi.it/2011/05/11/uds-day-1/"},{"title":"UDS day-0","text":"I left from Firenze with my friend Marco Trevisan , to go to Ubuntu Developer Summit in Budapest . We changed flight in Rome where we met also Andrea Azzarone . Unluckly Alitalia losts Marco's baggage , so he's still waiting for it. We arrived at the hotel at 20:00 more or less where we met other people of the community. There are lot of italians at UDS. Most work for Canonical, other were sponsored by. I met Marianna Raffaele (one of the UDS organizer... yeah, she's italian too!), I had to explain her a little problem I had with my booking (nothing bad) and she managed to help me. She also gave me a very nice guitar plettre with Ubuntu logo. Thank you Marianna for this! We went out with Jorge Castro to drink some beers (he offered me one, thanks Jorge!!!) and we met lot of other Ubuntu people. A really amazing start!","tags":"Ubuntu (EN), UDS","url":"https://www.andreagrandi.it/2011/05/11/uds-day-0/","loc":"https://www.andreagrandi.it/2011/05/11/uds-day-0/"},{"title":"Some ideas to improve Community collaboration for Ubuntu Developer Summit","text":"A few days ago I received an email from Jorge O. Castro of the Ubuntu Community, announcing me that my request of sponsorization for Ubuntu Developer Summit has been accepted. I have never attended an UDS before, so I must admit I feel a bit disoriented at the moment and maybe I'm missing some important informations, but at least I'm a good test for the situation of a community member approaching it for the first time. Since I would like to actively help the organization of the Summit, I started looking for the right place to do it. I've a good experience about events organization and during these years I helped, for example, in the organization of Maemo Summit and MeeGo Conference , so I'd like to share my experience with the Ubuntu Community too. USD Website The Ubuntu Developer Summit website is http://uds.ubuntu.com/ . It looks nice at first view, but it's missing a lot of important informations and it contains some errors. The Travel section, for example should be named \"Travel and Accomodation\" and should contains not only information about the main hotel where the Summit will take place, but also useful informations about cheap hotels/hostels for Community people who are not sponsored. The Tracks section is still empty. Is it possible that when less than 1 month is missing, official tracks are not available yet? I don't mean categories, I mean tracks inside them. The Schedule is still empty too. Clicking any track take to a page containing an error: I would like to submit this bug, but where? Even worse, clicking on Schedule takes the visitor to a different website and there is no ways to navigate back (except clicking the back button on browser). Forum I wasn't able to find any section in the official Ubuntu forum where to talk about Ubuntu Developer Summit. I think it would be useful to have a dedicated section to talk about UDS or about generic Ubuntu related events. It would be useful for people to be able to meet/know each other before attending. I was lucky to meet Marco Trevisan, from the Ubuntu Italian Community, so we will travel together (thanks to a Twitter message I sent!). IRC The #ubuntu-uds channel on FreeNode is not much populated and a couple of times I visited it nobody wrote anything. We should keep at least 2-3 people, in turns, always available to answer any question about UDS, it would be easier for people to find the informations they look for. Wiki It would be nice to have a page on the wiki to organize better the event. We could write a list of tasks to do and each Community member could pick one and help with it. In this way we could divide the jobs. I know there is a lot to do when we organize these kind of events and the help of the Community is something we cannot risk to miss. Media We should give some informations to people who will attend UDS to be sure they will use proper tags when they will publish pictures, tweets, blog entries ecc... Do we have a tag to use on Flickr? What is the right tag to use on Twitter? What keywords should we use when we will blog about the Summit? All these informations are important if we want to be sure other people will find our posts in an easy way. Mailing List Ubuntu has a lot of mailing lists , but it looks like none dedicated to events discussion. There is one called ubuntu-events-planners but nobody is using it since months ago. We should use a mailing list to discuss about events organization and/or create a dedicated one for UDS.","tags":"Ubuntu (EN)","url":"https://www.andreagrandi.it/2011/04/09/some-ideas-to-improve-community-collaboration-for-ubuntu-developer-summit/","loc":"https://www.andreagrandi.it/2011/04/09/some-ideas-to-improve-community-collaboration-for-ubuntu-developer-summit/"},{"title":"MeeGo Events Meeting - April 4th 2011 - Notes","text":"MeeGo Conference Updates We have 315 registrants as of today for the conference, so numbers are looking good without having any agenda published yet! A good portion of sessions should be approved by April 8th, this Friday and you will receive an email when/if your session has been approved yet. Not all the sessions will be approved by Friday though so if you do not hear from the committee then do not worry they are probably just working through it. The program committee is tenatively planning to have a first draft of the Agenda up by April 15th. Sponsored Travel attendees should start receiving approvals during next week and approvals will continue through April 25th. Warm-up You can follow the updates and planning on the Warm-up at http://wiki.meego.com/MeeGo_Conference_Spring_2011#MeeGo_Conference_Warm-Up T-shirt design contest For anyone who didn't see it on the mailing list this morning from Brian the winner of the T-shirt contest will receive sponsored airfare and hotel for the event in San Francisco. The contest closes next Friday, so get drawing! MeeGo Summit FI update MeeGo Summit FI (15-16th Apr). Summit will be 2-day developer oriented event as planned. Program contains keynotes, three tracks, meegathon competition, AR.Drone fun, evening party, Intel AppUp Lab, BoFs and more. http://summit.meegonetwork.fi Interest towards summit has been huge, beyond our expectations. We were fully booked after one week. We have \\~350 participants (limited by facilities and other details), over 140 are (still) in queue for cancellation seat. MeeGo Corporate Guidelines and Regional and Local Assets and Guidelines We in conjunction with Jarkko and the Finland team, the many contributors from the community, the Linux foundation, the events team, and the Caffelli design team have pulled together the guidelines for MeeGo Events. Thank you all for your contributions in putting these together! The Guidelines and Collateral Assets are posted on the Event's page at http://wiki.meego.com/Events#MeeGo_Conferences we would like your feedback and input so please email me amy.l.leeland@intel.com please send us things that you think we missed or things we could change to make the guidelines better. Note: you can find the original log here http://trac.tspre.org/meetbot/meego-meeting/2011/meego-meeting.2011-04-05-17.00.html","tags":"MeeGo","url":"https://www.andreagrandi.it/2011/04/06/meego-events-meeting-april-4th-2011-notes/","loc":"https://www.andreagrandi.it/2011/04/06/meego-events-meeting-april-4th-2011-notes/"},{"title":"Utilizzare la Carta Sanitaria Europea su Ubuntu Linux","text":"In questo periodo le regioni stanno inviando a casa di ogni cittadino la nuova versione della Carta Sanitaria Europea , simile a quella che potete vedere nella foto. Questa nuova carta, oltre a conservare gli stessi utilizzi di quella vecchia, comprende anche un micro chip che permette di utilizzarla con i comuni lettori di smartcard. Ma a cosa serve poter utilizzare la CSE con un lettore di smartcard? Ad esempio ad accedere al proprio fascicolo sanitario tramite il sito della regione, che ci permetterà di vedere alcuni nostri dati come ad esempio: medicine prese, esenzioni, ricoveri in ospedale, ricoveri al pronto soccorso, risultati delle analisi ecc... Per accedere all'area riservata non viene utilizzato il classico metodo di username/password, ma bensì l'autenticazione tramite smartcard. Installazione del lettore di smartcard Prima di utilizzare la carta su Ubuntu Linux è necessario intanto procurarsi un lettore di smartcard ( vi consiglio di acquistare il kit che vendono dove siete andati ad attivare la vostra CSE, poichè viene venduto ad un prezzo vantaggioso di 4,20€ mentre se provate a comprare il lettore altrove non lo troverete a meno di 15-20€) e poi installare sul proprio sistema alcuni pacchetti necessari al suo funzionamento. Il lettore, una volta inserito nel proprio PC dovrebbe essere identificabile tramite la seguente stringa: andrea@centurion: \\~\\$ lsusb Bus 002 Device 004 : ID 072f:90cc Advanced Card Systems, Ltd ACR38 SmartCard Reader Per installare il software necessario, occorre eseguire il seguente comando da terminale: sudo apt-get install pcsc-tools pcscd libccid dopo di che dovrete procurarvi il driver del lettore, che potete trovare a questo indirizzo ed installarlo con il seguente comando (dopo aver scompattato l'archivio in una cartella a piacimento): sudo dpkg -i libminilector38u-bit4id.deb Se tutto è stato eseguito correttamente, utilizzando il programma pcsc_scan da terminale, dovreste ottenere un output simile a questo: andrea@centurion: \\~\\$ pcsc_scan PC/SC device scanner V 1 .4.16 ( c ) 2001 -2009, Ludovic Rousseau <ludovic.rousseau@free.fr> Compiled with PC/SC lite version: 1 .5.3 Scanning present readers... 0 : ACS ACR 38U-CCID 00 00 Thu Nov 11 14 :08:37 2010 Reader 0 : ACS ACR 38U-CCID 00 00 Card state: Card inserted, ATR: 3B DF 18 00 81 31 FE 7D 00 6B 15 0C 01 81 01 11 01 43 4E 53 10 31 80 E8 Configurazione di Firefox Prima di poter configurare Firefox è necessario installare un'ultima libreria che permetterà al browser di poter interagire con il lettore di smartcard. Dobbiamo scaricare l'archivio presente a questo indirizzo , scompattarlo e poi copiare uno dei due file presenti (a seconda che si utilizzi un sistema a 32 o 64 bit) all'interno della cartella /usr/lib ed infine digitare il comando sudo ldconfig per aggiornare l'elenco delle librerie. A questo punto bisogna aprire Firefox ed andare su Modifica-->Preferenze-->Avanzate-->Cifratura-->Dispositivi di Sicurezza cliccare su Carica e specificare come descrizione \"CSE\" e come percorso quello dove avete copiato la libreria installata nel passo precedente (che ad esempio potrà trovarsi in /usr/lib/libaseCnsP11.so ). Per verificare che tutto funzioni correttamente è sufficiente fare click su Accedi e se ci verrà chiesto di inserire la \"password\" (che nel nostro caso sarà il PIN della smartcard) vorrà dire che tutto sta funzionando nel modo corretto. Per avere maggiori informazioni sulla Carta Sanitaria Europea e per conoscere tutti i servizi disponibili, vi consiglio di visitare la seguente pagina presente sul sito della Regione Toscana : http://www.regione.toscana.it/cartasanitaria/cse/cose/index.html","tags":"HowTo","url":"https://www.andreagrandi.it/2010/11/11/utilizzare-la-carta-sanitaria-europea-su-ubuntu-linux/","loc":"https://www.andreagrandi.it/2010/11/11/utilizzare-la-carta-sanitaria-europea-su-ubuntu-linux/"},{"title":"MeeGo Conference 2010 / Early Bird Events","text":"Introduction It would be nice to organize a weekend like the Barcelona Long Weekend we (the Maemo Community) organized on October 2009. These two days should be completly organized by the community and for the community. No formal conferences or talks, but interactive activities and hacking sessions where you, the participant, are the main actor. What about the content of these two days? We could have (for example) programming tutorials, Qt tutorials, hacking sessions on a specific task, round tables where a developer explains his difficoulties implementing a feature and the others help him, ecc... The first thing to do is spreading this and asking people (users, developers ecc...) what they would like to find during these two days. Once we've gathered some nice ideas we can organize them better. When and Where The basic idea is to organize these two days on November 13th, 14th . About the location that will host us we still have no idea. Probably it will be possible to use the same hotel used for the MeeGo Conference, but this must be confirmed yet. Ideas for the program structure Active participation in the event - less talk, more code. No powerpoints - just you, the editor and the compiler. Be productive! A two-day Hackathon: Start putting your ideas into fresh code, or finish a project that has been on the back burner for some time Participants are encouraged to share their progress at the end of each day - what they accomplished, where they need further help, etc. A short but intensive indroduction to Qt/C++ (something like 3-4 hours course, offered by some expert developer) Round tables to discuss about UI improvements or features implementation: a developer could have found some difficoult implementing the UI for his application or to provide a particular feature. Other expert developers could try to help him with his problem. A workshop for x86 developers on getting started with MeeGo development for ARM - end goal: By the end of the session, everyone has a sample application running in an emulator on their laptop Developer tools training - a half day on using git, valgrind, oprofile Discussion resources The official place where I would like to take this discussion forward is the MeeGo Forum. The official thread is available here: http://forum.meego.com/showthread.php?t=1342 We also have started a discussion on Maemo Forum and you can find it here: http://talk.maemo.org/showthread.php?t=61708 The official page with all informations available is on MeeGo Wiki: http://wiki.meego.com/MeeGo_Conference_2010/Early_Bird_Events","tags":"Linux, Maemo (EN), MeeGo, Programmazione","url":"https://www.andreagrandi.it/2010/09/05/meego-conference-2010-early-bird-events/","loc":"https://www.andreagrandi.it/2010/09/05/meego-conference-2010-early-bird-events/"},{"title":"Announcing my standing for the Maemo Council Q3-2010","text":"I've decided to candidate myself again (yes, I wasn't elected last time) for the Maemo Council elections . During these months I've tried to help more the Maemo Community and I've started working to two Qt/C++ projects. Here you can find something more about me. Name: Andrea Grandi maemo.org profile: Andy80 - http://maemo.org/profile/view/andy80/ Corporate affiliation: none Introduction My name is Andrea Grandi, I live in Italy and I'm a Computer Science student. I've worked for some years as a software developer, then I started university. I'm part of the Maemo Community since 2007. Since then I like to help new users, organizing events, developing applications for Maemo. During this year I've started developing applications using Qt/C++ for N900, to be ready when MeeGo for handled devices will be out. I really like to collaborate with other community members to build together the best product ever. My life in the Community May 2008: PyMaemo: Python for Nokia Internet Tablet @ PyCon Italia 2 - http://www.pycon.it/conference/talks/pymaemo-python-i-nokia-internet-tablet September 2008: ESBox and Pluthon Eclipse plugins: how to use Eclipse to develop Maemo applications @ Maemo Summit 2008 - http://wiki.maemo.org/Maemo_Summit_2008 Summer 2009: I worked to python-mafw bindings, during a stage in Igalia . October 2009: python-mafw: MAFW framework for Python developers @ Maemo Summit 2009 - http://wiki.maemo.org/Maemo_Summit_2009 May 2010: PySide: Python Bindings for the Qt Framework @ PyCon Italia 4 - http://www.pycon.it/conference/talks/qt-mobile-pyside-bindings Current Activities I'm currently working to two Maemo/MeeGo projects. The first one is mSoma , a Soma.Fm client that I'm developing with Lorenzo Bettini. The other one is LastGo , a Last.fm client. Both applications are written in Qt/C++ and are using QtMobility as multimedia libraries. mSoma : http://gitorious.org/msoma - http://maemo.org/packages/view/msoma LastGo : http://gitorious.org/lastgo - http://maemo.org/packages/view/lastgo Motivations I really would like to be able to do more for the community and one of the best way could be to be part of the council, to help both users/developers to explain their requests to Nokia and Nokia to understand the requests from the community. There are a lot of fantastic ideas coming from the community that could improve what we are doing: the key is to organize them and giving them more attention. This is what I've always looked for: working together to build something great! This will be probably the last Maemo Council, since now we (Maemo) and them (Moblin) are all part of the same community: MeeGo, and I'd like to help Maemo people to feel the most comfortable possible in our new Community.","tags":"Maemo (EN), MeeGo","url":"https://www.andreagrandi.it/2010/08/27/announcing-my-standing-for-the-maemo-council-q3-2010/","loc":"https://www.andreagrandi.it/2010/08/27/announcing-my-standing-for-the-maemo-council-q3-2010/"},{"title":"Maemo Coding Competition: voting open!","text":"What is Maemo Coding Competition? This competition has been organized by Maemo Community for the Maemo Community. Developer can work to an application and submit it for one of the six categories available: Desktop, System & Utilities, Games, Graphics & Multimedia, Location & Navigation, Other. Another category is available too, and it's for beginner developers. The competition entry has now ended, but voting is open. You can find more information about the competition, in the official wiki page: http://wiki.maemo.org/Maemo_Coding_Competition_1 How can I vote?** Voting is available using a forum's poll for each category. Every t.m.o. user can give one vote for each category. Here's the complete list of polls: Desktop: http://talk.maemo.org/showthread.php?p=760304 System & Utilities: http://talk.maemo.org/showthread.php?p=764039 Games: http://talk.maemo.org/showthread.php?t=58990 Graphics & Multimedia: http://talk.maemo.org/showthread.php?p=763679 Location & Navigation: http://talk.maemo.org/showthread.php?t=58964 Other: http://talk.maemo.org/showthread.php?t=59038 Beginners: http://talk.maemo.org/showthread.php?t=59074 p.s: I partecipate in the Graphics & Multimedia category with two applications: LastGo and mSoma . Please at least test them and let me know what do you think about!","tags":"Linux, Maemo (EN), MeeGo, Programmazione, Qt","url":"https://www.andreagrandi.it/2010/07/26/maemo-coding-competition-voting-open/","loc":"https://www.andreagrandi.it/2010/07/26/maemo-coding-competition-voting-open/"},{"title":"Announcing LastGo: Maemo/MeeGo client for Last.fm","text":"While I'm still working to mSoma with Lorenzo Bettini, I decided to start writing another application. I needed to write something from scratch to learn better how to use C++ and Qt libraries, so I decided to write a client for Last.fm service. The application is still in full development, but you can already taste it if you have extras-devel repository enabled on your N900 . At the moment it only supports basic radio features: tuning user's radio, playing a song, skipping a song and displaying song informations. Other basic Last.fm features like scrobbling, marking a song as loved or banned ecc.. are not supported yet, but of course they're planned for the stable release. Please not that the application is still a bit unstable even if it works for normal tasks. If you are a Last.fm subscriber and you want to test it, please install it from extras-devel repository and send me your feedback. Note: since it's not allowed to use Last.fm API from a mobile phone (due to API license restrictions) I cannot distribute a valid api key with the application. I'm writing this software mainly to learn C++ and Qt and for the future tablets and netbooks that will be based on MeeGo. If you feel to assume the responsability, you can download the api key file and import it using \"Import Api Key\" that you can find in the application menu.","tags":"Linux, Maemo (EN), MeeGo, Programmazione, Qt","url":"https://www.andreagrandi.it/2010/07/16/announcing-lastgo-maemomeego-client-for-last-fm/","loc":"https://www.andreagrandi.it/2010/07/16/announcing-lastgo-maemomeego-client-for-last-fm/"},{"title":"Announcing mSoma: Maemo/MeeGo client for SomaFM","text":"SomaFM is a streaming radio with near 16 different channels, available for free. Even if it's possible to copy-paste their streaming URLs to N900 Media Player, we ( me and Lorenzo Bettini ) decided to create a custom application, to make channels switching easier for the end user and to be able to add more features. We decided to take advantage of the new Nokia SDK and write the application in Qt/C++. Source code is available on Gitorious and it's always updated with latest version we're working on. If someone want to test the application, it's available in extras-devel repository (\"msoma\" under Multimedia section) of N900. The UI is still in development as you can see. The application is already usable, but of course we have to work hard on the user interface. Feel free to test/use it and send us any feedback. If you want to contribute to our project (coders are welcome) please send us a patch with your code or ask us to be added to mSoma development team in Gitorious.","tags":"Linux, Maemo (EN), MeeGo, Qt, Recensione","url":"https://www.andreagrandi.it/2010/07/03/announcing-msoma-maemomeego-client-for-somafm/","loc":"https://www.andreagrandi.it/2010/07/03/announcing-msoma-maemomeego-client-for-somafm/"},{"title":"Twitter client for Maemo in Qt + Python: call for developers and UI designers","text":"Introduction My name's Andrea Grandi , I'm italian and I'm a Maemo user/lover/contributor since the Nokia 770 . I love Python as development language and few months ago I also gave some contributions to the PyMaemo project. In these days I had the idea to start writing a Twitter client for Maemo with a precise direction in my mind. I'll try to explain all my reasons here. First of all I've to thank the author of Mauku client. I use it since its first version and I'm quite happy with it. Then, why do I want to write another one? Maemo (MeeGo) is moving to Qt and for this reason I'm going to use Qt, while Mauku uses Gtk. I'm learning Qt and what is better than writing a complete (but not too complex) application to learn better? Mauku is not free as lot of people could think. Reading the source codeyou find this \"You are NOT allowed to modify or redistribute the source code.\", while I want to write a client and release it under GPL2 or GPL3 license. Mauku is not updated since some months and we have no news about it. I love Python and I like to write free software in this language. I want to give to Maemo a stronger contribute. My request for help Before lot of people start writing their own client resulting in 4-5 twitter clients for Maemo, why don't we join our strength and work to a common project? I'm not a Python expert nor a Qt one, but I've some experience as project/team leader and since this is not a complex project, I would be glad to lead it. So, I'm looking for Python developers, Qt developers, UI designers and whoever want to contribute to this project. I still have to find a good name and logo for this application. Who want to help me?","tags":"Linux, Maemo (EN), MeeGo, Programmazione, Python, Qt","url":"https://www.andreagrandi.it/2010/02/22/twitter-client-for-maemo-in-qt-python-call-for-developers-and-ui-designers/","loc":"https://www.andreagrandi.it/2010/02/22/twitter-client-for-maemo-in-qt-python-call-for-developers-and-ui-designers/"},{"title":"Nokia N900: reboot loop after PR 1.1.1 upgrade is not a firmware bug","text":"Few days ago I published some notes about my personal experience with PR 1.1.1 firmware upgrade in Nokia N900 . In particular my device got an infinite reboot loop after upgrading the firmware and I had to flash the firmware image from scratch to fix the problem. Today I was kindly contacted by Max Waterman (I suppose he works for Nokia) and he explained me what was the problem. It was caused by a little bug in Harmattan UI demo and they fixed it (the fix is already available in extras-devel). No surprise for me: extras-devel contains unstable packages and if user enables it, he does at his own risk. The most important thing is the fact that the official firmware without any unstable application doesn't suffer of this problem at all. The thing that really impressed me so much (in a positive sense) it's that I was contacted privately by a Nokia developer apologizing for the bug (no problem man, it's part of the game if someone want to test extras-devel software) and explaining that they already fixed it. This is what I like of Maemo (or should I already call it MeeGo?), I really feel to be a part of it!","tags":"Linux, Maemo (EN), MeeGo","url":"https://www.andreagrandi.it/2010/02/20/nokia-n900-reboot-loop-after-pr-1-1-1-upgrade-is-not-a-firmware-bug/","loc":"https://www.andreagrandi.it/2010/02/20/nokia-n900-reboot-loop-after-pr-1-1-1-upgrade-is-not-a-firmware-bug/"},{"title":"Nokia N900: some problems with latest PR 1.1.1 firmware","text":"I don't know if it's just a case or if I'm the only one who had these problems, but I'll report them anyway, maybe somebody had my same problem and we could try to prepare a proper bug report to make the Maemo team fix them. Infinite boot loop after upgrade First of all I have to say that before upgrading to PR 1.1.1 I checked if I had enough space on the rootfs. I only had 27 Mb and so I decided to remove some unused applications, deleted some *.deb in /var/cache/apt/archives and disabled extras repositories. Of course I also did a backup of all my configuration. After the cleaning operation I had near 60 Mb free on rootfs, enough to install the upgrade. I closed all running applications, started the application manager and began the upgrade. After the upgrade was completed, the device did a reboot... then another one, then again, again.... until I had to remove the battery to stop it. Conclusion: I had to re-flash the device with the latest image to make it work again. mafw-dbus-wrapper taking all the CPU I was watching a video (using subtitles) and after some minutes the whole UI became unresponsive. Strange because I already did this before without having any problem. I tried to check the problem using \"top\" utility from terminal and I saw that there was a mafw process (mafw-dbus-wrapper) that was taking 80-90% of CPU. My fault is that normally there are at least 3-4 , mafw-dbus-wrapper processes and I didn't check which one was causing the problem. Anyway I made a screenshot, just in case it can help. I hope this short report can be useful to help Maemo team to fix or at least investigate what happened. Just leave a comment or contact me if you need more informations.","tags":"Linux, Maemo (EN), Recensione","url":"https://www.andreagrandi.it/2010/02/17/nokia-n900-some-problems-with-latest-pr-1-1-1-firmware/","loc":"https://www.andreagrandi.it/2010/02/17/nokia-n900-some-problems-with-latest-pr-1-1-1-firmware/"},{"title":"Maemo 6 (Harmattan) UI Screenshots","text":"Nokia has published a demo application for N900 , available in extras-devel repository, that shows a preview of Maemo 6 (Harmattan) user interface. Here there are some screenshots of the demo: Demo application main window Question dialog Text entry dialog Progress indicator Information banner Event banner Please note that installing this demo will also install Qt 4.6.2 on the N900 and about 52 Mb are required.","tags":"Linux, Maemo (EN), Qt, Recensione","url":"https://www.andreagrandi.it/2010/02/16/maemo-6-harmattan-ui-screenshots/","loc":"https://www.andreagrandi.it/2010/02/16/maemo-6-harmattan-ui-screenshots/"},{"title":"Fon: how long are you going to play tricks on users?","text":"Introduction As many of you already know, Fon is a spanish company that some years ago had the interesting idea of creating a wifi community to share the Internet connection. The idea is quite simple: each \"fonero\" buy a Fonera (the router sold by Fon), register it on the Fon system and get a username/password. If the fonero travels around the world he's able to connect to wifi signal of other foneras and browse the web for free. When I bought my first fonera few years ago, I was one of the first people in my city. I bought it because I was really beliving in this project. During these years Fon produced new models of fonera and I bought each of them (the WRT54 router, Fonera, Fonera+, Fonera 2.0g, Fonera 2.0n ecc....). Since first year, the Fon community has grown a lot and now there are a lot of foneros around the world. Actual situation Few months ago Fon launched a very interesting product: Fonera 2.0g . Thats's not only a router. Fonera 2 is capable of managing torrents, rapidshare downloads, uploading photo on Facebook and Flickr, and much more. Whats's wrong with this product? It's very unstable ! There are a lot of users that bought this router when it was anounced and they're still waiting for a lot of bugs to be fixed by Fon developers team (composed by only ONE person!). Why users had to wait so long? Simple! They were working to Fonera 2.0n! Wow! Faster router, more RAM, 4 ethernet port, wonderful! But... another very unstable router! And with unstable I mean: it disconnects/reboots often , connection is unstable, applications don't work ecc.... I'm talking about a 79€ router, not about something that users had as preview product. Me and other users were still waiting for an uograde when... Fon announced a new product ! Yes, another one! Fon priority is not to fix a product that thousand of users have already bought. Fon priority is to produce and sell a new product! Conclusion It could be only my opinion, but I don't trust you anymore Fon! I'm really disappointed about your behaviour you had with your customers. I've already spent (wasted) a lot of money with your not-working products and I'm not going to buy your products anymore! I'm tired of being illuded by your promises: how long are you going to play tricks on users?","tags":"Linux, Recensione","url":"https://www.andreagrandi.it/2010/02/13/fon-how-long-are-you-going-to-play-tricks-on-users/","loc":"https://www.andreagrandi.it/2010/02/13/fon-how-long-are-you-going-to-play-tricks-on-users/"},{"title":"Questions/Answers about Nokia N900 and Discounted Device Program","text":"Being one of the developers who received the discount to buy a N900, during these days I contacted the DDP customer care to have more informations and details. I'll publish here both my original question and the official reply. 1) The price of N900 is 250€ and I've read of people who paid it this price. Anyway here you say that the VAT is not included: https://pro.forum.nokia.com/site/global/tech_resources/discounted_devices/l_ddp.jsp so it should costs 300€ not 250€, right? The VAT applies only for Finnish developers, for the others the price is the price they see in the eStore, no VAT is added to that. So, all non-finnish european people, will pay 250€ for the N900. 2) How much time can I wait before ordering it? In this moment I'm in Valencia (Spain) and I won't come back to Italy before Christmas. I'd like the order to be shipped to my home in Italy (I registered as italian user and I want italian keyboard layout), but I'd like to wait to order it, because since there's no warranty and I need to tell you about any problem within a week, if I order it now I will be able to check it only at the end of december when I'll come back to Italy. I guess this should not be a problem. This part is not confirmed yet, since Quim told us to hurry up to buy it. 3) How many devices can I buy at that price? Here you say I can buy two: https://pro.forum.nokia.com/site/global/tech_resources/discounted_devices/l_ddp.jsp but here you say I can buy one: https://pro.forum.nokia.com/showProduct.do?product_id=5096 I don't want two devices, but another friend of mine, who help me in a project for the Maemo Community, would like to be able to buy one for the same price (he wasn't able to get the discount because his karma is still low). As far as I know, you can only purchase 1x device per person, regarding MAEMO N900. 4) Where can we find the new firmware? In the FAQ you say: DDP does not flash devices. It's ok, I can do it, but there's no public firmware for N900 at the moment. To update N900, can possibly be using NSU. Nokia software updater. 5) Is it possible to have a device with localized keyboard (for example italian one) ? All N900 will have EURO variant, Italian language is one option. Note: even these replies come from the official customer care, I don't assume any responsability if they shouldn't be all exact. If you have any doubt, please contact them directly at DDP.program@nokia.com","tags":"Maemo (EN)","url":"https://www.andreagrandi.it/2009/11/12/questionsanswers-about-nokia-n900-and-discounted-device-program/","loc":"https://www.andreagrandi.it/2009/11/12/questionsanswers-about-nokia-n900-and-discounted-device-program/"},{"title":"UX meets Code hackfest in December @ Barcelona: confirmed!","text":"Quim Gil just confirmed the UX hackfest in Barcelona for 4, 5, 6 december : http://talk.maemo.org/showthread.php?t=33719 What is UX hackfest? It's a three days meeting for Maemo developers, UX experts and people who want to learn about designing good user interfaces. When?** On 4, 5, 6 december 2009 Where? Barcelona, Spain. The exact location has still to be confirmed, but it should be http://citilab.eu How many people invited?** About 50 people invited (Maemo developers, UX experts, ecc....) If you are a Maemo developer and you have good user interface designer skills, this is the place for you. If you are a Maemo developer and you are not a UX expert, this IS anyway the place for you: you'll have the possibility to talk with experts and improve your knowledge about UI design. Anyone interested, please join the discussion here: http://talk.maemo.org/showthread.php?t=33719 Update 3/11/2009 - 16:00: a wiki page with all information has been created here: http://wiki.maemo.org/Maemo-Barcelona_Long_Weekend please add your name/data to the page if you requested to join the UX hackfest.","tags":"Linux, Maemo (EN), Programmazione","url":"https://www.andreagrandi.it/2009/11/03/ux-meets-code-hackfest-in-december-barcelona-confirmed/","loc":"https://www.andreagrandi.it/2009/11/03/ux-meets-code-hackfest-in-december-barcelona-confirmed/"},{"title":"Giving Lightning Talks","text":"During next Maemo Summit we will have at least 2 hours (one on saturday and another one on sunday) of lightning talks, about 20 talks where people will try to explain or present something in just 5 minutes . Last year, during Maemo Summit 2008, I did a lightning talk too and I must admit: even if I knew a lot about the subject of my talk and even if I had already done many other talks, I think it wasn't so good as I expected. This year I've been selected again (more details will follow) to give a 5 minutes talk and with this great news the kind Dave Neary also suggested me a link with an article about some best practices when giving lightning talks. I'll try to resume the most important points, hoping this will be useful for people who is going to give a short presentation at Summit. Go straight to the point Five minutes finish sooner than you can expect. You have to talk about the main topic of your talk within the two first minutes, else you risk to talk too much about the rest and you couldn't have the time for the most important thing. Leave details away People will never remember too many details explained in so little time. It's better to leave them away and put them in a more detailed blog post that you can link within your slides. Slides For a five minute talk you can avoid preparing slides, but if this can help you to concentrate on points you have to talk about, please prepare them. Two or three slides can be useful to introduce yourself, to write any reference of what you're talking about many other things. Another important thing, make sure your slides are ready before starting your presentation: people don't want to wait 20-30 seconds it takes to start Open Office or any other similar application. Consider any eventuality The presentation file could be damaged (be sure to have a copy of it, better in PDF format), your laptop could have no more battery (make sure you've a copy of your slides in a USB key), aliens could take you away, ecc... (ok, this last eventuality is remote). Concluding your talk Don't worry if you finish one or two minutes before, people won't bother about it. It's better to finish one minute before than 30 seconds later. If you want to leave an URL where people can find more details, how to contact you, put it in every slide so people will be able to take note of it from the first minute. I hope to have resumed the most important points of the original article . If you think there are any other important things to say, please leave me a comment and I'll add them. I really hope you will enjoy Maemo Summit and its lightning talks!","tags":"Igalia, Maemo (EN)","url":"https://www.andreagrandi.it/2009/09/03/giving-lightning-talks/","loc":"https://www.andreagrandi.it/2009/09/03/giving-lightning-talks/"},{"title":"Writing Python bindings of existing C libraries – (3) – Building and Installing with distutils","text":"In the last post of this series, we saw how to write a simple binding and we finished to build and install it manually. This is of course not a good way to manage the building/installation procedure. In Python we can use a library called distutils that let us to automatize the building and installing process. I'll use the foo source code to create the package, so it will be easier to understand. Using distutils All we have to do is to write a setup.py file similar to this one: from distutils.core import setup , Extension foomodule = Extension ( 'foo' , sources = [ 'foo.c' ]) setup ( name = 'Foo' , version = '1.0' , description = 'This is a package for Foo' , ext_modules = [ foomodule ] ) As you can see, we have to first import needed modules with: from distutils.core import setup, Extension then we create an entry for each module we have (in this case just one, \"foomodule\"). We then call the setup() method passing it all the parameters and our setup.py is complete. Building and installing To test it we can try to build the package in this way: python2.5 setup.py build if we want to install the module in our system: python2.5 setup.py install References Official Python documentation: http://docs.python.org/extending/building.html","tags":"HowTo, Igalia, Linux, Maemo (EN), Programmazione, Python","url":"https://www.andreagrandi.it/2009/08/13/writing-python-bindings-of-existing-c-libraries-building-and-installing-with-distutils/","loc":"https://www.andreagrandi.it/2009/08/13/writing-python-bindings-of-existing-c-libraries-building-and-installing-with-distutils/"},{"title":"PyMaemo (Python for Maemo) second beta release for Fremantle","text":"The PyMaemo team is pleased to announce the second beta release of PyMaemo for Fremantle ! This new release is available through the extras-devel repository, see installation instructions in http://pymaemo.garage.maemo.org/sdk_installation.html#fremantle What is it? Python for Maemo (PyMaemo for short) main objective is to make possible to use Python programming language as the scripting and development language for Maemo Platform, providing a better alternative for fast prototyping and programming in Maemo environment besides the C programming language. Python is for serious programming and to have fun. Python has a nice syntax, it is easy to learn and powerful enough for a vast range of applications, this is why we choose Python for Maemo. What has changed? New packages: python-mafw (0.1-1maemo1) Python bindings for the Media Application Framework [1] Supported API is very basic at the moment, and there are some bugs. Feedback is welcome! python-hildondesktop (0.0.3-1maemo1) Python bindings for the home/status widgets API python-notify (0.1.1-2maemo1) Python bindings for libnotify pyclutter (0.8.0-1maemo2) Python bindings for the Clutter API [2] Experimental package, waiting for developer feedback Updated packages: gnome-python (2.26.1-1maemo1) major upgrade, matching current Debian testing release; feedback on this is welcome, as it replaces a fairly old version (2.18). pygtk (2.12.1-6maemo7) Enable glade support. python2.5 (2.5.4-1maemo1) Updated to latest upstream 2.5.x release. add support to --install-layout=deb flag. python-central (0.6.11.1maemo1) dependency needed by the new python-setuptools version. python-defaults (2.5.2-3maemo3) Change PREVVER in debian/rules, avoiding old python2.5-minimal versions that had \"/usr/bin/python\" and thus conflicts with python-minimal. python-hildo n (0.9.0-1maemo10) lots of bug fixes python-setuptools (0.6c9-1maemo1) add support to --install-layout=deb flag. Bugs fixed: MB#4530 [3], MB#4450 [4], MB#4629 [5], MB#4628 [6], MB#4647 [7], MB#4632 [8], MB#4646 [9], MB#4750 [10], MB#4749 [11], MB#4791 [12] Known issues MB#4782 [13]: osso.Context causes segmentation fault MB#4821 [14]: Cannot create HildonTouchSelector with single text column MB#4824 [15]: python-mafw: source_browsing.py example does not work MB#4839 [16]: python-mafw: mafw.Registry lacks list_plugins() method MB#4849 [17]: python-mafw: MafwPluginDescriptorPublic structure is missing We will not migrate to python2.6 in fremantle due to a (unresolved) bug (MB#4734 [18]), where a core SDK package explicitly conflicts with python >= 2.6, preventing any further upgrades from the 2.5.x series. This release is supposed to be compatible with previous releases. If you have any issues regarding building your Python application on Fremantle, feel free to report it on the pymaemo-developers mailing list [19]. Acknowledgments Thanks to everybody who helped making this release possible. Bug reports, as always, should go to our Bugzilla [20]. Use the pymaemo-developers mailing list for help, feedback or suggestions. References [1] https://garage.maemo.org/projects/mafw/ [2] http://www.clutter-project.org/ [3] https://bugs.maemo.org/show_bug.cgi?id=4530 [4] https://bugs.maemo.org/show_bug.cgi?id=4450 [5] https://bugs.maemo.org/show_bug.cgi?id=4629 [6] https://bugs.maemo.org/show_bug.cgi?id=4628 [7] https://bugs.maemo.org/show_bug.cgi?id=4647 [8] https://bugs.maemo.org/show_bug.cgi?id=4632 [9] https://bugs.maemo.org/show_bug.cgi?id=4646 [10] https://bugs.maemo.org/show_bug.cgi?id=4750 [11] https://bugs.maemo.org/show_bug.cgi?id=4749 [12] https://bugs.maemo.org/show_bug.cgi?id=4791 [13] https://bugs.maemo.org/show_bug.cgi?id=4782 [14] https://bugs.maemo.org/show_bug.cgi?id=4821 [15] https://bugs.maemo.org/show_bug.cgi?id=4824 [16] https://bugs.maemo.org/show_bug.cgi?id=4839 [17] https://bugs.maemo.org/show_bug.cgi?id=4849 [18] https://bugs.maemo.org/show_bug.cgi?id=4734 [19] https://garage.maemo.org/mailman/listinfo/pymaemo-developers [20] https://bugs.maemo.org/enter_bug.cgi?product=PyMaemo Credits This post was possible thanks to Anderson Lizardo , from PyMaemo team, who posted these informations on pymaemo-developers mailing list.","tags":"Igalia, Linux, Maemo (EN), Programmazione, Python","url":"https://www.andreagrandi.it/2009/08/10/pymaemo-python-for-maemo-second-beta-release-for-fremantle/","loc":"https://www.andreagrandi.it/2009/08/10/pymaemo-python-for-maemo-second-beta-release-for-fremantle/"},{"title":"Making Maemo email client usable with GMail","text":"I must admit, I wasn't using Maemo email client, because I did find it was simply unusable, at least with my GMail account. I tried both POP3 and IMAP, but having about 25.000+ messages in my account, downloading just the headers was a job that the client simply couldn't manage. Yesterday I knew about \" recent mode \" support in POP3 , a functionality that GMail supports too. This mode allow you to download only last 30 days messages (in my case, no more than 1000) so the client can manage them without any problem. All you have to do to enable this mode is put the \" recent: \" string before the username. For example: if your username is \"username@gmail.com\" you have to write \" recent:username@gmail.com \". Important: this mode only works with POP3, not with IMAP. To conclude, let me say thank you to the kind guy who let me discover this mode. Thank you Sergio ! Now there is another thing I can do with my tablet!","tags":"HowTo, Igalia, Linux, Maemo (EN)","url":"https://www.andreagrandi.it/2009/08/08/making-maemo-email-client-usable-with-gmail/","loc":"https://www.andreagrandi.it/2009/08/08/making-maemo-email-client-usable-with-gmail/"},{"title":"Writing Python bindings of existing C libraries – (2) – A simple example of binding","text":"Introduction As I promised in the preceding post, I'll provide a very easy example of a python binding. Let's suppose we don't want to use the methods included in Python to sum two integer values and we want to do it in C and then call the add method from a python script. I'll write the complete source code first and then I'll explain all the parts of it. Source Code #include <Python.h> static PyObject * foo_add ( PyObject * self , PyObject * args ) { int a ; int b ; if ( ! PyArg_ParseTuple ( args , \"ii\" , & a , & b )) { return NULL ; } return Py_BuildValue ( \"i\" , a + b ); } static PyMethodDef foo_methods [] = { { \"add\" , ( PyCFunction ) foo_add , METH_VARARGS , NULL }, { NULL , NULL , 0 , NULL } }; PyMODINIT_FUNC initfoo () { Py_InitModule3 ( \"foo\" , foo_methods , \"My first extension module.\" ); } How it works First of all we have to include Python.h in our C file. This allows us to write an extension for Python language. To be able to include this header, we must have the python development packages installed in our system. For example in Debian based distributions we can install them with this command: sudo apt-get install python2.5-dev Every module has at least three parts. In the first part we write methods we want to call from the final python module: in this case we have a method called foo_add where \" foo \" is the name of the module and \" add \" the name of the method. Every method is declared as static PyObject . The method does anything particular except calling PyArg_ParseTuple to validate the input (we'll discuss this later), adding the two passed numbers and returning the result. In the second part we have something like a dictionary, defined as static PyMethodDef and called foo_methods (where \"foo\" again is the name of the module). For each method we want to expose in our python module, we have to add something like this: { \"add\" , ( PyCFunction ) foo_add , METH_VARARGS , NULL } where \" add \" is the name of the method we want to be visible in our module, (PyCFunction)foo_add is a pointer to our foo_add method, implemented in the C module, METH_VARARGS means that we want to pass some parameters to the function and the last one would be the description of the method (we can leave it NULL if we want). Third part allows us to register the defined method/s and the module: Py_InitModule3 ( \"foo\" , foo_methods , \"My first extension module.\" ); Parsing Parameters The PyArg_ParseTuple function extracts arguments from the PyObject passed as parameter to the current method and follows almost the sscanf syntax to parse parameters (in this case we had \"ii\" for two integers). You can fin the complete reference here: http://docs.python.org/c-api/arg.html Building and installing To build the module, we have to be in the source directory and execute this command: gcc -shared -I/usr/include/python2.5 foo.c -o foo.so then we've to copy the generated module to the python's modules directory: cp foo.so /usr/lib/python2.5/site-packages/ Testing our module Testing the module is really easy. We've to start a python shell or create a python script with the following source code: import foo print foo . add ( 2 , 3 ) if all is working fine, the printed result should be 5 References http://docs.python.org/extending/extending.html http://www.wrox.com/WileyCDA/WroxTitle/productCd-0764596543.html","tags":"HowTo, Igalia, Linux, Maemo (EN), Programmazione, Python","url":"https://www.andreagrandi.it/2009/08/06/writing-python-bindings-of-existing-c-libraries-a-simple-example-of-binding/","loc":"https://www.andreagrandi.it/2009/08/06/writing-python-bindings-of-existing-c-libraries-a-simple-example-of-binding/"},{"title":"MAFW and Python: asking for developers feedback","text":"MAFW is a new multimedia framework that will be used in Fremantle. The PyMaemo team is currently working on writing bindings for Python language for this library and at the moment we've released a 0.1 version of python-mafw that you can install directly from Scratchbox repository. Not all the methods are implemented (you can manage the Registry and the Playlist, but nothing more), because even if we're using codegen to generate bindings (and it's helping us a lot), we've seen that at least 30-40 methods have to be overridden by hand so it's taking us more time than we expected and we're trying to organize how to continue this work. We would like to get feedback from python application developers and also from C application developers that are currently using MAFW so we can work on a \"roadmap\" that reflects what developers want: What are the functionalities you're using in your application that you think they cannot miss in the Python binding? Have you already started using MAFW or even better python-mafw to develop something? What is the currently missing method/methods you would like to be implemented first? Come on developers! We're waiting for your feedback :)","tags":"Igalia, Linux, Maemo (EN), Programmazione, Python","url":"https://www.andreagrandi.it/2009/08/05/mafw-and-python-asking-for-developers-feedback/","loc":"https://www.andreagrandi.it/2009/08/05/mafw-and-python-asking-for-developers-feedback/"},{"title":"Writing Python bindings of existing C libraries - (1) - Introduction","text":"This summer I'm having the pleasure of working in Igalia (a spanish free software company) for a couple of months and they assigned me to an interesting project: developing Python bindings for MAFW library (a Maemo multimedia library that will be used in Fremantle release). Having the opportunity to work both with C (yes, Python bindings are almost C code) and Python (it's a good practice to write unittest of all implemented methods) it's a good way to improve my knowledges in both languages and since I wasn't able to find much documentation about these kind of things, I'm going to share my own experiences. What is a Binding? A binding is a Python module, written in C language, that allows Python developers to call functions from existing C libraries from their python applications. It's just like a \" bridge \" from C world to Python one. Why writing bindings? There are a couple of reasons to write python bindings instead of writing a library in python language from scratch. First of all I don't think is good duplicating code, so if a library already exists and it's written in C, why writing it again in another language? There's no reason. A lot of code already exist in C world and all we have to do is to create a bridge with python world. Another good reason, in particular when a C library doesn't exist yet, is the fact that python code is slower than C code for some tasks (for example multimedia codecs). In these cases is good to implement the core library in C language and then create a python binding for it. Coming next As the title of this post says, this is only an introduction to the subjects I'm going to write about. If you have any particular request about any argument you would like to read, please feel free to leave me a comment. Next posts will talk about these things: A simple example of binding: I'll write a simple library in C language and I'll show how to create the relative python binding, providing complete source code and an example for python developers. Building and installing python bindings with distutils: I'll explain how to use distutils to build and install the binding (using the well know method \"python setup.py install\"). Defining new types: this post will be about how to write new types in C language and being able to use them from python code. Using codegen to write bindings: I'll explain how to use codegen utils to automate lot of tasks, to generate the most part of binding code and how to customize the generated code using overrides.","tags":"HowTo, Igalia, Linux, Maemo (EN), Programmazione, Python","url":"https://www.andreagrandi.it/2009/08/03/writing-python-bindings-of-existing-c-libraries-1-introduction/","loc":"https://www.andreagrandi.it/2009/08/03/writing-python-bindings-of-existing-c-libraries-1-introduction/"},{"title":"I officially joined the PyMaemo team","text":"This summer I'm working for 2 months at Igalia , a spanish free software company, and they assigned me the project of writing a Python binding for MAFW (a new multimedia library that will be included in Freemantle ). After few days I discovered that PyMaemo team was already working to it, so I asked to join them and they accepted me! I really love Python language and since I think other developers love it too, I think we should provide good bindings for every library available in Maemo, so lot of developers can start writing their applications in this language. I'll work to this project full time until the first week of september, so I hope to be able to learn a lot and to contribute as much as I can to this project. If anyone else want to join PyMaemo team and help us to develop Python bindings, I think he will be welcome!","tags":"Igalia, Linux, Maemo (EN), Programmazione, Python","url":"https://www.andreagrandi.it/2009/07/25/i-officially-joined-the-pymaemo-team/","loc":"https://www.andreagrandi.it/2009/07/25/i-officially-joined-the-pymaemo-team/"},{"title":"Registration to Maemo Summit 2009 open!","text":"Registration for the Maemo Summit 2009 has been opened. The summit will have free entrance, but registration is required to grant you food, drinks, a maemo.org shirt and a seat. Please register as soon as possible, so we can get a clear picture of how many people are expected. The registration form also has an option for sponsorship requests. Details about sponsorship will be published later and requests will be evaluated after this. You can always change your registration entry at a later point in time if needed. The event location details and a list of participants can be found here . See you all in Amsterdam at Maemo Summit 2009!","tags":"Linux, Maemo (EN)","url":"https://www.andreagrandi.it/2009/07/22/registration-to-maemo-summit-2009-open/","loc":"https://www.andreagrandi.it/2009/07/22/registration-to-maemo-summit-2009-open/"},{"title":"Ridimensionare immagini automaticamente con un batch e ImageMagick","text":"Spesso capita di dover compiere azioni noiose e ripetitive su delle immagini, come ad esempio ridimensionarle o salvarle in formati diversi da quello originale. Queste operazioni possono richiedere moltissimo tempo, soprattutto se abbiamo a che fare con una grande quantità di immagini. Per chi usa Linux è disponibile però l'utility ImageMagick , che unita ad un pizzico di script in bash ci permette di risolvere agevolmente il problema. Per prima cosa è necessario installare il tool sulla propria distribuzione. Su Ubuntu (o in qualsiasi altra distribuzione basata su Debian) procedere nella seguente maniera: sudo apt-get install imagemagick A questo punto basta posizionarsi nella cartella dove si trovano le immagini (vi consiglio di crearvi una copia a parte delle immagini da modificare, visto che lo script andra' a lavorare direttamente su quelle originali) ed eseguire un comando come questo: find ./ -iname '*.JPG' -exec convert '{}' -resize '1024' '{}' \\; Questo comando convertirà tutte le immagini .JPG che trova in un formato di 1024 pixel di larghezza, mantenendo ovviamente le proporzioni dell'immagine originale.","tags":"HowTo, Linux","url":"https://www.andreagrandi.it/2009/07/05/ridimensionare-immagini-automaticamente-con-un-batch-e-imagemagick/","loc":"https://www.andreagrandi.it/2009/07/05/ridimensionare-immagini-automaticamente-con-un-batch-e-imagemagick/"},{"title":"Risolvere il crash all'avvio di Songbird su Ubuntu","text":"Se si prova a far girare la versione di Songbird scaricabile dal sito ufficiale su Ubuntu (ma il problema sembra riguardare anche altre distribuzioni visto che si tratta di un bug del driver Nvidia) si otterrà quasi sicuramente un crash dell'applicazione stessa. Per risolvere il problema è sufficiente disinstallare un plugin ( libvisual-0.4-plugins ) utilizzando il seguente comando: sudo apt-get remove libvisual-0.4-plugins**** Una nota negativa: questo bug è presente fin dalla versione 8.10 di Ubuntu... che aspettano a correggerlo invece di far ricorrere gli utenti a questi trucchetti?","tags":"HowTo, Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2009/06/24/risolvere-il-crash-allavvio-di-songbird-su-ubuntu/","loc":"https://www.andreagrandi.it/2009/06/24/risolvere-il-crash-allavvio-di-songbird-su-ubuntu/"},{"title":"Last.fm: the money music revolution!","text":"Non c'è alcun errore nel titolo di questo post. Sebbene lo slogan originale di Last.fm fosse \" The Social Music Revolution \", ho voluto modificarlo in questo modo, per sottolineare il recente cambiamento di rotta di un servizio che fino a pochi giorni fa ritenevo uno dei migliori, se non il migliore, del suo genere. Facciamo un passo indietro per spiegare cos'è Last.fm. Si tratta di un servizio che permette, una volta registrati, di condividere le canzoni che ascoltiamo (titolo e autore, non il file audio) in modo che si possa essere messi in contatto con altre persone che ascoltano i nostri gruppi preferiti oppure di ricevere suggerimenti su gruppi simili a quelli che ascoltiamo. Grazie a questa funzione ho avuto la possibilità di conoscere ed apprezzare gruppi musicali di cui prima ignoravo l'esistenza. Oltre a permettere lo scrobbling (invio del titolo della canzone) e la creazione automatica di classifiche, il sito mette a disposizione moltissimi strumenti che hanno permesso la creazione di una vasta community musicale. La community, grazie a questi strumenti, ha arricchito il sito web di moltissimi dati importanti: un wiki con i dati dei gruppi musicali, i tag su ogni canzone, gruppi di discussione e la creazione di eventi e ritrovi. Last.fm è anche una \"radio\", ma in un modo un po' diverso rispetto a quello a cui siamo abituati. Non esistono playlist valide per tutti gli utenti, ogni utente ha la propria playlist, in base ai brani ascoltati, ai gruppi simili ed ai suggerimenti degli amici. Oltre alle proprie playlista è inoltre possibile ascoltare quelle dei \"vicini\", degli amici e dei gruppi ai quali siamo iscritti. Se oggi Last.Fm è diventata quello che tutti vediamo, è in gran parte grazie al lavoro svolto dalla community musicale. Che cosa è successo per portarmi alla decisione di eliminare il mio account , vecchio di 3 anni , con piu' di 30.000 brani ascoltati? Circa un mese fa i vertici di Last.fm hanno deciso che entro poco tempo il servizio di radio in streaming sarebbee diventato a pagamento, a causa dell'aumento dei costi di licenza imposti dalle major. Per continuare ad ascoltare la radio si dovranno pagare 3€ al mese . Quello che ha scatenato l'ira di moltissimi utenti e che mi ha fatto prendere la decisione di disiscrivermi, è il fatto che USA , Inghilterra e Germania potranno continuare ad usufruire gratuitamente del servizio. Questa divisione in paesi di serie A e paesi di serie B non è piaciuta proprio a nessuno, basta guardare le centinaia di commenti che sono arrivati sul blog ufficiale di Last.fm. Io mi associo al pensiero comune: se anche USA, Inghilterra e Germania pagassero, il costo potrebbe scendere a 1 o 2 euro al mese ed inoltre non ci sarebbero divisioni e/o discriminazioni a seconda del paese di provenienza. Avrei pagato volentier anche 3€/mese se non ci fossero state queste differenze. Perchè gli altri paesi devono pagare pochi privilegiati? A mio parere Last.fm ha commesso un gravissimo errore facendo questa mossa e sono convinto che entro breve perderà moltissimi utenti smettendo inoltre di essere una community ricca di contenuti creati dagli utenti stessi. Staremo a vedere se ci saranno inversioni di rotta o se continueranno a seguire questa strada.","tags":"Recensione","url":"https://www.andreagrandi.it/2009/05/11/lastfm-the-money-music-revolution/","loc":"https://www.andreagrandi.it/2009/05/11/lastfm-the-money-music-revolution/"},{"title":"Come passare dalla modalità enduser alla modalità developer su Fonera 2","text":"Fino ad ora, i possessori di Fonera 2.0 che volevano passare alla modalità \" developer \" (e quindi avere anche l'accesso via SSH ) dovevano flashare la fonera con un'apposita immagine, facendo uso del cavo seriale oppure della procedura con il cavo di rete che utilizza Redboot. Da oggi è disponibile un nuovo plugin che permette di passare automaticamente alla modalità developer, basta andare (ad esempio) su questa pagina del router: http://192.168.0.105/luci/fon_devices/fon_plugins La Fonera passerà a questo punto in modalità developer e dovremo effettuare due reboot affinchè SSH sia attivato. Non dimenticatevi ovviamente di aprire l'accesso SSH nella configurazione del firewall della Fonera. Accedendo via SSH, vi troverete davanti questi messaggi: ssh root@192.168.0.105 The authenticity of host '192.168.0.105 (192.168.0.105)' can 't be established. RSA key fingerprint is e5:6e:fc:70:73:44:f6:cd:30:bd:ac:2d:53:d2:ab:a9. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added ' 192 .168.0.105 ' (RSA) to the list of known hosts. root@192.168.0.105' s password: BusyBox v1.11.1 ( 2009 -04-17 12 :45:57 CEST ) built-in shell ( ash ) Enter 'help' for a list of built-in commands. __ _.-~ ) _..--~~~~, ' ,-/ _ .-' . . . . ' ,-' , ' ,' ) , '. . . _ ,--~,-' __..- ' ,' , '. . . (@)' ---~~~~ , ' /. . . . ' ~~ ,- ' /. . . . . ,-' ; . . . . - . , ' : . . . . _ / . . . . . ` -.: . . . ./ - . ) . . . | _____..---.._/ ____ Seal _ ~---~~~~----~~~~ ~~ Flipper -------- Fonera 2 .0 Firmware ( v2.2.5.0 ) ----------- * Based on OpenWrt - http://openwrt.org * Powered by FON - http://www.fon.com ---------------------------------------------------- root@Fonera:~# uname -a Linux Fonera 2 .6.26.2 #9 Tue Apr 21 11:32:31 CEST 2009 mips unknown root@Fonera:~# Cercherò prossimamente, nel caso ci sia interesse, di scrivere qualche post piu' approfondito su questa nuova Fonera, in modo da mostrare le caratteristiche di questo dispositivo.","tags":"HowTo, Linux, Recensione","url":"https://www.andreagrandi.it/2009/05/05/come-passare-dalla-modalita-enduser-alla-modalita-developer-su-fonera-2/","loc":"https://www.andreagrandi.it/2009/05/05/come-passare-dalla-modalita-enduser-alla-modalita-developer-su-fonera-2/"},{"title":"Ubuntu 9.04 (Jaunty) su Asus EeePC 901","text":"Con l'uscita della versione 9.04 di Ubuntu Linux , questa distribuzione ha veramente fatto passi da gigante per quanto riguarda il supporto ai netbook . Oltre a rilasciare una versione specificatamente pensata per i piccoli device (che integra di default l'interfaccia Notebook Remix ), sono stati inclusi nel kernel tutti i moduli necessari a far funzionare le periferiche di questi device. Per installare Ubuntu sull'EeePC dobbiamo per prima cosa procurarci la ISO dell'ultima versione e poi utilizzare una delle seguenti utility per preparare una chiavetta USB (da almeno 1 Gb) che ci permetterà di effettuare l'installazione: USB Startup Disk Creator , disponibile a partire dalle ultime versioni di Ubuntu (si trova in System-->Administration) oppure Unetbootin , che potete trovare a questo indirizzo: http://unetbootin.sourceforge.net/ Nel caso vogliate installare la versione NBR (Notebook Remix) di Ubuntu, che viene distribuita in formato .img dovete invece attenervi alle istruzioni che trovate su questa pagina: https://help.ubuntu.com/community/Installation/FromImgFiles Una volta preparata la chiavetta USB (o in alternativa va bene anche una memoria di tipo SD) dovrete utilizzarla per fare il boot (vi ricordo che per fare il boot da USB dovete premere ESC nei primi secondi di accensione dell'EeePC) e procedere all'installazione come se fosse un normale PC. Se posso darvi un consiglio su come partizionare, vi suggerisco di utilizzare il disco da 4 Gb per la root / e quello da 16 Gb (o 12 Gb a seconda dei modelli) per la /home . Completata l'installazione, al riavvio dell'EeePC avrete una piacevole sorpresa: tutte le periferiche saranno perfettamente riconosciute! Questo dimostra l'ottimo lavoro che è stato fatto per supportare questa fascia di dispositivi. E' necessaria tuttavia qualche altra piccola ottimizzazione per poter sfruttare al 100% il nostro netbook. Per prima cosa vi consiglio di installare gli script di elmurato che vi permetteranno di utilizzare correttamente tutti i tasti funzione (Fn+Fx). Perchè possano funzionare dovrete anche installare sia un pacchetto presente nella Ubuntu, sia uno incluso nel tar.gz, seguendo le seguenti istruzioni: sudo apt-get install dkms sudo apt-get remove --purge nvidia-common tar xzvf Jaunty_Eeeasy-Scripts.tar.gz cd Jaunty_Eeeasy-Scripts sudo dpkg --install asus-eee-dkms_3.0_all.deb sudo ./eeeasy-scripts.sh ` A questo punto non vi resta che riavviare il vostro EeePC e l'installazione sarà completata. Se vogliamo essere precisi, ci sono ancora un paio di piccole cose da migliorare. Noterete infatti che il tasto per abilitare/disabilitare il bluetooth non funziona correttamente. Si tratta di un bug del kernel 2.6.28 che viene fortunatamente risolto con la versione 2.6.29 di cui elmurato fornisce i pacchetti .deb già compilati: http://www.informatik.uni-bremen.de/~elmurato/EeePC/ (dovrete installare linux-headers-* e linux-image-* ). La versione 2.6.29 del kernel include anche una versione aggiornata del modulo che fa funzionare la scheda wireless , permettendoci di avere un segnale piu' stabile . Consiglio infine di aggiungere la seguente stringa in fondo al file /etc/modprobe.d/options (createlo se non esistesse): options psmouse proto = imps questa opzione fa in modo che il touchpad funzioni meglio rispetto a come viene configurato di default.","tags":"EeePC, HowTo, Linux, Recensione, Ubuntu (IT)","url":"https://www.andreagrandi.it/2009/04/26/ubuntu-904-jaunty-su-asus-eeepc-901/","loc":"https://www.andreagrandi.it/2009/04/26/ubuntu-904-jaunty-su-asus-eeepc-901/"},{"title":"PyngFM: Python implementation of Ping.fm API","text":"I've just released PyngFM , a Python implementation of Ping.fm API. Ping.fm is a simple service that allow you to update multiple social networks (Facebook, Twitter, Jaiku ecc...) with a single post. You can find complete source code and documentation on the official website: http://code.google.com/p/pyngfm/ Please contact me if you have any suggestion or if you find any bug in the code, so I'll be able to fix it.","tags":"Python","url":"https://www.andreagrandi.it/2009/04/02/pyngfm-python-implementation-of-pingfm-api/","loc":"https://www.andreagrandi.it/2009/04/02/pyngfm-python-implementation-of-pingfm-api/"},{"title":"Dropbox: 2Gb di disco online che si integrano con Windows, OSX e Linux","text":"Da tempo stavo cercando un servizio che mi offrisse un piccolo spazio online, sempre accessibile ed utilizzabile come una chiavetta USB, per poterci mettere i miei dati ed averli sempre disponibili ovunque andassi. In questi giorni, dopo aver sentito parlare molto bene di Dropbox da parte di un amico, mi sono deciso a provarlo. Dropbox offre 2 Gb (espandibili fino a 5 Gb invitando altre persone ad usare il servizio) di spazio gratuito, da utilizzare come disco personale. La cosa interessante è che non si tratta di una semplice cartella tipo FTP, ma tramite il loro client si integra perfettamente nel sistema operativo che stiamo utilizzando ( Windows , OSX o Linux ) e si occupa automaticamente di sincronizzare online le modifiche che facciamo ai file locali. I nostri file infatti si trovano sia sul nostro disco locale, sia in copia sul nostro spazio online. Se ad esempio abbiamo installato il client sul nostro PC fisso e lavoriamo a dei file, questi vengono automaticamente sincronizzati online. Immaginiamo adesso di installare il client anche sul nostro portatile, non appena accediamo ad Internet i file verranno automaticamente sincronizzati, quasi in tempo reale. Tra le altre funzionalità che il servizio offre, c'è anche quella di poter creare in automatico delle gallerie fotografiche. E' sufficiente creare una sotto cartella dentro la cartella Photos predefinita ed in automatico verrà creata la fotogallery. Per quanto riguarda la sicurezza dei nostri file, quello che mettiamo su Dropbox rimane accessibile solo a noi, fatta eccezione per quello che viene messo nella sotto cartella Public. Il trasferimento dei file dal nostro PC allo spazio online inoltre avviene in modo cifrato. Nessuno però ci garantisce che i nostri documenti, uan volta sui server di Dropbox, non vengano sbirciati da qualcuno... il mio consiglio quindi è quello di crearsi una ulteriore sotto cartella, magari chiamandola Secure, e metterci dentro un file di Truecrypt sul quale andremo a montare la nostra cartella cifrata. In questo modo il file di Truecrypt sara' sincronizzato online, ma il suo contenuto sara' inaccessibile a chiunque, eccetto noi. Un'ulteriore doverosa precisazione: il client che installiamo sul nostro PC non è opensource. A parte questo piccolo difetto, il servizio è veramente valido! Per chi avesse bisogno di maggiore spazio, esiste anche una versione a pagamento del servizio, dove per 10\\$/mese vengono messi a disposizione 50 Gb di spazio. Chi volesse provare il servizio, puo' iscriversi utilizzando questo link: https://www.getdropbox.com/referrals/NTgzNTM0MTk In questo modo sia voi che io guadagneremo +250 Mb di spazio da aggiungersi ai 2 Gb che vengono dati di base.","tags":"HowTo, Linux, Recensione, Windows","url":"https://www.andreagrandi.it/2009/03/29/dropbox-2gb-di-disco-online-che-si-integrano-con-windows-osx-e-linux/","loc":"https://www.andreagrandi.it/2009/03/29/dropbox-2gb-di-disco-online-che-si-integrano-con-windows-osx-e-linux/"},{"title":"Announcing my standing for the Maemo Council","text":"After the suggestion from a member of this community (I don't want to nominate him because I don't want to influence anyone) I've decided to candidate myself for the Maemo Council. Here I'm! You can read something about me and about my motivations in the rest of this post. Name: Andrea Grandi maemo.org : Andy80 - http://maemo.org/profile/view/andy80/ Corporate affiliation: none Introduction My name is Andrea Grandi, I'm 28 and I live in Pistoia (Tuscany, ITALY). I'm a programmer, in particular very interested in Linux and opensource. I've been working for some years as computer programmer, then I decided to begin studing at university, and currently I'm attending at \"Università degli studi di Firenze\" to get the Computer Science degree. I spend lot of my time to manage the Pistoia Linux User Group I founded in 2001. My life in the community I'm part of the community since I bought my first Nokia 770. I started contributing to the mailing lists, I wrote some tutorials (in italian language, then I translated them to english) and I ported SPIM (a MIPS emulator) to Nokia 770. Later I had the possibility to buy a N810 and I was able to experiment more with the Maemo SDK. I was at the Maemo Summit in Berlin, doing a light talk about Maemo development using Eclipse, PluThon and EsBox plugins. Motivations I really would like to be able to do more for the community and one of the best way could be to be part of the council, to help both users/developers to explain their requests to Nokia and Nokia to understand the requests from the community. There are a lot of fantastic ideas comung from the community that could improve what we are doing: the key is to organize them and giving them more attention. This is what I've always looked for: working together to build something great!","tags":"Maemo (EN)","url":"https://www.andreagrandi.it/2009/02/28/announcing-my-standing-for-the-maemo-council/","loc":"https://www.andreagrandi.it/2009/02/28/announcing-my-standing-for-the-maemo-council/"},{"title":"Develop a GPS-aware application for the Nokia N810","text":"Paul Ferrill has written a serie of three articles about writing a GPS-aware application for the Nokia N810, using the Maemo SDK, Eclipse and PluThon plugin. Here is the complete serie: Develop a GPS-aware application for the Nokia N810, Part 1: Development environment: Learn how to configure a development environment targeted at the Nokia N810 Internet Tablet, including setting up Eclipse on a target development machine for the Python language. Develop a GPS-aware application for the Nokia N810, Part 2: Consider your options: Discover the details of code design, library selection, unit testing, and user interface choices that make the most sense for you. Develop a GPS-aware application for the Nokia N810, Part 3: Finish the job : In this last of three installments, you'll put the final touches to the GPS trip tracker and get it ready for release.","tags":"HowTo, Linux, Maemo (EN), Programmazione, Python","url":"https://www.andreagrandi.it/2009/02/24/develop-a-gps-aware-application-for-the-nokia-n810/","loc":"https://www.andreagrandi.it/2009/02/24/develop-a-gps-aware-application-for-the-nokia-n810/"},{"title":"Convertire i file WMA in MP3 sotto Linux","text":"Se abbiamo dei file audio in formato .wma e li vogliamo convertire in formato .mp3 utilizzando Linux, è sufficiente creare un piccolo script in bash che facendo uso di mplayer e lame provveda a convertire tutti i file che si trovano all'interno di una certa directory. Creiamo un file chiamato wma2mp3.sh con all'interno il seguente script: #!/bin/bash current_directory = $( pwd ) #remove spaces for i in *.wma ; do mv \" $i \" ` echo $i | tr ' ' '_' ` ; done #remove uppercase for i in *. [ Ww ][ Mm ][ Aa ] ; do mv \" $i \" ` echo $i | tr '[A-Z]' '[a-z]' ` ; done #Rip with Mplayer / encode with LAME for i in *.wma ; do mplayer -vo null -vc dummy -af resample = 44100 -ao pcm:waveheader $i && lame -m s audiodump.wav -o $i ; done #convert file names for i in *.wma ; do mv \" $i \" \"`basename \" $i \" .wma`.mp3\" ; done rm audiodump.wav a questo punto basta mettere lo script nella cartella dove ci sono i file .wma, dare i permessi di esecuzione a tale file ( chmod +x wma2mp3.sh ) ed eseguirlo con ./wma2mp3.sh Fonte: http://www.linuxquestions.org/linux/answers/Applications_GUI_Multimedia/Convert_WMA_to_MP3 *","tags":"HowTo, Linux, Programmazione","url":"https://www.andreagrandi.it/2009/02/22/convertire-i-file-wma-in-mp3-sotto-linux/","loc":"https://www.andreagrandi.it/2009/02/22/convertire-i-file-wma-in-mp3-sotto-linux/"},{"title":"Evitare che Wordpress modifichi il codice da copia-incollare","text":"Il precedente post che ho fatto mi aveva fatto veramente disperare. Come potete leggere dai comandi, è necessario passare alcuni parametri utilizzando il doppio trattino. Wordpress trasformava automaticamente il doppio trattino in un trattino singolo , facendo si che se qualcuno provava a fare il copia-incolla di quel comando ricevesse un errore di sintassi dal sistema. Poco dopo aver risolto un po' alla peggio, mi sono imbattuto in questo utilissimo post . In pratica si piega come evitare che Wordpress modifichi in automatico i caratteri all'interno dei blocchi di codice. E' sufficiente modificare il file functions.php del tema Wordpress che stiamo utilizzando ed aggiungere questa riga in fondo al file: <?php remove_filter ( 'the_content' , \"wptexturize\" ); ?>","tags":"HowTo, WordPress","url":"https://www.andreagrandi.it/2009/02/14/evitare-che-wordpress-modifichi-il-codice-da-copia-incollare/","loc":"https://www.andreagrandi.it/2009/02/14/evitare-che-wordpress-modifichi-il-codice-da-copia-incollare/"},{"title":"Importare le chiavi pubbliche PGP in apt su Ubuntu","text":"Utilizzando i repository esterni su Ubuntu , capita spesso di non avere una procedura automatica per importare anche le relative chiavi pubbliche PGP , che ci permettono di avere la garanzia che i pacchetti che stiamo scaricando siano autentici e che quindi provengano dall'autore originale. Sul sito web dei progetti che mettono a disposizione un repository, solitamente è indicato anche l'ID della chiave pubblica PGP. Ad esempio sul sito del Blueman Development Team troviamo 6B15AB91951DC1E2 . Per importare questa chiave pubblica dentro apt di Ubuntu, sono sufficienti i seguenti comandi da terminale: gpg --keyserver keyserver.ubuntu.com --recv 6B15AB91951DC1E2 gpg --export --armor 6B15AB91951DC1E2 | sudo apt-key add - Ovviamente dovrete sostituire l'ID della chiave PGP con quello che vi interessa aggiungere. Qui di seguito potete vedere un esempio completo dei messaggi di conferma che si ricevono quando si aggiunge la chiave: gpg --keyserver keyserver.ubuntu.com --recv 6B15AB91951DC1E2 gpg: requesting key 951DC1E2 from hkp server keyserver.ubuntu.com gpg: key 951DC1E2: public key \"Launchpad PPA for Blueman Development Team\" imported gpg: Total number processed: 1 gpg: imported: 1 ( RSA: 1 ) gpg --export --armor 6B15AB91951DC1E2 | sudo apt-key add - OK","tags":"HowTo, Linux, Sicurezza, Ubuntu (IT)","url":"https://www.andreagrandi.it/2009/02/14/importare-le-chiavi-pubbliche-pgp-in-apt-su-ubuntu/","loc":"https://www.andreagrandi.it/2009/02/14/importare-le-chiavi-pubbliche-pgp-in-apt-su-ubuntu/"},{"title":"Maemo on Google Summer of Code 2009","text":"This year the Maemo community will try to join the Google Summer of code program again. Google Summer of code can be a very good opportunity for the Maemo Community, and can also give a lots of good things, like new projects/features and new people developing for Maemo. In order to apply to Summer of code, we need help from the community, we need project ideas, mentors and interested students. The mentor organizations submissions starts in March 9 . There is a wiki page with some information regarding the Maemo participation in GSoC, feel free to add more information to the pages, especially for people that participated in previous editions of GSoC. In 2007 some Nokia employee offered their help as mentors and backup mentors, will be fine if that happens this year too. Note: * I reported this news thanks to Valerio Valerio who wrote this on maemo-community* mailing list.","tags":"Google, Maemo (EN), Programmazione, Recensione","url":"https://www.andreagrandi.it/2009/02/11/maemo-on-google-summer-of-code-2009/","loc":"https://www.andreagrandi.it/2009/02/11/maemo-on-google-summer-of-code-2009/"},{"title":"Nuove versioni di Skype per Linux: qualcosa si muove","text":"Gli utenti Linux che utilizzano Skype lo sanno: la versione disponibile per il pinguino non è mai stata aggiornata come quella per Windows. Su Linux siamo ancora alla versione 2.0.0.72 da piu' di un anno, nonostante siano stati segnalati da tempo vari problemi sia con l' audio che con il video . Pochi giorni fa uno degli sviluppatori della versione Linux di Skype, ha pubblicato sul proprio blog qualche aggiornamento su come sta procedendo lo sviluppo della versione Linux, in particolare: la libreria audio è stata completamente riscritta e sono state risolte delle incompatibilità con gli auricolari bluetooth aggiornamenti anche alla libreria video in modo da renderla piu' stabile e compatibile con un maggior numero di webcam l' interfaccia utente verrà completamente ridisegnata ispirandosi alla versione 4.0 per Windows verrà aggiunto il supporto per un maggior numero di sistemi operativi, come ad esempio FreeBSD , OpenSolaris e le versione di Linux a 64 bit sono stati assunti in questi mesi diversi sviluppatori esperti di Linux e delle librerie Qt e ne verranno assunti altri nei prossimi mesi A questo punto non ci resta che attendere, sperando di veder uscire una nuova versione almeno entro la fine dell'anno.","tags":"Linux, Skype","url":"https://www.andreagrandi.it/2009/02/07/nuove-versioni-di-skype-per-linux-qualcosa-si-muove/","loc":"https://www.andreagrandi.it/2009/02/07/nuove-versioni-di-skype-per-linux-qualcosa-si-muove/"},{"title":"Google Latitude: scopri dove sono i tuoi amici in tempo reale!","text":"Google ha appena lanciato il servizio Latitude che si integra con la nuova versione di Google Maps per cellulari, la 3.0 che è appena stata rilasciata. Si tratta di una funzionalità che permette di localizzare i propri amici sulla mappa , persino in tempo reale. Gli amici che si possono localizzare vanno selezionati tra i propri contatti di Gmail, dopo di che è possibile visualizzarli sulla mappa. Niente paura per la privacy : l'impostazione di default non attiva Latitude. E' necessario attivarlo manualmente e scegliere tra una delle seguenti modalità di aggiornamento: Automatica: in questo modo Google Maps/Latitude cercherà di rilevare automaticamente la nostra posizione utilizzando il GPS (se disponibile) oppure sfruttando le celle GSM (con una precisione meno accurata). Manuale: è possibile selezionare manualmente la propria posizione sulla mappa. Nascosta: con questa modalità saremo invisibili a tutti i nostri i contatti sulla mappa. Gli amici che possiamo vedere sulla mappa, inoltre, devono autorizzarci esplicitamente . Questo significa che senza una particolare autorizzazione, non saremo in grado di vedere tutti i nostri contatti di GMail sulla mappa. Al momento è possibile utilizzare Google Maps e Latitude con i seguenti telefoni: Android-powered devices, such as the T-Mobile G1 iPhone and iPod touch devices (coming soon) most color BlackBerry devices most Windows Mobile 5.0+ devices most Symbian S60 devices (Nokia smartphones) many Java-enabled (J2ME) mobile phones, such as Sony Ericsson devices (coming soon)","tags":"Google, Recensione","url":"https://www.andreagrandi.it/2009/02/04/google-latitude-scopri-dove-sono-i-tuoi-amici-in-tempo-reale/","loc":"https://www.andreagrandi.it/2009/02/04/google-latitude-scopri-dove-sono-i-tuoi-amici-in-tempo-reale/"},{"title":"Ubuntu Linux 8.10 su Asus EeePC 901","text":"Dal momento in cui ho acquistato l' Asus EeePC 901 , ho rimosso la versione personalizzata di Xandros Linux che viene installata su questi modelli, ed ho installato una versione personalizzata di Ubuntu: Ubuntu-eee 8.04.1 . Questa versione, pensata appositamente per i netbook della Asus, è davvero molto comoda perchè integra di default un kernel con tutte le patch ed i driver per far funzionare l'EeePC, che invece non sono contenuti nel kernel distribuito dalla Ubuntu 8.04 standard. Ubuntu-eee installa anche l'interfaccia Netbook Remix che è una particolare interfaccia grafica adatta per i netbook con schermi di ridotte dimensioni. L'idea di avere una distribuzione basata su Ubuntu che integra già tutte le patch necessarie per farla funzionare mi è sembrata subito una buona idea, tanto che ho anche pensato di inviare un piccolo contributo in denaro durante la campagna di raccolta fondi per finanziarne lo sviluppo. I problemi di Easy Peasy Dalla versione successiva alla 8.04.1, Ubuntu-eee ha dovuto cambiare nome (per non violare le regole del marchio \"Ubuntu\" di proprietà di Canonical), e fin qui nulla di male. Quello che non mi è affatto piaciuto è che mentre per il logo è stato fatto un apposito concorso e poi scelto il migliore, per il nome l'autore ha scelto a \"gusto\" proprio: Easy Peasy . Digerita la questione del nome, ho deciso di provarla sul mio EeePC. L'impressione è stata a dir poco pessima. Tanto per cominciare si nota da subito che la distribuzione non è stata minimamente testata: al primo riavvio dopo l'installazione, si presenta di nuovo l'installer, come se la dovessimo installare da zero. Il fix non è ancora stato rilasciato, in compenso l'autore ha spiegato come risolverlo a mano. Oltre a questo, leggendo il forum , saltano fuori almeno un'altra decina di problemi con la Easy Peasy. Tutti problemi che sarebbero stati facilmente risolvibili in fase di creazione della distribuzione personalizzata, se solo fosse stata minimamente testata. Che ci possano essere dei problemi su una distribuzione generica come ad esempio la Ubuntu (che è pensata per girare su qualsiasi configurazione) lo posso anche capire. Non mi pare accettabile che possano esserci così tanti problemi su una distribuzione che dovrebbe essere fatta appositamente per un certo modello di netbook. Ubuntu 8.10 Deluso dalla versione personalizzata, ho deciso di provare ad installare la versione standardi di Ubuntu, sistemando a mano le cose che non andavano. Installazione di base L'installazione di Ubuntu 8.10 è identica a quella di Ubuntu-eee/EasyPeasy. E' sufficiente creare una versione di Ubuntu che faccia il boot da una chiavetta USB oppure da una memoria SD, utilizzando la comoda utility presente in Ubuntu 8.10 (System->Administration->Create a USB startup disk) oppure tramite Unetbootin . Completata l'installazione, come già accennato, molte periferiche (come ad esempio la webcam, la scheda wireless o i tasti funzione) non saranno riconosciuti, ma questo già lo sapevamo. La scheda ethernet è invece riconosciuta e configurata perfettamente da Ubuntu 8.10, quindi è possibile utilizzare provvisoriamente il cavo per connettersi e completare l'installazione delle componenti mancanti. Il kernel ottimizzato per EeePC La prima cosa da installare è il kernel personalizzato di Adam . Questo kernel integra tutte le patch necessarie al funzionamento di tutte le periferiche dell'EeePC. Non mi dilungherò in questo post nella spiegazione di come si installa, rimandandovi invece all'howto originale, presente sul sito dell'autore: http://array.org/ubuntu/setup-intrepid.html eee-control Questa utility ci permette di far funzionare tutti i tasti funzione del nostro EeePC (Fn+F*) e di tenere sotto controllo alcuni parametri di sistema come ad esempio la temperatura, la velocità della ventolina ed infine di disabilitare le periferiche che non utilizziamo sul momento (come ad esempio il bluetooth o la wifi) in modo da prolungare la durata della batteria . Per installarla è sufficiente seguire le istruzioni sul sito dell'autore oppure scaricarla direttamente da questo indirizzo: http://greg.geekmind.org/eee-control/deb/eee-control_0.8.3_all.deb Altre ottimizzazioni Per ottenere il massimo dal proprio EeePC è necessario effettuare ancora qualche piccolo aggiustamento. I consigli che seguono potrebbero applicarsi anche ad altri modelli di EeePC anche se personalmente ho avuto modo di testarli solo con l'EeePC 901. laptop-mode Per abilitare alcune ottimizzazioni per i notebook, dobbiamo abilitare il laptop-mode all'interno del file /etc/default/acpi-support ENABLE_LAPTOP_MODE=true infine dobbiamo modificare il file /etc/laptop-mode/laptop-mode.conf ENABLE_LAPTOP_MODE_ON_BATTERY=1 noatime E' consigliabile utilizzare l'opzione noatime al posto di relatime per fare il mount delle partizioni ext3. In questo modo si evita che vengano scritte su disco le informazioni relative all'ultimo accesso (anche in lettura) di un file. Dobbiamo modificare /etc/fstab in questo modo: UUID=dce586c1-db13-43c3-8e12-9e1aec67afce / ext3 noatime,errors=remount-ro 0 1 N.B: questa riga non va copiata così com'è, va soltanto sostituito relatime con noatime in quella del proprio file. Altre ottimizzazioni possono essere trovate sul wiki di Ubuntu-eee: http://www.ubuntu-eee.com/wiki/index.php5?title=User_Guides Conclusioni Ammetto che avere una distribuzione che integri di suo tutte queste modifiche potrebbe far risparmiare del tempo. Se questa distribuzione però non viene rilasciata con già tutti i fix necessari a far funzionare il modello di netbook per cui è stata fatta, a che serve? A quel punto tanto vale installare una distribuzione normale e cogliere l'occasione per imparare qualcosa, effettuando a mano le modifiche necessarie per farla funzionare.","tags":"EeePC, HowTo, Linux, Recensione","url":"https://www.andreagrandi.it/2009/02/02/ubuntu-linux-810-su-asus-eeepc-901/","loc":"https://www.andreagrandi.it/2009/02/02/ubuntu-linux-810-su-asus-eeepc-901/"},{"title":"Scanner Mustek ScanExpress 1248 USB su Ubuntu Linux","text":"Lo scanner Mustek ScanExpress 1248 USB è pienamente compatibile con Linux, però purtroppo non basta connetterlo per farlo funzionare. Ubuntu Linux 8.10 non distribuisce il firmware necessario al suo funzionamento, però è possibile reperirlo ed installarlo con molta facilità. Per prima cosa dobbiamo assicurarci di avere il modello esatto di questo scanner. Per scoprirlo è sufficiente dare il comando lsusb da terminale. Dovremmo ottenere una stringa come la seguente: Bus 002 Device 003 : ID 055f:021f Mustek Systems, Inc. SNAPSCAN e22 A questo punto possiamo scaricare il suo firmware da un sito che li raccoglie tutti (quelli che sono compatibili ovviamente): http://www.meier-geinitz.de/sane/gt68xx-backend/firmware/SBSfw.usb Questo file va messo all'interno della cartella /usr/share/sane/gt68xx/ (occorrono i permessi di root per poterlo fare, quindi il file andra' copiato tramite il comando sudo cp SBSfw.usb /usr/share/sane/gt68xx/ ). Infine dobbiamo assicurarci di aver installato tutti i pacchetti necessari a farlo funzionare: sudo apt-get install sane libsane sane-utils libsane-extras xsane xsane-common Lo scanner è adesso pronto per funzionare. Nota: nella Ubuntu 12.04 la directory /usr/share/sane/gt68xx/ non è presente di default e va creata manualmente con sudo mkdir /usr/share/sane/gt68xx/****","tags":"HowTo, Linux","url":"https://www.andreagrandi.it/2008/12/17/scanner-mustek-scanexpress-1248-usb-su-ubuntu-linux/","loc":"https://www.andreagrandi.it/2008/12/17/scanner-mustek-scanexpress-1248-usb-su-ubuntu-linux/"},{"title":"OS 2008 update for Nokia N810: 5.2008.43 released","text":"A new update for Os2008 is available for Nokia N810 . The released version is 5.2008.43 . You can upgrade it OTA (over the air): connect to Internet open the Application Manager install updates Thats's all! Enjoy and test the new updates!","tags":"Maemo (EN)","url":"https://www.andreagrandi.it/2008/12/17/os-2008-update-for-nokia-n810-5200843-released/","loc":"https://www.andreagrandi.it/2008/12/17/os-2008-update-for-nokia-n810-5200843-released/"},{"title":"Android e Developer Device Program: come al solito l'Italia è di serie B","text":"Google ha appena annunciato che metterà a disposizione per gli sviluppatori, delle versioni particolari del G1, quello che tutti ormai conoscono come il nuovo telefono cellulare di Google. Il G1 per sviluppatori costa circa 399\\$ ed è SIM-unlocked, rendendo quindi possibile l'utilizzo con qualsiasi operatore di telefonia mobile. Il dispositivo non sara' disponibile da subito in tutti i paesi , ma solo in 18 che Google ha selezionato: USA, Inghilterra, Germania, Giappone, India, Canada, Francia, Taiwan, Spagna, Australia, Singapore, Svizzera, Olanda, Austria, Svezia, Finlandia, Polonia e Ungheria. Ebbene si: persino Polonia e Ungheria hanno avuto la precedenza rispetto all'Italia! Prima veniamo esclusi dal concorso per lo sviluppo di applicazioni per Android (a causa di problemi legati alla nostra burocrazia), e adesso questo. Noi poveri italiani cosa possiamo fare? Assolutamente niente, se non cercare di far acquistare il G1 a qualche amico che si trova all'estero. Questo però non porterà mai alla creazione di una community italiana di sviluppatori per Android. Una piccola nota, che non c'entra specificatamente con l'Italia, ma che ci tengo a fare notare è che Google, dal suo comunicato, sembra ammettere che sul G1 ufficiale possono girare solo le applicazioni che sono state scaricate dal Market di Android : \"Note that Android Dev Phone 1 devices are not intended for non-developer end users. Since the devices can be configured with system software not provided by or supported by Google or any other company, end users operate these devices at their own risk.\" Ovvero (tradotto molto liberamente): i dispositivi per sviluppatori non sono destinati agli utenti finali. Su questi telefoni è possibile installare software non fornito o supportato da Google o da altre compagnie, gli utenti li utilizzeranno a loro rischio e pericolo.","tags":"Google, Programmazione","url":"https://www.andreagrandi.it/2008/12/06/android-e-developer-device-program-come-al-solito-litalia-e-di-serie-b/","loc":"https://www.andreagrandi.it/2008/12/06/android-e-developer-device-program-come-al-solito-litalia-e-di-serie-b/"},{"title":"Utilizzare webcam V4L2 con Flash su Linux","text":"Introduzione Il supporto per le webcam su Linux non è mai stata una cosa molto semplice. I motivi principali per cui le webcam non sono ben supportate sono principalmente due: la scarsa collaborazione dei produttori di hardware , che dovrebbero fornire almeno le specifiche a chi sviluppa i driver per Linux e il quasi completo disinteresse di chi scrive le applicazioni per l'utente finale (in particolare Microsoft con MSN e Skype che utilizzano entrambi un protocollo proprietario e non documentato). Da diverso tempo si stanno diffondendo applicazioni scritte in Flash che permettono di utilizzare la webcam: dalle videochat, all'applicazione di Youtube che permette di pubblicare un video registrandolo direttamente, fino ai recenti servizi di streaming video come ad esempio JustinTV e UStream . Il plugin Flash della Adobe, purtroppo ha iniziato a supportare le webcam su Linux utilizzando il protocollo V4L1 quando ormai la maggior parte di esse funzionava solo con il nuovo protocollo V4L2 . A partire dalla versione 10 di Flash, finalmente la Adobe ha iniziato a supportare il protocollo V4L2, anche se il supporto non è ancora completo. Modelli differenti di webcam infatti utilizzano svariati formati di trasmissione video. Fortunatamente lo sviluppatore che lavora per Adobe si è reso disponibile per ricevere il feedback da parte degli utenti e per implementare questi formati in modo da supportare il maggior numero possibile di webcam. Per chi volesse contribuire è possibile seguire le istruzioni su questa pagina: http://blogs.adobe.com/penguin.swf/2008/07/paparazzi_v2_1.html gstfakevideo: un workaround per emulare V4L1 Visto che il supporto per le webcam che utilizzano V4L1 è molto piu' stabile, l'ingegno della community Linux non è stato ad aspettare con le mani in mano. Il metodo utilizzato è basato su quello che veniva usato su Skype per supportare un maggior numero di webcam: in pratica viene creato un device virtuale V4L1 sul quale viene redirezionato l'output della webcam V4L2 . Il codice originale purtroppo aveva bisogno di alcuni aggiustamenti, mi sono permesso quindi di modificarlo e di applicarli. La compilazione non dovrebbe comportare particolari problemi: è sufficiente eseguire make all'interno della cartella dei sorgenti. Per testare il funzionamento della webcam è sufficiente esegurie lo script che si trova all'interno della cartella. Verrà avviato Firefox con il supporto per le webcam V4L1 . Visitando uno dei siti web che hanno un'applicazione Flash che utilizza la webcam citati all'inizio, sara' possibile verificarne il corretto funzionamento. Riferimenti: le istruzioni in questo post sono state in parte prese da questo sito web (in inglese): http://www.jtolds.com/newsletter/2008/7/27/how-to-get-v4l2-devices-to-work-with-flash","tags":"HowTo, Linux","url":"https://www.andreagrandi.it/2008/11/25/utilizzare-webcam-v4l2-con-flash-su-linux/","loc":"https://www.andreagrandi.it/2008/11/25/utilizzare-webcam-v4l2-con-flash-su-linux/"},{"title":"What I expect in the future of Maemo Development","text":"In these days I was thinking about: what could be done to improve Maemo Development and power user experience? There are some points that would need to be improved. This little list pretends to be just a starting point. I hope to get some feedback so we can discuss further in the maemo-developers mailing list. Documentation: Maemo developers use different libraries and toolkit (GTK, libui, ecc...). There is not a common place where I can look for documentation. I've to visit each library website and get it. It would be great to have a tool just like Qt Assistant, integrating all documentation, including examples and aggregating external articles using a \"live RSS aggregator\". Kinetic scrolling: I really love Mauku application because of its kinetic scrolling, thanks to the Miaouw library . It would be great to have this kind of scrolling to be part of Hildon UI. Of course I'd love to have Python bindings too :) Eclipse Support: I think Eclipse support should be improved. I'd like to have a tool that makes .deb creation easier so developers can spend more time coding and not packaging applications. I'd like to see a GUI designer integrated into Eclipse (for \"integrated\" I mean something like Visual Studio GUI designer.... not an external tool like Glade). Qt Creator: Trolltech (Nokia) just released a preview release of their Qt Creator . A very powerfull IDE to develop Qt/C++ applications. It's still in alpha release, but... what about integrating Maemo development into it? (Supporting Python development too). Maemo SAS hosting: sometimes we (well.. me at least :D ) need to write an application that uses a server part too and need to expose some API. Maemo.org offers hosting for the project, but what about the server part of the application? It would be fine if developers had the possibility to have the server side hosted by Maemo.org or Nokia. Better GPS support: the GPS unit shipped with N810 is something unusable yet. I've tried using A-GPS too, but position fixing time is still bad, compared to an external GPS/bluetooth receiver. I often have to use my external GPS receiver to use my N810 without problems. More audio/video codecs: often I'm not able to listen to online radios, streamings ecc... just because of a missing codec for the default Media Player. These are just some ideas. Please feel free to comment them, I'd like to discuss them together.","tags":"Maemo (EN)","url":"https://www.andreagrandi.it/2008/11/17/what-i-expect-in-the-future-of-maemo-development/","loc":"https://www.andreagrandi.it/2008/11/17/what-i-expect-in-the-future-of-maemo-development/"},{"title":"Ubuntu 8.10: novità, problemi e soluzioni","text":"Il 30 ottobre 2008 è stata rilasciata la versione 8.10 di Ubuntu . Questa release presenta come al solito moltissime novità per l'utente finale, ma non è esente da alcuni problemi che solitamente riguardano le distribuzioni appena uscite. Questo articolo vuole essere un riferimento per chi sta utilizzando una versione precedente di Ubuntu Linux o per chi ci si avvicina per la prima volta, in modo che possa essere fatta una scelta in base agli effettivi vantaggi e svantaggi. Novità per l'utilizzo desktop Per l'utente desktop di, sono state introdotte alcune caratteristiche che possono facilitarne l'utilizzo in particolare a chi utilizza Ubuntu sui notebook, migliorando anche la sicurezza dei propri dati personali. Supporto alle connessioni 3G: la versione 0.7 del NetworkManager inclusa in questa release permette di gestire anche le connessioni GPRS/UMTS/HSDPA in maniera piu' semplice, sia che si utilizzi un modem interno, un dongle USB oppure che ci si connetta utilizzando il proprio cellulare tramite il bluetooth. Installazione ed avvio da dischi USB: è stato incluso un comodo tool che permette di installare Ubuntu su una chiavetta o un disco USB tramite una semplicissima interfaccia grafica. In questo modo sarà possibile portarsi dietro la propria copia di Ubuntu ovunque si vada e avendo anche la possibilità di salvare le impostazioni ed i propri documenti. Utente Guest: adesso è possibile lasciare in sospeso la propria sessione utente avviando temporaneamente una seconda sessione ospite per permettere ad esempio ad un nostro amico o collega di controllare la propria posta elettronica o di navigare sul web senza che questo possa curiosare nei nostri documenti o memorizzare file in maniera permanente. Contenuti BBC: grazie ad un accordo fra la Canonical e la BBC è stato sviluppato un plugin che permette agli utenti di accedere ai contenuti online della BBC tramite Totem Movie Player o Rhythmbox . Gnome 2.24: questa versione di Gnome incorpora un nuovo client di instant-messaging , migliora il file manger Nautilus introducendo i tab come su Firefox, migliora il supporto ai monitor multipli ed aggiunge alcuni nuovi formati al gestore degli archivi compressi. Cartella privata cifrata: è possibile creare in maniera molto semplice una cartella privata che viene montata soltanto quando l'utente è loggato nella propria sessione ed il cui contenuto viene cifrato. Questa funzionalità è molto utile per chi ad esempio utilizza Linux in un portatile: in caso di smarrimento del portatile nessuno sarebbe in grado di accedere al contenuto di tale cartella. X.Org 7.4: questa nuova versione di X.Org consente il riconoscimento di mouse, tastiere e tavolette grafiche a caldo (nel senso che vengono riconosciute non appena si inseriscono, quando il sistema è già avviato). DKMS: si tratta di un tool sviluppato dalla Dell. Quando una nuova versione del kernel viene rilasciata, tutti moduli vengono automaticamente ricompilati. Novità per l'utilizzo server Le novità non mancano anche per chi utilizza Ubuntu come server. Sono stati introdotti sostanziali miglioramenti nel campo della virtualizzazione, per chi sviluppa in Java e nei tool della gestione di sistema. Virtualizzazione: la versione JeOS di Ubuntu è stata integrata in Ubuntu Server. Si tratta di una versione ridotta di Ubuntu, adatta a girare all'interno delle macchine virtuali. Ubuntu Server è anche ufficialmente supportata come sistema guest su Xen . Java: Apache Tomcat 6.0 e OpenJDK 6 sono completamente supportati ed incusi nel repository principale di Ubuntu. Mail Server: sono stati integrati nel repository principale sia ClamAV che SpamAssassin . Questi due programmi permettono di integrare nel server di posta sia il controllo anti-virus che l'anti-spam. Supporto RAID: dalla versione 8.10 è stato aggiunto il supporto che permette di fare il boot anche da un RAID degradato . Questo significa che se si dovesse rompere uno dei due dischi, verrà chiesto all'utente se si vuole procedere ugualmente al boot, in modo da non dover per forza bloccare quella macchina. Uncomplicated Firewall: è stato migliorato il supporto al firewall semplificato. Adesso è possibile specificare direttamente il nome del servizio che si vuole aprire o chiudere, senza dover specificare il numero della porta. I problemi della nuova Ubuntu 8.10 Come ho anticipato all'inizio, puo' capitare che una nuova release, oltre ad introdurre nuove funzionalità, abbia anche dei problemi sia perchè viene distribuita con versioni piu' recenti dei vari pacchetti, sia perchè non è stata sufficientemente testata prima di essere rilasciata. Cerchero' di riassumere quelli che sono i problemi principali di questa versione, in modo che ogni persona possa capire, a seconda dell'uso che ne fa del PC e a seconda dell'hardware sul quale andra' ad installare Ubuntu, se questi saranno o no un problema per l'utilizzo quotidiano. Il lettore CD/DVD mangia le dita ( bug #283316 ): non allarmatevi! Non esce alcun mostro dal lettore a mangiare le vostre dita... Si tratta semplicemente di un bug che fa si che il carrellino del lettore CD venga reinserito troppo velocemente quando si richiede che un CD venga fatto uscire. In pratica si ha meno di un secondo a disposizione per togliere il CD, in caso contrario il carrello verra' chiuso e dovremo premere manualmente il pulsante di eject. La sessione di Gnome non viene memorizzata ( bug #249373 ): a causa di un cambiamento nel protocollo utilizzato per salvare la sessione, la maggior parte delle applicazioni (come ad esempio Pidgin, Skype ecc...) non sono piu' in grado di essere avviate automaticamente quando si salva la sessione. E' necessario avviarle manualmente dopo ogni login. La ricezione e l'invio dei files tramite Bluetooth non funziona piu' con i normali tool ( bug #290875 ): cercando di connettersi ad un dispositivo esterno tramite Bluetooth, per lo scambio dei files, si otterrà un errore. Sono stati introdotti nuovi tool (che non sono ancora completi) ma non vengono installati di default. Le stampanti condivise con Samba non riescono a stampare quando non è richiesta autenticazione ( bug #283811 ): un bug di CUPS aggiunge ad ogni avvio una riga nel file di configurazione che obbliga a richiedere l'autenticazione per poter stampare e questo impedisce alle applicazioni di stampare. Il plugin UPnP di Rhythmbox non viene caricato ( bug #160592 ): quando si tenta di abilitare questo plugin dentro Rhythmbox si ottiene un errore e non è possibile quindi attivarlo. Per farlo funzionare occorre installare il pacchetto python-coherence . Questi sono solo alcuni dei problemi noti della Ubuntu 8.10. Potete trovare la lista completa nella pagina delle release notes: http://www.ubuntu.com/getubuntu/releasenotes/810 La maggior parte di questi problemi riguardano solo alcune particolari configurazioni oppure hardware ben preciso, quindi se il vostro sistema non rientra in uno dei casi che vengono elencati, potete installare la nuova Ubuntu senza alcun timore. Soluzioni ai problemi della nuova Ubuntu La maggior parte dei problemi che ho citato sopra, sono stati nel frattempo corretti e sono stati rilasciati i pacchetti aggiornati che verranno inseriti poi nella prossima bug-fix release (presumibilmente la 8.10.1 ). Per testare in anteprima le patch che vengono rilasciate, occorre abilitare il repository intrepid-proposed tramite System->Administration->Software Sources->Updates . E' opportuno specificare che si tratta di patch che sono ancora sotto fase di testing ma che nel 99% dei casi riescono a risolvere il problema. Un suggerimento che vorrei dare agli utenti con un minimo di esperienza, è quello di non attendere che i bug vengano corretti standosene con le braccia incrociate . Esiste un comodissimo strumento che si chiama Launchpad che Ubuntu utilizza per raccogliere le segnalazioni dei bug nei programmi. E' fondamentale che piu' persone diano il loro feedback su un particolare problema, in modo da aiutare gli sviluppatori a correggerlo nel minor tempo possibile. Conclusioni Volendo fare il punto della situazione, la Ubuntu 8.10 introduce interessanti novità per l'utente finale, ma anche diversi bug . Se si utilizza Ubuntu in ambienti critici , il mio consiglio è quello di attendere almeno un mesetto prima di fare l'aggiornamento , in modo che almeno i problemi piu' gravi possano essere risolti. Per tutti gli altri problemi ricordo quanto sia importante dare il proprio contributo. Non è necessario avere competenze tecniche da programmatori o hacker per migliorare una distribuzione. Occorre solo armarsi di pazienza e saper dialogare con gli sviluppatori per segnalare in tempi brevi i problemi ed attendere che vengano corretti. Riferimenti La recensione delle novità e dei problemi della nuova Ubuntu 8.10 è stata possibile sia grazie all'utilizzo diretto (è la distribuzione che uso sul PC fisso) sia grazie alla lettura di alcuni post e alle release notes ufficiali. Per approfondimenti: Avoiding feature regressions should be more important than (exact) time based releases: http://ernstfamily.ch/jonathan/2008/11/avoiding-feature-regressions/ Ubuntu 8.10 Release Notes: http://www.ubuntu.com/getubuntu/releasenotes/810 Ubuntu Desktop Edition: http://www.ubuntu.com/news/ubuntu-8.10-desktop Ubuntu Server Edition: http://www.ubuntu.com/news/ubuntu-8.10-server","tags":"Recensione, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/11/07/ubuntu-810-novita-problemi-e-soluzioni/","loc":"https://www.andreagrandi.it/2008/11/07/ubuntu-810-novita-problemi-e-soluzioni/"},{"title":"Qt Creator: disponibile la preview release dell'IDE per Qt/C++ di Trolltech","text":"Trolltech ha appena rilasciato la preview release di Qt Creator . Si tratta di un' IDE pensato appositamente per lo sviluppo di applicazioni multi piattaforma tramite Qt e C++ . Tra le funzionalità piu' importanti ci sono sicuramente un'avanzato completamento del codice digitato, l'integrazione con QtDesigner ed il debugger integrato . Mancano ancora alcune feature che siamo abituati a trovare su altri IDE, come ad esempio l'integrazione con SVN/CVS, templates per il codice sorgente, opzioni di personalizzazione della formattazione ecc... tuttavia l'ambiente promette veramente bene, per essere una preview release. L'architettura a plugin che sta alla base dell'IDE, non esclude che funzionalità di questo tipo possano essere aggiunte in un secondo momento e rese disponibili anche da sviluppatori di terze parti. Nonostante le librerie Qt stiano prendendo sempre piu' campo nei dispositivi portatili (palmari, cellulari ecc...), non è al momento supportato lo sviluppo di applicazioni per questo tipo di device. E' una funzionalità prevista per le future release , anche se al momento non sono noti i tempi esatti di rilascio. Al momento è possibile scaricare l'IDE per tutte le principali piattaforme: Windows (Xp e Vista), Linux (32 e 64 bit), OSX . La disponibilità in futuro è però limitata soltanto dalle piattaforme per le quali esiste un porting delle librerie Qt. La versione definitiva di Qt Creator dovrebbe essere rilasciata poco dopo il rilascio delle Qt 4.5 , ovvero entro la prima metà del 2009 . Così come le librerie Qt, sara' rilasciato con una licenza GPL compatibile che permettera' di sviluppare sia applicazioni commerciali che opensource .","tags":"Programmazione, Qt","url":"https://www.andreagrandi.it/2008/10/31/qt-creator-disponibile-la-preview-release-dellide-per-qtc-di-trolltech/","loc":"https://www.andreagrandi.it/2008/10/31/qt-creator-disponibile-la-preview-release-dellide-per-qtc-di-trolltech/"},{"title":"Mini antenna parabolica per potenziare il segnale dei router wireless","text":"Dopo averne sentito tanto parlare, senza mai aver avuto occasione di provarla direttamente, mi sono deciso a costruire una mini antenna parabolica per potenziare il segnale del router wireless . Dalle poche prove che ho potuto fare, in effetti il segnale viene potenziato abbastanza. Ad esempio ricercando le reti wireless con il palmare da camera mia al salotto, il segnale del router era di circa metà. Avendo messo l'antenna nuova il segnale è quasi pieno! Consiglio a tutti di provare questa soluzione, potrebbe potenziare molto il vostro segnale wireless e permettervi di avere un segnale molto piu' stabile in qualsiasi punto della casa.","tags":"HowTo","url":"https://www.andreagrandi.it/2008/10/29/mini-antenna-parabolica-per-potenziare-il-segnale-dei-router-wireless/","loc":"https://www.andreagrandi.it/2008/10/29/mini-antenna-parabolica-per-potenziare-il-segnale-dei-router-wireless/"},{"title":"Install Fest Ubuntu Linux 8.10 a Pistoia","text":"Il Pistoia Linux User Group organizza un \" install fest \" sabato 22 novembre a partire dalle ore 15:00 fino alle ore 19:00 , presso la propria sede al Centro Giovani ( Via Nazario Sauro, 289 - Pistoia ). Durante la giornata lo staff del PtLUG sarà a disposizione per aiutare tutti coloro che vogliono installare Linux sul proprio PC (portatile o fisso). La distribuzione che verrà installata sara' principalmente la Ubuntu 8.10 , per festeggiare la nuova versione che verrà appunto rilasciata fra pochi giorni. Sara' inoltre possibile richiedere una copia del CD di Ubuntu, sia facendoselo masterizzare sul momento, sia ordinandolo gratuitamente tramite il sito di Ubuntu . L'evento è completamente gratuito ed aperto a tutti. E' necessario però iscriversi tramite il nostro sito web per prenotare l'installazione di Linux sulla propria macchina, in modo da assicurarci che ci siano abbastanza persone disponibili per le installazioni: http://www.ptlug.org/installfest Vi aspettiamo!","tags":"Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/10/28/install-fest-ubuntu-linux-810-a-pistoia/","loc":"https://www.andreagrandi.it/2008/10/28/install-fest-ubuntu-linux-810-a-pistoia/"},{"title":"24 ore di lezioni no-stop all'Università di Firenze","text":"Il Collettivo di Matematica degli Studenti di Scienze dell' Università di Firenze ha organizzato una 24 ore no-stop di lezioni da lunedi 27 ottobre alle ore 8:30 fino a martedi 28 ottobre alle ore 8:30 . Le lezioni si terranno presso il dipartimento di Matematica a Firenze in Viale Morgagni (zona Careggi) nell' aula 3 del plesso Ulisse Dini . Durante la notte verrà offerto gratuitamente caffe' a tutti i partecipanti. Sarà possibile inoltre seguire le lezioni anche da casa, collegandosi alla diretta in streaming audio/video tramite VLC al seguente indirizzo: http://radio.math.unifi.it:8000/24hnostop.m3u Qui di seguito il programma delle lezioni: 08.30 Ricci: \"Testa, croce o successioni\" 09.30 Primicerio: \"Innovazione tecnologica: la risorsa matematica\" 10.30 Pepino: \"La chimica nel piatto\" 11.30 Giachetti: \"I fatti e le idee fondamentali che hanno dato origine alla meccanica quantistica\" 12.30 Righini: \"Il sole, la relazione terra sole e il clima terrestre\" 13.30 Paolini: \"Come imparare a risolvere il cubo di Rubik\" 14.30 Trosti: \"La simmetria\" 15.30 Livi: \"Aspetti elementari della complessità\" 16.30 Landi: \"Reti neurali artificiali\" 17.30 Casalbuoni: \"Radici quadrate e antimateria\" 18.30 Ottaviani: \"Enriquez e Severi\" 19.30 Baracca: \"Energia nucleare\" 20.30 Maggesi: \"La meccanizzazione della matematica\" 21.30 Casolo: \"La matematica in letteratura\" 22.30 Borsi: \"Modelli matematici per fluidi in mezzi porosi: dalla suola delle scarpe alle falde inquinate\" 23.30 Gentili: \"Che cos'e' la congettura di Poincarè\" 00.30 Rubei: \"Geometria tropicale\" 01.30 Vannini: \"Chi ha paura di Darwin ovvero a cosa servono le zanzare\" 02.30 Cupini: \"Temperamento:un enigma musicale da Pitagora a Bach\" 03.30 Puglisi: \"In cerca dei numeri primi\" 04.30 Cannicci: \"Il contributo della zoologia nelle investigazioni scientifiche\" 05.30 Romito: \"Mentire con la statistica\" 06.30 Bagnoli: \"La fisica sotto il naso\" 07.30 Casetti: \"L'ultimo lavoro di Fermi e i fondamenti della meccanica statistica\"","tags":"Unifi","url":"https://www.andreagrandi.it/2008/10/27/24-ore-di-lezioni-no-stop-alluniversita-di-firenze/","loc":"https://www.andreagrandi.it/2008/10/27/24-ore-di-lezioni-no-stop-alluniversita-di-firenze/"},{"title":"LinuxDay 2008 a Pistoia: un successo strepitoso!","text":"E' con estremo piacere che mi sento di dire che l'edizione di quest'anno del LinuxDay a Pistoia è stata un successo senza precedenti! Si sono registrate all'evento circa 170 persone e, contando anche quelle che non si sono registrate, contiamo di aver raggiunto oltre le 200 presenze in tutta la giornata. Un ringraziamento particolare va fatto ai docenti dell' ITC Capitini di Agliana che hanno accompagnato due classi e agli studenti dell' ITIS Silvano Fedi che per qualche ora hanno rinunciato ad occupare il loro istituto per tenere fede all'impegno di partecipare al LinuxDay. La manifestazione si è svolta nella nuovissima Biblioteca SanGiorgio , messa gentilmente a disposizione dal Comune di Pistoia ed è stata suddivisa in due target particolari: la mattina è stata dedicata a scuole, pubblica amministrazione ed aziende, mentre il pomeriggio sono stati affrontati temi di carattere piu' generale. E' ovviamente disponibile il programma delle conferenze che si sono svolte e sempre sulla stessa pagina, sarà possibile a breve scaricare le slides degli interventi. All'esterno della sala conferenze erano state allestite 6 postazioni con Ubuntu e Fedora installate per permettere ai visitatori di provare Linux direttamente. Lo staff del PtLUG era a disposizione dei visitatori per rispondere a domande tecniche oppure per installare Linux direttamente sui PC. Una delle attrazioni che hanno suscitato piu' interesse è stato il videogioco da sala giochi dentro il quale era stato posizionato un PC con il Mame , che permetteva di giocare a moltissimi videogiochi che hanno fatto la storia delle sale giochi. Grazie al supporto del personale della biblioteca, sono state effettuate le registrazioni sia audio che video di tutte le conferenze . Non appena ci verrà consegnato il DVD avrò cura di rippare i contenuti e di pubblicarli da qualche parte in modo che siano accessibili anche a chi non è potuto essere presente fisicamente. La giornata del LinuxDay ci ha permesso di entrare in contatto con diverse nuove persone che si sono dimostrate interessate a partecipare al PtLUG e a dare una mano per quanto riguarda i prossimi progetti che realizzeremo. Ci auguriamo che il successo di quest'anno possa ripetersi anche nei prossimi anni, riuscendo a coinvolgere un numero sempre piu' grande di persone, per riuscire a diffondere in modo ancora piu' capillare la cultura del software libero e opensource .","tags":"Linux","url":"https://www.andreagrandi.it/2008/10/27/linuxday-2008-a-pistoia-un-successo-strepitoso/","loc":"https://www.andreagrandi.it/2008/10/27/linuxday-2008-a-pistoia-un-successo-strepitoso/"},{"title":"Il Presidente della Repubblica Napolitano esprime il proprio apprezzamento per il LinuxDay","text":"Grazie ad un'iniziativa di Davide Dozza (Presidente dell'Associazione PLIO) e Michele Dalla Silvestra (Presidente di Italian Linux Society), il Presidente della Repubblica Napolitano era stato invitato ufficialmente all'edizione di Roma del LinuxDay 2008 . Purtroppo i suoi numerosi impegni non hanno reso possibile confermare la propria presenza all'evento, ma si è comunque interessato di esprimere il proprio appoggio all'iniziativa ed ha inviato un cordiale saluto a tutti quelli che parteciperanno al LinuxDay 2008 in tutta Italia. Di seguito un estratto della lettera, di cui potete trovare la scansione a questo indirizzo . Il Presidente Napolitano esprime apprezzamento per l'iniziativa che, nel diffondere l'iniziativa del software libero, concorre a far conoscere e a rendere accessibile la cultura informatica e le sue tecnologie consentendo così la piu' ampia fruibilità del nuovo sistema di comunicazione ed informazione che su di esso si basa.","tags":"Linux","url":"https://www.andreagrandi.it/2008/10/19/il-presidente-della-repubblica-napolitano-esprime-il-proprio-apprezzamento-per-il-linuxday/","loc":"https://www.andreagrandi.it/2008/10/19/il-presidente-della-repubblica-napolitano-esprime-il-proprio-apprezzamento-per-il-linuxday/"},{"title":"Trusted Computing: perchè fidarsi di chi non si fida di noi?","text":"E' notizia di questi giorni il fatto che Google abbia previsto un meccanismo di \"sicurezza\" che consentirà a loro stessi di rimuovere automaticamente , dai telefonini GPhone che verranno venduti, le applicazioni non ritenute sicure. Google avrà quindi la possibilità di controllare i propri dispositivi da remoto, accedere alla memoria del telefono e rimuovere quello che non desidera ci sia installato: chi ci assicura che non si mettano a controllare pure il testo degli SMS che inviamo o riceviamo, magari per inviarci pubblicità mirata a seconda delle nostre esigenze? Della stessa pasta sono fatti anche i dispositivi della Apple , in particolare l' iPhone . Anche questo dispositivo incorpora infatti un chip che impedisce alle applicazioni non consentite di girare sul telefonino. L'unico modo per installare applicazioni sull'iPhone è quello di scaricarle dall' Apple Store , ed ovviamente Apple si riserva il diritto di decidere quali applicazioni possano apparire nello store e quali invece no, ed una nota nella licenza che devono firmare gli sviluppatori di applicazioni per iPhone, si dice anche che essi non possono in alcun modo dire pubblicamente che una loro applicazione è stata esclusa dallo store. Tutto questo in nome della nostra \"sicurezza\".","tags":"Censura, Google, Sicurezza","url":"https://www.andreagrandi.it/2008/10/18/trusted-computing-perche-fidarsi-di-chi-non-si-fida-di-noi/","loc":"https://www.andreagrandi.it/2008/10/18/trusted-computing-perche-fidarsi-di-chi-non-si-fida-di-noi/"},{"title":"Creare mappe personalizzate e condivise con Google Maps","text":"Il servizio che Google offre per consultare le mappe di quasi tutto il mondo, non ha certo bisogno di presentazioni. Ormai integrato in qualsiasi tipo di dispositivo, Google Maps ci permette di ricercare velocemente un indirizzo oppure un'attività commerciale e di poterlo visualizzare sulla cartina. Avere una mappa fatta da altri puo' essere utile a volte, ma spesso puo' capitare di avere l'esigenza di creare una propria mappa (inserendo i propri punti di interesse) per condividerla magari con amici. Mappe Personalizzate Google da la possibilità di utilizzare la loro enorme banca dati per poter costruire una mappa personalizzata a seconda delle proprie esigenze. Facciamo l'esempio di una persona che voglia condividere con altri tutte le birrerie dov'è andato fino ad ora, indicandole sulla cartina e scrivendo anche una piccola recensione. Per poter creare una mappa personalizzata occorre avere un account Google (va benissimo quello che si usa per la posta di GMail), andare sul sito di Google Maps e cliccare su \"Crea una nuova mappa\". Ci vengono richiesti un titolo, una descrizione ed in particolare se vogliamo che questa mappa sia pubblica oppure privata . Da sottolineare il fatto che per privata si intende soltanto una mappa che non compare nei risultati di ricerca , ma che non richiede alcun tipo di autorizzazione per essere consultata. Chi conosce l'URL esatto della mappa quindi puo' consultarla senza alcun problema. A questo punto la mappa è pronta per essere personalizzata. Tra le informazioni che possiamo inserire ci sono i punti di interesse , tracciare linee di percorso personalizzate ed infine evidenziare delle aree . Condivisione Mappe Riuscire a personalizzare una mappa è di sicuro una gran cosa, ma ancora piu' utile è poterlo fare con l'aiuto di piu' persone. Tramite Maps infatti è possibile permettere ad altri utenti (che abbiano un Google account) di modificare la nostra mappa , inserendo altri punti di interesse, annotazioni, foto ecc... Inserendo l'email della persona con la quale vogliamo condividere la mappa, faremo in modo che questa riceva una mail di invito per poter iniziare a personalizzare la mappa. Conclusioni Il mio invito è quello di provare a crearsi una mappa personalizzata e condividerla con amici. Vedendo la procedura scritta puo' sembrare tutto molto piu' complicato di quanto lo sia in realtà. Vi assicuro che dopo qualche prova, creare mappe personalizzate e condividerle sarà un'operazione semplicissima e che vi permettera' di realizzare cose che fino a ieri pensavate impossibili.","tags":"Google, HowTo","url":"https://www.andreagrandi.it/2008/10/16/creare-mappe-personalizzate-e-condivise-con-google-maps/","loc":"https://www.andreagrandi.it/2008/10/16/creare-mappe-personalizzate-e-condivise-con-google-maps/"},{"title":"LinuxDay 2008 a Pistoia","text":"Per l'ottavo anno consecutivo il Pistoia Linux User Group , di cui faccio parte, organizza l'edizione di Pistoia del LinuxDay , che si terrà sabato 25 ottobre dalle ore 9:00 fino a sera. Il LinuxDay è una manifestazione che si svolge ogni anno inoltre 100 città d'Italia con lo scopo di diffondere l'utilizzo del sistema operativo Linux ed il software libero . Ogni evento viene organizzato in maniera indipendente e promosso dai singoli LUG (Linux User Group) locali. L'evento di Pistoia si svolgerà nella prestigiosa Biblioteca San Giorgio di Pistoia, situata in via Pertini ed ha ottenuto il patrocinio di Regione Toscana , Comune di Pistoia e Comune di Monsummano Terme (PT) . Abbiamo suddiviso la giornata in due momenti principali: la mattina verrà dedicata (ma non in modo esclusivo) a scuole, aziende e pubblica amministrazione . Il pomeriggio sara' invece dedicato a tutti gli utenti che conoscono ancora poco Linux o a chi lo vuole conoscere per la prima volta. L' ingresso alla manifestazione è ovviamente gratuito ed aperto a tutti . Si consiglia in ogni caso di registrarsi online in modo da agevolare gli organizzatori dell'evento e per avere la possibilità di vincere i premi messi in palio dai nostri sponsor: 2 licenze ActiveState per Komodo IDE 3 abbonamenti alla rivista Linux&C 100 gagliardetti con il logo PtLUG messi a disposizione da Ricami Nerozzi 10 affiliazioni annuali a Manuali.Net 10 corsi online Ubuntu Linux di Manuali.Net 10 router wireless FON 50 copie della rivista LinuxPro Di seguito il programma ufficiale dell'evento di Pistoia: Mattina 09:00/09:15 - Introduzione ( Andrea Grandi ) 09:15/09:30 - Spazio riservato istituzioni (Assessore Tommaso Braccesi del Comune di Pistoia ) 09:30/10:00 - Spazio riservato SIS Informatica (Gruppo CNA) 10:00/10:30 - Presentazione Progetto Wireless ( Andrea Grandi e Alessandro De Filippo ) 10:30/11:00 - Progetti opensource all' ITIS 11:00/11:30 - Linux per aziende ( Alessandro De Filippo ) 11:30/12:00 - PostgreSQL ( Gabriele Bartolini di ItPUG ) 12:00/12:30 - Italc ( Andrea Cappelli ) 12:30/13:00 - Domotica ( Alessandro De Filippo ) Pomeriggio 15:00/15:30 - Perchè Opensource ( Alessandro De Filippo ) 15:30/16:00 - Presentazione Ubuntu ( Andrea Grandi ) 16:00/16:30 - Presentazione Fedora ( Lorenzo Villani ) 16:30/17:00 - Registrare musica con Linux ( Carlo Ascani ) 17:00/17:30 - Firefox ( Enrico Sorcinelli ) 17:30/18:00 - Wikimedia ( Lorenzo Losa ) 18:00/18:30 - Giocare con Linux ( Simone Vassili ) 18:30/18:45 - Conclusione dei lavori ( Andrea Grandi ) Per essere informati sulle ultime novità, vi consiglio di visitare il sito web ufficiale dell'evento, dove potrete trovare informazioni piu' approfondite e tutti i dettagli per partecipare.","tags":"Linux","url":"https://www.andreagrandi.it/2008/10/10/linuxday-2008-a-pistoia/","loc":"https://www.andreagrandi.it/2008/10/10/linuxday-2008-a-pistoia/"},{"title":"Dieci buoni motivi per non utilizzare PHP","text":"Quando in questi giorni ho appreso la triste notizia che il progetto da consegnare per l' esame di Laboratorio di Reti avrebbe dovuto essere realizzato in PHP , sono stato preso un po' dallo sconforto. Per anni mi sono sempre rifiutato di imparare ed utilizzare questo linguaggio ed ho persino declinato diverse offerte di lavoro, visto che già sulla carta ne avevo sempre sentito parlare male. Adesso è arrivato il momento di ingollare il rospo ed imparare almeno il minimo indispensabile alla realizzazione del progetto. Ho approfittato della situazione per documentarmi un po' sul PHP e per ribadire alcuni motivi che per anni mi hanno tenuto lontano da questo linguaggio. I punti che seguono prendono spunto sia da considerazioni personali, sia da un ottimo articolo di Edwin Martin . 1. Ricorsione?! Chi era costei... La ricorsione , come molti di voi sapranno, è un meccanismo che permette ad una funzione di chiamare se stessa. Viene impiegata nell'implementazione di moltissimi algoritmi, come ad esempio il Quick Sort . Se vengono generate troppe chiamate ricorsive in PHP, il linguaggio va letteralmente in palla e non funziona piu' correttamente. Questa cosa è stata segnalata come bug e la motivazione che è stata data dagli sviluppatori è che PHP utilizza lo stack al posto dell'heap per le chiamate ricorsive. Questo cosa c'entra? Mi viene da chiedere... eppure in altri linguaggi la ricorsione funziona benissimo! 2. Molti moduli PHP non sono thread safe Anche se tutti i moduli del core di PHP sono garantiti thread safe , la maggior parte degli altri moduli non lo sono . Questo rende completamente inutile il fatto che Apache 2 supporti la modalità multithreaded: gli sviluppatori di PHP sconsigliano pure di utilizzare questa versione di Apache. 3. PHP è azzoppato per motivi commerciali Vi sembra che PHP sia un po' lento ? Non avete provato la versione commerciale di Zend PHP , che garantisce maggiori prestazioni! La versione gratuita di PHP infatti non ha alcuna ottimizzazione e a meno di non utilizzare un qualche meccanismo di cache (come ad esempio APC ) le prestazioni saranno basse. 4. Nessun supporto ai Namespace Se due moduli hanno una funzione che si chiama read, non possono essere utilizzati contemporaneamente. Era stata proposta una soluzione a questo problema in PHP5, ma alla fine non è stata inclusa nella release definitiva. L'unico modo per evitare la collisione dei nomi dei metodi è quello di nominarli aggiungendo il nome del modulo all'inizio. Ecco perchè non è strano trovare metodi che ad esempio si chiamano xsl_xsltprocessor_transform_to_xml che di sicuro non aumentano la leggibilità del codice. 5. Caratteri di formattazione delle date non standard La maggior parte dei linguaggi di programmazione utilizza uno standard per quanto riguarda i caratteri di formattazione delle date, che deriva da Unix e dal linguaggio C. PHP utilizza un proprio formato , completamente incompatibile. 6. Inconsistenza nei nomi delle funzioni Quando i nomi dei metodi contengono piu' di una parola, solitamente ci sono tre modi diversi per poterli scrivere. Prendiamo ad esempio un'ipotetica funzione che restituisce il numero dei file aperti. Potremmo chiamarla getnumberofopenfiles , get_number_of_open_files oppure getNumberOfOpenFiles . Quale metodo utilizza PHP ? Tutti e tre ovviamente! Oltre a questo è opportuno far notare che i nomi dei metodi e delle funzioni non sono case sensitive . 7. Assenza di un framework integrato Il modello piu' corretto per sviluppare un'applicazione web, sarebbe quello chiamato MVC , dove la parte di visualizzazione , la business logic e la validazione dei dati ed infine l' interazione con il database , sono parti separate del progetto. Nella maggior parte dei siti scritti in PHP è molto comune trovare sorgenti che includono tutti e tre questi aspetti in un unico file! Poche righe sopra viene fatta la connessione al database, poi c'è una parte di visualizzazione di alcuni dati, verso la metà ci sono le funzioni di validazione ed infine di nuovo altro codice html di visualizzazione. Credo che questo sia il peggiore dei modi di realizzare un'applicazione web. Pensate che sia facile per un grafico dover apportare modifiche alla parte di visualizzazione senza toccare il codice PHP? E viceversa... pensate che sia facile per un programmatore, aggiungere codice PHP senza rischiare di scombinare il layout della pagina? Altri linguaggi con Ruby o Python ci hanno ormai abituati a framework come Rails e Django , rispettivamente. Per fortuna le cose sono in miglioramento anche su PHP, grazie a framework come CakePHP o Symfony . 8. Mancanza del supporto Unicode Questa lacuna forse potra' non riguardarci da vicino, visto che il set di caratteri che utilizziamo in Europa ed in America è ampiamente supportato, ma non è certo così per Cina , Giappone ed altre nazioni dove viene utilzzato un set di caratteri e di simboli molto diverso dal nostro. Tramite Unicode è possibile supportare anche questi caratteri. PHP avrà il supporto per Unicode solo nella futura versione 6 . 9. Lentezza Pensate che il Java sia un linguaggio lento? Beh, niente a confronto di PHP! Leggendo questo report si mettono in evidenza le scarse prestazioni di questo linguaggio. Persino Rasmus Lerdorf , il creatore di PHP ammette che non c'è modo di migliorare le prestazioni di PHP. Rasmus tra l'altro sconsiglia persino l'utilizzo dei frameworks sopra citati (CakePHP e Symfony) perchè rallenterebbero inutilmente le prestazioni dei siti web. 10. Estrema facilità di utilizzo Ammetto che questo ultimo punto possa essere non condiviso da molte persone , si tratta infatti di una mia personalissima opinione . Il fatto che un linguaggio di programmazione sia troppo facile da usare, secondo me puo' presentare anche degli svantaggi. Permette infatti anche a chi ha scarse conoscenze di programmazione, di cimentarsi in progetti, con il rischio poi di far abbassare notevolmente la qualità del codice che si trova in giro. Non è difficile infatti imbattersi in programmi scritti in PHP che all'apparenza possono risultare gradevoli ed accattivanti (magari perchè scritti da persone che principalmente si occupano di web design), ma che sotto sotto sono dei veri e propri pastoni di codice mal scritto . Conclusioni A favore di PHP possiamo sicuramente dire che si tratti di un linguaggio molto semplice da imparare ed ampiamente supportato dalla maggior parte dei servizi di hosting in tutto il mondo. A parte queste due motivazioni però, non mi sentirei in alcun modo di consigliarlo per sviluppare un'applicazione web. Sicuramente qualcuno mi fara' notare che lo stesso blog sul quale sto scrivendo è scritto in linguaggio PHP. Per l'utilizzo che ne devo fare, Wordpress va piu' che bene, almeno per le mie esigenze. Questo non toglie che PHP soffra ugualmente di tutti i problemi che sono stati esposti sopra. E' mia intenzione che questo articolo sia di avvertimento a chi si sta per avvicinare per la prima volta al PHP o chi già lo utilizza. Ci tengo però al fatto che non contenga imprecisioni , perchè credo che servirebbero solo a screditare la natura stessa dell'articolo. Invito quindi i lettori che rilevassero imprecisioni a segnalarmele , indicandomi dove poter trovare maggiori informazioni per verificare la validità di quanto riportato.","tags":"Programmazione","url":"https://www.andreagrandi.it/2008/10/09/dieci-buoni-motivi-per-non-utilizzare-php/","loc":"https://www.andreagrandi.it/2008/10/09/dieci-buoni-motivi-per-non-utilizzare-php/"},{"title":"Installazione e configurazione di Ubuntu Eee 8.04.1 su Asus EeePC 901","text":"La versione di Linux che viene installata sugli EeePC ( Xandros Linux) da Asus, sebbene sia l'ideale per chi non ha mai utilizzato Linux e desidera un netbook semplice da usare, tuttavia non permette di sfruttare pienamente le potenzialità che l'EeePC ha. Poco tempo dopo l'uscita dei primi modelli degli EeePC sono iniziate quindi ad essere rilasciate distribuzioni alternative alla Xandros, ottimizzate per il netbook di Asus. E' ovviamente possibile installare una qualsiasi distribuzione Linux, ma ovviamente il lavoro da compiere per far funzionare tutte le periferiche sarà maggiore rispetto a quello necessario con una distribuzione realizzata ad hoc. La distribuzione che ho deciso di installare sul mio EeePC 901 è la Ubuntu Eee 8.04.1 . Per installare la Ubuntu Eee è necessario scaricarla dal sito web dedicato e poi trasferirla su una chiavetta USB o su un disco USB esterno (visto che l'EeePC non è dotato di lettore CD/DVD) utilizzando una utility chiamata Unetbootin e seguendo le istruzioni presenti sul wiki . Dopo aver trasferito l'installazione sulla chiavetta USB dobbiamo inserirla nell'EeePC ed avviare premendo piu' volte il tasto Esc . Quando compare il menu di avvio, dobbiamo selezionare il disco USB dalla lista e premere Invio per continuare. Nel caso la Ubuntu Eee non si dovesse avviare, i motivi possono essere diversi. Per prima cosa dobbiamo controllare nella sezione Boot del BIOS se il disco USB è al primo posto nell'ordine dei dischi da cui fare il boot. Se non dovesse avviarsi nemmeno in questo caso, è possibile che la chiavetta USB non sia compatibile : a me è successo di non essere in grado di utilizzare una chiavetta USB da 1 Gb che avevo e sono dovuto ricorrere ad un disco esterno USB. Se riusciamo ad avviare la Ubuntu Eee, saremo in grado di utilizzare l'installer grafico senza alcun problema. Il mio consiglio è quello di scegliere il partizionamento manuale e di utilizzare il primo disco SSD da 4 Gb per la root / ed il disco SSD da 16 Gb per la /home . Le caratteristiche della Ubuntu Eee la rendono praticamente la distribuzione perfetta per gli EeePC: supporto per gli Asus EeePC 701, 900, 900A, 901, 1000 e 1000H occupa 1.8 Gb di spazio Kernel ottimizzato di Adam con supporto per tutte le periferiche degli EeePC interfaccia Notebook Remix predefinita (è possibile cambiarla tramite un'apposita utility) Sebbene il setup e la configurazione predefiniti di Ubuntu Eee siano quasi perfetti, tuttavia sono necessari ancora alcuni ritocchi per fare in modo che tutto funzioni regolarmente. Per prima cosa occorre commentare l'ultima riga di /etc/fstab , quella relativa al cdrom, altrimenti si otterrà un errore durante la fase di mount quando si inserisce una chiavetta USB. Per ottenere il meglio dal risparmio energetico , consiglio di installare gli script ACPI di Murat che potete trovare a questo indirizzo: http://www.informatik.uni-bremen.de/~elmurato/EeePC/Hardy_ACPI_scripts-EeePC_900A_901_1000.tar.gz Gli script permettono di attivare/disattivare alcune periferiche come il bluetooth, la webcam, la wifi ecc... consentendo alla batteria di durare piu' a lungo. Per l'installazione sono sufficienti i seguenti passaggi: tar xfvz Ubuntu_ACPI_scripts-EeePC_900A_901_1000.tar.gz cd Ubuntu_ACPI_scripts-EeePC_900A_901_1000/ chmod +x install.sh sudo ./install.sh ` In particolare le funzionalità che vengono aggiunte sono le seguenti (gli hotkey sono quei tasti hardware posizionati sopra ad i tasti F1, F2, ecc...): Fn+F1 Standby Fn+F2 WLAN-toggle Fn+F3/F4 Brightness Fn+F5 VGA-toggle Fn+F6 Taskmanager Fn+F7/F8/F9 Volume new hotkey Display-toggle (internal) new hotkey Bluetooth-toggle new hotkey CPU frequency control or user-defined new hotkey Webcam-toggle or user-defined Gli script di Murat purtroppo introducono un piccolo bug : viene disattivata la funzionalità \"Dim when idle\" del display (in pratica non viene abbuiato lo schermo quando non si usa l'EeePC). Per ripristinare questa funzionalità è sufficiente eseguire questo comando: sudo cp /etc/acpi/backup/hal-system-lcd-set-brightness-linux /usr/lib/hal/scripts/linux/ A questo punto la configurazione dovrebbe essere al completo. Si consiglia di riavviare l'EeePC per rendere effettive tutte le modifiche. Per ulteriori trucchetti su come ottimizzare la configurazione, vi consiglio di visitare direttamente il wiki di Ubuntu Eee dove potrete trovare articoli piu' approfonditi.","tags":"EeePC, HowTo, Linux","url":"https://www.andreagrandi.it/2008/10/05/installazione-e-configurazione-di-ubuntu-eee-8041-su-asus-eeepc-901/","loc":"https://www.andreagrandi.it/2008/10/05/installazione-e-configurazione-di-ubuntu-eee-8041-su-asus-eeepc-901/"},{"title":"Come aggiornare il BIOS dell'Asus EeePC","text":"L'aggiornamento del BIOS su un Asus EeePC puo' essere fatto in una maniera che è completamente indipendente dal tipo di sistema operativo utilizzato. Per prima cosa occorre scaricare dal sito della Asus, nell'apposita pagina di supporto , l'ultima versione del BIOS, facendo ben attenzione a selezionare il modello di EeePC che possediamo. Una volta scaricato il file, dobbiamo decomprimerlo e copiarlo su una chiavetta USB o su un disco esterno USB, avendo cura di rinominarlo con il numero del modello del nostro EeePC. Se ad esempio possediamo l' Asus EeePC 901 , dovremo rinominare il file in 901.ROM A questo punto dobbiamo inserire la chiavetta USB nel nostro EeePC e riavviare il computer, premendo ALT+F2 durante la fase iniziale di avvio. L'EeePC avvia l'utility di aggiornamento del BIOS che provvede a cercare sulla chiaveta USB il file \" 901.ROM \". Si consiglia di eseguire questa operazione alimentando l'EeePC tramite l'adattatore di corrente e di non affidarsi alla batteria perchè se si dovesse improvvisamente scaricare durante l'aggiornamento, il BIOS rimarrebbe in uno stato inutilizzabile. Dopo pochi minuti l'aggiornamento sara' completato ed il portatile verrà riavviato. Al primo avvio sara' necessario riconfigurare nuovamente i parametri del BIOS, perchè essi vengono cancellati quando si esegue l'aggiornamento. Il mio consiglio infine è quello di far effettuare l'aggiornamento ad una persona esperta, perchè in caso di errori l'EeePC diventerebbe inutilizzabile.","tags":"HowTo","url":"https://www.andreagrandi.it/2008/10/04/come-aggiornare-il-bios-dellasus-eeepc/","loc":"https://www.andreagrandi.it/2008/10/04/come-aggiornare-il-bios-dellasus-eeepc/"},{"title":"ControlEee - Control panel for EeePC","text":"ControlEee è una piccola applicazione che ho scritto utilizzando Python/Qt4 e che permette di abilitare/disabilitare i dispositivi del bluetooth , della webcam e della wlan su un Asus EeePC . Installando una versione personalizzata di Linux sugli EeePC (come ad esempio la Ubuntu-eee), non si ha la possibilità di attivare/disattivare questi dispositivi in maniera semplice (è possibile farlo solo da riga di comando) e di conseguenza si rischia di tenere attivate queste periferiche anche se non le utilizziamo, con lo svantaggio di consumare inutilmente piu' batteria di quella di cui abbiamo bisogno. Non trovando niente di semplice di già pronto in giro, mi sono deciso a scrivere questa utility. Al momento è in hosting presso Google Code e la potete trovare a questo indirizzo: http://code.google.com/p/controleee/ Al momento l'applicazione è stata testata soltanto su un Asus EeePC 901 con la distribuzione Ubuntu-eee 8.04.1 , non è quindi garantito il funzionamento anche sugli altri modelli e/o utilizzando altre distribuzioni.","tags":"EeePC, Linux, Python, Qt","url":"https://www.andreagrandi.it/2008/10/01/controleee-control-panel-for-eeepc/","loc":"https://www.andreagrandi.it/2008/10/01/controleee-control-panel-for-eeepc/"},{"title":"Ubuntu 8.04 in RAID1 non può fare il boot con un solo disco","text":"La modalità RAID1 (detta anche modalità mirror ) è una particolare configurazione nella quale vengono utilizzati due hard disk al posto di uno, per leggere/scrivere gli stessi dati. Questo permette di avere un'esatta copia degli stessi dati su due dischi diversi , facendo in modo che se uno si dovesse rompere, l'altro conterrebbe una copia esatta dei dati, permettendoci quindi di sostituire il disco rotto senza alcuna perdita. Quello che ci si aspetta quando uno dei due dischi si rompe è che il sistema continui a funzionare normalmente , magari avvisandoci della rottura di uno dei due dischi. Il comportamento di Ubuntu 8.04 purtroppo non segue questa procedura . Gli script di avvio sono infatti configurati in modo che venga impedito il boot di sistema se il RAID risulta degradato. Questo comportamento è stato inizialmente segnalato come bug su launchpad.net e successivamente confermato e marcato come \"risolto\" per la prossima release di Ubuntu, la 8.10 che dovrebbe uscire alla fine di ottobre. Lo sviluppatore che si è occupato di risolvere il problema, Dustin Kirkland , ha anche creato un'apposita pagina sul wiki di Ubuntu dove spiega uno scenario reale e come il problema è stato risolto. Ci saremmo aspettati di veder incluso questo fix anche nell'attuale Ubuntu 8.04, visto che si tratta di una LTS (non tutti vorranno abbandonare una versione la cui stabilità e gli aggiornamenti sono mantenuti per almeno 3 anni) solo per risolvere un problema col RAID1, ma per adesso non sembra rientrare nei piani degli sviluppatori.","tags":"Linux, Sicurezza, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/09/25/ubuntu-804-in-raid1-non-puo-fare-il-boot-con-un-solo-disco/","loc":"https://www.andreagrandi.it/2008/09/25/ubuntu-804-in-raid1-non-puo-fare-il-boot-con-un-solo-disco/"},{"title":"Un bug del Kernel Linux 2.6.27 potrebbe danneggiare le schede ethernet con driver e1000e","text":"Secondo quanto riportato sulla mailing list di sviluppo di Ubuntu, un bug presente nella versione 2.6.27 del kernel Linux potrebbe danneggiare irreparabilmente le schede ethernet dotate di chipset Intel GigE che utilizzano il driver e1000e . Secondo le prime analisi, il bug andrebbe a sovrascrivere la eprom di queste schede di rete, rendendole inutilizzabili. L'attuale alpha 6 di Ubuntu contiene questo bug, si consiglia quindi di non utilizzarla se si possiede tale scheda, ma di attendere almeno la prossima release (la beta dovrebbe uscire il 2 ottobre), dove il bug è già stato corretto.","tags":"Linux, Sicurezza","url":"https://www.andreagrandi.it/2008/09/24/un-bug-del-kernel-linux-2627-potrebbe-danneggiare-le-schede-ethernet-con-driver-e1000e/","loc":"https://www.andreagrandi.it/2008/09/24/un-bug-del-kernel-linux-2627-potrebbe-danneggiare-le-schede-ethernet-con-driver-e1000e/"},{"title":"Apple vieta agli sviluppatori di lamentarsi pubblicamente per App Store","text":"Siete sviluppatori di applicazioni per iPhone e la Apple ha appena rifiutato di includere la vostra applicazione all'interno del proprio App Store ? Da oggi non potete piu' lamentarvi pubblicamente , un NDA lo vieta esplicitamente. Nei giorni precedenti, almeno un paio di sviluppatori si erano visti rifiutare da parte di Apple, l'inclusione della propria applicazione all'interno dello store e si erano pubblicamente lamentati perchè ritenevano si trattasse di un'ingiustizia, visto che non avevano violato in alcun modo il regolamento che riguarda le applicazioni che si possono scrivere. Nel primo caso era stata creata un' applicazione per scaricare i podcast direttamente sull'iPhone invece di ascoltarli in streaming come permette iTunes. Secondo Apple questa applicazione duplica le funzionalità che sono già incluse in iTunes e pertanto non puo' essere accettata. Nel secondo caso era stata invece creata un' applicazione che permetteva di controllare la posta su piu' account Gmail senza dover fare logout e login da ogni account per passare da un account all'altro. Anche in questo caso l'applicazione è stata rifiutata da Apple. Entrambi gli autori, come potete leggere dai loro blog, si sono pubblicamente lamentati di questo rifiuto, e dopo qualche giorno la Apple ha aggiornato il messaggio che viene mandato agli sviluppatori ai quali viene rifiutata l'inclusione di un'applicazione nell'App Store, aggiungendo questo NDA: \" THE INFORMATION CONTAINED IN THIS MESSAGE IS UNDER NON-DISCLOSURE \". Apple quindi impedisce di fatto di rivelare (legalmente) che una propria applicazione sia stata rifiutata dall'App Store. Personalmente trovo sempre piu' ridicola questa politica protezionista intrapresa da Apple, che non sta facendo altro che attirare critiche su di se e tener lontani ottimi sviluppatori che altrimenti sarebbero ben felici di scrivere applicazioni per l'iPhone. Staremo a vedere in che modo si comporterà Google con il proprio repository online di applicazioni.","tags":"Censura, Programmazione","url":"https://www.andreagrandi.it/2008/09/24/apple-vieta-agli-sviluppatori-di-lamentarsi-pubblicamente-per-app-store/","loc":"https://www.andreagrandi.it/2008/09/24/apple-vieta-agli-sviluppatori-di-lamentarsi-pubblicamente-per-app-store/"},{"title":"Scollegate i carica batterie quando non li usate!","text":"Secondo quanto dichiarato da Nokia (che negli ultimi device usciti addirittura visualizza un messaggio di avviso sul display quando il dispositivo è completamente carico), è stato calcolato che se anche solo tutti gli utenti Nokia scollegassero i loro carica batterie quando la carica è completata, si potrebbe risparmiare energia per alimentare circa 100.000 case di media dimensione in tutta Europa. Quando si lascia il carica batterie inserito nella presa di casa infatti, viene ugualmente consumata una certa quantità di energia che noi riteniamo irrilevante o addirittura non esistente. A leggere i dati di Nokia non è così. Questo ovviamente non vale soltanto per i loro carica batterie, ma anche per quelli dei cellulari di altre marche. Se vogliamo dare il nostro piccolo contributo per il risparmio energetico mondiale, tutto quello che dobbiamo fare è scollegare il carica batterie dalla parete una volta che abbiamo finito di ricaricare il cellulare.","tags":"Sicurezza","url":"https://www.andreagrandi.it/2008/09/23/scollegate-i-carica-batterie-quando-non-li-usate/","loc":"https://www.andreagrandi.it/2008/09/23/scollegate-i-carica-batterie-quando-non-li-usate/"},{"title":"Maemo Summit (Berlino) - giorno 2","text":"Con circa 30 minuti di ritardo (maledetto stinco di maiale della sera prima!) arriviamo al C-base . La sede del C-base è veramente straordinaria: costruita sulle fondamenta di un vecchio edificio lungo le rive del fiume, ha al suo interno ben due bar, tre sale conferenza, e tantissime altre stanze dove vengono fatte altre attività (una scuola di musica, una scuola di ballo ecc...). Dopo aver ritirato i nostri badge, ci accomodiamo nella sala principale dove Ari Jaaksi , il vice-presidente di Nokia , sta tenendo il talk introduttivo della giornata. La sala è stracolma di persone e siamo quindi costretti a sistemarci in piedi in fondo alla sala. Il talk successivo è a cura di Jay Sullivan , sviluppatore di del team di Mozilla . Non vengono annunciate particolari novità, il talk che seguirà sarà molto piu' interessante. Harri Kiljander di Nokia ci presenta alcune delle novità che saranno presenti in Maemo 5 e nei futuri device. Tra le cose piu' importanti che vengono messe in risalto, ci sarà finalmente il supporto per il multi touch . Dopo un altro paio di talk ed una breve pausa per riorganizzare le idee, arriva il momento tanto temuto: quello di tenere il talk! Il motivo per cui sono andato al Summit infatti era per tenere un talk (seppur breve) su due plugin ( Pluthon e ESBox ) per Eclipse che vengono utilizzati per sviluppare applicazione per Maemo. Nei cinque minuti messi a disposizione, riesco per fortuna a dire quelle poche cose che mi ero \"preparato\". Onestamente non avevo preparato però alcuna slide, e questo non mi è stato di grande aiuto. Ho pensato subito che se avessi avuto con me anche 5 o 6 slide che sintetizzavano quello che avrei dovuto dire, sarebbe stato tutto molto piu' facile. Oltretutto il talk doveva essere in inglese. Finalmente arriva l'ora di pranzo. Veniamo tutti dirottati in una sala al piano terra dove gli organizzatori hanno fatto arrivare vassoi di crostini, panini e schiacciatine di ogni tipo! Una volta mangiato qualcosa, ci trasferiamo tutti in un'altra zona del C-base, ovvero quella somigliante ad una stazione spaziale. Il C-base infatti, secondo una leggenda metropolitana, sarebbe costruito soprai resti di un'antica stazione spaziale. Entrando nel cuore del C-base in effetti sembra di entrare proprio all'interno di una stazione spaziale . Le poltrone sono fatte come le sedie di uno shuttle, al muro ci sono incastonati pezzi di schede madre, processori ed altri componenti hardware. La \"stazione\" ospita anche un bar dove viene venduta dell'ottima birra freschissima a soli 2€ a bottiglia! Il pomeriggio del summit prosegue con ben tre sessioni parallele di talk e a fine serata viene organizzata una festa all'interno del C-base. Questa volta la birra viene offerta gratuitamente! Ci sistemiamo tutti intorno ai tavoli, ognuno con il proprio tablet a parlare fra noi, chattare, leggere email e qualcuno a bloggare in tempo reale quello che succede intorno. Durante la serata ho avuto modo di conoscere meglio Alberto Garcia , uno sviluppatore spagnolo con il quale collaboro per il progetto Vagalume (un player Last.fm di cui curo la traduzione in italiano). Ho molto apprezzato inoltre che Quim Gil (marketing manager di Nokia per il progetto Maemo) sia venuto da ognuno di noi a chiederci le nostre impressioni, le nostre idee e tutto quello che potevamo dirgli sulla prima giornata del summit. Dopo essere stati alla festa fino a circa mezzanotte, faccio rientro in albergo, visto che la mattina dopo ci sarebbe stata un'altra giornata intensa di conferenze e talk tecnici.","tags":"Maemo (IT)","url":"https://www.andreagrandi.it/2008/09/21/maemo-summit-berlino-giorno-2/","loc":"https://www.andreagrandi.it/2008/09/21/maemo-summit-berlino-giorno-2/"},{"title":"Maemo Summit (Berlino) - giorno 1","text":"Come da programma, sono arrivato a Berlino alle 16:30 circa e dopo aver raggiunto l'Hotel dove alloggio, ho cercato per prima cosa una connessione wireless da poter utilizzare in camera. L'Hotel dove mi trovo mette a disposizione una wireless a pagamento, alla \"modica\" cifra di 9 euro al giorno! Controllando bene ho visto che era disponibile anche un access point della T-Mobile (sempre a pagamento) che offriva una connessione senza limiti per 30 giorni a 29€ . Pur dovendo rimanere soltanto 5 giorni ho optato per questa soluzione. Una piccola nota per chi si trovasse a volerla utilizzare: la velocità di upload è quella di una normale ADSL, ed il tempo di ping è attorno agli 80ms, la velocità di download però è bassissima , con solo 300 kbps , sufficienti appena per utilizzare Skype e navigare. Una volta connesso mi sono messo in contatto con i miei colleghi del summit, in particolare con i due italiani che alloggiano nel mio stesso hotel. Dopo essermi ambientato, mi sono subito aggiornato sulle novità che riguardano Maemo, che erano state annunciate in questi giorni all' Osim : un nuovo device che verrà fornito con un processore piu' potente di quello attuale, ovvero un OMAP3 supporto HSPA di serie una videocamera di qualità migliore piu' spazio di archiviazione sul dispositivo rilascio di Maemo 5 Quello che ancora non è stato detto è se Maemo 5 sara' compatibile con gli attuali dispositivi N800/N810: Maemo 5 avra' il supporto per OpenGL che attualmente i dispositivi non hanno. Si pensa quindi che possa essere rilasciata una particolare versione del sistema, senza effetti grafici OpenGL, proprio per mantenere la compatibilità con questi dispositivi. In caso contrario gli utenti saranno costretti ad acquistare un nuovo dispositivo per poter godere delle nuove feature di Maemo 5. All'ora di cena ho avuto modo finalmente di conoscere Daniele Maio , uno degli italiani presenti al summit. Devo dire che Berlino (e sopratutto la zona di Alexander Platz) ci ha abbastanza disorientati! Non è stato così facile come credevamo trovare un posto tipico dove poter cenare. Per la strada si incontravano diversi McDonald, Burger King, Doner Kebab ecc... ma pochissimi pub tipici. Finalmente la nostra fatica è stata ampiamente ripagata e ci siamo sistemati in una birreria dove abbiamo ordinato, oltre a due birre grandi, un ottimo stinco di maiale con crauti, patate, cetriolo e senape. Finita la cena siamo subito rientrati, visto che la mattina dopo alle ore 9:00 si sarebbero aperte le porte del C-base per le conferenze in programma.","tags":"Linux, Maemo (IT)","url":"https://www.andreagrandi.it/2008/09/20/maemo-summit-berlino-giorno-1/","loc":"https://www.andreagrandi.it/2008/09/20/maemo-summit-berlino-giorno-1/"},{"title":"Maemo Summit sto arrivando!","text":"Grazie a Nokia , avrò l'occasione fra pochi giorni di partecipare al Maemo Summit che si terrà a Berlino . Si svolgerà nei giorni di venerdi 19 e sabato 20 settembre e sarà ospitato nella splendida sede del C-base . Il Maemo Summit è un meeting degli sviluppatori e appassionati di Maemo, la piattaforma utilizzata sugli internet tablet della Nokia. Sarà un'occasione per conoscere di persona tantissima gente con la quale fino ad ora ho avuto a che fare soltanto tramite la mailing list o il canale IRC. Nei prossimi giorni sperò di riuscire a postare, quasi in tempo reale e connessione internet permettendo, un report dettagliato di quello che verrà fatto all'interno del C-base. Non mancheranno ovviamente le fotografie, che avrò cura di pubblicare su Flickr!","tags":"Maemo (IT)","url":"https://www.andreagrandi.it/2008/09/17/maemo-summit-sto-arrivando/","loc":"https://www.andreagrandi.it/2008/09/17/maemo-summit-sto-arrivando/"},{"title":"Vorreste che il vostro LUG fosse integrato nell'Help di Ubuntu?","text":"Per coloro che utilizzano Linux , spiegare cosa si un LUG mi pare una cosa quasi superflua, in ogni caso vi rimando all'apposita pagina di Wikipedia . Come saprete, in Italia ci sono piu' di 100 LUG che si occupano di diffondere l'utilizzo di Linux e del software opensource e di offrire supporto ai neofiti . Molti neo-utenti Linux però (chi trova Linux allegato ad una rivista in edicola, chi prende il cd da un amico ecc...) non sanno che cosa sia un LUG e a cosa possa servire. Da questo \"problema\" è nata l'idea: perchè non sfruttare una delle distribuzioni piu' note al momento (e di sicuro la piu' utilizzata dai principianti) per diffondere maggiormente i LUG? In pratica l'utente dovrebbe, una volta impostata durante l'installazione la città dove vive, poter accedere tramite il menu Help ad un \"Supporto live\" che a sua volta dovrebbe aprire una finestrina con una mappa che gli mostrerebbe i LUG piu' vicini alla città in cui vive. Che ne pensate? Se credete che l'idea possa essere interessante, non dovete far altro che votarla tramite questa pagina: http://brainstorm.ubuntu.com/idea/12932/ Le idee piu' votate verranno prese in considerazione dal team di sviluppo di Ubuntu e probabilmente implementate ed inserite nella prossima versione.","tags":"Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/09/08/vorreste-che-il-vostro-lug-fosse-integrato-nellhelp-di-ubuntu/","loc":"https://www.andreagrandi.it/2008/09/08/vorreste-che-il-vostro-lug-fosse-integrato-nellhelp-di-ubuntu/"},{"title":"Mozilla Fennec on Nokia N800/810","text":"Fennec is a particular version of Mozilla, designed for handled devices and internet tablets. With the latest development version, stability has been improved, but the application is still a bit slow and \"memory hungry\". Speed an memory improvements are scheduled for the next release (Alpha1 - September 9, 2008). Latest available version, Fennec M7 , has the following improvements: Initial Add-on Manager support has landed. Tap \"+\" button in the sidebar to display the Add-on Manager. Use it to install, view and remove add-ons. Use the application menu button to dismiss the panel. Clicking on an add-on XPI in a webpage will also display the manager. The current UX design is not final. The top URL bar has been changed to work as designed: The bar will scroll into view at the top of the web content or will float over content otherwise. Support for kinetic scrolling has been added to the web content. Support for non-modal Password Manager UI was added. Some tabbed browsing fixes. Some zooming fixes. Some stability fixes. To install it on your tablet, you've to configure Application Manager with the following parameters: Web Address: ftp://ftp.mozilla.org/pub/mobile/ Distribution: chinook (Note: The chinook builds work on diablo as well.) Components: release If you're not sure or if you want further instructions about installing Fennec, you can find a step by step guide on Mozilla website. Note: M7 supports the Maemo chinook & diablo distributions.","tags":"Linux, Maemo (EN)","url":"https://www.andreagrandi.it/2008/08/31/mozilla-fennec-on-nokia-n800810/","loc":"https://www.andreagrandi.it/2008/08/31/mozilla-fennec-on-nokia-n800810/"},{"title":"Full Circle Magazine #16 disponibile per il download","text":"E' uscito il numero 16 di Full Circle Magazine , la rivista gratuita dedicata ad Ubuntu Linux . In questo numero troverete: Command and Conquer - Creating And Moving Files. How-To: Create Your Own Ubuntu, Create Your Own Server Part 8, Using GIMP Part 5 and GNOME-Look Guide. My Story - Out With The New, In With The Old My Opinion - GNOME And KDE Themes MOTU Interview - Jamie Strandboge Top 5 - Twitter Clients Potete scaricare la rivista (per adesso in inglese ma nelle prossime settimane sarà disponibile anche la traduzione in italiano) da questo indirizzo: http://fullcirclemagazine.org/issue-16/","tags":"Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/08/30/full-circle-magazine-16-disponibile-per-il-download/","loc":"https://www.andreagrandi.it/2008/08/30/full-circle-magazine-16-disponibile-per-il-download/"},{"title":"Installare il plugin Flash 9.0r48 sui Nokia Internet Tablet (OS2008)","text":"I Nokia Internet Tablet (N800/N810) che hanno l'ultimissimo firmware OS2008 (diablo release), non comprendono purtroppo un plugin Flash molto aggiornato. La versione 9.0r31 fornita con l'OS2008 risulta purtroppo un po' obsoleta per alcuni siti web (come ad esempio Facebook). Grazie alla community di MaemoApps.org è stata creata una patch che permette di installare la versione 9.0r48 in modo molto semplice. E' sufficiente installare il seguente pacchetto sul proprio tablet: http://timeless.justdave.net/maemo/flash-player-r48-0.1.deb Fonte: http://www.internettablettalk.com/forums/showthread.php?t=22862","tags":"HowTo, Linux, Maemo (IT)","url":"https://www.andreagrandi.it/2008/08/18/installare-il-plugin-flash-90r48-sui-nokia-internet-tablet-os2008/","loc":"https://www.andreagrandi.it/2008/08/18/installare-il-plugin-flash-90r48-sui-nokia-internet-tablet-os2008/"},{"title":"Os 2008 4.2008.30 available OTA","text":"A new update for Nokia Os 2008 is available for Nokia N810 (and I suppose N800 too). All you have to do is connect to Internet, refresh package list and install the updates. The main application that have been updated are Mail client and web browser . Map application has been updated too. The total size to download is about 19 Mb and for the first time, no re-flash is required to update N810 firmware. At the end of the installation you're only required to restart the device. N.B: be sure to have at least 19Mb free on the device, else the upgrade will fail.","tags":"Maemo (EN)","url":"https://www.andreagrandi.it/2008/08/13/os-2008-4200830-available-ota/","loc":"https://www.andreagrandi.it/2008/08/13/os-2008-4200830-available-ota/"},{"title":"Crepes HowTo: come preparare le crepes alla Nutella!","text":"Chi l'ha detto che all'interno di un LUG vengono realizzati soltanto guide e howto tecnici? Anche i pinguini dovranno pur mangiare, non trovate? Grazie alla nostra pinguina Laura, il PtLUG è lieto di presentarvi il \" Crepes HowTo \", una video-guida che spiega come preparare le crepes alla Nutella ! Gustatevi il video... e le crepes!","tags":"HowTo","url":"https://www.andreagrandi.it/2008/08/09/crepes-howto-come-preparare-le-crepes-alla-nutella/","loc":"https://www.andreagrandi.it/2008/08/09/crepes-howto-come-preparare-le-crepes-alla-nutella/"},{"title":"Quali sono i comandi bash che usate di piu'?","text":"Prendendo spunto da alcuni post apparsi sulla versione inglese di Planet Ubuntu, ho deciso di provare questo comando: history | awk '{a[$2]++ } END{for(i in a){print a[i] \" \" i}}' | sort -rn | head che dovrebbe stampare la lista dei comandi piu' digitati nella bash della vostra macchina Linux. Il risultato è stato il seguente: history | awk '{a[$2]++ } END{for(i in a){print a[i] \" \" i}}' | sort -rn | head 4884 git 1023 eval 382 isort 381 docker-compose 379 nox 318 cd 305 ls 228 docker 224 pip 151 workon interessante, non trovate?!","tags":"Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/08/05/quali-sono-i-comandi-bash-che-usate-di-piu/","loc":"https://www.andreagrandi.it/2008/08/05/quali-sono-i-comandi-bash-che-usate-di-piu/"},{"title":"Viaggiate negli USA? Possono sequestrarvi il PC, senza motivo","text":"Secondo una denuncia fatta dal Washington Post e ripresa poi anche da un quotidiano italiano , la situazione privacy per chi viaggia negli Stati Uniti sta diventando sempre piu' critica. Un documento inviato a tutti i principali agenti di controllo (aeroporti, porti, frontiere ecc...) contenente una policy di comportamento per quanto riguarda i controlli da fare a chi entra negli Stati Uniti, spiega che qualsiasi tipo di apparecchio elettronico puo' essere sequestrato ed esaminato senza che esista alcun sospetto particolare o ci sia una ragione precisa per farlo. La policy prevede che possano essere sequestrati PC, notebook, cellulari, iPod, dischi USB e tutti quei dispositivi in grado di memorizzare informazioni, indistintamente a tutti i cittadini che entrano negli USA, senza che vi sia una ragione particolare. I dati acquisiti possono essere esaminati sul posto oppure trattenuti per essere verificati in altra sede. La policy purtroppo non dice nulla riguardo a cosa si debba fare dei dati sensibili delle persone (dati sanitari, finanziari ecc...). Vale davvero la pena andare a spendere i propri soldi in un paese che, con la scusa della sicurezza e della lotta al terrorismo, ficca il naso negli affari di tutti, facendo vivere le persone in un continuo stato di allerta e di terrore, piu' di quanto non facciano i veri terroristi? Capisco che in questo modo ci sia anche la possibilità di beccare veramente qualche malintenzionato, ed in questo caso non ci sarebbe niente di male, ma a che costo viene fatto tutto questo?","tags":"Censura, Sicurezza","url":"https://www.andreagrandi.it/2008/08/01/viaggiate-negli-usa-possono-sequestrarvi-il-pc-senza-motivo/","loc":"https://www.andreagrandi.it/2008/08/01/viaggiate-negli-usa-possono-sequestrarvi-il-pc-senza-motivo/"},{"title":"Utilizzare le annotazioni standard in Java","text":"Premetto di non aver certo scoperto l'acqua calda, visto che si tratta di una feature di Java 5 . Pochi giorni fa mi sono imbattuto in una funzionalità di Java che non avevo mai avuto modo di utilizzare. Si tratta della annotazioni standard. Grazie alla segnalazione di un amico ed al post che mi ha passato, ho potuto fare chiarezza su questo argomento. Si tratta di tre annotazioni che possiamo utilizzare nel codice Java: @Deprecated , @Override , @SuppressWarnings . @Deprecated: come il nome ci suggerisce, se utilizzato prima della definizione di un metodo o di una classe, fara' stampare un messaggio di avviso al compilatore Java che ci avviserà che il metodo è appunto obsoleto. Un esempio del suo utilizzo: // class @Deprecated public class SomeClass { // field @Deprecated public int field ; // constructor @Deprecated public SomeClass () { } // method @Deprecated public void method () { } } @Override: si utilizza per avvisare esplicitamente il compilatore che stiamo ridefinendo un metodo. Nel caso commettessimo un errore di digitazione nel scrivere il nome del metodo, il compilatore ci avviserebbe che nella classe padre non esiste un nome con quel metodo che abbiamo specificato. Un esempio del suo utilizzo: public class MyClass { // Won't compile - there is no toStirng method on java.lang.Object. @Override public String toStirng () { return \"MyClass toString implementation\" ; } } @SuppressWarnings: quest'ultima notazione invece, viene utilizzata per fare in modo che il compilatore \"chiuda un occhio\" su eventuali warnings rilevati nel codice.","tags":"Java, Programmazione","url":"https://www.andreagrandi.it/2008/07/10/utilizzare-la-annotazioni-standard-in-java/","loc":"https://www.andreagrandi.it/2008/07/10/utilizzare-la-annotazioni-standard-in-java/"},{"title":"Android su Nokia N810","text":"Il tanto atteso sistema operativo basato su Linux e Java, che Google sta sviluppando in questi mesi, è stato portato sul dispositivo Nokia N810 . Grazie al lavoro di alcune persone è stato creato un installer che permette in pochi semplici passi di installare Android sul proprio tablet, senza ovviamente rendere il tablet inutilizzabile, ma permettendo una sorta di multi boot. L'installazione, come già anticipato, è davvero molto semplice: bisogna solo assicurarsi di avere almeno 135 Mb di spazio libero sulla memory card. Prima di procedere con l'installazione, dopo aver fatto un BACKUP COMPLETO dei dati presenti sul proprio tablet, dobbiamo scaricare sul nostro PC i seguenti file: Immagine compressa di Android (md5sum: 84c2ceb6164f8f5bf60ddbc1dbe8a62b) Installer di Android (md5sum: 23315b6a70ee249bc9d0dc398e5276e7) Kernel originale per N810 (diablo release) (md5sum: 9c30818ab139097ca60bef58671c41bf) A questo punto, tutto quello che dobbiamo fare per installare Android è copiare il file android.img.bz2 sulla memory card e poi installare il pacchetto android-installer.deb che provvedera' automaticamente all'installazione. Una volta completata l'installazione, noteremo che una voce è stata aggiunta al menu Extra del nostro tablet. Non avviate subito Android: è necessario effettuare un reboot del dispositivo prima di poter utilizzare Android. Quando avrete riavviato il tablet, vi coniglio di connettervi alla vostra rete wifi (Android non permette di configurare la connessione wireless) ed in seguito di lanciare Android. Quando si clicca sull'icona di Android il dispositivo sembra non rispondere piu' ai nostri comandi. E' necessario attendere almeno 1 minuto prima di veder comparire il boot animato ed infine la schermata di benvenuto. Di seguito alcune immagini del risultato finale:","tags":"Google, Linux, Maemo (IT)","url":"https://www.andreagrandi.it/2008/07/02/android-su-nokia-n810/","loc":"https://www.andreagrandi.it/2008/07/02/android-su-nokia-n810/"},{"title":"A-GPS per Nokia N810","text":"Insieme alla nuova versione del firmware per Nokia N800/N810, Nokia ha rilasciato anche una utility che promette di migliorare notevolmente i tempi di fix per il GPS del N810. Si tratta di agps-ui ed è disponibile sia nei repository \"Maemo Extra\", sia nel sito Nokia Beta Labs . A-GPS sta per Assisted GPS e si tratta di una tecnica che \"aiuta\" il ricevitore GPS a sintonizzarsi con i satelliti in un tempo assai minore da quello richiesto normalmente. In sintesi, sia triangolando la posizione grazie all'ausilio delle celle GSM, sia facendo indicare all'utente la posizione approssimativa di dove ci si trovi, il ricevitore GPS cerca di connettersi a quei satelliti che sa che sono visibili nella zona indicata, riducendo notevolmente il tempo richiesto per fare il fix della posizione.","tags":"Linux, Maemo (IT)","url":"https://www.andreagrandi.it/2008/06/27/a-gps-per-nokia-n810/","loc":"https://www.andreagrandi.it/2008/06/27/a-gps-per-nokia-n810/"},{"title":"Aggiornamento del sito a WordPress 2.5.1","text":"Il sito web è stato aggiornato alla versione 2.5.1 di WordPress . Dovrei aver seguito correttamente le istruzioni su questa pagina , però ho avuto pochissimo tempo per testare se tutto funziona correttamete come prima.","tags":"WordPress","url":"https://www.andreagrandi.it/2008/06/23/aggiornamento-del-sito-a-wordpress-251/","loc":"https://www.andreagrandi.it/2008/06/23/aggiornamento-del-sito-a-wordpress-251/"},{"title":"Creative Live Cam Notebook su Ubuntu Linux","text":"Finalmente sono riuscito a trovare una webcam che funzioni (dopo qualche ricerca su Google) abbastanza bene su Linux. Dopo aver provato una Logitech Quickcam for Notebook mi ero quasi perso d'animo, poi ho deciso di fare un ultimo tentativo con la Creative Live! Cam Notebook . Prima di proseguire nella lettura di questa guida, vi consiglio di verificare che il modello di \"Creative Live Cam\" che state cercando di installare, sia lo stesso che ho testato io. Potete verificarlo scrivendo in un terminale il comando lsusb : lsusb Bus 003 Device 001 : ID 0000 :0000 Bus 002 Device 001 : ID 0000 :0000 Bus 001 Device 018 : ID 041e:4068 Creative Technology, Ltd Bus 001 Device 001 : ID 0000 :0000 ` Ovvero dovrete verificare che l'identificativo del vostro modello sia esattamente 041e:4068 Devo dire che al primo tentativo (ovvero inserendo il cavo USB nel mio notebook e sperando che funzionasse) non ci sono riuscito, quindi mi sono deciso a fare una piccola ricerca su Google. Ho notato che molte persone hanno tentato (senza alcun successo) di far funzionare questa webcam con i driver spca5xx che solitamente supportano un gran numero di webcam. Proseguendo nella mia ricerca ho trovato i driver ov51x-JPEG che invece supportano il mio modello di webcam. L'installazione non è difficile, dobbiamo però assicurarci di aver installato sulla nostra macchina tutto il necessario per poter ricompilare il modulo, quindi dovrete eseguire (da utente root oppure utilizzando sudo) questo comando: apt-get install build-essential linux-headers- $( uname -r ) A questo punto dovrete scaricare i sorgenti del driver, da questo indirizzo: http://www.rastageeks.org/downloads/ov51x-jpeg/ov51x-jpeg-1.5.7.tar.gz wget http://www.rastageeks.org/downloads/ov51x-jpeg/ov51x-jpeg-1.5.7.tar.gz Dobbiamo poi scompattarli con il seguente comando: tar xfvz ov51x-jpeg-1.5.7.tar.gz Infine dobbiamo compilare il modulo ed installarlo: cd ov51x-jpeg-1.5.7 make make install Se la compilazione e l'installazione del modulo sono andati a buon fine, possiamo finalmente caricare il modulo: modprobe ov51x-jpeg Prima di poter utilizzare la webcam con Skype, c'è ancora una piccola cosa da aggiustare, per evitare problemi di incompatibilità. Dobbiamo modificare il file /etc/modprobe.d/options ed aggiungere la seguente riga: options ov51x-jpeg forceblock = 1 ovviamente prima di caricare il modulo. A questo punto l'installazione dovrebbe essere completa. Se ci fossero problemi o difficoltà potete scrivere lasciando un commento a questo post, in modo che anche altri possano poi leggere la domanda/risposta.","tags":"Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/06/05/creative-live-cam-notebook-su-ubuntu-linux/","loc":"https://www.andreagrandi.it/2008/06/05/creative-live-cam-notebook-su-ubuntu-linux/"},{"title":"Agile Web Development with Rails: imparare Rails 2.x","text":"Chi volesse cimentarsi nell'apprendimento del framework per lo sviluppo web Rails , troverà al momento, a parte qualche tutorial qua e la, solo manuali che trattano la versione 1.2 di Rails. Da fine dicembre 2007 è uscita la versione 2.0 e da pochi giorni la 2.1. Le modifiche al framework e le differenze nella stesura del codice sono così numerose da aver interrotto la compatibilità con la versione precedente. Per esperienza personale, avevo installato la versione 2.0.2 di Rails, seguendo un manuale che purtroppo era basato sulla 1.2. Ad ogni capitolo qualcosa non funzionava (rispetto a quanto spiegato nel libro) ed ero costretto a ricorrere a Google oppure ai forum dedicati per chiedere spiegazioni. A quel punto mi sono chiesto: ma non esiste un libro che sia basato su Rails 2.x ?! Per fortuna, dopo una breve ricerca ho scoperto l'esistenza di questo fantastico manuale: Agile Web Development with Rails, Third Edition . Il libro non è ancora stato rilasciato in versione definitiva, tanto che uscira' d ottobre 2008. Come fare ad averlo in anteprima? Gli autori mettono a disposizione (a prezzo piuttosto ridotto) la versione beta in formato PDF e permettono di pre-ordinarela versione cartacea. Una volta acquistata la versione in PDF (al prezzo di circa 15€ , grazie al cambio favorevole euro/dollaro) si ha diritto a tutti gli aggiornamenti che vengono rilasciati (ogni 2 o 3 settimane circa) ed alla versione definitiva del PDF quando verrà rilasciato il libro ad Ottobre. Per quello che posso dirvi, soprattutto avendo iniziato a leggere un manuale analogo che trattava la versione 1.2, si tratta di un ottimo prodotto che, anche se in versione beta, è praticamente pronto per essere studiato con estremo profitto. Quasi tutti i capitoli sono stati già rivisti e quindi ripensati per la sintassi e le funzionalità di Rails 2.x, in particolare quelli che trattano ActiveRecord .","tags":"Programmazione, Ruby, Ruby on Rails","url":"https://www.andreagrandi.it/2008/06/05/agile-web-development-with-rails-imparare-rails-2x/","loc":"https://www.andreagrandi.it/2008/06/05/agile-web-development-with-rails-imparare-rails-2x/"},{"title":"Applicazioni Ruby On Rails che non utilizzano database","text":"Se a qualcuno fosse capitato di recente di creare una semplice applicazione \" Hello World \" utilizzando il framework Ruby on Rails , avrà notato che in fase di esecuzione si ottiene un errore di questo tipo: Can 't connect to local MySQL server through socket ' /var/run/mysqld/mysqld.sock ' ( 2 ) Perchè un errore relativo a MySQL in un'applicazione che stampa semplicemente una stringa di testo? Nelle nuove versioni di RoR vengono caricati per default i moduli ActiveRecord , ActiveResource e ActionMailer . ActiveRecord in particolare si aspetta di trovare (per le impostazioni di default) un database MySQL funzionante. Per evitare questo errore è sufficiente decommentare una riga all'interno di environment.rb che si trova in $PATH_APPLICAZIONE/config/environment.rb : # Skip frameworks you're not going to use (only works if using vendor/rails). # To use Rails without a database, you must remove the Active Record framework config . frameworks -= [ :active_record , :active_resource , :action_mailer ] Fonte: http://www.swards.net/2008/02/ruby-on-rails-application-with-no.html","tags":"Linux, Programmazione, Ruby, Ruby on Rails","url":"https://www.andreagrandi.it/2008/05/26/applicazioni-ruby-on-rails-che-non-utilizzano-database/","loc":"https://www.andreagrandi.it/2008/05/26/applicazioni-ruby-on-rails-che-non-utilizzano-database/"},{"title":"Microsoft Office 2007 SP2 con supporto OpenOffice (ODF) e PDF","text":"Finalmente una bella notizia. Microsoft ha confermato alla redazione di BetaNews che Microsoft Office 2007 Service Pack 2 includerà il supporto per il formato ODF di OpenOffice e per il PDF di Adobe . Grazie a questa funzionalità sarà possibile non solo aprire documenti in formato ODF o PDF, ma sarà anche possibile salvarli in tali formati e scegliere una delle due estensioni come formato predefinito per il salvataggio dei propri documenti. Nei piani di Microsoft c'è anche il rilascio di una serie di API che permetteranno ai programmatori di scrivere add-in per Microsoft Office in modo da aggiungere il supporto per ulteriori formati. Questo è sicuramente un bel passo avanti sia per quanto riguarda l' interoperatibilità di sistemi diversi (Windows, Linux, OsX) sia per quanto riguarda la diffusione del formato ODF di OpenOffice . Gli utilizzatori di OpenOffice non dovranno piu' preoccuparsi di salvare il proprio documento in formato .doc prima di inviarlo all'amico o all'azienda che magari non usa ancora OpenOffice. Il documento verrà aperto e visualizzato in modo nativo, senza la necessità di installare ulteriori plugin. La versione SP2 di Office verrà rilasciata verso la metà del 2009 , ci auguriamo quindi che la promessa venga mantenuta e che le due suite possano finalmente scambiarsi i documenti in maniera ottimale.","tags":"Linux, OpenOffice, Windows","url":"https://www.andreagrandi.it/2008/05/21/microsoft-office-2007-sp2-con-supporto-openoffice-odf-e-pdf/","loc":"https://www.andreagrandi.it/2008/05/21/microsoft-office-2007-sp2-con-supporto-openoffice-odf-e-pdf/"},{"title":"MSN e la censura delle conversazioni","text":"Lo sapevate che i server di MSN censurano le vostre conversazioni , filtrando i messaggi che, secondo loro, sono ritenuti \"potenzialmente pericolosi\"? Non si tratta certo di una novità, purtroppo però molte persone ancora non sono a conoscenza di questo fatto e penso sia opportuno fare quanta piu' informazione possibile per mettere gli utenti MSN al corrente del comportamento di questo sistema di instant messaging. Come funziona la comunicazione fra utenti MSN? Quando ci si connette a MSN e si vuole inviare un messaggio ad un nostro amico nella lista dei contatti, il messaggio viene prima inviato ai server di MSN e poi viene successivamente inviato al nostro amico da parte del server. Questo meccanismo fa si che la conversazione non sia diretta, ma passi attraverso qualcosa che è in grado di fare qualsiasi cosa: registrarla , analizzarla e persino bloccarla . E' quello che è accaduto in questi giorni con i link ai video di Youtube e quello che sta accadendo da sempre a moltissimi link ritenuti pericolosi da \"mamma Microsoft\". Provate ad esempio ad inviare tramite MSN un link contenente la stringa \"download.php\" come ad esempio il link per scaricare OpenOffice (sarà un caso?!): http://www.plio.it/download.php?q=d&product=OpenOffice.org&os=winwjre&lang=it&version=2.4.0 Il comportamento sarà lo stesso per tutti, qualsiasi client si usi (anche se utilizziamo un client MSN-compatibile, tipo Pidgin, su un altro sistema operativo), visto che il filtro avviene a livello di server: il messaggio non verrà recapitato alla persona alla quale abbiamo tentato di inviarlo. Come possiamo sapere quali saranno le parole che verranno censurate dai server di MSN? Non c'è modo. La lista delle parole censurate è ovviamente segreta. Cosa succederà un giorno se a Microsoft (magari con l'appoggio o la spinta di qualche governo) verrà in mente di iniziare a filtrare altri contenuti ritenuti \"pericolosi\"? Questa situazione purtroppo ricorda molto da vicino \" la grande muraglia \", ovvero il firewall con il quale tutti i navigatori residenti in Cina sono costretti a fare i conti durante la navigazione. La soluzione ovviamente esiste: non utilizzare MSN come sistema di instant messaging, ma usare invece una piattaforma completamente aperta e non centralizzata, come ad esempio Jabber dove la comunicazione avviene tra piu' server, e dove chiunque puo' mettere su un proprio server. Spero che questo post abbia aperto un po' gli occhi a coloro che fino ad ora erano un po' scettici su questo tipo di cose.","tags":"Censura, Sicurezza","url":"https://www.andreagrandi.it/2008/05/13/msn-e-la-censura-delle-conversazioni/","loc":"https://www.andreagrandi.it/2008/05/13/msn-e-la-censura-delle-conversazioni/"},{"title":"Skype SMS su Linux: grazie a Skype4Py si puo'!","text":"Il client di Skype per Linux non supporta al momento l' invio degli SMS . Questa puo' essere per molti una grossa limitazione, visto che è molto conveniente come metodo per inviare gli sms (costano 10 centesimi) rispetto a molte tariffe in circolazione al momento, con i principali gestori italiani.La mancanza di questa funzionalità è però soltanto apparente! Infatti è stata già implementata a livello di librerie di Skype ed è già disponibile tramite le API. Grazie alla libreria Skype4Py , ufficialmente supportata da Skype e sviluppata da Arkadiusz Wahlig (che ha tenuto un talk proprio su questo argomento nella giornata di ieri del PyCon Due), è possibile scrivere applicazioni multipiattaforma (Windows, Linux, Mac) che interagiscano con Skype. Una volta installata la libreria nel proprio sistema, dobbiamo soltanto avviare il client Skype. Le applicazioni che possiamo scrivere, per automatizzare alcune funzioni di Skype, sono moltissime. In questo caso particolare farò vedere un piccolo script Python che invia un SMS utilizzando il client (ed il credito) dell'istanza di Skype che sta girando sulla vostra macchina: import Skype4Py number = '+393*******' text = 'Messaggio di prova da PySms4Skype!' skype = Skype4Py . Skype () skype . FriendlyName = 'PySms4Skype' skype . Attach () sms = skype . CreateSms ( Skype4Py . smsMessageTypeOutgoing , number ) sms . Body = text sms . Send () Quando eseguite questo script, Skype vi chiedera' la conferma per autorizzare la vostra applicazione ad utilizzare le API, basterà quindi dare conferma per continuare. Nello script ovviamente dovrete sostituire il numero di telefono con uno valido.","tags":"Linux, Programmazione, Python, Skype","url":"https://www.andreagrandi.it/2008/05/11/skype-sms-su-linux-grazie-a-skype4py-si-puo/","loc":"https://www.andreagrandi.it/2008/05/11/skype-sms-su-linux-grazie-a-skype4py-si-puo/"},{"title":"Slides del talk su PyMaemo al PyCon Due","text":"Per chi avesse seguito il mio talk su PyMaemo al PyCon Due a Firenze, metto a disposizione le slide che ho utilizzato. Potete liberamente scaricarle, modificarle e distribuirle. Slides ospitate sul sito di Slideshare : http://www.slideshare.net/andy80/conferenza-pymaemo Conferenza Pymaemo from Andrea Grandi Inoltre vi riporto un piccolo abstract del talk: Il talk prevede una breve introduzione alla piattaforma Maemo ed ai Nokia Internet Tablet, sia dal punto di vista dell'utente comune, sia da quello dello sviluppatore. Verrà poi spiegato come configurare ed installare l'ambiente Scratchbox, il principale ambiente utilizzato per sviluppare applicazioni per Maemo. Infine verranno presentati due plugin per Eclipse: ESbox e PluThon. Il primo si interfaccia con Eclipse e Scratchbox, permettendo di sviluppare sia applicazione C/C++ che Python e di testarle all'interno dell'ambiente Scratchbox. Il secondo è un plugin specifico per Python e permette di eseguire e debuggare le applicazioni direttamente sul dispositivo.","tags":"Linux, Maemo (IT), Programmazione, Python","url":"https://www.andreagrandi.it/2008/05/10/slides-del-talk-su-pymaemo-al-pycon-due/","loc":"https://www.andreagrandi.it/2008/05/10/slides-del-talk-su-pymaemo-al-pycon-due/"},{"title":"Inizia il PyCon: Richard Stallman oggi a Palazzo Vecchio (Firenze) ore 16:00","text":"Come da programma, oggi a Palazzo Vecchio (Firenze) ci sarà il talk di apertura del PyCon Italia 2008 , tenuto dal leader e fondatore della Free Software Foundation , Richard Stallman . Richard Stallman parlerà degli obiettivi e della filosofica del Movimento per il Software Libero, e della storia e stato attuale del sistema operativo GNU che, in combinazione con il kernel Linux , è usato oggi da decine di milioni di utenti in tutto il mondo. L'evento di oggi è completamente gratuito e aperto a tutti (fino ad esaurimento dei posti disponibili). Quelli che si sono registrati per il PyCon avranno ovviamente la precedenza. Per ulteriori informazioni sull'evento e sul PyCon, potete consultare il sito ufficiale dell'evento .","tags":"Linux, Programmazione, Python","url":"https://www.andreagrandi.it/2008/05/09/inizia-il-pycon-richard-stallman-oggi-a-palazzo-vecchio-firenze-ore-1600/","loc":"https://www.andreagrandi.it/2008/05/09/inizia-il-pycon-richard-stallman-oggi-a-palazzo-vecchio-firenze-ore-1600/"},{"title":"Installare le Qt 4.4.0 su Ubuntu Linux 8.04","text":"Da pochi giorni la Trolltech ha rilasciato la versione 4.4.0 delle proprie librerie multipiattaforma Qt. La versione corrente di Ubuntu (la 8.04) contiene al momento le librerie Qt nella versione 4.3.4. Gli sviluppatori che utilizzano le Qt potrebbero voler installare l'ultima release delle librerie, per testare le nuove funzionalità o per verificare il funzionamento di una propria applicazione con questa particolare versione. La buona notizia è che non c'è bisogno di scaricarsi i sorgenti delle Qt 4.4.0 e ricompilarli, perchè il team di Ubuntu ha già preparato i pacchetti per la Ubuntu Hardy. Per installarli è necessario abilitare il repository chiamato hardy-backports andando su System->Administration->Software Sources . A questo punto la versione 4.4.0 dovrebbe essere disponibile tra gli aggiornamenti di sistema. Basterà quindi un apt-get upgrade per procedere all'aggiornamento.","tags":"Linux, Programmazione, Qt, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/05/08/installare-le-qt-440-su-ubuntu-linux-804/","loc":"https://www.andreagrandi.it/2008/05/08/installare-le-qt-440-su-ubuntu-linux-804/"},{"title":"Come ascoltare Radio Deejay su Ubuntu Linux con Rhythmbox","text":"Quante volte vi è capitato di voler ascoltare dal vostro PC la vostra radio preferita e magari il plugin incorporato nel browser non funzionava correttamente? Nel caso di Radio Deejay mi è capitato molto spesso, a seconda della versione di Firefox che stavo usando o a seconda della distribuzione. E' possibile ascoltare le radio che trasmettono in streaming anche senza utilizzare il browser. Per fare questo è necessario un programma che riesce a leggere gli streaming audio/video e nel mio caso ho utilizzato Rhythmbox . Bisogna aprire il programma ed andare su Radio e cliccare su \"New Internet Radio Station\" ed inserire il seguente URL: http://live.mediaserver.kataweb.it/radiodeejay A questo punto sarà possibile ascoltare la nostra radio preferita senza bisogno di utilizzare il browser. Nota: queste istruzioni potrebbero funzionare benissimo anche nel caso di altre radio e con altre versioni di Ubuntu. Nel mio caso l'ho testato con Ubuntu Linux 8.04","tags":"Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/05/07/come-ascoltare-radio-deejay-su-ubuntu-linux-con-rhythmbox/","loc":"https://www.andreagrandi.it/2008/05/07/come-ascoltare-radio-deejay-su-ubuntu-linux-con-rhythmbox/"},{"title":"I problemi della nuova Ubuntu Hardy 8.04","text":"Il 24 aprile è uscita la tanto attesa Ubuntu Hardy 8.04 , sicuramente una tra le distribuzioni piu' utilizzate al momento dagli utenti Linux. Trattandosi di una release LTS (long time support, ovvero supportata per ben 3 anni dal rilascio) ci si aspettava che potesse trattarsi di una distribuzione assai stabile. Dopo circa una decina di giorni di utilizzo (avevo iniziato a fare l'upgrade pochi giorni prima dell'uscita ufficiale), devo purtroppo confermare le lamentele che molti stanno sollevando riguardo a questa versione. Molti fattori, tra cui l'instabilità di alcuni applicativi che sono stati distribuiti con questa versione, non ancora pronti al momento del rilascio, hanno fatto si che questa versione risulti una delle piu' instabili tra tutte quelle che sono state rilasciate fino ad ora. Qui di seguito farò una panoramica dei problemi che ho personalmente riscontrato, premettendo che si tratta ovviamente di una lista di problemi non completa e relativa in particolare ai miei due PC sul quale ho avuto modo di testarla. Firefox 3 la versione di Firefox distribuita al momento del rilascio della Ubuntu 8.04 è la versione 3.0 beta 5 . Pur trattandosi di una versione \"abbastanza stabile\", non è del tutto esente da alcuni fastidiosi bug, in particolare si riscontrano frequenti crash del browser quando si cerca di visualizzare video tramite il plugin Flash . PulseAudio il nuovo sistema di gestione audio adottato da Ubuntu, sebbene abbia sulla carta ottime funzionalità, non è ancora compatibile con la maggior parte dei programmi in circolazione. Questo fa si che, ad esempio, anche programmi opensource come il client ufficiale di Last.Fm abbiano problemi nel gestire la periferica audio, dando spesso il seguente errore \"The Alsa soundsystem is either busy or not present\". Bluetooth fino alla versione 7.10 di Ubuntu riuscivo ad inviare correttamente le foto dal mio Nokia N73 al PC. Con la 8.04 non ci riesco piu'. Il bug è già stato segnalato e riguarda anche altre persone oltre a me. Clock Applet cliccando sull'orologio per visualizzare il calendario, va in crash gnome-panel. Anche questo bug è stato già segnalato ed era stato \"fixato\" prima del rilascio della versione definitiva, ma ancora il problema non è risolto. Evolution e Google Calendar una delle funzioni tanto attese sarebbe dovuta essere la possibilità di integrare Calendar di Google nel calendario di Evolution. Purtroppo si tratta di un altro bug ancora non risolto. Nvidia ed il driver proprietario sia a me che ad altre persone, non viene installato correttamente il driver proprietario aggiornato, dopo aver aggiornato ad Ubuntu 8.04. Io ho risolto disattivando il modulo e reinstallandolo da capo. Il problema però non è ancora stato risolto. Tracker il tool di indicizzazione integrato nella Ubuntu, non indicizza correttamente il contenuto di alcuni file. Cercando ad esempio \"Benedetta\" vengono fuori anche i documenti che contengono \"Benedetto\". Anche questo bug è stato segnalato. In conclusione, non mi sento proprio di consigliare, almeno per il momento, l'aggiornamento alla Ubuntu 8.04 a meno che non si voglia contribuire attivamente alla segnalazione dei bug, in modo che il team di sviluppo di Ubuntu possa correggerli al piu' presto. Non ci resta che attendere la versione 8.04.1 che uscirà prossimamente e conterrà i principali fix dei bug che sono stati segnalati in questi giorni.","tags":"Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/04/29/i-problemi-della-nuova-ubuntu-hardy-804/","loc":"https://www.andreagrandi.it/2008/04/29/i-problemi-della-nuova-ubuntu-hardy-804/"},{"title":"Diventa un Ubuntero!","text":"Vorrei segnalarvi un sito web che forse molti di voi conosceranno già: https://launchpad.net/ è un sito messo in piedi dalla Canonical (la società che finanzia lo sviluppo di Ubuntu) e presenta alcune funzioni molto interessanti: Code è possibile pubblicare qui una propria patch ad un programma, in modo che gli sviluppatori la possano unire al codice ufficiale. Bugs un modulo per segnalare i bug della Ubuntu e degli altri progetti che sono registrati su launchpad. Blueprints il posto dove pubblicare le proprie idee, proposte di miglioramento, suggerimenti sulle future funzionalità ecc.... della Ubuntu. Se avete un'idea originale per una funziona che ancora non è presente in Ubuntu, potete scriverla qui. Translations consente di visualizzare le stringhe ed i messaggi non ancora tradotti dei programmi di Ubuntu e permette di scrivere la propria traduzione, nella lingua desiderata. La traduzione verrà poi sottoposta ad approvazione. Un ottimo modo per suddividersi il lavoro di traduzione dei vari programmi. Answers qui è possibile fare domande (come su un forum) e rispondere alle domande che ancora sono \"open\" (cioè senza risposta). Tutti i contributi che date in una di queste sezioni, vanno ad aumentare il vostro \"karma\", ovvero la notorietà, la popolarità e l'importanza all'interno della community di Ubuntu. La mia pagina ad esempio è questa: https://launchpad.net/~andy80 Se non vi sentite ancora dei programmatori esperti, ma volete comunque far qualcosa per migliorare la Ubuntu (o altri progetti registrati in quel sito), quello è il posto giusto nel quale spendere un po' del proprio tempo.","tags":"Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/04/22/diventa-un-ubuntero/","loc":"https://www.andreagrandi.it/2008/04/22/diventa-un-ubuntero/"},{"title":"Scratchbox on Ubuntu Hardy troubleshooting","text":"Yesterday I upgraded from Ubuntu 7.10 to the new 8.04 RC and I \"broke\" my Scratchbox installation. I tried to install it again and I had still some problems logging into Scratchbox and installing the SDK . The I found this page: http://suppressingfire.livejournal.com/35277.html that explain how to fix these problems. In particular if you get this kind of error trying to log into Scratchbox: Inconsistency detected by ld.so: rtld.c: 1192 : dl_main: Assertion ` ( void * ) ph->p_vaddr == _rtld_local._dl_sysinfo_dso ' failed! You can fix it in this way: echo 0 | sudo tee /proc/sys/vm/vdso_enabled You can read the complete fix in my updated wiki: http://www.ptlug.org/wiki/Howto_Installing_Maemo_SDK_4","tags":"Maemo (EN)","url":"https://www.andreagrandi.it/2008/04/21/scratchbox-on-ubuntu-hardy-troubleshooting/","loc":"https://www.andreagrandi.it/2008/04/21/scratchbox-on-ubuntu-hardy-troubleshooting/"},{"title":"Installing Maemo SDK 4 HowTo Updated","text":"I've updated my previous howto that explain how to install Maemo SDK 4 (Chinook) . The other howto was written when Maemo SDK 4 Beta was out, now it's updated to 4.0.1 version of the SDK. You can find it, as usual, on this wiki: http://www.ptlug.org/wiki/Howto_Installing_Maemo_SDK_4 If you have any suggestion or if you want to give me any idea to improve this howto, please leave me a comment.","tags":"Maemo (EN)","url":"https://www.andreagrandi.it/2008/04/17/installing-maemo-sdk-4-howto-updated/","loc":"https://www.andreagrandi.it/2008/04/17/installing-maemo-sdk-4-howto-updated/"},{"title":"Using GtkIconView in Python: a small tutorial","text":"In these days I was looking for a simple tutorial to understand how to use GtkIconView , but the only thing I was able to find was an example in PHP-Gtk. So I decided to translate it in Python language, thinking it would be useful for other people trying to use that Gtk control. You can find the code here: import gtk import gobject DEFAULT_IMAGE_WIDTH = 100 # Main Window setup window = gtk . Window ( gtk . WINDOW_TOPLEVEL ) window . set_size_request ( 400 , 240 ) window . connect ( \"destroy\" , gtk . main_quit ) window . set_title ( \"Python GtkIconView Test\" ) # Add a VBox vbox = gtk . VBox () window . add ( vbox ) # Setup Scrolled Window scrolled_win = gtk . ScrolledWindow () scrolled_win . set_policy ( gtk . POLICY_AUTOMATIC , gtk . POLICY_AUTOMATIC ) # Setup ListStore to contain images and description model = gtk . ListStore ( gtk . gdk . Pixbuf , gobject . TYPE_STRING ) # Create a tuple with image files immagini = ( \"BD786-TFR.jpg\" , \"guido_sottozero.jpg\" , \"IMG_0056.JPG\" , \"movies_card.jpg\" ) for im in immagini : try : pixbuf = gtk . gdk . pixbuf_new_from_file ( im ) pix_w = pixbuf . get_width () pix_h = pixbuf . get_height () new_h = ( pix_h * DEFAULT_IMAGE_WIDTH ) / pix_w # Calculate the scaled height before resizing image scaled_pix = pixbuf . scale_simple ( DEFAULT_IMAGE_WIDTH , new_h , gtk . gdk . INTERP_TILES ) model . append (( scaled_pix , im )) except : pass # Setup GtkIconView view = gtk . IconView ( model ) # Pass the model stored in a ListStore to the GtkIconView view . set_pixbuf_column ( 0 ) view . set_text_column ( 1 ) view . set_selection_mode ( gtk . SELECTION_MULTIPLE ) view . set_columns ( 0 ) view . set_item_width ( 150 ) # Pack objects and show them all scrolled_win . add ( view ) vbox . pack_start ( scrolled_win ) window . show_all () gtk . main () The important thing to notice is that you have to store all the images in a GtkListStore and pass it to the GtkIconView as \"model\" parameter. I hope this example is clear. If you have any question, please comment this post and I'll try to answer. This is a screenshot of this example:","tags":"Linux, Programmazione, Python","url":"https://www.andreagrandi.it/2008/04/15/using-gtkiconview-in-python-a-small-tutorial/","loc":"https://www.andreagrandi.it/2008/04/15/using-gtkiconview-in-python-a-small-tutorial/"},{"title":"PyMaemo Talk on May 10th in Florence at PyCon2 Conference","text":"PyCon2 is the second edition of the Italian Python Conference and will take place on May 9/10/11 , 2008 in Florence . The conference is organized by Python Italia and more than 300 developers, students and researchers will be present for three days of tutorials and other important events. PyCon 2008 edition will be opened by Richard Stallman with a keynote on Free Software and Free Ethics . Other famous developers will be presento too: Alex Martelli , Samuele Pedroni , Brian Fitzpatrick and many other. I'll partecipate at the conference as speaker on May 10, with a talk on PyMaemo: Python for Nokia Internet Tablets . In particular I'll talk about Maemo platform, Maemo SDK (how to install and configure it) and I'll explain how to use the two Eclipse plugins ESBox and Pluthon . If you want to give me any suggestion or idea for this talk, please leave me a comment on this post, so I'll integrate it with my slides.","tags":"Linux, Maemo (EN), Python","url":"https://www.andreagrandi.it/2008/04/09/pymaemo-talk-on-may-10th-in-florence-at-pycon2-conference/","loc":"https://www.andreagrandi.it/2008/04/09/pymaemo-talk-on-may-10th-in-florence-at-pycon2-conference/"},{"title":"PyCon2: conferenza italiana dedicata al linguaggio Python","text":"PyCon Due è la seconda conferenza italiana dedicata al linguaggio di programmazione Python . La conferenza è organizzata da un gruppo di appassionati e senza finalità di lucro; si prefigge la divulgazione di Python, e di dare visibilità agli sviluppatori professionisti, studenti, aziende e semplici interessati al linguaggio. Dove e quando La conferenza si tiene a Firenze nelle giornate di Venerdì 9 , Sabato 10 e Domenica 11 Maggio . L'evento di apertura si terrà a Palazzo Vecchio nel pomeriggio di Venerdì, durante il quale terrà un keynote Richard Stallman . Sabato e Domenica, al Viva Hotel Laurus (Via Cerretani 54/r), nei pressi del Duomo, si svolgeranno 3 track parallele di conferenze. Gli Interventi Durante la conferenza si terranno due tipi di interventi: i keynote ed i talk . I keynote sono interventi di ampio respiro che trattano temi di attualità del mondo dell'informatica; hanno una durata indicativa di 90' e verranno tenuti in occasione dell'evento di apertura di venerdì 9 ed alla chiusura delle due giornate successive. I talk sono invece interventi focalizzati su un particolare argomento; hanno una durata indicativa di 45', comprensivi del tempo per le domande del pubblico. I talk di PyCon Due si tengono durante le giornate di sabato 10 e domenica 11, e si dividono in tre track: \" Scoprire Python \", \" Diffondere Python \" e \" Imparare Python \": Scoprire Python è una track introduttiva su librerie, framework e metodologie, pensata per chi si sta avvicinando al Python o desidera una prima trattazione di un argomento; Diffondere Python è una track dedicata ad aspetti più avanzati del linguaggio, esempi di integrazione della piattaforma e casi d'uso in azienda; Imparare Python è una track interattiva: i talk sono parzialmente guidati dal pubblico, che discute la trattazione dell'argomento insieme al relatore, proponendo scenari e commentando le soluzioni proposte. Registrazione per partecipare all'evento occorre registrarsi. La registrazione puo' essere fatta direttamente sul sito ufficiale del PyCon2 . Sempre sul sito ufficiale, potrete trovare a breve l'elenco delle conferenze che verranno fatte, non appena si concluderanno le votazioni per il Call For Paper che sono in corso in questi giorni.","tags":"Linux, Programmazione, Python","url":"https://www.andreagrandi.it/2008/04/06/pycon2-conferenza-italiana-dedicata-al-linguaggio-python/","loc":"https://www.andreagrandi.it/2008/04/06/pycon2-conferenza-italiana-dedicata-al-linguaggio-python/"},{"title":"Il costo di un computer senza Windows Vista","text":"Navigando sul sito web di una nota catena di negozi di hardware/software italiana, mi sono imbattuto in un'offerta davvero interessante. Vengono proposti due PC apparentemente \"diversi\", ma dalle caratteristiche del tutto simili. Il primo PC costa 399 euro e viene venduto con la seguente configurazione hardware: Case RAY Midi Tower Black/Aluminium con alimentatore da 500W Scheda Madre ASUS M2N-MX SE AM2 nForce6100 VGA 2SATA Raid PCI-E Processore AMD Athlon64 X2 5000+ (Socket AM2) + ventola RAM 2 GB DDR2 667MHz (PC5300) Hard Disk Drive 320 GB SATA2 8MB Scheda Video NVIDIA GeForce 6100 GPU integrata nel chipset Scheda Audio integrata Unità ottica DVD±RW DualLayer black Il secondo PC invece, viene venduto a 339 euro , con le seguenti caratteristiche: Case H@L Midi Tower ATX Black con alimentatore da 500W Scheda Madre ASUS M2N-MX SE+ AM2+ nForce6100 VGA 2SATARaidPCI-E Processore AMD Athlon64 X2 5000+ (Socket AM2) + ventola RAM 2GB (1.024 MB x 2) DDR2 667MHz (PC5300) Hard Disk Drive 320GB SATA2 8MB Scheda Video nForce6100 integrata su M/B Scheda Audio integrata su M/B Unità ottica LG H54/5/8N 18X DVD±RW DualLayer black Cos'è che vale 60 euro di differenza? La risposta è molto semplice: il primo PC viene venduto con Windows Vista Home Basic preinstallato, mentre il secondo viene venduto con Kubuntu Linux . Questo per chi crede ancora (purtroppo me lo senti dire spesso \"ma.. Windows è gratis... io l'ho trovato insieme al computer!\" ) che Windows sia gratuito quando lo si trova pre-installato in un nuovo computer. Nota: non ho voluto citare il nome della catena di computer che ha questi due PC a listino, visto che nessuno mi ha pagato per scrivere questo articolo ;) Al limite posso dirvelo in privato, ma credo che anche altri venditori abbiano ormai offerte simili a questa.","tags":"Linux, Windows","url":"https://www.andreagrandi.it/2008/03/26/il-costo-di-un-computer-senza-windows-vista/","loc":"https://www.andreagrandi.it/2008/03/26/il-costo-di-un-computer-senza-windows-vista/"},{"title":"Conferenza OLPC a Firenze con Nicholas Negroponte: la recensione","text":"Venerdi 7 marzo 2008 si è svolta a Firenze, a Palazzo Vecchio, la prima presentazione ufficiale in Italia dell' OLPC , che ha visto la presenza del fondatore stesso del progetto, Nicholas Negroponte . La conferenza è durata circa 2 ore ed è iniziata con un intervento dell'Assessore alle Politiche Sociali, Lucia De Siervo , che ha manifestato l'impegno da parte del Comune di Firenze di aderire al progetto G1G1 di OLPC. G1G1 (Give one get one) prevede che con ogni acquisto di un OLPC che viene fatto in una scuola, ne venga acquistato un secondo da donare ad un'altra scuola di quelle nel terzo mondo. Il costo di ogni OLPC è attualmente di 128 euro ciascuno (al prezzo bisogna aggiungere l'IVA e le spese di spedizione), anche se la cifra potra' subire lievi variazioni a causa del cambio euro/dollaro. L'intervento di Nicholas Negroponte non è durato moltissimo purtroppo, perchè sarebbe dovuto tornare entro il pomeriggio negli Stati uniti. A sentire le sue parole, dobbiamo sentirci onorati. Siamo la prima città, non solo in Italia, ma anche nel resto del mondo, che ha aderito al progetto OLPC a livello di pubblica amministrazione. L'accordo infatti prevede che l'amministrazione comunale di Firenze acquisti qualche centinaio di OLPC da distribuire in alcune scuole. Di questo progetto si occuperà direttamente OLPC Italia . OLPC Italia è un'iniziativa che è nata per volontà dell'Assessorato allInformatica del Comune di Firenze e prevede la creazione di un centro competenza che faciliti l'accesso dei piu' piccoli, di qualunque paese, all'utilizzo di strumenti informatici e di altre tecnologie dell'informazione. Gli obbiettivi di OLPC Italia sono i seguenti: dare un sostegno all'iniziativa globale OLPC \"Give 1 Get 1\" di Nicholas Negroponte proporsi come unico tramite locale tra la realtà nazionale, i paesi in via di sviluppo ed il mondo delle tecnologie dell'informatica e della comunicazione offrire un supporto tecnico completo all'utilizzo dell'OLPC grazie al Centro di Competenza e di sviluppare utility ed altro software per il laptop stesso. La conferenza si è conclusa con una dimostrazione pratica del funzionamento degli OLPC e molti bambini di una scuola elementare che aveva partecipato all'evento, hanno potuto provare ad usare direttamente i laptop, senza il bisogno che qualche adulto dovesse spiegare loro il funzionamento.","tags":"Linux, OLPC","url":"https://www.andreagrandi.it/2008/03/08/conferenza-olpc-a-firenze-con-nicholas-negroponte-la-recensione/","loc":"https://www.andreagrandi.it/2008/03/08/conferenza-olpc-a-firenze-con-nicholas-negroponte-la-recensione/"},{"title":"Maps for Nokia OS2008","text":"I report this news from Andrew Jorgensen (Monologue): The Map application for Nokia's OS2008 (for N800 and N810) lets you download map data for a number of regions. The USA-West and USA-East regions are very large, though, and I have never been able to download them — it always fails about half way through. I know others have dealt with the same problem. This morning I got a reply from Wayfinder Customer Support: Dear Sir, Thank you for contacting Wayfinder. If the map download fails through the Internet Tablet, you can download the maps from this address: http://www.navicoretech.com/Consumer/Support/Downloads/tablet/en_GB/wfnavigator/ Best regards, Annette Customer Support Wayfinder Instructions for installing the map data are on that site. It's still a slow download but at least you can use a download manager.","tags":"HowTo, Linux, Maemo (EN)","url":"https://www.andreagrandi.it/2008/03/06/maps-for-nokia-os2008/","loc":"https://www.andreagrandi.it/2008/03/06/maps-for-nokia-os2008/"},{"title":"Utilizzare SSH senza password: chiavi SSH","text":"Quando vogliamo connetterci ad un server SSH , solitamente utilizziamo un comando simile al seguente: ssh user@remotehost.com Una volta connessi ci viene richiesta la password di accesso e subito dopo siamo connessi. Digitare ogni volta la password puo' essere scomodo, ed in alcuni casi questo potrebbe addirittura impedirci di creare uno script di automazione per velocizzare alcuni compiti. Ci vengono in aiuto le chiavi SSH . Generando una coppia di chiavi pubblica/privata di SSH sulla propria macchina, ed esportando la chiave pubblica sul server remoto, possiamo fare in modo di autorizzare la nostra chiave remota, facendo si che le connessioni successive avvengano senza la richiesta di alcuna password. Supponiamo (a scopo dimostrativo) che il server remoto si trovi all'indirizzo IP 192.168.0.2 e supponiamo inoltre di avere un account chiamato user sulla macchina remota. Per prima cosa dobbiamo generare la coppia di chiavi sulla nostra macchina locale (n.b: non utilizzo alcuna passphrase, altrimenti mi verrebbe richiesta comunque al primo login di ogni sessione): andy80@noteboontu:~$ ssh-keygen -t dsa Generating public/private dsa key pair. Enter file in which to save the key ( /home/andy80/.ssh/id_dsa ) : Enter passphrase ( empty for no passphrase ) : Enter same passphrase again: Your identification has been saved in /home/andy80/.ssh/id_dsa. Your public key has been saved in /home/andy80/.ssh/id_dsa.pub. The key fingerprint is: 22 :99:69:d2:8d:8e:a5:f1:f4:dc:0f:d8:49:52:53:cd andy80@noteboontu A questo punto dobbiamo copiare la chiave pubblica appena generata, sul server remoto: cd ~/.ssh/ scp id_dsa.pub user@192.168.0.2:./id_dsa.pub Ci verrà chiesta la nostra password remota, per poter effettuare la copia del file. A questo punto dobbiamo connetterci via SSH al server remoto: ssh user@192.168.0.2 Quando abbiamo effettuato correttamente il login, dobbiamo procedere con i seguenti comandi: cd .ssh touch authorized_keys2 chmod 600 authorized_keys2 cat ../id_dsa.pub >> authorized_keys2 rm ../id_dsa.pub Il gioco è fatto! Le successive connessioni SSH che effettueremo verso il server remoto, avverranno senza la richiesta di alcuna password.","tags":"HowTo","url":"https://www.andreagrandi.it/2008/02/29/utilizzare-ssh-senza-password-chiavi-ssh/","loc":"https://www.andreagrandi.it/2008/02/29/utilizzare-ssh-senza-password-chiavi-ssh/"},{"title":"Full Circle Magazine #10","text":"E' appena stato rilasciato il numero 10 di Full Circle Magazine , la rivista elettronica gratuita dedicata a Linux e ad Ubuntu in generale. In questo numero: Installazione di Linux Mint HowTo: installare un programma da sorgenti, utilizzare TuxPaint, rippare un DVD con AcidRip, creare il proprio server (parte 2) Recensione dell'Asus EeePc con eeeXubuntu Lettere, domande & risposte, ecc... La rivista è interamente in inglese e potete scaricarla da questo indirizzo: http://fullcirclemagazine.org/issue-10/","tags":"Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/02/29/full-circle-magazine-10/","loc":"https://www.andreagrandi.it/2008/02/29/full-circle-magazine-10/"},{"title":"OLPC a Firenze il 7 marzo con Nicholas Negroponte","text":"Il 7 marzo 2008 , presso il salone De'Dugento a Palazzo Vecchio (Firenze), dalle ore 10:00 verrà presentato il portatile da 100$ One Laptop Per Child dove parteciperà anche l'ideatore del progetto, Nicholas Negroponte . Qui di seguito il comunicato ufficiale del Comune di Firenze: ONE LAPTOP FOR CHILD, IL 7 MARZO PRESENTAZIONE A LIVELLO NAZIONALE, DELLA CAMPAGNA DI DIFFUSIONE DEL PRIMO PC ADATTO AI BAMBINI DI TUTTO IL MONDO Parte da Firenze, per la prima volta in Italia, la presentazione di One Laptop Per Child (OLPC) Italia: il portatile adatto ai bambini e disegnato per imparare a imparare. L'importante appuntamento, organizzato dall'assessorato all'informatica, è per il 7 marzo nel salone de' Dugento in Palazzo Vecchio. L'evento vanta la partecipazione di Nicholas Negroponte, Fondatore del Massachusetts Institute of Technology (MIT) Media Lab di Boston ed ideatore del laptop XO-OLPC. Il nuovo portatile verrà presentato alle 10,30 durante una conferenza stampa nel Salone de' Dugento, dove parteciperà anche Nicholas Negroponte. Seguirà poi una dimostrazione del laptop OLPC e verranno anche installate anche delle postazioni. \"È un progetto educativo, non solo un semplice portatile.\" Come ribadisce Negroponte , il laptop è una risposta alla sfida globale di combattere l'analfabetizzazione, l'inclusione sociale ed il divario digitale. \" Il laptop XO, un portatile adatto per i bambini e disegnato per imparare a imparare\". L'XO incorpora le teorie costruzionistiche sviluppate per prime negli anni '60 dal professore del MIT Media Lab, Seymour Papert, più tardi rielaborate da Alan Kay e complementate da principi articolati da Nicholas Negroponte nel suo libro, Essere Digitale. OLPC Italia nasce dalla sensibilità dell'assessore all'informatica, che ha deciso di aderire all'iniziativa globale OLPC Give 1 Get 1 (G1G1) sul territorio locale, promuovendo il laptop XO non solo per i bambini delle scuole fiorentine ma anche per i Paesi in via di sviluppo gemellati con il Comune di Firenze. OLPC Italia si sviluppa sul territorio italiano, partendo dal Comune di Firenze, attraverso modelli sinergetici tra scuole nazionali ed in PVS. Ciascun studente italiano che acquisterà un laptop, donerà un altro laptop ad un suo coetaneo di un' altra città del Sud del mondo. Mobilitando risorse e partner, OLPC Italia tende a creare una rete di solidarietà civica internazionale, gestendo in prima persona l'implementazione ed il monitoraggio di tali progetti nei PVS. Durante la giornata sarà possibile assistere ad una dimostrazione sull'utilizzo e le principali funzioni che caratterizzano XO, nonché provare il laptop stesso e condividere la rete tra i vari XOs collegati. Il progetto OLPC è stato fondato da Nicholas Negroponte con un nucleo di veterani del Media Lab, e ha presto coinvolto persone di talento e costanza eccezionali, provenienti dall'ambiente accademico, dalle belle arti e dalla comunità open source. Ogni individuo che partecipa porta con sé un insieme di capacità uniche, e una profonda passione per il progetto. La campagna G1G1 presentata negli Stati Uniti a novembre, ha venduto sul territorio americano oltre 200.000 macchine in un mese e mezzo. Per informazioni rivolgersi a giulia@laptop.org","tags":"Linux, OLPC","url":"https://www.andreagrandi.it/2008/02/27/olpc-a-firenze-il-7-marzo-con-nicholas-negroponte/","loc":"https://www.andreagrandi.it/2008/02/27/olpc-a-firenze-il-7-marzo-con-nicholas-negroponte/"},{"title":"Eclipse plugins for Maemo Development","text":"Maemo Team has just released a plugin for Maemo Eclipse integration . This tool allows developers to use Eclipse IDE to develop and test Maemo applications. This release includes: maemo PC Connectivity version [0.1] (Beta) maemo ESBox plugin for Eclipse IDE version [1.3.6] (Beta) maemo Pluthon plugin for Eclipse IDE version [0.1.7] (Beta) Maemo PC connectivity packages are tools and other components developer needs to install into his Internet Tablet to enable connectivity between developer PC and Internet Tablet. Maemo ESBox plugin for Eclipse IDE integrates maemo SDK Scratchbox based development environment to the Eclipse development environment. ESBox plugin supports application developers using C, C++ or Python programming language. Developers are able to do all their development work inside Eclipse, from starting the project using template to packaging final application into maemo installation package. Maemo Pluthon plugin for Eclipse IDE integrates Eclipse IDE development environment to the Internet Tablet so that maemo Python developers do not need to use maemo SDK and Scratchbox as development environment. Maemo Pluthon plugin fully supports application development process with Python where developer develops and tests his Python application directly with Internet Tablet. You can find more informations on the official plugin websites: ESbox: http://esbox.garage.maemo.org/ PluThon: http://pluthon.garage.maemo.org/","tags":"Linux, Maemo (EN), Programmazione, Python","url":"https://www.andreagrandi.it/2008/02/26/eclipse-plugins-for-maemo-development/","loc":"https://www.andreagrandi.it/2008/02/26/eclipse-plugins-for-maemo-development/"},{"title":"APC Back-UPS 500 USB e Ubuntu Server","text":"L'utilizzo di una unità UPS è certamente una delle cose piu' consigliate quando vogliamo proteggere l'integrità di un computer da sbalzi di corrente o interruzioni dell'alimentazione. Cosa succede però quando la batteria dell'UPS si esaurisce? In casi normali è molto semplice: la corrente viene a mancare del tutto ed il nostro PC verrà spento bruscamente. Alla mancanza di corrente non c'è modo di porre un rimedio definitivo, però possiamo almeno fare in modo che il nostro computer venga spento in maniera corretta, prima che la batteria dell'UPS si esaurisca del tutto. Nel caso di una macchina Linux, ci viene in aiuto una utility chiamata apcupsd . Installarla su Ubuntu è molto semplice: apt-get install apcupsd A questo punto, dando per scontato che abbiate già connesso l'UPS al PC/server, collegate il cavo USB a corredo in modo da far riconoscere l'UPS a Linux, in modo da poter proseguire con la configurazione. Il primo file da modificare è /etc/apcupsd/apcupsd.conf ed impostare i seguenti parametri come segue: UPSCABLE usb UPSTYPE usb DEVICE A questo punto non ci resta che modificare il file /etc/default/apcupsd in modo da rendere effettive le modifiche: ISCONFIGURED = yes Infine dobbiamo soltanto avviare il demone ed il gioco è fatto: /etc/init.d/apcupsd start Per default apcupsd effettuerà lo shutdown nel PC quando la batteria sarà arrivata al 5% della sua capacità, consentendo così uno shutdown controllato del sistema, ed evitando quindi possibili perdite di dati.","tags":"Linux, Ubuntu (IT)","url":"https://www.andreagrandi.it/2008/02/15/apc-back-ups-500-usb-e-ubuntu-server/","loc":"https://www.andreagrandi.it/2008/02/15/apc-back-ups-500-usb-e-ubuntu-server/"},{"title":"Android: rilasciata la m5-rc14 dell'SDK","text":"I laboratori di Google hanno da poco rilasciato una versione aggiornata di Android , l'SDK che permette di sviluppare applicazioni per i futuri telefonini Google, si tratta della versione m5-rc14 . Le principali novità di questa release sono le seguenti: Nuova interfaccia utente: anche se si tratta di una versione ancora in sviluppo, è stata aggiornata l'interfaccia grafica di Android. Layout Animations: è stata aggiunta la possibilità di creare animazioni grazie alle classi presenti nel package android.view.animation . Si consiglia di controllare gli esempi presenti nei file LayoutAnimation*.java Geo-coding: il package android.location.Geocoder permette di trasformare un indirizzo in coordinate geografiche e viceversa. Nuovi codec multimediali: è stato aggiunto il supporto per i seguenti formati: OGG Vorbis, Midi, XMF, iMelody, RTTL/RTX e OTA. Aggiornato il plugin per Eclipse: il plugin per eclipse presente alcune novità, in particolare un editor per il Manifesto Ulteriori informazioni sulle modifiche alle API, possono essere trovate su questa pagina . Per tutto il resto si rimanda alla pagina principale del progetto Android.","tags":"Google, Linux, Programmazione","url":"https://www.andreagrandi.it/2008/02/14/android-rilasciata-la-m5-rc14-dellsdk/","loc":"https://www.andreagrandi.it/2008/02/14/android-rilasciata-la-m5-rc14-dellsdk/"},{"title":"Rilasciato WordPress 2.3.3: corretta una grave falla di sicurezza","text":"E' stata rilasciata da poche ore la versione 2.3.3 di WordPress . Con questa release viene corretta una falla piuttosto grave che riguarda in particolar modo quei blog che permettono la registrazione di altri utenti. A causa di un bug in xmlrpc.php è infatti possibile per un utente qualsiasi del blog, editare i contenuti scritti da un altro utente. Oltre a questo bug, sono stati corretti anche altri piccoli problemi che riguardavano la versione 2.3.2 di WordPress. E' consigliato un tempestivo aggiornamento, seguendo la procedura indicata sul sito ufficiale.","tags":"Sicurezza, WordPress","url":"https://www.andreagrandi.it/2008/02/06/rilasciato-wordpress-233-corretta-una-grave-falla-di-sicurezza/","loc":"https://www.andreagrandi.it/2008/02/06/rilasciato-wordpress-233-corretta-una-grave-falla-di-sicurezza/"},{"title":"MySQL: quando si deve pagare la licenza?","text":"Una delle domande che mi vengono fatte piu' di frequente è \" MySQL si paga per uso commerciale? \". La risposta non è delle piu' semplici. Leggendo direttamente il sito web di MySQL , si possono trovare due pagine dedicate alle licenze: una per chi fa sviluppo di software opensource ed una per chi sviluppa software commerciale . Dopo una lettura superficiale delle due pagine, potremmo essere tratti in inganno e pensare che sviluppando un'applicazione commerciale, si debba per forza acquistare una licenza commerciale di MySQL. Questo non è vero. Tutto dipende dal tipo di librerie di interfacciamento che vogliamo utilizzare. MySQL mette a disposizione due modi per interfacciarsi al database: una propria API scritta in linguaggio C ed un socket in ascolto che riceve comandi tramite una normale connessione TCP/IP. E' chiaro che scrivendo un'applicazione che va a fare l'include di (faccio un esempio) mysql.h poi io debba rilasciarne i sorgenti. La licenza GPL con il quale è stato rilasciato MySQL (ed anche le sue librerie client) dice chiaramente che quando si \" linka \" codice GPL ad altro codice, il risultato deve essere per forza rilasciato sotto licenza GPL. La licenza GPL però non impone vincoli di utilizzo dell'applicazione stessa. Utilizzare quindi una libreria client che al posto delle API, usa il socket TCP/IP, ci permette di utilizzare MySQL anche da un'applicazione closed-source, senza bisogno di ottenere una licenza commerciale. E' esattamente quello che fa la libreria di interfacciamento di Python oppure di PHP . Esse utilizzando il metodo di connessione al socket, senza fare l'include del codice di MySQL. Riassumendo: se ci troviamo a scrivere un'applicazione commerciale che sappiamo non verrà distribuita insieme al codice sorgente, dobbiamo preoccuparci solo di utilizzare una libreria client che utilizzi il metodo di connessione tramite socket al database. C'è infine da aggiungere una cosa: se si utilizza codice opensource per uso personale oppure interno alla propria azienda, senza distribuirlo in giro, la GPL non ci impone di rilasciare le modifiche che abbiamo fatto ai sorgenti GPL che stiamo utilizzando. Il caso piu' lampante è quello di Google : essi utilizzano tonnellate di codice GPL, però non distribuiscono un programma, offrono un servizio. Questo gli permette di non dover rendere pubbliche le modifiche fatte al codice originale. Credits: questo articolo è stato possibile in gran parte grazie all'aiuto ed ai consigli di Giovanni Bajo (che pur chiedendomi di specificare che non è un avvocato e che quindi potrebbe anche sbagliarsi, ha senz'altro fatto un ottimo lavoro) .","tags":"Linux, MySQL","url":"https://www.andreagrandi.it/2008/02/05/mysql-quando-si-deve-pagare-la-licenza/","loc":"https://www.andreagrandi.it/2008/02/05/mysql-quando-si-deve-pagare-la-licenza/"},{"title":"Ubuntu 8.04 Alpha 4","text":"E' stata da poco rilasciata la Alpha 4 di Ubuntu 8.04 , ovvero la versione di Ubuntu che vedrà la luce in Aprile. Le novità sono molte e si vanno a sommare a quelle già introdotte nelle precedenti release Alpha: Xorg è stato aggiornato alla 7.3 Il kernel è stato aggiornato alla versione 2.6.24 Il nuovo server audio predefinito diventa PulseAudio Tramite PolicyKit è possibile configurare le applicazioni da amministratore che può far girare anche l'utente normale Firefox è stato aggiornato alla versione 3.0 beta 2 e presenta una migliore integrazione con il layout di sistema Trasmission è il nuovo client BitTorrent che sostituirà lo Gnome BitTorrent downloader Vinagre sarà il nuovo client VNC predefinito ed andrà a sostituire xvnc4viewer Brasero (il programma per masterizzare CD/DVD) è stato aggiornato e si integra perfettamente con Nautilus, sostituendo anche Serpentine per quanto riguarda la creazione dei CD audio L'applet orologio permetterà di vedere l'orario ed il meteo di altre località (configurabili) contemporaneamente Per quanto riguarda il file system virtual usato da Nautilus, GVFS prenderà il posto di GnomeVFS Gnome System Monitor è stato ridisegnato e adesso disegna i grafici tramite le librerie Cairo KVM viene ufficialmente mantenuto all'interno dei Kernel di Ubuntu rendendo piu' semplice l'integrazione con i sistemi di virtualizzazione Ufw (Uncomplicated Firewall) è una nuova applicazione che permetterà di scrivere regole di firewall senza dover imparare la complicata sintassi di iptables Queste sono solo alcune delle novità che vedremo nella prossima versione di Ubuntu. Per visualizzare alcuni screenshot e scaricare questa versione di Ubuntu, vi rimando alla pagina ufficiale: http://www.ubuntu.com/testing/hardy/alpha4","tags":"Linux","url":"https://www.andreagrandi.it/2008/02/03/ubuntu-804-alpha-4/","loc":"https://www.andreagrandi.it/2008/02/03/ubuntu-804-alpha-4/"},{"title":"Utilizzare WordPress da remoto grazie a XML-RPC","text":"Come molti utenti WordPress avranno già notato, esistono svariati client per poter gestire il proprio blog, che possono essere utilizzati invece della normale gestione via web. Gestire WordPress da un client nativo o comunque da remoto, è possibile grazie ad XML-RPC .Questo semplice script Python vi mostrerà quanto sia semplice connettersi al proprio blog ed invocare un metodo: from xmlrpclib import Server server = Server ( \"http://www.andreagrandi.it/xmlrpc.php\" ) userinfo = server . blogger . getUserInfo ( '' , 'admin' , 'password' ) print userinfo vi stamperà a video le informazioni sul vostro utente (ovviamente dovrete sostituire l'URL con quello del vostro blog e mettere gli user e password corretti.","tags":"Python, WordPress","url":"https://www.andreagrandi.it/2008/02/01/utilizzare-wordpress-da-remoto-grazie-a-xml-rpc/","loc":"https://www.andreagrandi.it/2008/02/01/utilizzare-wordpress-da-remoto-grazie-a-xml-rpc/"},{"title":"Rimborso Windows: come ottenerlo e perche'","text":"Che lo si voglia o no, acquistando un computer in un qualsiasi negozio si e' costretti a comprare anche il sistema operativo Microsoft Windows gia' installato. Ma non tutti sanno che è possibile restituire il software non voluto ed ottenere un rimborso. Questo e' il tema dell'incontro che si terra' alla Stazione di Confine in via Attavante a Firenze il 2 Febbraio 2008 alle ore 21:00 Durante l'hacknight organizzata dall' Hacklab di Firenze ed Firenze Linux User Group in video conferenza con l' Hacklab di Caserta , verrano illustrati i modi con cui far valere il diritto al rimborso e le gravi conseguenze generate dall'aggressione alla concorrenza sul mercato mondiale del software, non esclusivamente dei sistemi operativi, e anche a danno dello sviluppo tecnologico. Alla serata interverranno l'avv. Moretti dell' ADUC (Associazione Diritti Utenti e Consumatori) che ha seguito la prima causa italiana vinta da un utente che ha richiesto il rimborso del software preisntallato sul PC, e Marco Pieraccioli, l'utente che ha comprato quel computer ed avviato un processo che mira alla liberalizzazione del mercato del software, sarà presente un rappresentante dell'associazione Software Libero. L'evento potra' essere seguito anche in diretta su Internet. Per maggiori informazioni visitate il sito dell'ADUC: http://www.aduc.it/dyn/rimborsowindows L'Hacklab di Firenze: http://hacknight.firenze.linux.it/wiki.php FLUG Firenze Linux User Group: http://www.firenze.linux.it L'Hacklab di Caserta: http://81100.eu.org/ La Stazione di Confine: http://www.stazionediconfine.it/ Associazione Software Libero: http://www.softwarelibero.it/ Per contatti: FLUG Firenze Linux User Group (Hacklab Firenze/ FLUG ): info@firenze.linux.it","tags":"Linux","url":"https://www.andreagrandi.it/2008/02/01/rimborso-windows-come-ottenerlo-e-perche/","loc":"https://www.andreagrandi.it/2008/02/01/rimborso-windows-come-ottenerlo-e-perche/"},{"title":"First post from MaemoWordpy using N810","text":"This is the first post from my N810 using MaemoWordpy client. This is very cool! I can blog from everywhere now :)","tags":"Maemo (EN)","url":"https://www.andreagrandi.it/2008/02/01/first-post-from-maemowordpy-using-n810/","loc":"https://www.andreagrandi.it/2008/02/01/first-post-from-maemowordpy-using-n810/"},{"title":"Il crivello di Eratostene","text":"Questo codice Python di esempio, genera una lista di numeri primi che vanno da 2 fino al numero passato come parametro. def eratostene ( x ): primi = range ( 3 , x + 1 , 2 ) for i in primi : if ( pow ( i , 2 ) > x ): break for j in primi : if ( i != j ) and ( j % i == 0 ): primi . remove ( j ) primi . insert ( 0 , 2 ) return primi","tags":"Python","url":"https://www.andreagrandi.it/2008/01/30/il-crivello-di-eratostene/","loc":"https://www.andreagrandi.it/2008/01/30/il-crivello-di-eratostene/"},{"title":"Wordpress e le localizzazioni in altre lingue","text":"Pensando di fare una cosa gradita ai futuri lettori di questo blog, uno dei primi problemi di cui mi sono occupato dopo aver installato Wordpress è stato quello della localizzazione in lingua italiana. Sono bastate pochissime letture della documentazione ufficiale per approdare finalmente a questa pagina che, con chiarissime istruzioni, spiegava quali erano i semplici passi da compiere. Purtroppo le semplici istruzioni non hanno funzionato al primo colpo, in quanto il blog continuava ad essere completamente in inglese. Tramite una breve ricerca nel forum di supporto, ho scoperto che si tratta di una fastidiosa incompatibilità con i server a 64 bit che pare verrà corretta nella prossima release. La patch sembra funzionare molto bene. Una volta applicata (almeno per quanto riguarda la mia installazione di Wordpress, ospitata su un hosting di Bluehost) sembra funzionare tutto correttamente. Come mai il blog si trova ancora in lingua inglese? Beh... qui non si tratta di un bug, ma di una proverbiale incapacità di chi ha curato la traduzione in italiano. Installare la localizzazione e poi leggere una frase del genere \"Grazie per creare utilizando WordPress\" mi ha lasciato senza speranze ;) Quando la qualità della localizzazione avrà raggiunto un livello accettabile, forse tornerò a farci un pensierino... per adesso rimane in inglese!","tags":"WordPress","url":"https://www.andreagrandi.it/2008/01/30/wordpress-e-le-localizzazioni-in-altre-lingue/","loc":"https://www.andreagrandi.it/2008/01/30/wordpress-e-le-localizzazioni-in-altre-lingue/"},{"title":"wxGTK working on Maemo","text":"Reading the official WxWidget blog , I discovered that one of their developer was working to hildonize [WxWidgets]{style=\"font-weight: bold;\"}. I wanted to know if that was just a test or if this library could work in Maemo, so I followed his suggestion and I grabbed the latest SVN sources: svn checkout http://svn.wxwidgets.org/svn/wx/wxWidgets/trunk wxWidgets and I compiled it in this way: cd wxWidgets ./configure --with-hildon make make install then I grabbed a simple \"HelloWorld\" from the official documentation. You can find the complete source code here . I compiled the source code in this way: g++ hworld.cpp wx-config --libs wx-config --cxxflags -o hworld then I ran it in the usual way: run-standalone.sh ./hworld The result? I think that a screenshoot is better than thousand words :) Note: I tested this inside Scratchbox, using CHINOOK_x86 target, so I think it will work fine on Os2008. This could be a good thing to help other developers porting some interesting applications (uhm... aMule for example ;) ) to Maemo.","tags":"HowTo, Linux, Maemo (EN), Programmazione","url":"https://www.andreagrandi.it/2007/12/17/wxgtk-working-on-maemo/","loc":"https://www.andreagrandi.it/2007/12/17/wxgtk-working-on-maemo/"},{"title":"Nokia N810 available in Italy!","text":"For the joy of all italian people, the internet tablet Nokia N810 is available in the italian Nokia shop. You can find it here. The price is 459 € . N.B: the discount code doesn't work yet.","tags":"Linux, Maemo (EN)","url":"https://www.andreagrandi.it/2007/12/14/nokia-n810-available-in-italy/","loc":"https://www.andreagrandi.it/2007/12/14/nokia-n810-available-in-italy/"},{"title":"Lower price for N800 in Italy...maybe N810 coming closer?!","text":"I was looking in the Italian Nokia official shop, and I noticed that the N800 price was decreased to 259€ instead of 289€ You can verify it on the official website . Maybe the N810 is coming closer? Who knows ;)","tags":"Linux, Maemo (EN)","url":"https://www.andreagrandi.it/2007/12/13/lower-price-for-n800-in-italymaybe-n810-coming-closer/","loc":"https://www.andreagrandi.it/2007/12/13/lower-price-for-n800-in-italymaybe-n810-coming-closer/"},{"title":"Skype on N770 (using Os2007 HE)","text":"Great news for all N770 users! Someone discovered that is possible to make Skype run on N770 with Os2007 HE . All you have to do is follow these steps: Install skype-ui through Application Manager Download this package in your PC and extract the file named skyhost Find a way to copy the file skyhost to your maemo device in /usr/bin execute this from root on your device: chown user:users /usr/bin/skyhost That's all! You can find more information on the original post .","tags":"HowTo, Linux, Maemo (EN), Skype","url":"https://www.andreagrandi.it/2007/12/10/skype-on-n770-using-os2007-he/","loc":"https://www.andreagrandi.it/2007/12/10/skype-on-n770-using-os2007-he/"},{"title":"Alternative way to generate .deb packages for Maemo","text":"Thanks to Mohammed Hassan now I know an alternative (alternative to the official howto ) way to generate a .deb package for Maemo. If the package already exist in the Debian repositories, you can get the .dsc file (for example in an ftp like this: http://ftp.debian.org/debian/pool/non-free/s/spim/ ) and execute the following commands: dget -x DSC_FILE_URL It will download the package and will unpack it in the current folder. You have to enter in the created folder and edit the debian/* files to personalize settings, mantainer data, add deps ecc... When you're done, you can generate the package with the usual command: dpkg-buildpackage -rfakeroot","tags":"HowTo, Linux, Maemo (EN), Programmazione, Ubuntu (EN)","url":"https://www.andreagrandi.it/2007/11/20/alternative-way-to-generate-deb-packages-for-maemo/","loc":"https://www.andreagrandi.it/2007/11/20/alternative-way-to-generate-deb-packages-for-maemo/"},{"title":"The UNOFFICIAL way to get Os2008 into Nokia N800","text":"Since Os2008 for N810 is out, a lot of people were asking about the possibility to install it on their N800 . Nokia will relase Os2008 for N800 too, but at the moment they don't offer the possibility to download it since the N810 firmware it's not 100% compatible with the old N800. The only way to download a Nokia tablet firmware is being the owner of a tablet. The user has to enter it's own MAC-address to be able to download the file. To download a N810 firmware you need to have a valid N810 MAC-address. A post on News.com describes the exact procedure to follow if you want to try this in your N800: Go to the N810 software download page . Enter the serial number for a valid N810 device. To get one of these, pick any number between 001d6e9c0000 to 001d6e9cffff . Pick any random 4 digits (between 0-9 and a-f hex) as the last 4 digits. Download the file named RX-44_2008SE_1.2007.42-18_PR_COMBINED_MR0_ARM.bin Download the latest firmware-upgrading software, \"flasher-3.0\" . Now that you have the firmware flasher and the 2008 N800 software update in the same directory, open up a terminal (on a Linux desktop/laptop), and type: chmod a+x ./flasher-3.0 ./flasher-3.0 -u -F RX-44_2008SE_1.2007.42-18_PR_COMBINED_MR0_ARM.bin That will unpack the software, and it may take a few seconds. Once that is done, plug the N800 into your computer, using the included USB cable, then reboot the Nokia device while holding the home button. Now execute the following commands: sudo ./flasher-3.0 --enable-rd-mode sudo ./flasher-3.0 -k zImage -f sudo ./flasher-3.0 -n initfs.jffs2 -f sudo ./flasher-3.0 -r rootfs.jffs2 -f -R That should be it. Your device should now boot up with the new 2008 version of the Nokia Maemo operating system. Note: Nokia DOESN'T SUPPORT this procedure in ANY way. You can follow this procedure at your own risk. Neither me or Nokia have the responsability of any damage caused to your device.","tags":"HowTo, Linux, Maemo (EN)","url":"https://www.andreagrandi.it/2007/11/16/the-unofficial-way-to-get-os2008-into-nokia-n800/","loc":"https://www.andreagrandi.it/2007/11/16/the-unofficial-way-to-get-os2008-into-nokia-n800/"},{"title":"Installing qemu-arm-eabi patch into Scratchbox","text":"Using Scratchbox and in particular the Maemo SDK with ARMEL target, very often when we try to execute some application we can get into this kind of errors (for example): sem_post: Function not implemented This happens because not all the functions have been implemented in the emulated environment.[ Lauro Venâncio]{style=\"font-weight: bold;\"} has created a patched version of qemu-arm called [qemu-arm-eabi]. Thanks to Marcelo Lira , we have a simple howto to install the patch into the Scratchbox environment. Note: you have to execute these commands from outside the Scratchbox environment and you should not be logged into the environment at the same time. You need gcc 3.4, SDL dev library andZlib dev: sudo apt-get install gcc-3.4 libsdl1.2-dev zlib1g-dev Get the patched qemu-arm. Notice that the patches are already applied, everything is here, and you don't need to get the qemu sources. svn co https://qemu-arm-eabi.svn.sourceforge.net/svnroot/qemu-arm-eabi qemu-arm-eabi cd qemu-arm-eabi ./configure --target-list = arm-linux-user --static make Copy qemu to the cputransp dir on scratchbox: sudo cp arm-linux-user/qemu-arm /scratchbox/devkits/cputransp/bin/qemu-arm-eabi-sb2 Add it to the list of cputransp methods. Open the file: sudo vim /scratchbox/devkits/cputransp/etc/cputransp-methods and add this line: qemu-arm-eabi-sb2 Configure the target to use the patched qemu as transparency method. Edit the file: vim /scratchbox/users/USERNAME/targets/CHINOOK_ARMEL.config and change this line: SBOX_CPUTRANSPARENCY_METHOD = /scratchbox/devkits/cputransp/bin/qemu-arm-eabi-sb2 That's all! You're now ready to log again into your Scratchbox environment.","tags":"HowTo, Linux, Maemo (EN), Programmazione","url":"https://www.andreagrandi.it/2007/11/16/installing-qemu-arm-eabi-patch-into-scratchbox/","loc":"https://www.andreagrandi.it/2007/11/16/installing-qemu-arm-eabi-patch-into-scratchbox/"},{"title":"Upgrading Maemo SDK 4 Beta to Maemo SDK 4 final release","text":"The final version of Maemo SDK 4 is out. Like most other people I couldn't wait for the final release and I installed the beta version. The big question, when I did read about the final version was \"how can I upgrade to the final version without installing it from scratch?!\". Luckly one kind person helped me on maemo-developer mailing list, and suggested me to do a dist-upgrade from inside the Scratchbox environment. So, login into tour Scratchbox environment and execute this: [ sbox-SDK_BETA_X86: ~ ] > fakeroot apt-get update [ sbox-SDK_BETA_X86: ~ ] > fakeroot apt-get dist-upgrade That's all! I don't know if this is the official method to do the upgrade, but it worked for me. I checked, after the upgrade, if I had the right packages installed, using this page: http://tablets-dev.nokia.com/4.0/4.0b_vs_4.0_content_comparison.html and they were right.","tags":"HowTo, Linux, Maemo (EN), Programmazione","url":"https://www.andreagrandi.it/2007/11/11/upgrading-maemo-sdk-4-beta-to-maemo-sdk-4-final-release/","loc":"https://www.andreagrandi.it/2007/11/11/upgrading-maemo-sdk-4-beta-to-maemo-sdk-4-final-release/"},{"title":"Spim - MIPS Emulator for N770","text":"Spim is a self-contained simulator that will run MIPS32 assembly language programs. It reads and executes assembly language programs written for this processor. spim also provides a simple debugger and minimal set of operating system services. spim does not execute binary (compiled) programs. I made a port of spim for the Nokia 770/800 device just for fun and to start learning how to do ports. Download You can download spim for N770/800 from here: http://www.ptlug.org/download/packages/spim_7.3-1_armel.deb References To create the package i followed the guide lines in these websites: http://www.maemo.org/platform/docs/howtos/howto_making_an_application_package.html http://www.debian.org/doc/maint-guide/index.en.html http://www.cs.wisc.edu/\\~larus/spim.html","tags":"Linux, Maemo (EN), Programmazione","url":"https://www.andreagrandi.it/2007/10/25/spim-mips-emulator-for-n770/","loc":"https://www.andreagrandi.it/2007/10/25/spim-mips-emulator-for-n770/"},{"title":"Installing Maemo SDK 4 Beta","text":"Introduction Maemo is an opensource development platform for Linux based devices. Actually is the base for the operating system installed on Nokia N770 , N800 and the upcoming N810 but it could be adopted, with few changes, even by other similar devices. In particular, this version of Maemo SDK is the only one that allow developers to develop new applications for N810 and to start porting old application to this new platform. The SDK is not only a set of libraries and compiler, it gives you a real environment that emulates the Nokia device, so the developer can write applications, debug them and test them. Both command line and gui application are supported in emulator. Graphical environment is based on a real X server , a window manager and on GTK libraries, with a particular extension called Hildon . With Maemo SDK you can: Test Maemo applications using a normal PC with Linux. Write and debug applications written by you. Port existing applications written for Linux/GTK and verify if they work correctly. Compile and build ARMEL package so you can install them in the device. Requirements These are the minimum requirements to work with Maemo SDK: Intel compatible processor (x86), at least 500 Mhz 256 Mb RAM 2 Gb space on hard disk A Linux distribution (I suggest Debian or Ubuntu) You need the following software packages: Scratchbox: a cross-compiling toolkit that allows you to compile applications for different platform Maemo SDK: you can find it at this address: http://www.maemo.org/downloads/download-sdk.html Xephyr Xserver: Starting from 4.x version, Maemo has a simple installer script, so all you need are these two files: maemo-scratchbox-install_4.0beta.sh maemo-sdk-install_4.0beta.sh Installing Scratchbox The first tool you have to install is Scratchbox . I suggest you to use the script provided but you could choose also to install it manually (in this case please refer to this site for detailed instructions). Before beginning the installation of Scratchbox, you have to become root . First of all set the permission of the script file: chmod +x maemo-scratchbox-install_4.0beta.sh Then run it with these parameters: ./maemo-scratchbox-install_4.0beta.sh -d -u andy80 Please note that -d tells the installer to install from Debian dpkg packages while -u specifies your username (in my case is andy80, you have to change it using your local username). Scratchbox environment will be installed in /scratchbox/ Please note that you'll have to logout and login again to be able to log into you new Scratchbox environment. To test it you simply have to start Scratchbox from your local user: /scratchbox/login Welcome to Scratchbox, the cross-compilation toolkit! Use 'sb-menu' to change your compilation target. See /scratchbox/doc/ for documentation. Installing Maemo SDK When Scratchbox is correctly installed on your system, you can install the Maemo SDK . Please note that you have to do it from normal user (the user you specified in the installation of Scratchbox). Simply run this command and follow instructions: bash maemo-sdk-install_4.0beta.sh At the end you should get this message: Installation was successful! ---------------------------- IMPORTANT! Please read this. You now have the maemo 4 .0beta 'chinook' installed on your computer. You can now start your maemo SDK session with /scratchbox/login and then select your target with 'sb-conf select SDK\\_BETA\\_ARMEL' for the armel target or 'sb-conf select SDK\\_BETA\\_X86' for the i386 target. If you have any problems with targets ' package databases, you can try running ' fakeroot apt-get -f install ' on your scratchbox target. This command will try to fix any problems with the package database. Happy hacking! Installing Xephyr Xephyr is an X11 server that provides a device screen for the developer so that you can see all the maemo application windows and visuals on your computer. To install it in a Debian based distribution, simply execute this (from root): apt-get install xserver-xephyr Running Xephyr To see if all works fine, you should start Xephyr and Maemo environment. Execute this from outside the Scratchbox environment: Xephyr :2 -host-cursor -screen 800x480x16 -dpi 96 -ac -extension Composite Now, from another shell, log into Scratchbox and execute this: [ sbox-SDK_BETA_X86:~ ] > export DISPLAY = :2 [ sbox-SDK_BETA_X86:~ ] > af-sb-init.sh start This should start the Hildon Application Framework inside the Xephyr window. That's all! References Here you can find a list of website where I took information from to write this guide: http://tabletsdev.maemo.org/unstable/chinook-beta/INSTALL.txt http://www.maemo.org","tags":"HowTo, Linux, Maemo (EN), Programmazione","url":"https://www.andreagrandi.it/2007/10/25/installing-maemo-sdk-4-beta/","loc":"https://www.andreagrandi.it/2007/10/25/installing-maemo-sdk-4-beta/"}]};