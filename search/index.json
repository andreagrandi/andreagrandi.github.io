[{"content":"Introduction When working with Claude Code on macOS, you might find yourself waiting for long-running tasks to complete or missing important prompts for user input. The terminal-notifier utility provides an elegant solution by sending desktop notifications directly from the command line, helping you stay informed about your Claude Code sessions even when you\u0026rsquo;re focused on other tasks.\nNote: I decided to use terminal-notifier both because I can customise the notification I receive and also because my setup was having issues and I didn\u0026rsquo;t always get notifications from my terminal.\nWhat is terminal-notifier? terminal-notifier is a command-line tool for macOS that allows you to send user notifications from the terminal to the Notification Center. It\u0026rsquo;s particularly useful for automation scripts and development workflows where you need to be alerted about specific events.\nInstalling terminal-notifier The easiest way to install terminal-notifier is through Homebrew:\n1 brew install terminal-notifier Using terminal-notifier with Claude Code Claude Code can be configured to use terminal-notifier for sending notifications in different ways. The most realiable (and deterministic) is using the new /hooks feature. Add this configuration to your ~/.claude/settings.json:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026#34;hooks\u0026#34;: { \u0026#34;Notification\u0026#34;: [ { \u0026#34;matcher\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;hooks\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;command\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;terminal-notifier -title \\\u0026#34;üîî Claude Code\\\u0026#34; -message \\\u0026#34;Claude needs your input\\\u0026#34;\u0026#34; } ] } ], \u0026#34;Stop\u0026#34;: [ { \u0026#34;matcher\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;hooks\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;command\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;terminal-notifier -title \\\u0026#34;‚úÖ Claude Code\\\u0026#34; -message \\\u0026#34;The task has been completed\\\u0026#34;\u0026#34; } ] } ] } The other method (not deterministic, but you can customise the message you get) is to add instructions to your global or project-specific CLAUDE.md file:\n1 2 3 4 ## Notification - IMPORTANT: YOU MUST ALWAYS DO THIS: When you need to send me a notification because you need input or when you have finished a task, please use terminal-notifier tool like this: terminal-notifier -title \u0026#34;üîî Claude Code: request\u0026#34; -message \u0026#34;Claude needs your permission to use ...\u0026#34;, or terminal-notifier -title \u0026#34;‚úÖ Claude Code: done\u0026#34; -message \u0026#34;The task has been completed\u0026#34; - Always customise the message using a short summary of the input needed or the task just completed Save the file and start a new Claude Code session.\nFinal result If everything worked, once Claude has finished elaborating a task, you should get a notification like this:\nTroubleshooting Notifications Not Appearing Check that notifications are enabled for Terminal in System Preferences \u0026gt; Notifications Ensure terminal-notifier is properly installed and in your PATH Try running a test notification manually to verify functionality: terminal-notifier -title \u0026quot;Hello\u0026quot; -message \u0026quot;World!\u0026quot; Conclusion Integrating terminal-notifier with Claude Code creates a more efficient and responsive development workflow. By receiving timely notifications about task completion and input requests, you can maintain focus on other work while staying connected to your Claude Code sessions.\nThe combination of Claude Code\u0026rsquo;s automation capabilities with macOS\u0026rsquo;s native notification system provides a seamless development experience that keeps you informed without being intrusive.\n","date":"2025-07-12T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-terminal-notifier-claude-code-custom-notifications/","title":"Using terminal-notifier in Claude Code to get custom notifications"},{"content":"Following my previous post, today I wanted to see if I could replace my pyenv and pyenv-virtualenv usage with uv.\nInstall uv If you haven\u0026rsquo;t done it yet, you need to first install uv using either this method or one of the methods described in the documentation:\n1 2 brew update brew install uv Install Python uv can detect Python versions installed in different ways in the system or it can install its own copies. You can check which ones are installed, using this command:\n1 uv python list --only-installed Now we are going to install the latest (at the time of writing) version of Python:\n1 uv python install 3.13.1 Create a virtual environment Creating virtual environment with uv is quite easy. We can do it in this way:\n1 uv venv --python 3.13.1 --prompt my-project With --python 3.13.1 we specify the Python version we want and with --prompt my-project we customise the text that will appear in the prompt.\nAs the output will say, we can simply activate the environment with this command:\n1 source .venv/bin/activate Automatically activate the virtual environment Running source .venv/bin/activate every time we enter the project directory can be boring. We can automate this by using direnv.\ndirenv is a tool which can automatically set environment variables or run simple commands when we enter inside a directory.\nYou can install it with:\n1 brew install direnv Once it\u0026rsquo;s installed, we need to add this configuration inside our .zshrc:\n1 eval \u0026#34;$(direnv hook zsh)\u0026#34; or, in case we are using bash, we need to do it inside .bashrc:\n1 eval \u0026#34;$(direnv hook bash)\u0026#34; At this point simply close and reopen your terminal (it\u0026rsquo;s the quickest way to reload the configuration) and finally create a file named .envrc inside your project folder, containing these two lines (or append these two lines in case you are already using this file):\n1 2 export VIRTUAL_ENV=$PWD/.venv export PATH=$VIRTUAL_ENV/bin:$PATH After you save this file and you get back to your terminal, you will get an error like this:\n1 direnv: error /Users/andrea/Projects/my-project/.envrc is blocked. Run `direnv allow` to approve its content Just run that command to allow direnv to load your configuration:\n1 direnv allow Installing Python packages At this point you can use uv pip (which is a drop in replacement for pip with a few limitations) just like you would use pip:\n1 uv pip install requests Make an alias for uv pip If you are happy to use the uv version of pip, you can use it anywhere, even in virtual environments which are not managed by uv. You can create an alias by adding this to your .zshrc (or .bashrc etc\u0026hellip;)\n1 alias pip=\u0026#34;uv pip\u0026#34; This way, every time you invoke pip, you will use the uv version:\n1 pip --version Conclusion Using uv pip, uv venv and uv python you can definitely speed up Python installation, virtual environments creations and Python packages installation.\nBut uv is much more. You can also manage dependencies, lock them and do many other things. At this point I don\u0026rsquo;t feel like switching completely to this tool, especially because a few things (like dependencies locking) are not standard across Python ecosystem and the risk is to use a workflow which is not supported by other existing tools (for example if you are using dependabot you won\u0026rsquo;t be able to just use uv.lock file, you will need to extract requirements.txt files)\nMy final advice is to use just the parts which are compatible with your existing workflow and wait until a standard for locking dependencies will be universally accepted, before jumping in with both feet.\n","date":"2025-01-30T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-uv-to-install-python-create-virtualenv/","title":"Using uv to install Python and create a virtual environment"},{"content":"I heard about uv and Astral last year and as I previously mentioned in this blog post, I did (and still have) have some concerns about them.\nBy the way, inspired by some work a colleague of mine is doing, I wanted to give it a chance and I checked if I could start using it without disrupting my pyenv workflow.\nNote: Even if you don\u0026rsquo;t want to migrate away from your favourite Python environment and virtualenv manager, there are a few ways to use it to speed up your existing configuration, so stay with me.\nWhat is uv? uv is a package manager for Python which is written in Rust, it\u0026rsquo;s extremely fast and it\u0026rsquo;s becoming the favourite package manager across the Python community. As usual, please refer to the official website for more details: https://docs.astral.sh/uv/\nInstalling uv It seems obvious but before proceeding with this tutorial, you need to install uv. There are a few different ways described in the official documentation, but if you are using MacOS and also use brew, you can install it with:\n1 brew install uv Using uv pip uv reimplements pip so instead of doing pip install -r requirements.txt you can do uv pip install requirements.txt (or similar), and believe me: It\u0026rsquo;s faster!\nThis is a pip command I used to upgrade the dependencies in the virtual environment of one of the work projects (I only renamed the project name)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ‚ùØ uv pip install -U -r requirements/base.txt Using Python 3.12.8 environment at: /Users/andrea/.pyenv/versions/3.12.8/envs/my-project Resolved 74 packages in 879ms Prepared 8 packages in 1.50s Uninstalled 8 packages in 300ms Installed 8 packages in 28ms - alembic==1.14.0 + alembic==1.14.1 - attrs==24.3.0 + attrs==25.1.0 - boto3==1.35.98 + boto3==1.36.2 - botocore==1.35.99 + botocore==1.36.8 - deprecated==1.2.15 + deprecated==1.2.18 - s3transfer==0.10.4 + s3transfer==0.11.2 - sentry-sdk==2.19.2 + sentry-sdk==2.20.0 - structlog==24.4.0 + structlog==25.1.0 The speed is impressive! I almost thought the command had failed because it finished so quickly. You can find more details in the docs: https://docs.astral.sh/uv/pip/packages/\nUsing nox[uv] For the same project, we use nox as a wrapper to run tests and it takes care of creating specific virtual environments. By default it uses virtualenv but there is a simple trick to make it use uv.\nFirst you need to install nox[uv]\n1 uv tool install \u0026#39;nox[uv]\u0026#39; Then you just need to set this environment variable:\n1 export NOX_DEFAULT_VENV_BACKEND=uv That\u0026rsquo;s it! I can\u0026rsquo;t provide the full output of our test suite, but I timed (time nox -s test ...) the execution and by using uv as backend, our virtual environment is created 13 seconds faster!\nConclusion I used \u0026ldquo;part 1\u0026rdquo; as suffix for this blog post, because I\u0026rsquo;m sure these experiments will continue in the next days, by using more of the available uv tools. Once I\u0026rsquo;ve learned more, I will share my experience again.\n","date":"2025-01-29T00:00:00Z","image":"https://www.andreagrandi.it/posts/stepping-my-feet-into-uv-world-part-1/uv-speed.png","permalink":"https://www.andreagrandi.it/posts/stepping-my-feet-into-uv-world-part-1/","title":"Stepping my feet into uv world - part 1"},{"content":"In the past couple of days I was having this annoying issue while trying to pull a model from Ollama: I was running the command ollama pull deepseek-r1:8b, it was downloading something like 4-5% of the model and then the connection was reset, the client was \u0026ldquo;crashing\u0026rdquo; and it always restarted from 0%.\nIt looks like I wasn\u0026rsquo;t alone: https://github.com/ollama/ollama/issues/8406\nNote: I\u0026rsquo;m running Ollama 0.5.7, it\u0026rsquo;s likely they will fix the issue in one of the next releases.\nSolution Someone kindly posted a workaround which is a bash script able to invoke Ollama client and resume the download where it was left (Ollama client should to that, but it\u0026rsquo;s not doing it correctly when it crashes).\nSave this script in a file like ollama-pull.sh and make it executable with chmod +x ollama-pull.sh:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #!/bin/bash die(){ echo \u0026#34;$1\u0026#34; exit 1 } #DRYRUN=echo _=$(command -v jq) || die \u0026#34;Need jq\u0026#34; _=$(command -v curl) || die \u0026#34;Need curl\u0026#34; [ -z \u0026#34;$1\u0026#34; ] \u0026amp;\u0026amp; die \u0026#34;usage: $0 modelname\u0026#34; name=${1%%:*} [[ \u0026#34;$1\u0026#34; = *:* ]] \u0026amp;\u0026amp; tag=\u0026#34;${1##*:}\u0026#34; || tag=latest OLLAMA_MODELS=${OLLAMA_MODELS-/usr/share/ollama/.ollama/models} cd $OLLAMA_MODELS || die \u0026#34;Couldn\u0026#39;t cd to OLLAMA_MODELS ($OLLAMA_MODELS)\u0026#34; [ ! -d blobs -o ! -d manifests ] \u0026amp;\u0026amp; die \u0026#34;Missing blobs or manifests directory\u0026#34; manifest_dir=\u0026#34;manifests/registry.ollama.ai/library/$name\u0026#34; [ -e \u0026#34;$manifest_dir/$tag\u0026#34; ] \u0026amp;\u0026amp; die \u0026#34;$name:$tag already exists\u0026#34; [ ! -d \u0026#34;$manifest_dir\u0026#34; ] \u0026amp;\u0026amp; { $DRYRUN mkdir -p \u0026#34;$manifest_dir\u0026#34; || die \u0026#34;Couldn\u0026#39;t mkdir manifest dir ($manifest_dir)\u0026#34; ; } manifest=$(curl -sL https://registry.ollama.ai/v2/library/$name/manifests/$tag) || die \u0026#34;Couldn\u0026#39;t fetch manifest\u0026#34; errors=$(jq -cn \u0026#34;$manifest |.errors\u0026#34;) [ \u0026#34;$errors\u0026#34; = \u0026#34;null\u0026#34; ] || die \u0026#34;$errors\u0026#34; config=$(jq -rn \u0026#34;$manifest | .config.digest\u0026#34;) || die \u0026#34;No config digest\u0026#34; $DRYRUN curl -#L -C - -o blobs/${config/:/-} https://registry.ollama.ai/v2/library/$name/blobs/$config || die \u0026#34;Couldn\u0026#39;t fetch config blob\u0026#34; for layer in $(jq -rn \u0026#34;$manifest | .layers[].digest\u0026#34;) ; do $DRYRUN curl -#L -C - -o blobs/${layer/:/-} https://registry.ollama.ai/v2/library/$name/blobs/$layer || die \u0026#34;Couldn\u0026#39;t fetch layer\u0026#34; done [ -n \u0026#34;$DRYRUN\u0026#34; ] \u0026amp;\u0026amp; echo \u0026#34;echo \u0026#39;$manifest\u0026#39; \u0026gt; \u0026#39;$manifest_dir/$tag\u0026#39;\u0026#34; || { echo \u0026#34;$manifest\u0026#34; \u0026gt; \u0026#34;$manifest_dir/$tag\u0026#34; || die \u0026#34;Couldn\u0026#39;t write manifest\u0026#34; ; } and run the script in this way:\n1 OLLAMA_MODELS=~/.ollama/models ./ollama-pull.sh deepseek-r1:8b (replace deepseek-r1:8b with the name:tag of the model you want to pull)\n","date":"2025-01-26T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-workaround-ollama-pull-issues/","title":"How to workaround Ollama models pull issues"},{"content":"I found out about Micro.blog platform thanks to Jeff Triplett a few months ago and I even decided to give it a try, but to be honest, having already a main blog, made with Hugo, which is hosted for free on GitHub Pages, I couldn\u0026rsquo;t really justify spending another $5/month for a micro blogging platform.\nMicro.one Then Manton Reece (the creator of Micro.blog) announced (actually he didn\u0026rsquo;t do it officially when I discovered it, but I found out anyway!) a new plan: Micro.one\nFor just $1/month (or $10/year if you switch to the annual plan!) I can have my micro blog hosted, with custom domain support, I can post text, photos and even podcasts!\nWhat is Micro.blog? Micro.blog (and Micro.one too) is an hosting solution for static blogs. The user selects a template, creates the content and the platform uses Hugo to create the pages which are then published.\nNothing revolutionary for me, but I reckon this is a quite good solution for many people who would like to have a blog but they don\u0026rsquo;t have the skills to use Hugo or create a CI jobs which publish to GitHub Pages.\nWhy a micro blog? I often have content to post which is too short to justify a proper blog post but it\u0026rsquo;s too long to be posted on Mastodon or BlueSky. For this type of posts, Micro.blog is perfect!\nConclusion If you are looking for an easy to use solution to create a personal blog, look no further. Oh, and you can visit mine at this address: https://micro.andreagrandi.it\n","date":"2025-01-21T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/i-got-micro-one-blog/","title":"I got a Micro.one blog"},{"content":"After having thought about this for a while, I finally decided to start sponsoring some of the open source projects I regularly use. I set aside a monthly budget and I evenly divided the amount across the projects.\nWho am I sponsoring? So far I\u0026rsquo;ve started sponsoring these projects / people (in no particular order):\niTerm2 - a terminal for MacOS I\u0026rsquo;ve been using for years Sebasti√°n Ram√≠rez - author of FastAPI Homebrew - a package manager for MacOS Cryptomator - a tool to encrypt, decrypt and easily access files in various clouds Pallets - they develop and maintain Flask, Click and a few other tools Mastodon - the social network I use most Atuin - a shell history which supports a few different shells How much am I donating? If you were expecting to find an amount, please move to the next paragraph üòÖ\nWhat I can say is that everyone should donate an amount based on their own possibilities and estabilished budget. If all the users of the projects I mentioned, donated as much as I\u0026rsquo;m doing, those developers would be rich üòâ\nHow am I donating? For my own simplicity, I decided to support only projects with a Sponsor page on GitHub. This way I can manage all the donations from a single website. I can decide to adjust the amounts and to sponsor more projects. I don\u0026rsquo;t want to discriminate anyone, but at the end of the day it\u0026rsquo;s up to me deciding who to support and how ü§∑üèª‚Äç‚ôÇÔ∏è\nCould I do more? Yes, but\u0026hellip; there was a specific thing which prevented me from donating to other projects I wanted to sponsor. These projects (which I won\u0026rsquo;t mention, but I\u0026rsquo;ve contacted them in private to suggest considering a more flexible option) all have a minimum amount set in their Sponsor settings.\nHonestly I can\u0026rsquo;t understand the reason for this, and I\u0026rsquo;m sure it\u0026rsquo;s not about fees, because GitHub takes a fixed fees percentage (3% credit card processing fee + 3% GitHub service processing fee) so receiving 1$ from 100 people or 100$ from 1 person doesn\u0026rsquo;t change the final amount of money the developer receives.\nMy humble suggestion is to remove the minimum amount: not everyone can or is willing to donate the minimum amount some of these projects have set and you will be able to collect more donations from more people.\nConclusion My personal opinion is that every cent counts. No matter if you can only afford 5$/month or if you are able to donate 100$/month: every person should donate based on their own preferences and possibilities.\nI onestly would prefer to get 1$ from 100 different people than 100$ from a single person. A larger number of people believing in my projects is more important than the final amount.\nSo, if you really care about open source, beware that GitHub stars can\u0026rsquo;t be used to pay the bills üòâ please consider donating to the projects you love as much as you can!\n","date":"2025-01-03T00:00:00Z","image":"https://www.andreagrandi.it/posts/new-year-resolution-sponsoring-opensource-projects/sponsor.png","permalink":"https://www.andreagrandi.it/posts/new-year-resolution-sponsoring-opensource-projects/","title":"New Year resolution: sponsoring some of the open source projects I use"},{"content":"Inspired by this post from Nicola Iarocci, I decided to check my own bash zsh history:\n1082 git 99 cd 95 nox 38 pip 37 ls 33 pytest 29 brew 26 code 19 curl 16 pyenv Even for me, my biggest usage of the terminal is because of git üòÖ\nYou can produce your own list by using this command: history | awk '{print $2}' | sort | uniq --count | sort --numeric-sort --reverse | head -10\n","date":"2025-01-02T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/my-zsh-history/","title":"My ZSH history"},{"content":"I\u0026rsquo;ve always wanted a dog (actually\u0026hellip; my family had one ~30 years ago, but since I wasn\u0026rsquo;t directly involved with him, I never felt him as my own). Life (and sometimes laziness) had not allowed me to own one in the past (living abroad, moving back to Italy but living in a small apartment etc\u0026hellip;) so when I finally had the chance, I got him!\nHis name is Fulvio and he\u0026rsquo;s a Basset Hound breed (yes, the same breed as Lieutenant Columbo one üòÖ)\nSince I got him, my life has definitely changed. Mostly for good things (like doing a 45-50 minutes walk every morning which is helping me a lot to be more healthy!) but there are definitely things I still need to get used to ü•≤\nI\u0026rsquo;m lucky to have 3 weeks off for this Christmas holidays and this means plenty of time to play with him and to get to know each other.\nI don\u0026rsquo;t have much else to say, so I will leave you with another picture of him.\nGreeting from me and Fulvio! üëã üê∂\n","date":"2024-12-14T00:00:00Z","image":"https://www.andreagrandi.it/posts/welcome-fulvio/fulvio_cover.jpg","permalink":"https://www.andreagrandi.it/posts/welcome-fulvio/","title":"I got a Basset Hound dog: welcome Fulvio!"},{"content":"I recently found out (thanks to this article from Juha-Matti Santala) that not only you can power a RaspberryPi device through the USB-C of an iPad but that you can also get an ethernet connection through it\nRequirements an USB-C iPad (I used an iPad Air 4th gen) a USB-C cable (I used the one that comes with the iPad) a RaspberryPi (you need at least a RPI 4. I used a RPi 5) you already have SSH access to the RaspberryPi (I won\u0026rsquo;t cover this part in this tutorial) an updated bootloader on the RaspberryPi (check this documentation) Configuration Connect to the RaspberryPi using SSH Become super user on the RaspberryPi: sudo su Edit /boot/firmware/cmdline.txt and add these options after rootwait: 1 modules-load=dwc2,g_ether Edit /boot/firmware/config.txt and make sure that otg_mode=1 is uncommented. Then add this line after the [all] section: 1 dtoverlay=dwc2 Use this command to add a new connection: 1 nmcli con add type ethernet con-name ethernet-usb0 Edit /etc/NetworkManager/system-connections/ethernet-usb0.nmconnection and make sure you have these settings: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [connection] id=ethernet-usb0 uuid=\u0026lt;random group of characters here\u0026gt; type=ethernet autoconnect=true interface-name=usb0 [ethernet] [ipv4] method=shared [ipv6] addr-gen-mode=default method=auto [proxy] Edit /usr/local/sbin/usb-gadget.sh and add this: 1 2 3 #!/bin/bash nmcli con up ethernet-usb0 Make the file executable: 1 chmod a+rx /usr/local/sbin/usb-gadget.sh Edit /lib/systemd/system/usbgadget.service and add this: 1 2 3 4 5 6 7 8 9 10 11 12 [Unit] Description=My USB gadget After=NetworkManager.service Wants=NetworkManager.service [Service] Type=oneshot RemainAfterExit=yes ExecStart=/usr/local/sbin/usb-gadget.sh [Install] WantedBy=sysinit.target Enable the service using this command: 1 systemctl enable usbgadget.service Reboot the RaspberryPi: 1 reboot Check the configuration is working Connect the RaspberryPi to the iPad using the USB-C cable and wait for it to boot. Once it finishes booting up, open Settings on the iPad and check if there is an Ethernet section below the WiFi Connection. If you find the entry, then it means the connection is successful.\nReferences This tutorial has been written thanks to this other tutorial https://github.com/verxion/RaspberryPi/blob/main/Pi5-ethernet-and-power-over-usbc.md\n","date":"2024-10-26T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/howto-configure-ethernet-connection-ipad-raspberrypi-usbc/","title":"How to configure an Ethernet connection between iPad and RaspberryPi through USB-C"},{"content":"This is my user manual. If we are working together (or planning to), please read it carefully. You will learn how to deal with me productively and avoid misunderstandings. I initially wrote this for my current colleagues, but I thought it could be a good idea to make it public for everyone else I daily interact with.\nMy style I need to understand why I\u0026rsquo;m doing something I love working as a part of a team, not as an individual I love pair programming I like to have a very basic working version first and iterate on it I love to help What I value honesty direct and straight communication people who quickly get to the point leading by example What I don‚Äôt have patience for process for the sake of process long meetings where no actions are taken at the end indirect feedback (heard from third parties) How best to communicate with me chat (public channel unless it\u0026rsquo;s personal) email is ok\u0026hellip;ish absolutely not by phone How I make decisions I need some context first I understand the problem I draft some options and evaluate them I pick the one which is less complicated but at the same time doesn\u0026rsquo;t prevent further improvements I iterate and improve the implemented solution How to help me give me cooking tips not ready meals! - I appreciate help and I don\u0026rsquo;t hesitate asking for it when I need, but whenever I do I like to be given tips to unblock me not a ready solution or someone else doing the task for me. offer me to do pair programming Random things I like dogs (especially Basset Hounds) music (listening to and playing acoustic guitar, bass guitar and analogic synths) cooking photography learning new cool things Random things I dislike warm beer Italian food blasphemy (like putting pineapple on pizza, \u0026ldquo;fettucine Alfredo\u0026rdquo;, etc\u0026hellip; üòú ) ","date":"2024-09-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/my-user-manual/","title":"My User Manual"},{"content":"If you work in software development, chances are high that your company is using open source software to build their products. Nowadays open source software is nearly everywhere: it can be included in your operating system, in commercial software or it can be responsible for hosting your website or your application.\nIn this post I will focus mainly on languages, libraries and frameworks which are being used to build software applications, because they are the components I\u0026rsquo;m most familiar with.\nContext Suppose your company needs to build a new software service which is going to be offered as an API. You will need to pick a language (for example Python), possibly a web framework (like Django, Flask or FastAPI) and some additional libraries (like SQLAlchemy, requests, etc\u0026hellip;) to build your service.\nUsually developers will pick the tools they are most familiar with, or the tools which are most popular in the community, but very few people ask themselves: who is behind these tools? Who is maintaining them? Who is fixing the bugs? Who is adding new features?\nAnd most importantly: how are these people being paid? (You are not expecting them to work for free, right? üòè)\nThe current funding models Some languages and frameworks have a no profit foundation behind them (ie: Python has Python Software Foundation, Django has Django Software Foundation, etc.) which are responsible for managing the project and the community around it.\nThey can receive a lot of independent donations or being funded by big companies like Google or Microsoft (ie: Guido Van Rossum, the creator of Python, was previously working for Google and now he is currently working for Microsoft).\nBig companies (those earning billions every year) usually don\u0026rsquo;t have any problem spending some money to sustain the tools they also use, but this also means they can have a big influence on the direction the project is taking.\nSome smaller projects (like FastAPI) are being funded entirely by independent donations: https://fastapi.tiangolo.com/fastapi-people/#sponsors but this is not a sustainable model for the long term because there is no guarantee that the donations will keep coming.\nThe Venture Capital model A different way to fund open source projects is through private investors or venture capital. For example pydantic (a library which is also used by FastAPI) has recently received a $4.7 million investment from a few VCs: https://techcrunch.com/2023/02/16/sequoia-backs-open-source-data-validation-framework-pydantic-to-commercialize-with-cloud-services/\nAnother quite recent example (which has sparked a lot of discussions in the Python community) is the case of Astral, a small company backed by VCs which are developing a couple of tools for the Python community: ruff which is a code linter and uv which is a Python package and project manager written in Rust.\nThe opinions from the Community With specific regard to Astra, there is an interesting conversation happening in a Mastodon thread, and from what I\u0026rsquo;ve seen, the opinions are quite divided.\nSome of them are concerned because this company is using Rust to implement these tools. This could cut Python developers out from directly contributing to the project, because they would need to learn a new language to do so.\nOthers are concerned because the company is backed by VCs, and they could cut funds at any time, leaving the project in an abandoned state. This of course is a valid concern, but since the project is open source, the community could fork it and continue the development.\nAnother issue that seems to be mentioned by a few people is the fact that Astral doesn\u0026rsquo;t seem to have a clear business model (at least until the time of this article). When asked directly, they have been vague about how they intend to monetize their projects and for this reason some people are being cautious before adopting their tools.\nSome people are being optimistic instead and looking at this funding as a good thing, because observing how quickly ruff and uv have evolved in so little time, they recognise a lot can be done when people are allowed to work full time on a project.\nMy own opinion In the specific case of ruff and uv, I personally don\u0026rsquo;t have anything against the fact that they are written in Rust. My mantra is \u0026ldquo;use the right tool for the job\u0026rdquo;, and if Rust is the right tool for the job (according to their tests, linting the whole CPython code base only takes 0.16s with ruff, while it takes 11.63s with flake8 and even 60s with pylint), then so be it.\nBy the way, relying on VCs for funding is a double-edged sword: on one side you now have a lot of money to hire people and let them work full time on the project. This ensures the development will proceed at fast pace and issues will be addressed quickly. On the other side, other companies and community members could initially be attracted by the tool, decide to adopt features which are not available (nor compatible with) in other similar tools and eventually find themselves locked in a proprietary ecosystem (check what recently happened to the data scientists community using Anaconda).\nWhat could we do instead I think an alternative and mid ground solution to the ones described above exists: each company should fund the projects they use and rely on most and / or they should allow employees to dedicate some time to contribute back to these projects.\nFunding projects Let\u0026rsquo;s pick for example the 5 top components a company could rely on: Python, FastAPI, SQLAlchemy, Pydantic and PostgreSQL.\nThe company should allocate a yearly budget for these components and donate regularly to the projects. Many companies have no issues purchasing licenses and seats for the services they use, so why donating regularly should be a problem?\nBy having many companies donating to a project, we avoid that a single company has too much influence on the direction of development. If a single company decides to stop funding a component, there would be many other continuing to support it.\nSmall projects (those with a single lead developer) could use the money income to be able to work full time on it. Larger projects could hire more people to work full time. The necessary structure and organisation should reflect the size of the project itself.\nThis would be a win win situation. Developers could work on something they love and being paid for it. Companies could trust the components they use even more because with people working full time on it, it\u0026rsquo;s more unlikely the project can be abandoned.\nThis is quite similar to the funding model of Django Rest Framework.\nAllowing employees to contribute back Sometimes project owners need some direct help fixing bugs, preparing releases etc\u0026hellip; another way of contribute could be allowing employees to dedicate some work time to contribute back directly. This can have multiple advantages: employees can work on something fun and they can learn new things (reminder: often employees leave a company because they want to work on more interesting stuff and because they are not learning enough in their current role) while projects can get additional (even if not regular) help.\nConclusion I\u0026rsquo;m convinced a more sustainable way for funding open source projects is possible. As software developers we can have an high impact on companies (spreading the word, speaking at conferences, leading by example etc\u0026hellip;) and this can be beneficial both for the longevity of existing projects and for the safety of companies.\nWhat do you think about this possibility?\n","date":"2024-09-07T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/building-healthy-sustainable-funding-model-opensource-software/","title":"Building a healthy and sustainable funding model for open source software"},{"content":"If you are using Tailscale in some of your devices, you also need to use Tailscale own DNS server to resolve the names of the devices in the network. If you are also a user of ControlD DNS, and you want to use it with Tailscale, you can finally do it!\nConfigure a new Endpoint on ControlD First of all, you need to create a new endpoint on ControlD. You can do it by logging in to your ControlD account, select Endpoints from the left menu, and then click on the plus button.\nScroll down to Router section and select Other as the device type. In the next screen you need to specify a name, I used tailscale-global but you can use any name you want.\nOnce you have created it, take note of the Resolver ID, because you will need it in the next step.\nConfigure the DNS on Tailscale At this point you need to go to Tailscale admin console, and select the DNS tab. Click on the Add nameserver menu, and select \u0026ldquo;Control D\u0026rdquo; from the list.\nOnce you have selected ControlD from the list, you will get this window and you will need to fill the Endpoint using the Resolver ID you got from the previous step.\nNow you can click on the Save button.\nVerify the configuration is working The configuration is done! If you already have some devices connected to your Tailscale network, you will be able to check if the configuration is working by checking the endpoints visible in the ControlD dashboard: https://controld.com/dashboard/endpoints\nIf you see a green dot next to the router icon, it means the endpoint is in use and the configuration is working.\nReferences Tailscale Documentation ControlD Documentation ","date":"2024-08-13T00:00:00Z","image":"https://www.andreagrandi.it/posts/using-controld-dns-with-tailscale/cover-controld-tailscale.png","permalink":"https://www.andreagrandi.it/posts/using-controld-dns-with-tailscale/","title":"It's now possible to use ControlD DNS with Tailscale"},{"content":"If you have ever used a flight tracking app like Flightradar24 or FlightAware you might have wondered how they get the data about the airplanes in real time. All these services use an existing network of ADS-B receivers to collect data about the airplanes in the sky.\nWhat is ADS-B? ADS-B stands for Automatic Dependent Surveillance-Broadcast and it\u0026rsquo;s a technology that allows aircraft to determine their position via satellite navigation and periodically broadcast it, enabling them to be tracked. The information can be received by air traffic control ground stations as a replacement for secondary radar.\nThis is all public information (it\u0026rsquo;s public data and you are legally allowed to receive it and share it).\nWhat do you need? To build the tracking device you need a few things:\na Raspberry Pi (I\u0026rsquo;m using a Raspberry Pi 2 Model B) an ADS-B receiver (I\u0026rsquo;m using a AirNav RadarBox FlightStick but any RTL2832/R820T2-based USB dongle should work) a 1090MHz capable antenna (I\u0026rsquo;m using a Bingfu Antenna RTL SDR, any similar antenna should work, just make sure the connector is compatible with your receiver otherwise you might need an adapter) a microSD card (I\u0026rsquo;m using a 16GB one) and a power supply for the Raspberry Pi Is a Raspberry Pi x enough? I\u0026rsquo;m using a Raspberry Pi 2 Model B, which is quite old (it was released in 2015) and it\u0026rsquo;s not the most powerful Raspberry Pi available. It\u0026rsquo;s still enough to run the software needed to track the airplanes, but if you have a newer Raspberry Pi (like a Raspberry Pi 4 or 5) you may be able to handle higher workloads (especially if you live nearby a busy airport) and feed multiple services.\nIf you are still not sure, have a look at the stats of my Raspberry Pi 2 while running the software: I\u0026rsquo;m using just 23% of the CPU and ~200MB of the total available memory.\nSetting up the Raspberry Pi Once you have all the components, you have two options to set up the Raspberry Pi:\ninstall the software from scratch (this is the most complicated way but it gives you more control over the system) use a pre-built image (this is the easiest way, you just need to flash the image on the microSD card and you are ready to go) like the one provided by FlightRadar24 or Flightaware I won\u0026rsquo;t cover the detailed instructions, but I opted for the first option (also because I wasn\u0026rsquo;t sure which service I was going to feed).\nSomething I can definitely suggest, in case you plan to install RaspbianOS from scratch, is to use the Raspberry Pi Imager and to install the Lite version of the OS (you don\u0026rsquo;t need the desktop environment for this project).\nI also suggest to install the Tailscale client and enable SSH access to the Raspberry Pi so you will be able to easily access the RaspberryPi from your computer, regardless of the network you are connected to.\nWhere to place the antenna? The antenna should be placed in a location where it has a clear view of the sky. The higher you can place it, the better the reception will be. I placed mine on the window sill, but if you have a balcony or a terrace you can place it there. To facilitate the installation of the device, I strongly recommend to at least use a WiFi connection for the Raspberry Pi, so all you need is a power supply and you just have to pass the antenna cable through the window.\nConfiguring the feeder Once you have the Raspberry Pi up and running, you need to install the software to receive the data from the ADS-B receiver and feed it to the services.\nThe instructions for this step depend on the service you want to feed. In my case I decided to feed to ADS-B Exchange and Flightradar24, which they booth provide detailed instructions and scripts to install the software:\nADS-B Exchange Flightradar24 Note: it\u0026rsquo;s worth saying that if you opt for the easier setup (using a pre-built image) you won\u0026rsquo;t have to install the software manually, but you will still need to configure the feeder to send the data to the services (by answering a few questions during the setup, about your location and type of receiver).\nAdd nice stats to your Raspberry Pi If you want to have some nice stats like the ones I showed you before, you can install install and utility called graphs1090. This utility doesn\u0026rsquo;t just show you CPU and memory stats, but also data from the ADS-B receiver like the number of messages received, the number of aircrafts tracked, and the number of positions reported.\nWhich other services could or I should feed? There are a few other serviced you could feed, and it\u0026rsquo;s totally up to you which one you want to use. Just keep in mind these two things:\neach service you feed will likely give you back a premium account, which will give you access to more features and data. So if you are interested in a specific service, you might want to feed it. most of the services are \u0026ldquo;censored\u0026rdquo; (didn\u0026rsquo;t I say the data is public?) and they don\u0026rsquo;t show all the flights. If you want to see all the flights you need to feed to ADS-B Exchange which is the only service that shows all the flights, regardless of the aircraft owner üòè Here are a few other services you could feed:\nFlightAware RadarBox24 Planefinder OpenSky Network Note: some of these services may also send you a free ADS-B receiver or a complete kit if you provide them with a good location to place the receiver (but if you don\u0026rsquo;t live in a location they are interested in, they won\u0026rsquo;t send you anything).\nConclusion With a total budget of around 120‚Ç¨ (Raspberry Pi 2 Model B, AirNav RadarBox FlightStick, Bingfu Antenna RTL SDR) and a couple of hours available, you can build your own flight tracking device and feed multiple services. It\u0026rsquo;s a fun project and it\u0026rsquo;s also useful to track the flights in your area. I didn\u0026rsquo;t know anything about ADS-B receivers before a couple of weeks ago and I totally have to \u0026ldquo;blame\u0026rdquo; my friend Alan Pope who told me about this project üòÖ\nReferences Here are other useful resources I found while setting up the Raspberry Pi:\nBuild your own Raspberry Pi flight tracker ADSB Wiki ","date":"2024-08-10T00:00:00Z","image":"https://www.andreagrandi.it/posts/tracking-airplanes-raspberrypi-adsb/cover-adsbexchange-flights.png","permalink":"https://www.andreagrandi.it/posts/tracking-airplanes-raspberrypi-adsb/","title":"Tracking airplanes with a Raspberry Pi and an ADS-B receiver"},{"content":"I recently started using Umami (a privacy first, GDPR compliant solution) for this website analytics but I immediately found out that their free plan was not enough for my needs (10k page views per month).\nSince it\u0026rsquo;s completely open source, you can self host it anywhere you want.\nI was initially evaluating between buying a Raspberry Pi or renting a VPS, but I eventually found a third solution which comes at zero cost.\nRequirements Your are going to need a few accounts if you want to follow exactly these steps, but keep in mind that my exact configuration is just an example and that you are free to use any other combination of services.\nGitHub: used to login on other services and to host a fork of Umami Umami source code: it\u0026rsquo;s available on their GitHub account Vercel: used to host the app itself, they have a generous free plan Xata: they offer a very generous (15GB) free account for managed PostgreSQL Cloudflare: this service is optional, but I found it quite useful to get a nice stats.andreagrandi.it which points to the deployed instance on Vercel I won\u0026rsquo;t get into every specific detail of the next steps (like \u0026ldquo;click on the second link of this page, then click\u0026hellip;\u0026rdquo;). If you decide to self host something like this, you should have a basic understanding of how a web application works, what GitHub and a database are etc\u0026hellip;\nGitHub Create a GitHub account, if you don\u0026rsquo;t have one, then go to https://github.com/umami-software/umami and fork their repository into your own account.\nFix Umami migration script There is an existing issue with Umami initial migration script and Xata PostgreSQL instance. Umami tries to create an extension (which Xata already has) but Xata doesn\u0026rsquo;t allow the creation of new extensions in the free plan and the returned error will make the script to fail.\nTo avoid this you need to comment the first line of this migration script (by the way, I got in touch with Xata support too and they mentioned they could eventually avoid returning an error in this case but I don\u0026rsquo;t have an estimate on when this will be done).\nXata Before you create the account on Vercel, I suggest you to create the Xata account. You will need the PostgreSQL connection string at hand during Vercel configuration, so it\u0026rsquo;s better to create it upfront.\nYou can use the GitHub account to login to Xata, then create a new database and select the \u0026ldquo;Enable direct access to Postgres\u0026rdquo; option.\nXata free plan allows you to have a database where you can store up to 15GB of data.\nFinally copy the connection string in a safe place, you will need it later.\nConnections limit Since we are here, I suggest you also add connection_limit=10 to the connection string, otherwise you risk to saturate all the available connections in the free plan.\n1 postgresql://abc123:\u0026lt;YOUR_API_KEY\u0026gt;@eu-central-1.sql.xata.sh/umami:main?sslmode=require\u0026amp;connection_limit=10 Vercel Vercel is an hosting service which allows you to run web applications in a completely managed environment. You won\u0026rsquo;t have to think about OS upgrades, manually install any framework or think about security. Everything will be managed and all the options can be adjusted from a web interface.\nThe company behind it is the same behind NodeJS.\nCreate an account using GitHub login, so you won\u0026rsquo;t have to use a specific user/password to login. Import the fork: in my case it\u0026rsquo;s the one at https://github.com/andreagrandi/umami Configure the project adding the PostgreSQL connection string: you can find this in the Xata dashboard. Test the connection and do the first deployment. Umami Once the deployment is completed, Umami should be up and running at the address specified here:\nAt this point you need to change the default password as soon as possible. Login using admin and umami and then go to the settings page to change it.\nCloudflare In case you already use Cloudflare (I don\u0026rsquo;t suggest you go through a configuration from scratch just to have a nice url), I will show you what I did to have my stats running on stats.andreagrandi.it\nTo do this, you need to create a new CNAME record in your Cloudflare dashboard, pointing to the Vercel deployment url, like I did here:\nOnce the record has been created, you need to go back to Vercel and add the new domain to the project settings (see the previous screenshot), so that the application will be reachable from the new domain.\nComplete the configuration The rest of the instructions are just about configuring the website and adding the analytics snippet to your website. I won\u0026rsquo;t go into details here, but you can find all the information you need in the official Umami documentation.\nAdd a website The first thing you have to do once you login to Umami is to add a new website. You can do this by clicking on \u0026ldquo;Settings\u0026rdquo; first, then \u0026ldquo;Websites\u0026rdquo; link in the left menu and then on the \u0026ldquo;Add website\u0026rdquo; button. You can find the complete instructions here.\nInstall the analytics snippet to your website Then you need to copy the tracking code and add it to your website. You can find the complete instructions here. How to do this depends on the technology you are using to build your website, but in general it must be placed inside the \u0026lt;head\u0026gt; tag of your website.\nConclusion If you are looking for a privacy first, GDPR compliant analytics solution, you should definitely consider Umami. It\u0026rsquo;s easy to use, free and open-source, and you don\u0026rsquo;t have to worry about your data being shared with third parties. You can host it yourself and have full control over your data.\n","date":"2024-07-31T00:00:00Z","image":"https://www.andreagrandi.it/posts/self-hosting-analytics-at-zero-cost/cover-self-hosting-analytics.png","permalink":"https://www.andreagrandi.it/posts/self-hosting-analytics-at-zero-cost/","title":"Self hosting a website analytics at zero cost"},{"content":"Recently I was planning to self host a service I\u0026rsquo;m using and I was immediately stuck on a decision: should I just buy a Raspberry Pi 5 or rent a VPS?\nRequirements Let\u0026rsquo;s starts from the basic question: what specs do I need to run this service? Reading around, it seems that something with 4GB of RAM and 20-30 GB of disk could be enough for my needs. Good.\nCosts A Raspberry Pi 5 would cost me around 100‚Ç¨ (including accessories) plus the cost of energy, while renting a VPS with similar characteristics, would cost me around 4,50‚Ç¨/month (I used Hetzner VPS prices as reference).\nTo compensate costs of purchasing a Raspberry Pi, I should keep running my service for at least a couple of years. After that time, having purchased a Raspberry Pi would come cheaper (if you consider the total cost per month) then keep paying Hetzner.\nComplexity Honestly, both solutions are quite challenging (if you want to do things in the right way) and similar in terms of administration, the main difference would be that in case of a Raspberry Pi, I would have to also include the setup of something like Tailscale Funnel, to be able to expose my device on the public Internet (my provider, Fastweb, doesn\u0026rsquo;t give public IP addresses to every user and most of them are behind a NAT).\nIn addition to this, I would also have to do the initial installation of the operating system and the network configuration, but it\u0026rsquo;s surely not the most difficult part.\nEverything else (installing a web server, a database, configuring them, installing and running the service etc\u0026hellip;) would be exactly the same.\nThe solution Both solutions are valid and both have pros and cons. So, what should one do? The best approach is evaluate both of them and pick the one that suits our needs.\nRaspberry Pi (buy) Let\u0026rsquo;s analyse the case we buy a Raspberry Pi.\nPros You physically own the hardware It can be more fun to own an electronic device After a couple of years you basically run your service for free (apart from the electricity) Your data is definitely private Cons Home connection is less reliable than a VPS network If the device breaks after two years, you have to buy it from scratch A bit more complexity for the initial setup If you don\u0026rsquo;t need the service anymore after a couple of months, you are left with an expensive device collecting dust Physical hardware gets old: the same Raspberry Pi is unlikely to serve you for many years and you will need to buy a new one every few years VPS (rent) What if we rent a Virtual Private server?\nPros Your service is always up (even when your local ISP fails) You don\u0026rsquo;t have an high initial cost If you decide to give up after a couple of months, you have only wasted less than 10‚Ç¨ Easier initial setup Cons Your data won\u0026rsquo;t be private If you keep running the service after 2 years (or the equivalent considering the cost of the Raspberry Pi) you also keep paying Conclusion As you can see, there is no right or wrong solution. Depending on our own priorities and preferences, we may choose to buy something or to rent.\nWhat did I end up choosing for my specific case? Well\u0026hellip; in the end I found a third solution which has some of the benefits of both, it was much easier to configure (I got it up and running in less than 1 hour) and most importantly costed me 0‚Ç¨!\nBut I will talk about it in another post üòâ\n","date":"2024-07-20T00:00:00Z","image":"https://www.andreagrandi.it/posts/buy-or-rent-raspberrypi-vs-vps/cover-raspberrypi-vs-vps.png","permalink":"https://www.andreagrandi.it/posts/buy-or-rent-raspberrypi-vs-vps/","title":"Buy or Rent? RaspberryPi vs VPS"},{"content":"This morning I randomly found this post from Miguel Grinberg: It\u0026rsquo;s Time For A Change: datetime.utcnow() Is Now Deprecated.\nThe main point is that Python utcnow() method is not timezone aware, and Python 3.12 is deprecating it. Therefore, you should start migrating your code to use now() instead.\nCurrent state until Python 3.11 Until Python 3.11, the utcnow() method returns a datetime object, and you would use it like this:\n1 2 3 \u0026gt;\u0026gt;\u0026gt; from datetime import datetime \u0026gt;\u0026gt;\u0026gt; datetime.utcnow() datetime.datetime(2024, 7, 17, 12, 17, 9, 835551) The issue with this method is that it doesn\u0026rsquo;t include timezone information, so you can\u0026rsquo;t be certain if the time is in UTC or not.\nChanges in Python 3.12 In Python 3.12, the utcnow() method is being deprecated. The new method to use is now(), with the appropriate parameter to make it timezone aware:\n1 2 3 \u0026gt;\u0026gt;\u0026gt; from datetime import datetime, timezone \u0026gt;\u0026gt;\u0026gt; datetime.now(timezone.utc) datetime.datetime(2024, 7, 17, 12, 20, 21, 831261, tzinfo=datetime.timezone.utc) Start migrating now The good news is that you can start migrating your code now, even if you are not using Python 3.12 yet. This way, when you upgrade to Python 3.12, you won\u0026rsquo;t have to worry about this change.\n","date":"2024-07-17T00:00:00Z","image":"https://www.andreagrandi.it/posts/python-now-time-to-migrate-from-utcnow/cover-python-utcnow.png","permalink":"https://www.andreagrandi.it/posts/python-now-time-to-migrate-from-utcnow/","title":"Python: it is now() time to migrate from utcnow()"},{"content":"Recently I finally restarted to read indie blogs more regularly. To do that I\u0026rsquo;m using NetNewsWire, a free and open-source RSS reader for macOS and iOS and every time somone posts an interesting article, for example on Mastodon, I make sure to follow the RSS feed of that blog.\nIn a few weeks, I\u0026rsquo;ve collected a list of blogs that I follow and I thought it would be nice to share it with you. I\u0026rsquo;m trying to read less mainstream news and more personal blogs, because I think that the personal touch of a blog is what makes it interesting and unique.\nSome of the blogs I follow Here are some of the blogs I follow and recommend. I try to read all the blogs I follow, but these surely are the ones I read more often:\nBrain Barking Author: dr. Wouter Groeneveld A blog about tech, games and food.\nJeff Triplett\u0026rsquo;s Micro.blog Author: Jeff Triplett Jeff is a DjangoCon organiser and a Python Software Foundation Fellow. He writes about Django, Python, and other tech topics.\nJuha-Matti Santala Author: Juha-Matti Santala Juhis writes a lot! About tech, life, and about writing. He often inspires me to write more.\nTerence Eden\u0026rsquo;s Blog Author Terence Eden Terence writes about tech, privacy, and other interesting topics. He often writes about very original gadgets and services and I always learn something new from him. Bonus point, he\u0026rsquo;s also a very nice person!\nFull list You can find the full list at this address: https://gist.github.com/andreagrandi/3226460db523a4c60e72f22e9ad896e9 or you can download the OPML file from here.\nTell me about your blog! I\u0026rsquo;m always looking for new blogs to follow, especially if they are indie blogs. If you have a blog and you think it\u0026rsquo;s worth reading, please let me know either as a reply on Mastodon, or leaving a comment on the gist on GitHub.\n","date":"2024-07-12T00:00:00Z","image":"https://www.andreagrandi.it/posts/my-curated-list-of-indie-blogs/cover-blog-list.webp","permalink":"https://www.andreagrandi.it/posts/my-curated-list-of-indie-blogs/","title":"My curated list of indie blogs"},{"content":"If you are using a cloud storage service like Google Drive, Dropbox, OneDrive, etc., you should be aware that your files are not encrypted by default. This means that the cloud provider is able to access and, in some cases, even share them with third parties. In case your cloud provider gets hacked, your files could also be exposed to the public.\nTo prevent this from happening, you can use a tool like Cryptomator to automatically encrypt your files before uploading them to the cloud.\nHow does it work? Cryptomator is a free and open-source software that allows you to create an encrypted vault on your computer where you can store your files. Once you have added your files to the vault, Cryptomator will encrypt them using strong encryption algorithms (256 bit AES).\nTo be more clear, Cryptomator doesn\u0026rsquo;t upload your files. Your cloud provider application does:\nYou write files to the Cryptomator vault -\u0026gt; Cryptomator encrypts them and writes them in a folder which is synced up to your cloud provider -\u0026gt; Your cloud provider application uploads the encrypted files to the cloud.\nWhen you want to access your files, you simply access them from your mounted vault and Cryptomator will automatically decrypt them for you.\nOnce the application is installed, you will see a new volume in your file manager and you will be able to work with your files as if they were on your file system. The cloud provider will only see the encrypted version of them:\nWhat systems are supported? Cryptomator is available for most operating systems, including Windows, MacOS, Linux, Android and iOS. This means that you can use it on your desktop computer, laptop, smartphone or tablet. The only limitation is that your cloud provider must have an application for the platform you are using, so you can keep your encrypted files in sync.\nI personally use it to keep my files safe on pCloud and I access them from my Mac, iPhone and iPad. Yes, I\u0026rsquo;m aware that pCloud has its own encryption system, but it comes at an additional cost to the user. I also think that it\u0026rsquo;s safer if they don\u0026rsquo;t have the encryption keys, in case they get hacked.\nHow much does it cost? Cryptomator is free and open-source, which means that you can use it without paying anything. The only application that is not free is the one for iOS, which costs a few dollars if you want to unlock all the features (for example the ability to write files), but you can still use it for free to read files (and there is a demo version available too).\nConclusion If you are using a cloud storage service and you want to keep your files safe and secure, you should definitely consider using Cryptomator. It is easy to use, free and open-source, and you don\u0026rsquo;t have to worry about your cloud provider being 100% safe, because even if your files get leaked, they will be encrypted and no one will be able to read them without the encryption key.\n","date":"2024-07-08T00:00:00Z","image":"https://www.andreagrandi.it/posts/cryptomator-end-to-end-encrypt-files-in-cloud/man-vault.png","permalink":"https://www.andreagrandi.it/posts/cryptomator-end-to-end-encrypt-files-in-cloud/","title":"Cryptomator: end-to-end encrypt files in any cloud"},{"content":"If you own a website and you don\u0026rsquo;t want AI bots to crawl it and you are already using Cloudflare, you are in luck. Cloudflare has recently added a new feature that allows people to easily block AI bots from crawling their website.\nSetup To enable this feature, you need to login to your Cloudflare account, select the website and once you are in the dashboard, go to the \u0026ldquo;Security\u0026rdquo; section and finally click on the \u0026ldquo;Bots\u0026rdquo; link.\nFrom there you need to enable both \u0026ldquo;Bot Fight Mode\u0026rdquo; and \u0026ldquo;Block AI Scrapers and Crawlers\u0026rdquo;.\nYes, it\u0026rsquo;s that simple! And you will be happy to know that this feature is available to all Cloudflare users, even those on the free plan.\nDoes it really work? According to Cloudflare logs, there seem to be a lot of AI bots trying to crawl my website. Here you can see just a few of them:\nIn particular you can see a bot coming from Singapore and recognised as Bytedance (the same company that owns TikTok) which are well known for their scraping activities.\nOther AI companies, like PerplexityAI, seem to have found a way around these blocks, because if you try to ask Perplexity to summarise one of the pages of this website, it will still be able to do it, but I\u0026rsquo;m sure that Cloudflare will soon find a way to block them too.\nConclusion I think people should be able to decide if they want their content to be used by AI models or not and Cloudflare is now providing an easy option to do that. AI tools are not bad per se, but they should not be built using other people\u0026rsquo;s content without their consent.\n","date":"2024-07-06T00:00:00Z","image":"https://www.andreagrandi.it/posts/use-cloudflare-to-block-ai-bots/cloudflare-ai-bots-settings.png","permalink":"https://www.andreagrandi.it/posts/use-cloudflare-to-block-ai-bots/","title":"If your website uses Cloudflare, you can now easily block AI bots"},{"content":"The robots.txt file is a simple text file that tells web robots (like search engine crawlers) which pages on your site to crawl and which not to crawl. It\u0026rsquo;s a standard that has been around for a long time and it\u0026rsquo;s still used today.\nSome examples of rules you can put in a robots.txt file are:\n1 2 User-agent: * Disallow: /private/ This rule tells all web robots to not crawl the /private/ directory.\n1 2 User-agent: Googlebot Disallow: /users/ This rule tells Googlebot to not crawl the /users/ directory.\nThen AI came In the age of AI, the existing robots.txt specification is not enough to express the rules for web crawlers. We can only tell agent if they can or cannot crawl a certain path, but we cannot express more complex rules.\nIn my opinion we should be able to express more detailed rules, like:\nIndexing: should a web crawler be able to index the content? Caching: should a web crawler be able to cache the content? LLM Training: should a web crawler be able to use the content to train a language model? Summarising: should a web crawler be able to summarise the content? etc\u0026hellip; Some of the above things were not possible in the past and it should be up to the website owner to decide if they want their content to be used in such ways.\nEnforcing the rules In addition to more detailed rules, we need new regulations to enforce them. It looks like the robots.txt file is not enough to stop certain companies from doing what they want.\nAs someone recently found out, Perplexity AI is using a fake user agent to crawl websites, pretending to be a regular user. This is a clear violation of the rules specified in robots.txt file. This claim has recently been confirmed by Wired and by MacStories.\nConclusion As we have seen, having good rules is not enough if they are not enforced. In particular we need regulators to take care of complaints from content owners and fine companies that do not respect the rules (like Perplexity AI), because small content creators cannot afford to take legal actions against big companies.\nAs with every single thing, it\u0026rsquo;s never \u0026ldquo;the tool\u0026rdquo;, but rather \u0026ldquo;how you use it\u0026rdquo;. AI itself can bring innovation in certain fields, but this can\u0026rsquo;t be done at the expense of other people\u0026rsquo;s work and rights.\nDisclaimer Yes, of course the cover image has been generated with AI. It\u0026rsquo;s far from perfect, but it\u0026rsquo;s still better than my drawing skills. The content of this article instead is 100% human generated.\n","date":"2024-06-22T00:00:00Z","image":"https://www.andreagrandi.it/posts/we-need-evolved-robotstxt-and-regulations/we-need-new-robots.png","permalink":"https://www.andreagrandi.it/posts/we-need-evolved-robotstxt-and-regulations/","title":"We need an evolved robots.txt and regulations to enforce it"},{"content":"Reading news and blog posts can be quite time consuming if we manually go to news websites to check if something new is out or if we spend all day checking social media, waiting for people we follow to post their latest article.\nAn efficient way to fetch new content is to follow the news sites and the blogs we want, using their RSS feed.\nWhat is the best way to do this for iOS and MacOS? There is no \u0026ldquo;best\u0026rdquo; way, since there are plenty of RSS clients and combinations of services, but I will tell you a simple and free solution I\u0026rsquo;m using.\nNetNewsWire and iCloud sync The client I\u0026rsquo;m using is NetNewsWire. It\u0026rsquo;s free, open source and available for both iOS and MacOS.\nThis client supports different synchronisation services, including iCloud, FeedBin and Inoreader or it can be used just on a single device, without using any of these services.\nI initially tried using Inoreader and it was \u0026ldquo;ok\u0026rdquo;, but it\u0026rsquo;s a paid service which injects ads in its free plan. Also, its cheaper paid plan only removes ads, without offering any additional value. I really couldn\u0026rsquo;t justify paying a subscription just to keep my feeds synced across devices, so I opted to use iCloud which, in my case, is exactly what I need and I don\u0026rsquo;t have to purchase any additional plan (I\u0026rsquo;m already on a paid plan, but even the free plan is enough for this).\nConclusion I\u0026rsquo;m sure there are better solutions around (especially RSS clients) and I would be glad to hear about them, but for now this simple client and iCloud is all I need to enjoy the news and read blog posts.\n","date":"2024-06-04T00:00:00Z","image":"https://www.andreagrandi.it/posts/simple-solution-to-read-rss-content-on-ios-macos/rss-sync-cover.webp","permalink":"https://www.andreagrandi.it/posts/simple-solution-to-read-rss-content-on-ios-macos/","title":"Simple and free solution to read content from RSS feeds on iOS and MacOS"},{"content":"When you have to compare dates in a SQL query, you often want to ignore the time part. For example if you have two very common fields like created_at and updated_at and you want to know if they are the same day, you have to truncate the time part.\nHow to do this depends on the database you are using. Here is how you can do it in PostgreSQL.\n1 2 3 4 SELECT * FROM users WHERE DATE(created_at) \u0026lt;\u0026gt; DATE(updated_at) ORDER BY created_at DESC; This query will return all the users where the created_at and updated_at fields are not on the same day, ignoring the time part.\n","date":"2024-05-18T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/truncating-time-in-postgresql-query/","title":"Truncating time when querying a PostgreSQL database"},{"content":"In the last 3 days I had the opportunity to participate to an internal hackathon organised by the company I work for.\nWe had to build a project based on an SDK and the needed skills to build it were those of a frontend developer.\nBeing a backend developer and having very basic (almost none) frontend skills, I was suggested to use ChatGPT to write some of the code.\nChallenge accepted Of course I accepted and I worked on the project with another colleague (also backend developer) who also used ChatGPT to write some of the code.\nHow I normally use ChatGPT ChatGPT is not new to me. I use it daily for my work, but I mostly use it as a \u0026ldquo;search engine on steroids\u0026rdquo;.\nRather than searching something on a search engine, read a few blog posts or forums, then landing on a Stack Overflow page, to find some code and adapt it, I ask the same question to ChatGPT and then I adapt the produced example.\nI never ask for a complete feature or even a whole method. I usually need a small example for a very specific thing which I then insert in an existing code base.\nHow I used it for the hackathon In the case of the hackathon, I knew what I wanted to achieve, but I had no idea how to do it, so I asked it to produce almost everything I needed.\nAt the beginning it was easy: I had nothing and I was adding small pieces every time.\nAfter a little bit I ended up with a lot of code I couldn\u0026rsquo;t understand anymore.\nI was having an issue with the produced code and ChatGPT, instead of helping, started to allucinate.\nInstead of asking it to fix a specific issue, I was passing back the whole JavaScript file, asking for the issues to be corrected.\nI didn\u0026rsquo;t notice that while fixing the issues, ChatGPT was also rewriting the whole file and in a couple of occasions it started changing the logic entirely.\nThe errors disappeared but the code started behaving differently.\nIn the end we had to revert to a simpler and older version of our code, which at least was working correctly.\nConclusion I remain confident that tools like ChatGPT can be valuable assets for software developers, provided they already possess a strong understanding of the relevant domain, such as Python backend development in my experience.\nHowever, for areas outside one\u0026rsquo;s expertise, such as frontend development, relying solely on ChatGPT is insufficient.\nWhat is your experience with similar tools? Let me know in the comments.\n","date":"2024-05-01T00:00:00Z","image":"https://www.andreagrandi.it/posts/ai-wont-take-your-job-yet/ai-doing-developers-work-cover.webp","permalink":"https://www.andreagrandi.it/posts/ai-wont-take-your-job-yet/","title":"AI won‚Äôt take your Software Developer job (not yet)"},{"content":"Every now and then, my Mastodon or LinkedIn timelines are full of messages either praising or condemning the use of AI tools for coding.\nAre they good or bad then? As usual I think the truth is in the middle, or to be more precise: it depends on how you use them.\nContext In the last couple of years, thanks to the advancements in the field of Large Language Models (also known as Generative AI) a few \u0026ldquo;AI tools\u0026rdquo; have been made available, to help developers with coding tasks.\nTools like GitHub Copilot or ChatGPT are being used more frequently by developers. They can either open new possibilities (like helping us to write code in a language we are not familiar with) or just speed up tasks we would do in a different (often slower) way.\nBeware of hallucinations Before we get into good or bad examples, it\u0026rsquo;s important to remember that by definition, LLMs (large language models) can hallucinate, which means that under certain conditions (which can occur unexpectedly) the model can make certain things up.\nEven ChatGPT reminds us about this, infact at the bottom of every page you will find:\nChatGPT can make mistakes. Consider checking important information.\nAn example of Good usage Before the existance of ChatGPT, whenever I had to do something I didn\u0026rsquo;t know exactly how to do it, my first \u0026ldquo;go-to\u0026rdquo; tool was Google.\nExample: \u0026ldquo;How do I find duplicated SQL rows with the same field?\u0026rdquo;\nI would search the thing I wanted to do, read a couple of blog posts talking about the subject, figure out if something was possible and then refining my search to find some code examples (usually on Stack Overflow) which then I had to adapt to my existing code base, after reading some documentation.\nAsking the same question to ChatGPT produced a correct (at least in my case) SQL query along with an explanation of the syntax being used (I tested this query on a local database, adapting field names to my own and it produced the expected result).\nI still had to adapt the produced code to my needs (renaming fields, inserting this script in a larger context etc\u0026hellip;) but I certainly saved a lot of time compared to the previous workflow.\nAI tools are like driving assistance systems: they are not supposed to drive for you, but they will help you to maintain the correct distance from the front vehicle, stay below the speed limits, warn you of you start overtaking a car when another one is close behind you etc\u0026hellip;\nConclusion AI tools can be very helpful with coding tasks. Like any tool, we are in charge of using them correctly and ensuring the end result is accurate. Paying attention to avoid introducing false information or non working code is crucial.\n","date":"2024-03-09T00:00:00Z","image":"https://www.andreagrandi.it/posts/using-ai-tools-for-coding-good-or-bad/ai-tools-cover.webp","permalink":"https://www.andreagrandi.it/posts/using-ai-tools-for-coding-good-or-bad/","title":"Using AI tools for coding: good or bad?"},{"content":"I recently started using iA Writer to edit my MarkDown files on iPad and I\u0026rsquo;m honestly quite impressed by its simplicity.\nWith the latest version they introduced a feature called Authorship which basically helps you to keep track of external contributors.\nFor example, suppose you asked a friend (or even ChatGPT) to write a conclusion for one of your articles, you copy-paste the text on your article and you start editing it. How do you keep track of what you or the other source wrote? With the Authorship feature, text edited by you will be rendered in a different way, so you can distinguish it.\nI think this is a brilliant idea and even if I don\u0026rsquo;t make much usage of GPT to write my posts (almost none so far), I may use it in the future.\nThe problem The problem with this feature is that if you enable it for one of your documents, iA Writer will add an \u0026ldquo;hidden\u0026rdquo; Authorship section at the end of the file.\nThis section won\u0026rsquo;t be visible in iA while editing the text, but it will be visible in any other editor.\nIn my case, I plan to use iA Writer to write my blog posts, which I then push to GitHub using Working Copy, where they are finally transformed by Hugo to my static website.\nUnless I edit the file with a different editor, if I submit my article as is, Hugo (but even Pelican, or Jekyll etc\u0026hellip; basically any engine which doesn\u0026rsquo;t know how to handle this block of information) will render the Authorship block into the final HTML page, which is something nobody really wants.\nPossible solutions I asked iA people on Mastodon about this issue and they told me they had considered different options but in any case something will break for someone.\nI agree, it\u0026rsquo;s not easy to find a solution which can cover every possible case, but I still think there could be margin for improvement.\nSaving Authorship in an external file If these additional data was saved in an external file, it would be much easier to exclude it from the built pages. By the way, this would mean spreading the information across different files, making it more difficult to maintain.\nUsing YAML metadata Adding the Authorship as metadata could be the best option, for a couple of reasons.\niA Writer already makes use of YAML metadata where you can add information, so existing users would be used to see something at the beginning of the file which is not their content.\nAny unknown metadata is usually ignored by static websites generators (at least Hugo and Pelican behave in this way) so the Authorship won\u0026rsquo;t be rendered in the final HTML page.\nA workaround for Hugo While I hope iA will consider giving alternative options in the future, I\u0026rsquo;ve written a simple script you can use to remove all Authorship blocks from any MarkDown file found in your content.\nPlease note that this will remove any Authorship block from your MarkDown files, even if you include them in a code block. If you want to improve the script, feel free to do it and let me know.\nConclusion The introduction of the Authorship feature in iA Writer presents a creative solution for managing and distinguishing between original content and external contributions within documents.\nWhile the feature offers significant advantages for content creators seeking to track their collaborations, it also introduces challenges, particularly in the integration with static site generators like Hugo.\nMy advice is that, as users, we give some constructive feedback to iA (you can contact them at support+newfeature@ia.net) to let them know how to improve this feature.\nAdditionally, if you are more familiar with GitHub, you can discuss this specific feature directly in their repository.\n","date":"2024-03-05T00:00:00Z","image":"https://www.andreagrandi.it/posts/ia-writer-authorship-brilliant-feature-problematic-implementation/ia-writer-authorship-cover.webp","permalink":"https://www.andreagrandi.it/posts/ia-writer-authorship-brilliant-feature-problematic-implementation/","title":"iA Writer Authorship: a brilliant feature with a problematic implementation"},{"content":"For my job (Software Developer) I make a daily use of tools like GitHub Copilot and ChatGPT. I want to explore alternative solutions which can be hosted autonomusly, without relying on an external service.\nDisclaimer Before I continue, let me clarify that these are tools which makes my job faster, they don\u0026rsquo;t do the job for me: a wrong assumption made by so many people is that AI tools will do the work for you.\nThis is quite not true. You are still responsible of knowing what to do, understanding the problem, asking the right questions and knowing what to do with the answers.\nIf you regularly search for stuff on Google or any other engine, to find examples in blog posts or Stack Overflow, read someone else example and then adapt the code for your needs, there is nothing wrong automating this: you are still in charge of the final result.\nThe experiment After I recently experimented with local LLMs using Ollama, I wanted to figure out if I could use some of these models to replace GitHub Copilot.\nMy intent is not to save some money (my company pays for these tools) or for privacy reasons (it would be pointless to keep your code \u0026ldquo;secret\u0026rdquo; from GitHub if you use it to host it), but to find out how good these alternative tools are and\u0026hellip; for fun!\nSetup and available resources The laptop I\u0026rsquo;m using is a MacBook Pro with M2 Pro CPU and 32 GB RAM.\nThis machine must be able to run my basic requirements, which are:\nSlack Docker (running my work containers) VSCode Safari / Chrome Let\u0026rsquo;s see if it can also run a Copilot replacement.\nTested models and extensions Basically, to run a Copilot replacement, you need to be able to run an LLM and use one of the available extensions for VSCode (in my case I use VSCode, but similar extensions exist for other IDEs).\nI\u0026rsquo;m running the models locally using Ollama. If you need to know how to use it, you can refer to my previous post.\nThe models I tested are:\nstable-code:3b-code-q4_0 codellama:7b-code-q4_K_M codellama:13b-code-q4_K_M The number before the b usually represents the number of parameters (3 billions, 7 billions, 13 billions etc\u0026hellip;) and you approximately need 4 GB, 8 GB and 16 GB RAM to use them.\nMeta has released models with 34 billions and 70 billions parameters, which are even more powerful, and you can find them here: https://ollama.com/library/codellama but you will need 64-128 GB RAM to run them properly.\nThe extensions I tested are:\nLLama Coder https://marketplace.visualstudio.com/items?itemName=ex3ndr.llama-coder Code GPT https://marketplace.visualstudio.com/items?itemName=DanielSanMedium.dscodegpt twinny https://marketplace.visualstudio.com/items?itemName=rjmacarthy.twinny Results The results I got have been quite mixed and mostly depending on the LLM model I was testing, rather than on the extension I was using.\nA model like stable-code:3b-code-q4_0 was quite fast to complete the code I was typing, but very often giving me wrong code or pure garbage (ie: the model wasn\u0026rsquo;t even able to correctly structure a simple Python method or to maintain the correct indentation)\nModels like codellama:7b-code-q4_K_M or codellama:13b-code-q4_K_M were giving me better results but despite having 32 GB RAM available and a quite fast CPU, they were taking 3-4 seconds to complete what I was typing, making themselves useless (at least for my use case).\nNone of them was even remotely close to the speed and accuracy of GitHub Copilot.\nConclusion While the idea of having a personal and private instance of a code assistant is interesting (and can also be the only available option in certain environments), the reality is that achieving the same level of performance as GitHub Copilot is quite challenging.\nDespite these challenges, I think with time both available models and extensions will get better and better, improving their quality and maybe reducing the amount of required resources.\nIn case I missed some better model or extension, please feel free to let me know in the comments. I will be glad to do more tests and update this posts or write a new one in the future.\nIn the mean time, at least for my personale usage, I think I will stick with GitHub Copilot.\n","date":"2024-03-03T00:00:00Z","image":"https://www.andreagrandi.it/posts/self-hosting-copilot-replacement/self-hosting-copilot-cover.webp","permalink":"https://www.andreagrandi.it/posts/self-hosting-copilot-replacement/","title":"Self hosting a Copilot replacement: my personal experience"},{"content":"I recently discovered a new tool called Ollama, which allows you to run Large Language Models (LLMs) locally, without the need of a cloud service. Its usage is similar to Docker, but it\u0026rsquo;s specifically designed for LLMs. You can use it as an interactive shell, through its REST API or using it from a Python library.\nWhat is Ollama? Ollama is a tool to run and manage Large Language Models locally. It\u0026rsquo;s designed to be easy to use and to be used in different ways:\nInteractive shell: you can run Ollama as a shell and interact with it, you will be able to chat with it, ask questions, and simulate a conversation. REST API: you can run Ollama as a service and send requests to it. Python library: you can use Ollama from your Python code. How does it work? After you installa Ollama, you can start chatting with it by simply using this command:\n1 ollama run llama2 ollama will pull the llama2 model from the cloud and start the interactive shell. You can then start chatting with it.\nDemo Using it through its REST API Ollama comes with an included REST API which you can use to send requests to it. For example to send a question to the llama2:13b-chat model you can use the following command:\n1 2 3 4 5 curl http://localhost:11434/api/generate -d \u0026#39;{ \u0026#34;model\u0026#34;: \u0026#34;llama2:13b-chat\u0026#34;, \u0026#34;prompt\u0026#34;: \u0026#34;What can you tell me about Pink Floyd?\u0026#34;, \u0026#34;stream\u0026#34;: false }\u0026#39; the response will be a JSON object with the generated text, like this one:\n1 {\u0026#34;model\u0026#34;:\u0026#34;llama2:13b-chat\u0026#34;,\u0026#34;created_at\u0026#34;:\u0026#34;2024-03-01T17:23:39.094249Z\u0026#34;,\u0026#34;response\u0026#34;:\u0026#34;\\nAh, Pink Floyd! One of the most iconic and influential rock bands of all time. The band was formed in 1965 by students Syd Barrett, Nick Mason, Roger Waters, and Richard Wright at the University of Cambridge. They began as a folk-rock group, but soon developed their own unique sound that blended psychedelic rock, progressive rock, and experimental music.\\n\\nPink Floyd is known for their immersive live shows, elaborate album artwork, and thought-provoking lyrics. Their music explores themes such as life, death, technology, and the human condition. Some of their most famous albums include \\\u0026#34;The Dark Side of the Moon,\\\u0026#34; \\\u0026#34;Wish You Were Here,\\\u0026#34; and \\\u0026#34;The Wall.\\\u0026#34;\\n\\nSyd Barrett, the band\u0026#39;s primary songwriter and lead vocalist, left the band in 1968 due to mental health issues. Roger Waters, who took over as the main songwriter and bassist, became the driving force behind the band\u0026#39;s sound and vision. David Gilmour, a guitarist and vocalist, joined the band in 1967 and remained a key member until the band\u0026#39;s breakup in 1996.\\n\\nPink Floyd released several critically acclaimed and commercially successful albums throughout their career, including \\\u0026#34;Atom Heart Mother,\\\u0026#34; \\\u0026#34;Meddle,\\\u0026#34; \\\u0026#34;Obscured by Clouds,\\\u0026#34; and \\\u0026#34;The Final Cut.\\\u0026#34; They are considered one of the greatest rock bands of all time, with a legacy that continues to inspire new generations of musicians and fans.\\n\\nSome of Pink Floyd\u0026#39;s most famous songs include \\\u0026#34;Comfortably Numb,\\\u0026#34; \\\u0026#34;Another Brick in the Wall (Part 2),\\\u0026#34; \\\u0026#34;Wish You Were Here,\\\u0026#34; and \\\u0026#34;Shine On You Crazy Diamond.\\\u0026#34; Their music has been covered by countless artists, and their influence can be heard in many different genres of music.\\n\\nPink Floyd\u0026#39;s live shows were known for their elaborate light shows, lasers, and pyrotechnics. They performed at numerous iconic venues, including the London Coliseum, the Royal Albert Hall, and the Earls Court Exhibition Centre. The band also made several memorable appearances at festivals such as the Bath Festival of Blues and Progressive Music and the Knebworth Festival.\\n\\nIn 1986, Pink Floyd released \\\u0026#34;The Wall,\\\u0026#34; a rock opera based on Roger Waters\u0026#39; experiences in school and his feelings about isolation and disillusionment. The album was a huge commercial success and spawned several hit singles, including \\\u0026#34;Another Brick in the Wall (Part 2)\\\u0026#34; and \\\u0026#34;Comfortably Numb.\\\u0026#34;\\n\\nPink Floyd continued to experiment with new sounds and techniques throughout their career. They incorporated elements of electronic music, synthesizers, and sound effects into their recordings, creating a distinctive and innovative sound. The band\u0026#39;s final studio album, \\\u0026#34;The Division Bell,\\\u0026#34; was released in 1994 and marked the end of Pink Floyd\u0026#39;s active career.\\n\\nOverall, Pink Floyd is a groundbreaking and influential rock band that has left an indelible mark on the music world. Their unique sound, thought-provoking lyrics, and iconic live shows have made them one of the most beloved and enduring bands of all time.\u0026#34;,\u0026#34;done\u0026#34;:true,\u0026#34;context\u0026#34;:[518,25580,29962,3532,14816,29903,29958,5299,829,14816,29903,6778,13,13,5618,508,366,2649,592,1048,349,682,383,18966,29973,518,29914,25580,29962,13,13,17565,29892,349,682,383,18966,29991,3118,310,278,1556,9849,293,322,7112,2556,7679,22706,310,599,931,29889,450,3719,471,8429,297,29871,29896,29929,29953,29945,491,8041,13923,2261,13158,29892,13853,28095,29892,14159,399,10412,29892,322,6123,22927,472,278,3014,310,12585,29889,2688,4689,408,263,19589,29899,20821,2318,29892,541,4720,8906,1009,1914,5412,6047,393,1999,2760,11643,287,295,293,7679,29892,6728,573,7679,29892,322,17986,4696,29889,13,13,29925,682,383,18966,338,2998,363,1009,5198,414,573,5735,3697,29892,19430,3769,1616,1287,29892,322,2714,29899,16123,17223,26627,1199,29889,11275,4696,3902,2361,963,267,1316,408,2834,29892,4892,29892,15483,29892,322,278,5199,4195,29889,3834,310,1009,1556,13834,20618,3160,376,1576,15317,19160,310,278,17549,1699,376,29956,728,887,399,406,2266,1699,322,376,1576,14406,1213,13,13,29903,2941,2261,13158,29892,278,3719,29915,29879,7601,4823,13236,322,3275,20982,391,29892,2175,278,3719,297,29871,29896,29929,29953,29947,2861,304,19119,9045,5626,29889,14159,399,10412,29892,1058,3614,975,408,278,1667,4823,13236,322,12760,391,29892,3897,278,19500,4889,5742,278,3719,29915,29879,6047,322,18551,29889,4699,11788,29885,473,29892,263,11210,391,322,20982,391,29892,8772,278,3719,297,29871,29896,29929,29953,29955,322,9488,263,1820,4509,2745,278,3719,29915,29879,2867,786,297,29871,29896,29929,29929,29953,29889,13,13,29925,682,383,18966,5492,3196,3994,1711,1035,13190,322,7825,5584,9150,20618,10106,1009,6413,29892,3704,376,4178,290,17778,21869,1699,376,19302,29881,280,1699,376,6039,1557,2955,491,14293,29879,1699,322,376,1576,9550,315,329,1213,2688,526,5545,697,310,278,14176,7679,22706,310,599,931,29892,411,263,25000,393,18172,304,8681,533,716,1176,800,310,2301,14722,322,24909,29889,13,13,9526,310,349,682,383,18966,29915,29879,1556,13834,12516,3160,376,1523,3921,2197,405,3774,1699,376,2744,1228,1771,860,297,278,14406,313,7439,29871,29906,511,29908,376,29956,728,887,399,406,2266,1699,322,376,2713,457,1551,887,14279,1537,22904,898,1213,11275,4696,756,1063,10664,491,2302,2222,17906,29892,322,1009,9949,508,367,6091,297,1784,1422,2531,690,310,4696,29889,13,13,29925,682,383,18966,29915,29879,5735,3697,892,2998,363,1009,19430,3578,3697,29892,1869,414,29892,322,11451,4859,3049,1199,29889,2688,8560,472,12727,9849,293,6003,1041,29892,3704,278,4517,1530,895,398,29892,278,7021,10537,6573,29892,322,278,5290,3137,9245,1222,6335,654,11319,29889,450,3719,884,1754,3196,26959,519,21712,472,29482,1338,1316,408,278,28256,8518,310,23434,322,20018,573,6125,322,278,476,484,29890,12554,8518,29889,13,13,797,29871,29896,29929,29947,29953,29892,349,682,383,18966,5492,376,1576,14406,1699,263,7679,14495,2729,373,14159,399,10412,29915,27482,297,3762,322,670,21737,1048,11695,362,322,766,453,3958,358,29889,450,3769,471,263,12176,12128,2551,322,29178,287,3196,7124,22102,29892,3704,376,2744,1228,1771,860,297,278,14406,313,7439,29871,29906,5513,322,376,1523,3921,2197,405,3774,1213,13,13,29925,682,383,18966,7572,304,7639,411,716,10083,322,13698,10106,1009,6413,29889,2688,11039,630,3161,310,27758,4696,29892,14710,267,19427,29892,322,6047,9545,964,1009,2407,886,29892,4969,263,8359,573,322,24233,1230,6047,29889,450,3719,29915,29879,2186,8693,3769,29892,376,1576,7946,10914,1699,471,5492,297,29871,29896,29929,29929,29946,322,10902,278,1095,310,349,682,383,18966,29915,29879,6136,6413,29889,13,13,3563,497,29892,349,682,383,18966,338,263,5962,1030,5086,322,7112,2556,7679,3719,393,756,2175,385,1399,295,1821,2791,373,278,4696,3186,29889,11275,5412,6047,29892,2714,29899,16123,17223,26627,1199,29892,322,9849,293,5735,3697,505,1754,963,697,310,278,1556,1339,8238,322,1095,3864,22706,310,599,931,29889],\u0026#34;total_duration\u0026#34;:46945500291,\u0026#34;load_duration\u0026#34;:9055150333,\u0026#34;prompt_eval_count\u0026#34;:31,\u0026#34;prompt_eval_duration\u0026#34;:241905000,\u0026#34;eval_count\u0026#34;:737,\u0026#34;eval_duration\u0026#34;:37647125000} Using it from a Python library Ollama has libraries for different programming languages, including Python. You can use it from your Python code like this:\n1 2 3 4 5 6 7 8 9 10 11 import ollama response = ollama.chat(model=\u0026#39;llama2:13b-chat\u0026#39;, messages=[ { \u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;Can you talk me about Pink Floyd?\u0026#39;, \u0026#39;stream\u0026#39;: False, }, ]) print(response[\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;]) Additional capabilities With Ollama you can also create a new model based on an existing one. Check the official documentation for more information.\nIn my examples I used the llama2:13b-chat model, but there are other models available, you can find the full list here.\nConclusion I think Ollama is a great tool for people who want to experiment with Large Language Models without the need of a cloud service. It\u0026rsquo;s easy to use and it\u0026rsquo;s available for different programming languages. I\u0026rsquo;m looking forward to see how it will evolve in the future.\n","date":"2024-03-01T00:00:00Z","image":"https://www.andreagrandi.it/posts/ollama-running-llm-locally/ollama-cover.webp","permalink":"https://www.andreagrandi.it/posts/ollama-running-llm-locally/","title":"Ollama: running Large Language Models locally"},{"content":"Recently I reviewed my backup strategy and started using a new open source software and a cloud service to keep my data safe.\nBefore this my only backup was keeping my data in the cloud (specifically I use pCloud), but I started thinking: what if they shut down? What if I loose access to my account?\nThis convinced me to have an additional copy of my data.\nActually two additional copies: a local one, on an USB disk, which is of course not reliable (disks can and will break!), but it\u0026rsquo;s fast if I need to recover something and a remote one, on a dedicated cloud service, which is of course slower but quite reliable (you pay for your data to be kept safe).\nMy personal requirements Requirements can be different from person to person, but in this case I think they are quite common sense.\nThe first thing I want from a backup solution is that it is encrypted and that I will be the only one having the encryption keys.\nThe second requirement is that the backup is incremental. This means that if I do a new backup every day, I expect the new backup to only contain the data which changed from the previous one.\nThe third requirement is that the backup can be automated. I don‚Äôt want to have to remember to backup my data, I want it to happen automatically.\nIn addition to the above, I have a strong preference for solutions which are open source and possibly free.\nBorgBackup The solution which matches all the above requirements is BorgBackup.\nI won\u0026rsquo;t spend time to explain how to install it, because the official documentation is very well made.\nI also won\u0026rsquo;t spend time to explain how to configure it, because that\u0026rsquo;s not how I used it.\nBorg is a command line software and using and configuring it is not straightforward, that\u0026rsquo;s why I immediately looked for a UI.\nVorta Here comes Vorta. As I mentioned before, while Borg has all the features I need, unfortunately it\u0026rsquo;s not easy to use and configure. A command line utility is a must if you are backing up a remote server, but it\u0026rsquo;s not really user friendly for desktop usage.\nVorta allows you to easily configure a new backup. All you have to do is create a new repository, set a password, select the files and folders you want to backup and decide from manual backup and regularly scheduled one.\nOptionally (but I strongly suggest you do it) you can flag a couple of options which will verify the backup integrity regularly.\nIn case you need to recover your files, you just have to select an existing archive and a folder on your laptop which will be used to mount the volume. At this point you will be able to access your files from the operating system file manager.\nBorgBase BorgBase is a service which provides hosted repositories for Borg backup.\nThey have three commercial plans, starting from $2/month for 250 GB (which is the plan I have) but they also offer a free plan with 10 GB included, so you can test the service as much as you want.\nThe same people also develop Vorta, so if you pay for the service you are also making sure the project remains funded.\nConclusion As you can see, configuring a good backup solution is not that difficult nor expensive. Remember the best day to start backing up is yesterday and today is still better than tomorrow üòâ\n","date":"2024-02-28T00:00:00Z","image":"https://www.andreagrandi.it/posts/my-backup-strategy/backup-strategy-cover.webp","permalink":"https://www.andreagrandi.it/posts/my-backup-strategy/","title":"My Backup Strategy with Borg, Vorta and BorgBase"},{"content":"As you may have noticed, the blog has a new look. I recently migrated from Pelican to Hugo and I am very happy with the result. I\u0026rsquo;ve known Hugo for a long time, but I never had the opportunity to use it in a real project. With a little help from a couple of friends, I was able to complete the migration in a few days.\nWhy did I migrate? I have been using Pelican for a long time and I have always been very happy with it. It is a great static site generator and it has served me well. However, I recently started having issues with PIP dependencies. For example one of the plugins required an older version of a sub dependency, which was causing conflicts with other plugins. I tried to fix it, but it was a rabbit hole and I decided to give Hugo a try.\nIn addition to the dependency issues, I realised that I was using a theme that was not being maintained anymore. The author himself had moved to Hugo and I was left with an outdated theme.\nLast but not least, the javascript library I was using to generate the indexing and search functionality was also not being maintained anymore.\nHow did I migrate? Both Pelican and Hugo are static site generators, and they both expects the content to be in Markdown format. This made the migration process a lot easier. By the way, there are some differences in the syntax of the Markdown files, and other few differences in the front matter (the metadata inside the MarkDown file), so I decided to write a small script to convert the files.\nYou can find the full script here https://gist.github.com/andreagrandi/0a7bf6e217d6561b00b6a5de6211ddaa but I have to warn you that it\u0026rsquo;s very specific to my blog (because of how I structured the content in Pelican and because of how I\u0026rsquo;m structuring it in Hugo) and it may not work for you. However, it can be a good starting point if you want to migrate from Pelican to Hugo.\nOther than migrating the content, I had to find a new theme and customise it to my needs. This honestly took most of the time. I\u0026rsquo;m really bad with CSS and I had to learn a lot of new things. I\u0026rsquo;m still not 100% happy with the result, but I think it\u0026rsquo;s good enough for now.\nThe theme I picked comes with a built-in search functionality, so I don\u0026rsquo;t have to worry about that anymore.\nFinally I had to rewrite the CircleCI configuration file to build the site with Hugo instead of Pelican. This took me a bit of try and error, but I managed to get it working.\nConclusion I\u0026rsquo;m very happy with the result. The site is easy to manage and I don\u0026rsquo;t have to worry about dependencies anymore. I\u0026rsquo;m also happy with the new theme, even if I still have to tweak it a bit (ie: comments don\u0026rsquo;t seem to be working yet). I wish I had done this migration earlier, but I\u0026rsquo;m glad I did it now. I hope you like the new look and if you find any issues, please let me know.\n","date":"2024-02-25T00:00:00Z","image":"https://www.andreagrandi.it/posts/migrating-from-pelican-to-hugo/migrating-from-pelican-to-hugo.webp","permalink":"https://www.andreagrandi.it/posts/migrating-from-pelican-to-hugo/","title":"Migrating from Pelican to Hugo"},{"content":"Once you have written and published an article, it‚Äôs very likely that you will want to share it on social media or send to your friends on a messaging app.\nOne method to make the link more ‚Äúattractive‚Äù is to include a cover image that will be shown in the link preview.\nHow do you set a cover image? You need to use a particular Open Graph tag named og:image.\nOpen Graph Open Graph is a protocol created by Facebook Meta to facilitate sharing articles and web pages on social media.\nThe syntax is very simple and all you have to do is to include a few meta tags in the header of your web page.\nThe most common tags to include are these ones:\nog:title is used as the main title of the page. It‚Äôs usually the biggest text being rendered og:description is the additional text shown below the title og:image this is probably the most important tag to set, because it takes the biggest space wherever it‚Äôs being rendered Pelican Depending on the template you use, your Pelican based website may already support the og:image tag.\nFor example in my case I need to add the Cover attribute to my page meta tags, like I did for this article:\n1 2 3 4 5 6 7 8 9 Title: How to show a cover image in Pelican based blog posts Date: 2024-02-06 22:03 Author: Andrea Grandi Category: Development Tags: Pelican, Python, blog, writing, images, cover, template, open, graph, meta Slug: how-to-show-cover-image-pelican-blog-posts Status: published Summary: How to add a cover image to Pelican based blog posts, so that when the article is shared on social media the image is shown in the preview. Cover: images/2024/02/pelican-website-banner.jpeg The template has a sub template (in my case it‚Äôs located here) may have something like this to render the image:\n1 2 3 4 5 {% if \u0026#39;cover\u0026#39; in article.metadata %} \u0026lt;meta property=\u0026#34;og:image\u0026#34; content=\u0026#34;{{ SITEURL }}/{{ article.metadata[\u0026#39;cover\u0026#39;] }}\u0026#34;\u0026gt; {% else %} \u0026lt;meta property=\u0026#34;og:image\u0026#34; content=\u0026#34;{{ SITELOGO }}\u0026#34;\u0026gt; {% endif %} Note: if you don‚Äôt specify a Cover, the template will use your SITELOGO image.\nIf your template doesn‚Äôt have something like this, you may have to use one of the following plugins. For the specific instructions about how to use them, please refer to their readme on GitHub.\npelican-seo plugin pelican-seo is a useful addition to your Pelican based website, even if your template already supports cover images, because it automatically adds all the Open Graph tags, which are useful to boost the SEO of your website.\nfeatured-image plugin featured-image is a much simpler plugin. All it does is to check if an image has already been included in the meta tags. If it‚Äôs not present, it tries to get the first one found in the page.\nConclusion Adding a cover image to your blog posts may seem a small thing, but it can make a huge difference if you decide to share your articles on social media.\n","date":"2024-02-06T00:00:00Z","image":"https://www.andreagrandi.it/posts/how-to-show-cover-image-pelican-blog-posts/pelican-website-banner.jpeg","permalink":"https://www.andreagrandi.it/posts/how-to-show-cover-image-pelican-blog-posts/","title":"How to show a cover image in Pelican based blog posts"},{"content":"It‚Äôs a not a news anymore that Google, the search engine which once was the best available, doesn‚Äôt work anymore for a lot of users.\nIts results are full of ads, they are not optimised for users, nor for advertisers and sometimes they also include malware. Their main goal is to boost ad revenue.\nSo why it‚Äôs still the most used search engine in the world? Well that‚Äôs ‚Äúeasy‚Äù, because Google pays (a lot!) to be the default search engine everywhere and users are often lazy to change their habits or don‚Äôt know alternatives are available.\nKagi My impressions After hearing a lot of good things about this search engine (especially from the folks on Mastodon), I decided to give it a try (there is a trial plan available with 100 search queries included, so don‚Äôt take my word and please test yourself!).\nThe first impression was terrific. I was finally able to find what I was looking for with the second or third (and sometimes with first) link in the results.\nWith Google I usually had to scroll past a few ads, then ignore old web pages (but with a good SEO), then go past another couple of irrelevant links and finally find what I was looking for. But the point is that you never know how bad the results are until you click, read a few lines and take a decision. At that point you already have wasted a lot of time just to find the right thing.\nWith Kagi I just save a lot of time, get better results and nobody is tracking what I search for to serve me related ads at later time.\nThe customisation features make the results I get even better and more tailored to my needs.\nWhy choosing Kagi Privacy: there are no ads in the results and there is no tracking in place. What you search is private. While Kagi relies on some existing search engines (Google, Bing, Brave etc‚Ä¶) they use them as a source of data and all the queries are always anonymised before being sent to them. Once their requests are back, results are aggregated and customised for the user.\nUser custom results: users can decide to exclude certain websites from ever appearing in their results, or rank higher or lower certain other websites. Tired of always seeing that click-bait website appearing? You can block it! Do you prefer to first look stuff in Wikipedia if available? You can rank it higher etc‚Ä¶\nLenses: once you get your results back, you can decide to filter them further by using lenses. For example you can use the ‚ÄúRecipe‚Äù lens, to search specifically for recipes, or the ‚ÄúDiscussions‚Äù one to search inside discussion forums.\nInstant answers: sometimes you can get an instant answer when you search for something, which already includes a lot of information, without the need to click on the found link. For example, searching for Python for loop will give you this:\nSummariser: this feature is still experimental, but I think it‚Äôs one of the best features available (AI haters please look somewhere else!). Kagi Summariser is able to create a summary of almost any public resource you can provide: a link to a web page, a podcast, a YouTube video etc‚Ä¶ it uses AI to transcribe audio/video and then it creates a summary of it. It saves me a lot of time, depending on what I‚Äôm looking for.\nUsing Kagi with Safari I use Safari as my main browser and unfortunately this browser doesn‚Äôt let you add any custom search engine, so Kagi engineers had to use a quick hack. They released a Safari extension which intercepts any query sent to your default engine and redirects it to Kagi. My personal advice? Change your default engine to DuckDuckGo or something else you trust if you don‚Äôt want to leak stuff to Google.\nPricing Kagi doesn‚Äôt offer a free plan (it only has a trial with 100 queries included) and it has three paid plans:\nStarter: it costs 5$/month and includes 300 queries/month Professional: it costs 10$/month, has unlimited queries and includes AI tools like Kagi Summariser Ultimate: it costs 25$/month, it‚Äôs like Professional plan but you get preview access to features which are still in development I personally have the Professional plan.\nConclusions I hope I stimulated your curiosity to at least convince you to use the trial. I‚Äôm curious to hear your opinions.\n","date":"2024-02-04T00:00:00Z","image":"https://www.andreagrandi.it/posts/kagi-paid-search-engine/kagi-landing-page.jpeg","permalink":"https://www.andreagrandi.it/posts/kagi-paid-search-engine/","title":"Kagi: a paid search engine which is worth the money"},{"content":"A few years ago, I migrated from my Wordpress based blog (which I self hosted‚Ä¶ yeah‚Ä¶ I know‚Ä¶ no comment!) to a static generated (using Pelican) one which is hosted (for free!) on GitHub Pages.\nThis setup, believe me or not, is cool. I‚Äôve all my blog posts written in MarkDown, versioned on and kept safe on GitHub and when I‚Äôm ready to publish, I just need to make a pull request, merge it and a CI job will take care of using Pelican to build the pages and push them to the right place. You can find more information about my setup in this other post.\nSo, what‚Äôs the problem? Well, as you can imagine, to do all of this, you need a GitHub client, a MarkDown editor and you need to be able to commit, push and do pull requests.\nIs this possible from an iPad? I believed it wasn‚Äôt (since the official GitHub client is very limited on what you can do, and online IDEs like VsCode.dev requires an internet connection, and I would like to be able to write also when I‚Äôm offline), but thanks to this blog post from Marco Gomiero, I recently found out it‚Äôs possible!\nWorking Copy: git client for iOS The most important part of my workflow would not be possible without this amazing git client.\nWorking Copy is so far the best Git client you can find on iOS. It allows you to clone repositories and work offline. Checked out content is made available through the File explorer, so any iOS app has access to it and this means you can use any client to edit your files.\nMWeb: a simple MarkDown editor for iOS Following the suggestion from Marco‚Äôs blog post I decided to start using this editor. To be honest I‚Äôm still not sold on it (literally: I haven‚Äôt purchased it yet and I‚Äôm still using the free version), because I‚Äôve found a couple of issues which I‚Äôve promptly reported to the author (let‚Äôs see if and how long it will take for them to reply) but they are not bad enough to entirely disrupt my workflow.\nIn case MWeb should not work for me, I‚Äôm planning to try a few others: Textastic, iWriter Pro and maybe iA Writer (but for its cost it has to be damn perfect!)\niOS Shortcuts and Automations Another idea I borrowed from Marco is the usage of iOS Shortcuts.\nIn my case I had to customise the flow quite a lot, either because I use Pelican instead of Hugo, and also because I‚Äôve some conventions I want to follow when writing my blog posts, but overall I implemented similar features:\n‚ÄúNew Blog Post‚Äù: the first shortcut creates a new branch in my repository and creates a new MarkDown file, following my own convention. Then it fills the empty file with some headers which are normally used in Pelican MarkDown files. ‚ÄúBlog Photo‚Äù: this shortcut let me select a photo from my gallery, it converts it to JPEG (most of the time pictures taken with my iPhone had *.heic format, so they need to be converted) and place it in the expected folder in my repository. Conclusion Thanks for reading my first blog post, entirely written from my iPad, while I was relaxing on my sofa. If you have any questions or suggestions for a good MarkDown editor for iOS, feel free to leave a comment.\n","date":"2024-02-01T00:00:00Z","image":"https://www.andreagrandi.it/posts/blogging-from-an-ipad/editing-markdown-with-mweb.jpeg","permalink":"https://www.andreagrandi.it/posts/blogging-from-an-ipad/","title":"Blogging from an iPad"},{"content":"I wanted to learn how to use OpenAI API in Python, so I decided to make it fun and created an interesting experiment: what would happen if I let two GPT powered bots \u0026ldquo;talk\u0026rdquo; to each other? Let\u0026rsquo;s find out!\nPrerequisites If you want to run this experiment locally you will need the following things:\nan OpenAI account 2 API keys (you can create them from here: https://platform.openai.com/account/api-keys ) Note: in my code I used gpt-4 as model, but in order to use this version, at the time I\u0026rsquo;m writing this article, you will need to request early access using this form https://openai.com/waitlist/gpt-4-api Until then, you can replace gpt-4 with gpt-3.5-turbo.\nPrepare the environment To be able to run the script, you first need to set two environment variables with the API key you generated previously:\n1 2 export OPENAI_API_KEY_1=your-api-key-1 export OPENAI_API_KEY_2=your-api-key-2 Then install the required Python libraries (I suggest you use a proper virtual environment. If you don\u0026rsquo;t know how to do that, you can follow my tutorial here: https://www.andreagrandi.it/2022/01/29/install-python-with-pyenv-and-pyenvvirtualenv-create-virtual-environment-with-specific-python-version-macos/ )\n1 pip install -r requirements.txt Then you can run the script by doing:\n1 python botchat.py The code You can find the complete and updated version of the code on GitHub https://github.com/andreagrandi/botchat but here below I will explain a few things.\n1 OPEN_AI_MODEL = \u0026#34;gpt-4\u0026#34; as I previously mentioned, I\u0026rsquo;m using gpt-4 by default, but if you don\u0026rsquo;t have access yet you will need to replace this with:\n1 OPEN_AI_MODEL = \u0026#34;gpt-3.5-turbo\u0026#34; When crafting the message to send to the bot I check if the input matches with the original context and if they don\u0026rsquo;t match I\u0026rsquo;m also sending the original context: this has definitely improved the quality of the conversation between the two bots, otherwise the API would not maintain the context between one message and the other.\n1 2 3 4 5 def conversation(input_text, original_context): if input_text != original_context: message = original_context + \u0026#34; \u0026#34; + input_text else: message = input_text I send the message to the first bot and I get a response back:\n1 2 3 4 5 6 7 8 bot_1_response = openai.ChatCompletion.create( model=OPEN_AI_MODEL, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: message} ], presence_penalty=0.5, api_key=OPENAI_API_KEY_1, ) and then I use the response to feed the second bot:\n1 2 3 4 5 6 7 8 9 10 message = original_context + bot_1_response.choices[0].message.content bot_2_response = openai.ChatCompletion.create( model=OPEN_AI_MODEL, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: message} ], presence_penalty=0.5, api_key=OPENAI_API_KEY_2, ) What to use as input? This is not a trivial question and it will highly affect the quality (and the success) of the \u0026ldquo;conversation\u0026rdquo;. My suggestion is to explain that you are expecting to have a conversation and to limit replies to a couple of paragraphs only. Then decide what the conversation is about.\nFor example you could input something like this:\n1 2 3 4 ‚úó python botchat.py Please enter your message: You are having a conversation with a person. Do not reply with more than 2 paragraphs. The conversation is about weather A full GPT conversation If you are curious to read the resulting \u0026ldquo;conversation\u0026rdquo; between two GPT powered bot, you can find here below. You will notice that at first they start talking about the weather, then they move to talk about outdoor activities and they finally end up talking about art.\nEnjoy the conversation!\n::text BOT 1: I just love how the weather has been lately. Sunny and warm during the day, with just the right cool breeze in the evening. It feels like the perfect balance between summer and autumn. Have you been enjoying it as well?\nYesterday, I took advantage of the great weather and went for a hike in the nearby park. The views were stunning, and it was so refreshing to be surrounded by nature. Do you have any favorite outdoor activities for this type of weather?\nBOT 2: I absolutely agree with you! This kind of weather is perfect for spending time outdoors and enjoying various activities. I have been enjoying it, taking walks in the evening when it\u0026rsquo;s cooler and sunnier during the day.\nAs for outdoor activities, I enjoy hiking and cycling in this type of weather. There\u0026rsquo;s something about being out in nature during the pleasant transition between summer and autumn that feels invigorating. What about you?\nBOT 1: Do you have any favorite outdoor activities you like to do during this time of year? I\u0026rsquo;m always looking for new ideas to make the most of this beautiful weather.\nBOT 2: One of my favorite outdoor activities during this time of year is hiking. It\u0026rsquo;s a great way to enjoy the pleasant weather, explore nature, and get some exercise. Additionally, it\u0026rsquo;s an activity that can be tailored to people of all fitness levels since you can choose trails based on difficulty. Just make sure you wear proper footwear and bring plenty water to stay hydrated.\nAnother enjoyable activity is having a picnic in the park. You can gather friends or family, pack up some delicious food, and find a nice spot to relax and enjoy the outdoors. It\u0026rsquo;s a wonderful way to catch up with loved ones while soaking up the sunshine or finding a shady spot under a tree. Plus, it\u0026rsquo;s an opportunity to play some lawn games or throw a frisbee around for added fun.\nBOT 1: I totally agree with you! Hiking is an amazing way to make the most of the good weather, and it\u0026rsquo;s a perfect excuse to get some fresh air and take a break from our busy lives. Plus, there\u0026rsquo;s nothing like reaching the top of a hill or a look-out point and taking in the stunning views. It\u0026rsquo;s one of those experiences that make you realize how beautiful the world really is.\nThe picnic idea is fantastic as well. It\u0026rsquo;s such a simple yet enjoyable way to spend time with friends and family. Everyone can bring their favorite dishes to share, so it\u0026rsquo;s also a great way to try out new food options. And as you mentioned, it offers the opportunity to include some fun outdoor games and create cherished memories together. The key to enjoying these outdoor activities, of course, is having wonderful weather - which makes us appreciate the sunshine even more!\nBOT 2: Absolutely! Having good weather is an essential component for truly enjoying these outdoor activities. And, they are also perfect opportunities to bond with loved ones or simply unwind and relax in nature, away from the stresses of daily life. Moments like these allow us to reconnect with ourselves and appreciate our surroundings, thanks to the great outdoors and a warm, sunny day.\nBut let\u0026rsquo;s not forget that even though we wish for perfect weather all the time, experiencing different forms of weather can also be fascinating and provides variety in our lives. Rainy days, for instance, can bring coziness and a feeling of comfort or offer a chance for introspection, while snowy days can turn into winter wonderlands for those who love to bundle up and play or appreciate the beauty of snow-covered landscapes. So, even if it\u0026rsquo;s not all sunshine and warmth, each type of weather can still offer memories and experiences worth cherishing.\nBOT 1: That\u0026rsquo;s very true! Different types of weather can create various moods and atmospheres that can be delightful and appreciated in different ways. Whether it\u0026rsquo;s the refreshing sensation of a light drizzle on a summer day or the comforting warmth of staying indoors with a hot cocoa during a snowstorm, these experiences enrich our lives and often evoke fond memories.\nIt\u0026rsquo;s important to note that while we appreciate the beauty and benefits of diverse weather conditions, we must also stay aware of possible extreme weather events and pay attention to forecasts and warnings to be prepared and ensure our safety. That being said, there\u0026rsquo;s no denying that the power and variety of weather is one of the many factors that make life on this planet so captivating and unique.\nBOT 2: I couldn\u0026rsquo;t agree more with you! It\u0026rsquo;s interesting how weather can impact not only our mood and experiences, but also inspire different forms of art, like music and paintings. Just think about how many songs or poems have been written about rain or sunny days ‚Äì weather certainly has an undeniable influence on our creativity.\nAs you mentioned, being prepared for extreme weather events is crucial as well. With climate change happening, we may experience more unpredictable weather patterns, and it\u0026rsquo;s important to adapt and take care of our environment to minimize adverse effects. Nonetheless, the diverse weather conditions we experience make Earth an incredible and fascinating place to live.\nBOT 1: Absolutely, the connection between weather and art is truly fascinating. It\u0026rsquo;s amazing to see how weather has been a source of inspiration for so many artists throughout history, giving us iconic masterpieces that help us understand and appreciate the beauty of our world even more.\nYou make an important point about the need to prepare for extreme weather events and climate change. As we continue to tackle these challenges, it\u0026rsquo;s essential to promote sustainability and have global cooperation to protect our planet. The incredible diversity of weather conditions on Earth reminds us of the precious and delicate nature of our home, and emphasizes how crucial it is to preserve it for future generations.\nBOT 2: I completely agree that a deeper appreciation for the beauty and intricacy of our planet\u0026rsquo;s weather systems, as showcased through art, can promote sustainability efforts. By realizing the value and uniqueness of our ecosystems, we may be more inspired to engage in actions that are environmentally responsible and find solutions to preserve our world for the future.\nArt also has the power to raise awareness about environmental issues, including extreme weather events and climate change. Artists can convey powerful messages through their work, often more effectively than words alone. With the increased understanding and empathy that comes from experiencing these artistic expressions, we can become more motivated to actively participate in efforts to curb climate change and protect our environment.\nBOT 1: Moreover, art can evoke strong emotions and create connections between people and their surroundings. By presenting the beauty of weather systems and their vulnerability to human actions, art can stir feelings of responsibility, compassion, and urgency to take action. This emotional connection could influence individuals or communities to implement sustainable practices to preserve these ecosystems.\nAdditionally, collaborations between artists, scientists, and policymakers can lead to innovative ways to communicate the importance of environmental conservation and climate change solutions. These interdisciplinary efforts can create more engaging and effective strategies in educational and public awareness campaigns, thus inspiring collective action towards a sustainable future.\nBOT 2: I completely agree that art can be a powerful tool in raising awareness about environmental issues like climate change and weather systems. This emotional connection provided through art could encourage people to take necessary steps toward a sustainable lifestyle, by fostering the feeling of responsibility and urgency.\nFurthermore, interdisciplinary collaborations between artists, scientists, and policymakers are essential in effectively addressing and communicating the importance of environmental conservation. These partnerships will help develop educational and public awareness initiatives that will not only engage people but also inspire them to work collectively towards a more sustainable future for our planet.\nBOT 1: Art has the ability to evoke emotions and stir personal connections to the environment, which in turn can lead to a deeper understanding and appreciation of our planet\u0026rsquo;s fragile state. Through various forms of artistic expression, be it paintings, sculptures, music or installations, artists have the power to convey critical messages about the importance of taking care of our environment.\nWhen people are moved by these visual and auditory experiences, it becomes more likely that they\u0026rsquo;ll realize the gravity of the situation and feel prompted to make necessary changes in their own lives. By incorporating climate change and environmental issues in their work, artists can leave a lasting impact on their audience, inspire further discussions, and potentially contribute to instigating actions that address the challenges faced by our Earth.\nBOT 2: Absolutely, art has a unique way of resonating with people on an emotional level, often more effectively than facts and statistics alone. Evoking emotions through art can create a personal connection to the environment, making the issue more real and urgent for the individual experiencing it. This personal connection can lead to raised awareness and a greater sense of responsibility when it comes to taking care of our planet.\nMoreover, art transcends language barriers and geographical boundaries, enabling it to reach a diverse audience. By showcasing environmental issues through artistic expression, the message becomes accessible to people from various backgrounds and cultures. This widespread reach could potentially create a united global response in addressing the urgent need for change regarding our environment and its preservation.\nBOT 1: Absolutely, art has a unique way of resonating with people on an emotional level, often more effectively than facts and statistics alone. Evoking emotions through art can create a personal connection to the environment, making the issue more real and urgent for the individual experiencing it. This personal connection can lead to raised awareness and a greater sense of responsibility when it comes to taking care of our planet.\nMoreover, art transcends language barriers and geographical boundaries, enabling it to reach a diverse audience. By showcasing environmental issues through artistic expression, the message becomes accessible to people from various backgrounds and cultures. This widespread reach could potentially create a united global response in addressing the urgent need for change regarding our environment and its preservation.\nBOT 2: I completely agree with you. Art can not only raise awareness about the impact of climate change and other environmental issues but also inspire people to take action in their own lives. People tend to connect with visual representations more strongly, and artistic expressions can vividly illustrate the effects of these challenges in a way that is easily understood by everyone.\nAdditionally, art can foster important conversations and facilitate a sense of community among individuals who share a concern for the environment. By creating spaces to engage in dialogues and exchange ideas, art can spark innovative solutions to environmental problems, motivating people to get involved and rally support for sustainable practices. The power of art lies in its ability to connect us, provoke emotions, and motivate us to pursue a better world.\nBOT 1: It\u0026rsquo;s true that art holds a special power to evoke emotions and create connections, making it a crucial tool for raising environmental awareness. The more we can expose people to various art forms depicting the consequences of climate change and our relationship with nature, the more likely they are to feel empathy and understanding towards the issues. This in turn can encourage them to make environmentally-conscious lifestyle choices or even advocate for policy change at a higher level.\nUsing art as a means of communication also transcends language barriers, meaning it can reach wider audiences and appeal to diverse groups of people. By including local communities and artists, we can create a connection on a personal level, giving people a sense of ownership and a stake in the cause. Art can act as a gateway for education, activism, and community engagement in the ongoing fight against climate change and other environmental concerns.\nBOT 2: Absolutely, the universality of art allows it to be a perfect medium for conveying important messages and generating global conversations about environmental issues. Visual arts, music, dance, and even literature can all become powerful tools in raising awareness, bridging cultural gaps, and inspiring positive actions.\nMoreover, involving local artists and communities in the creation of environmental art ensures that diverse perspectives are represented, promoting a sense of inclusivity in the movement. This collective effort towards sustainable living can have immense ripple effects as people from various backgrounds come together with a common purpose. Thus, art can be a catalyst for environmental action, ostering empathy and collective responsibility among its audience.\nBOT 1: Additionally, art has the unique ability to evoke emotions and make people feel more connected to certain causes. This emotional connection can lead to a greater sense of urgency, prompting individuals and communities to take action when it comes to climate change and other environmental issues. Art can effectively communicate complex problems and potential solutions in a more relatable manner, making the information accessible to a broader audience.\nFurthermore, environmental art often brings attention to aspects of our natural world that might be overlooked in daily life. By highlighting the beauty and vulnerability of our surroundings, it can encourage people to develop a stronger appreciation for the environment and inspire them to become more conscious about their own actions and choices. In this way, art plays a crucial role in promoting meaningful dialogue and action on climate change and sustainability.\nBOT 2: I agree with you. Art has a powerful influence on the way people perceive and understand complex issues like climate change. By presenting these problems in a more visually engaging and emotive manner, it becomes easier for people to grasp the severity of the situation and feel compelled to act. The use of symbolism and metaphor in art can also make abstract concepts like global warming more tangible and relatable.\nMoreover, when artists collaborate with scientists, they can create innovative ways to communicate climate data and environmental phenomena, making them more accessible to wider audiences who may not be familiar with scientific language. This interaction between art and science broadens the understanding of environmental challenges and fosters collective responsibility towards finding solutions. In the end, art serves as a vital tool to raise awareness, promote dialogue, and inspire positive change for a more sustainable future.\n","date":"2023-05-05T00:00:00Z","image":"https://www.andreagrandi.it/posts/use-openai-api-to-make-two-gpt-bots-talk/two-chatgpt-robots.jpeg","permalink":"https://www.andreagrandi.it/posts/use-openai-api-to-make-two-gpt-bots-talk/","title":"Use OpenAI API to make two GPT bots talk to each other"},{"content":"OpenAI is a research organization that develops and promotes friendly AI for the betterment of humanity. One of its most popular projects is the development of the GPT (Generative Pre-trained Transformer) series, which includes ChatGPT, a large language model trained to generate human-like text based on given prompts. In this blog post, we\u0026rsquo;ll show you how to use the OpenAI API for ChatGPT with Python examples.\nPrerequisites Before we start, you\u0026rsquo;ll need to create an OpenAI account and obtain an API key. You can do this by going to the OpenAI API website and signing up for an account. Once you have an account, you can obtain an API key from the API dashboard.\nYou\u0026rsquo;ll also need the openai Python package, which you can install using pip:\n1 pip install openai Example: Generating Text with ChatGPT Once you have your API key and have installed the openai package, you can start using the OpenAI API to generate text with ChatGPT. Here\u0026rsquo;s an example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import openai import os openai.api_key = os.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] prompt = \u0026#34;What is the meaning of life?\u0026#34; response = openai.Completion.create( engine=\u0026#34;davinci\u0026#34;, prompt=prompt, max_tokens=50, ) answer = response.choices[0].text.strip() print(answer) In this example, we import the openai package and set our API key using openai.api_key. We then define a prompt variable containing the text we want ChatGPT to generate more text from. We use openai.Completion.create() to send the prompt to the OpenAI API and receive a response containing generated text. Finally, we print the generated text using response.choices[0].text.strip().\nIn the openai.Completion.create() function, we specify the following parameters:\nengine: The name of the GPT model to use. In this case, we\u0026rsquo;re using the davinci model, which is the most capable and expensive model. prompt: The text prompt to send to the GPT model. max_tokens: The maximum number of tokens (words and punctuation) to generate in the response. You can customize these parameters to suit your needs. For example, you can use a different GPT model, a different prompt, or a different max_tokens value.\nConclusion Using the OpenAI API for ChatGPT is easy with the openai Python package. You can generate human-like text for a wide range of applications, such as chatbots, language translation, and content creation. With the power of the OpenAI API, you can take your AI projects to the next level.\nDisclaimer and attribution If you didn\u0026rsquo;t get it until now\u0026hellip; I need to tell you: all of the above has been generated by ChatGPT! This of course was just an experiment and I\u0026rsquo;ve no intention of regularly generating my blog posts with this tool. In case I did further experiments, I will always include this disclaimer at the bottom. I hope you enjoyed reading!\n","date":"2023-04-17T00:00:00Z","image":"https://www.andreagrandi.it/posts/how-to-use-openai-api-for-chatgpt-in-python/python-chatgpt.jpeg","permalink":"https://www.andreagrandi.it/posts/how-to-use-openai-api-for-chatgpt-in-python/","title":"HowTo use OpenAI API for ChatGPT in Python"},{"content":"If you are already using pytest to write your tests and are also using vcr to record and replay http responses, you already know that any http request is being recorded, so the next time the same request is made, the test won\u0026rsquo;t hit the real endpoint but it will use the recorded response.\nSometimes you need to exclude localhost (or other hosts) from being recorded and you can do thanks to this vcr parameter:\n1 2 3 4 @pytest.mark.vcr(ignore_hosts=[\u0026#34;localhost\u0026#34;]) def test_is_true(): # Intentionally dumb test to make things simple assert True This works, but what if you have many tests and you want to ignore localhost globally?\nYou can do it by adding this to your main conftest.py and all your vcr tests will ignore it by default:\n1 2 3 4 5 @pytest.fixture(scope=\u0026#34;module\u0026#34;) def vcr_config(): return { \u0026#34;ignore_hosts\u0026#34;: [\u0026#34;localhost\u0026#34;], } That\u0026rsquo;s it! I hope you find this suggestion useful.\n","date":"2022-12-02T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ignore-hosts-with-python-vcr/","title":"Ignoring hosts with python vcr when writing tests with pytest and generating cassettes"},{"content":"This is an update version of my previous tutorial Install Python with pyenv and pyenv-virtualenv create virtual environment with specific Python version. In this version I will show how to install Python 3.10.0 and create a virtual environment with that version.\nTo manage my Python versions I\u0026rsquo;m using using pyenv and pyenv-virtualenv and once they are correctly configured, it\u0026rsquo;s very easy to install a new Python version.\nMake sure you have the required packages installed First of all make sure you have all the latest packages installed (I\u0026rsquo;m using Homebrew for MacOS):\n1 2 3 brew update brew install pyenv brew install pyenv-virtualenv once installed you should see the latest version:\n1 2 pyenv --version pyenv 2.2.2 Configure pyenv and pyenv-virtualenv To be able to use pyenv and pyenv-virtualenv you need to write this basic configuration in your ~/.bashrc (or ~/.zshrc if you are using zsh):\n1 2 3 4 5 export PYENV_ROOT=\u0026#34;$HOME/.pyenv\u0026#34; export PATH=\u0026#34;$PYENV_ROOT/bin:$PATH\u0026#34; eval \u0026#34;$(pyenv init --path)\u0026#34; eval \u0026#34;$(pyenv init -)\u0026#34; eval \u0026#34;$(pyenv virtualenv-init -)\u0026#34; Install Python 3.10.0 To install Python 3.10.0 you only need pyenv install 3.10.0:\n1 2 3 4 5 6 7 8 9 10 11 12 pyenv install 3.10.0 python-build: use openssl@1.1 from homebrew python-build: use readline from homebrew Downloading Python-3.10.0.tar.xz... -\u0026gt; https://www.python.org/ftp/python/3.10.0/Python-3.10.0.tar.xz Installing Python-3.10.0... patching file aclocal.m4 patching file configure Hunk #5 succeeded at 10537 (offset -15 lines). python-build: use readline from homebrew python-build: use zlib from xcode sdk Installed Python-3.10.0 to /Users/andrea/.pyenv/versions/3.10.0 Set Python 3.10.0 as the local version Now that the version you want has been installed, you need to tell pyenv you want to use it:\n1 2 pyenv local 3.10.0 pyenv which python which will show you this:\n1 /Users/andrea/.pyenv/versions/3.10.0/bin/python Create a virtual environment using Python from pyenv To create a virtual environment named my-310-python using Python 3.10.0 version, you just need this command:\n1 pyenv virtualenv 3.10.0 my-310-python Verify that the virtual environment has been created:\n1 2 pyenv virtualenvs 3.10.0/envs/my-310-python (created from /Users/andrea/.pyenv/versions/3.10.0) Test and automatically activate the virtual environment Create a test folder:\n1 mkdir test-310 Create a .python-version file in the test folder:\n1 echo my-310-python \u0026gt; test-310/.python-version Now if you enter the folder (cd test-310), the virtual environment will be automatically activated:\n1 2 cd test-310 (my-310-python) ‚ûú test-310 At this point you can verify that the virtual environment is working, by using python --version:\n1 2 (my-310-python) ‚ûú test-310 python --version Python 3.10.0 ","date":"2022-01-29T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/install-python-with-pyenv-and-pyenvvirtualenv-create-virtual-environment-with-specific-python-version-macos/","title":"Using pyenv and pyenv-virtualenv to install Python and create a virtual environment on MacOS"},{"content":"You just got a new Arduino board (maybe a wifi enabled one), you wrote a useful application and you are about to share it on GitHub.\nIf your code looks like this:\n1 2 3 4 5 #include \u0026lt;WiFi101.h\u0026gt; char ssid[] = \u0026#34;myessid\u0026#34; char pass[] = \u0026#34;mypassword\u0026#34; ... do not share it! You would leak your ESSID, password and maybe othere secrets to everyone.\nStore secrets in an external file Create a separate file named arduino_secrets.h:\n1 2 #define SECRET_SSID \u0026#34;myessid\u0026#34; #define SECRET_PASS \u0026#34;mypassword\u0026#34; and change the main file in this way:\n1 2 3 4 5 6 #include \u0026lt;WiFi101.h\u0026gt; #include \u0026lt;arduino_secrets.h\u0026gt; char ssid[] = SECRET_SSID char pass[] = SECRET_PASS ... Note: using the SECRET_... naming convention is also useful if you use the Arduino Web Editor https://create.arduino.cc/projecthub/Arduino_Genuino/store-your-sensitive-data-safely-when-sharing-a-sketch-e7d0f0 because these values will be automatically added to a secret tab and will only be visible to you, even if you share your project.\nExclude secrets file from git Moving secrets to arduino_secrets.h would be pointless if we pushed this file to GitHub. To avoid this mistake, add arduino_secrets.h to .gitignore (create it in the root of the project if it doesn\u0026rsquo;t exist already).\nAdd an example for secrets file If you simply hide the original arduino_secrets.h, other users who would like to reuse your code may not know what to put inside. Create an example file named arduino_secrets.h.example with dummy values:\n1 2 #define SECRET_SSID \u0026#34;foo\u0026#34; #define SECRET_PASS \u0026#34;foo\u0026#34; and document that this needs to be renamed to arduino_secrets.h\nWhat if I need to build my code in a CI? In case you want to build your code in a CI environment, the full source code needs to be there, but at the same time you still don\u0026rsquo;t want to push your secrets to GitHub. What to do then?\nStore your secrets in environment variables Create an environment variable in your CI (or set it locally on your machine if you want to build it locally) for each secret:\n1 2 export WIFI_SSID_NAME=\u0026#34;myessid\u0026#34; export WIFI_PASSWORD=\u0026#34;mypassword\u0026#34; Create a Makefile Add a Makefile to your project, similar to this one:\n1 2 3 4 5 6 7 8 9 #!/bin/bash OUTPUT = \u0026#34;arduino_secrets.h\u0026#34; arduino_secrets: @echo \u0026#34;Generating $(OUTPUT)\u0026#34; @[ -e $(OUTPUT) ] \u0026amp;\u0026amp; rm $(OUTPUT) @echo \u0026#34;#define SECRET_SSID \\\u0026#34;$(WIFI_SSID_NAME)\\\u0026#34;\u0026#34; \u0026gt;\u0026gt; $(OUTPUT) @echo \u0026#34;#define SECRET_PASS \\\u0026#34;$(WIFI_PASSWORD)\\\u0026#34;\u0026#34; \u0026gt;\u0026gt; $(OUTPUT) If you run make you will generate a file named arduino_secrets.h containing the proper values.\nConclusion There may be alternative methods to safely store secrets. If you know a better one, you can leave a comment below.\nReferences https://create.arduino.cc/projecthub/Arduino_Genuino/store-your-sensitive-data-safely-when-sharing-a-sketch-e7d0f0 ","date":"2020-12-16T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-safely-store-arduino-secrets/","title":"How to safely store Arduino secrets"},{"content":"{width=30%}\nWith WebAssembly we can write a library in almost any language, compile it to WebAssembly (WASM) and use it from JavaScript.\nIn this tutorial I will show you how to get started with TinyGo by writing a simple add() method in Go and using it from a web page. All the code will be running in the browser without any backend process involved (you only need a static server to serve the html page and JavaScript files, but I will cover this part too).\nInstall TinyGo To be able to install TinyGo you need to have Go installed first. I have personally tested this on my Mac, so I will provide instructions for MacOS, but you can find instructions for the other operating systems directly on the project website: https://tinygo.org/getting-started\nYou can install TinyGo on MacOS using brew:\n1 2 brew tap tinygo-org/tools brew install tinygo If installation is successful, you should be able to run this:\n1 2 tinygo version tinygo version 0.15.0 darwin/amd64 (using go version go1.15.3 and LLVM version 10.0.1) Implement an add() method in Go Create a new empty project/repository using your favourite IDE (I personally used VSCode, but of course you can use anything else) and then create main.go file with this code:\n1 2 3 4 5 6 7 8 9 10 11 package main func main() { } // This function is exported to JavaScript, so can be called using // exports.add() in JavaScript. //export add func add(x, y int) int { return x + y } Compile to WebAssembly (WASM) To compile the above code to WebAssembly you need to run this command:\n1 tinygo build -o wasm.wasm -target wasm ./main.go that will create a file named wasm.wasm in the same directory of your project. This is the compiled web binary that will be loaded later by JavaScript.\nAdd required WASM library There is a file that is provided with TinyGo that you need to distribute with your application: wasm_exec.js. To include it in your project, you need to run this:\n1 cp $(tinygo env TINYGOROOT)/targets/wasm_exec.js . Script to load the WebAssembly At this point you will need an additional JavaScript file that will take care of loading the WebAssembly code. This file is not \u0026ldquo;standard\u0026rdquo; and may be different for every project, but the essential commands will be very similar.\nCreate a new file named wasm.js with this code and save it in the root of your project along with the other files:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026#39;use strict\u0026#39;; const WASM_URL = \u0026#39;wasm.wasm\u0026#39;; var wasm; function init() { const go = new Go(); if (\u0026#39;instantiateStreaming\u0026#39; in WebAssembly) { WebAssembly.instantiateStreaming(fetch(WASM_URL), go.importObject).then(function (obj) { wasm = obj.instance; go.run(wasm); }) } } init(); HTML page to collect input and show result We create a simple HTML page that will display two input boxes and a third one to show the result. Create a new file named index.html in the root of your project:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Go WebAssembly\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34; /\u0026gt; \u0026lt;script src=\u0026#34;wasm_exec.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;wasm.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;WebAssembly\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Add two numbers, using WebAssembly calling an add() method written in Go:\u0026lt;/p\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; id=\u0026#34;a\u0026#34; value=\u0026#34;2\u0026#34; /\u0026gt; + \u0026lt;input type=\u0026#34;number\u0026#34; id=\u0026#34;b\u0026#34; value=\u0026#34;2\u0026#34; /\u0026gt; = \u0026lt;input type=\u0026#34;number\u0026#34; id=\u0026#34;result\u0026#34;/\u0026gt; \u0026lt;button\u0026gt;Calculate\u0026lt;/button\u0026gt; \u0026lt;script\u0026gt; const button = document.querySelector(\u0026#39;button\u0026#39;); button.addEventListener(\u0026#39;click\u0026#39;, event =\u0026gt; { var a = parseInt(document.getElementById(\u0026#34;a\u0026#34;).value); var b = parseInt(document.getElementById(\u0026#34;b\u0026#34;).value); var res = wasm.exports.add(a, b); var sum_box = document.getElementById(\u0026#34;result\u0026#34;); sum_box.value = res; }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Please note: frontend development is really not my daily bread. I\u0026rsquo;m sure the above code can be written in a better way, but I can assure you that at least it works.\nServing the static files The project itself would be complete, but you need something able to serve static pages and set a couple of required headers. We can implement one with a few lines of Go. Create a new file named server.go:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strings\u0026#34; ) const dir = \u0026#34;./\u0026#34; func main() { fs := http.FileServer(http.Dir(dir)) log.Print(\u0026#34;Serving \u0026#34; + dir + \u0026#34; on http://localhost:8080\u0026#34;) http.ListenAndServe(\u0026#34;:8080\u0026#34;, http.HandlerFunc(func(resp http.ResponseWriter, req *http.Request) { resp.Header().Add(\u0026#34;Cache-Control\u0026#34;, \u0026#34;no-cache\u0026#34;) if strings.HasSuffix(req.URL.Path, \u0026#34;.wasm\u0026#34;) { resp.Header().Set(\u0026#34;content-type\u0026#34;, \u0026#34;application/wasm\u0026#34;) } fs.ServeHTTP(resp, req) })) } Testing the project The project is now complete and can be tested. There are at least two methods to check if everything works: using the webpage we just created and calling the method from the JavaScript console.\nTo test the application using the web page, run the server from the command line:\n1 go run server.go Open a web browser and visit the address http://localhost:8080\nYou should see something like this:\n{width=60%}\nOnce the page is loaded you can also open the JavaScript console (it\u0026rsquo;s in you browser developers tools and at least Chrome and Firefox have one) and call the method directly:\n{width=60%}\nConclusion If you want to learn more about TinyGo I suggest you to visit the project website https://tinygo.org while more technical information and details about WebAssembly can be found here https://webassembly.org\nYou can find the complete source code of this project on GitHub: https://github.com/andreagrandi/tinygo-adder\nCredits I want to thank my colleague Ross Jones for introducing me to WASM and for the help given.\nReferences https://tinygo.org/webassembly https://webassembly.org/ ","date":"2020-10-23T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/getting-started-with-tinygo-webassembly/","title":"Getting started with TinyGo and WebAssembly (WASM)"},{"content":"When using Python virtual environments it can be useful to have certain environment variables automatically set when we activate it. For example we can have a projects that needs to connect to a database or we may need specific settings to run a service. Automating this process makes sure we don\u0026rsquo;t forget about setting everything we need.\nStoring the configuration I strongly suggest to store all the configuration in the root of your project in a file named .env which you need to take care of adding to your .gitignore.\nAn example of .env file:\n1 2 3 MY_USERNAME=user1 MY_PASSWORD=secret MY_SERVICE_URL=http://localhost:5000 How to activate the configuration Python virtual environments have a few scripts that are beign executed in certain situations. In particular there is one named postactivate that is being run after you activate trhe virtual environment.\nYou need to first find the folder where it\u0026rsquo;s located and to do this, you need to first activate your virtual environment. Now you need to run cdvirtualenv in your terminal and your working directory will be set to where the virtual environment is located.\nAt this point edit postactivate file with (you can replace nano with your preferred editor) nano bin/postactivate and add the following script:\n1 2 3 4 5 #!/bin/zsh # This hook is sourced after this virtualenv is activated. set -a source .env set +a Note: I\u0026rsquo;m using zsh here but you can replace it with bash (the syntax should be the same).\nTest the configuration To make the configuration effective you need to deactivate your virtual environment and activate it again. The postactivate script will run automatically and you can now check that your environment variables have been set correctly (the ... have been placed to replace other existing values):\n1 2 3 4 5 (test-env) ‚ûú env ... MY_USERNAME=user1 MY_PASSWORD=secret MY_SERVICE_URL=http://localhost:5000 As you can see the values configured in the .env file have been correctly set.\n","date":"2020-10-16T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/set-specific-environment-variables-activating-python-virtual-environment/","title":"Set specific environment variables activating a Python virtual environment"},{"content":"When a client requests a web page, the browser begins to download the html page and parses it. If an external resource is found it begins to request that resource in a parallel request. This means the the complete loading of the page may be delayed until all the external resources have been downloaded. On mobile or slow connections, this can be a problem.\n{ width=60% }\nThe solution While it\u0026rsquo;s not possible to fix all the external resources, there is an attribute called defer that when included in \u0026lt;script\u0026gt; ... \u0026lt;/script\u0026gt; sections, it will make sure that javascript files will be loaded after the main page has been loaded, resulting in a quicker download of the main content.\nExample If you have a script like this:\n1 \u0026lt;script src=\u0026#34;https://www.andreagrandi.it/theme/tipuesearch/tipuesearch.min.js\u0026#34; type=\u0026#34;5ea4254e9004c2f036fc9ad2-text/javascript\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; just add the defer attribute like this:\n1 \u0026lt;script defer src=\u0026#34;https://www.andreagrandi.it/theme/tipuesearch/tipuesearch.min.js\u0026#34; type=\u0026#34;5ea4254e9004c2f036fc9ad2-text/javascript\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Compatibility Even if the defer option should be supported by the majority of the browsers, it\u0026rsquo;s always better to double check which are the browsers not supporting it yet. You can check the compatibility at this address: https://caniuse.com/script-defer\nNote: the defer attribute can\u0026rsquo;t always be used in all the pages. When you need a script to be available before the page is completely rendered, you can\u0026rsquo;t use it. You may have noticed that in this website I haven\u0026rsquo;t deferred the loading of jquery library. For example, I don\u0026rsquo;t know all the details, but I suppose it\u0026rsquo;s necessary to load, parse and render the search results for Tipue Search. Infact if I defer the script, no search results will appear in my website.\nReferences https://flaviocopes.com/javascript-async-defer/#just-tell-me-the-best-way ","date":"2020-10-15T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/optimise-website-javascript-loading-speed/","title":"Optimise your website JavaScript loading speed with defer"},{"content":"You may have notice that a few days ago this website changed its template. I\u0026rsquo;m still using Pelican static generator, but I switched to a template named Flex.\nThe template is really nice and it\u0026rsquo;s also optimised for mobile clients, but it\u0026rsquo;s not very optimised for SEO.\nI\u0026rsquo;m in no way an expert, so I tried to research for ways to optimise Pelican based websites and I discovered something I didn\u0026rsquo;t know.\nContent Duplication If you are, like me, hosting your website on GitHub static pages, you should know that your published content is also duplicated on GitHub. For example: the pages you see on https://www.andreagrandi.it are all available here https://github.com/andreagrandi/andreagrandi.github.io\nThis is a problem for search engines, because the content is the same, but they don\u0026rsquo;t know which one is the website you would like to be found in the search results.\nCanonical URL To solve this problem, pages needs to include a section like this:\n1 2 3 4 \u0026lt;head\u0026gt; ... \u0026lt;link rel=\u0026#34;canonical\u0026#34; href=\u0026#34;https://www.andreagrandi.it/2020/10/11/python39-introduces-removeprefix-removesuffix/\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; So even if that page is found on GitHub Google will know that the \u0026ldquo;official\u0026rdquo; page is located at the canonical url and will use that url in the search results.\nHow to fix your Pelican template Adding the canonical url in Pelican based websites is quite simple. You need to add a section like this to your base.html template file:\n1 2 3 4 5 ... {% if article %} \u0026lt;link rel=\u0026#34;canonical\u0026#34; href=\u0026#34;{{ SITEURL }}/{{ article.url }}\u0026#34; /\u0026gt; {% endif%} \u0026lt;/head\u0026gt; At this point, just rebuild and publish your pages and you are done!\nReferences https://blog.kmonsoor.com/pelican-how-to-make-seo-friendly/ https://moz.com/learn/seo/canonicalization ","date":"2020-10-14T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/improve-pelican-based-website-seo-adding-canonical-url/","title":"Improve your Pelican based website SEO by adding canonical url"},{"content":"Python 3.9.0 has introduced two new methods to work with strings: removeprefix and removesuffix. As their names suggest, one is used to remove a prefix from a string while the other one is used to remove a suffix.\nremoveprefix Given a string and a prefix, if the string begins with the prefix, the prefix is being removed, otherwise a copy of the original string is being returned:\n1 2 3 4 5 In [5]: \u0026#39;MyStringExample\u0026#39;.removeprefix(\u0026#39;My\u0026#39;) Out[5]: \u0026#39;StringExample\u0026#39; In [6]: \u0026#39;MyStringExample\u0026#39;.removeprefix(\u0026#39;Foo\u0026#39;) Out[6]: \u0026#39;MyStringExample\u0026#39; removesuffix Given a string and a suffix, if the string ends with the suffix, the suffix is being removed, otherwise a copy of the original string is being returned:\n1 2 3 4 5 In [7]: \u0026#39;ThisIsATest\u0026#39;.removesuffix(\u0026#39;Test\u0026#39;) Out[7]: \u0026#39;ThisIsA\u0026#39; In [8]: \u0026#39;ThisIsATest\u0026#39;.removesuffix(\u0026#39;Foo\u0026#39;) Out[8]: \u0026#39;ThisIsATest\u0026#39; Of course these are not the only features which have been added to Python 3.9.0, so I may cover more in the next days. If in the mean time you have any preferences, please leave a comment below and thanks for reading.\nReferences https://docs.python.org/3/library/stdtypes.html#str.removeprefix https://docs.python.org/3/library/stdtypes.html#str.removesuffix ","date":"2020-10-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/python39-introduces-removeprefix-removesuffix/","title":"Python 3.9 introduces removeprefix and removesuffix"},{"content":"A few days ago Python 3.9.0 has been released and I really wanted to test ist latest features (maybe I will do a separate post to talk about them) without messing my system with another Python version.\nTo manage my Python versions I\u0026rsquo;ve been using pyenv for a while and once configured, it\u0026rsquo;s very easy to install a new Python version.\nMake sure your pyenv is updated You should have at least pyenv 1.2.21 if you want to test Python 3.9.0 In case you haven\u0026rsquo;t updated it and you are using MacOS, you can do it with this command:\n1 brew update \u0026amp;\u0026amp; brew upgrade pyenv once installed you should see the latest version:\n1 2 pyenv --version pyenv 1.2.21 Install Python 3.9.0 To install Python 3.9.0 you only need pyenv install 3.9.0:\n1 2 3 4 5 6 7 8 9 pyenv install 3.9.0 python-build: use openssl@1.1 from homebrew python-build: use readline from homebrew Downloading Python-3.9.0.tar.xz... -\u0026gt; https://www.python.org/ftp/python/3.9.0/Python-3.9.0.tar.xz Installing Python-3.9.0... python-build: use readline from homebrew python-build: use zlib from xcode sdk Installed Python-3.9.0 to /Users/andrea/.pyenv/versions/3.9.0 Set Python 3.9.0 as the local version Now that the version you want has been installed, you need to tell pyenv you want to use it:\n1 2 3 pyenv local 3.9.0 pyenv which python /Users/andrea/.pyenv/versions/3.9.0/bin/python Install virtualenvwrapper for pyenv pyenv needs its own installation of virtualenvwrapper to manage virtualenvs. You can configure it using pyenv virtualenvwrapper:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 pyenv virtualenvwrapper Collecting virtualenvwrapper Using cached virtualenvwrapper-4.8.4.tar.gz (334 kB) Collecting virtualenv Downloading virtualenv-20.0.33-py2.py3-none-any.whl (4.9 MB) |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.9 MB 4.1 MB/s Collecting virtualenv-clone Using cached virtualenv_clone-0.5.4-py2.py3-none-any.whl (6.6 kB) Collecting stevedore Downloading stevedore-3.2.2-py3-none-any.whl (42 kB) |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42 kB 2.7 MB/s Collecting six\u0026lt;2,\u0026gt;=1.9.0 Using cached six-1.15.0-py2.py3-none-any.whl (10 kB) Collecting filelock\u0026lt;4,\u0026gt;=3.0.0 Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB) Collecting distlib\u0026lt;1,\u0026gt;=0.3.1 Using cached distlib-0.3.1-py2.py3-none-any.whl (335 kB) Collecting appdirs\u0026lt;2,\u0026gt;=1.4.3 Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB) Collecting pbr!=2.1.0,\u0026gt;=2.0.0 Using cached pbr-5.5.0-py2.py3-none-any.whl (106 kB) Using legacy \u0026#39;setup.py install\u0026#39; for virtualenvwrapper, since package \u0026#39;wheel\u0026#39; is not installed. Installing collected packages: six, filelock, distlib, appdirs, virtualenv, virtualenv-clone, pbr, stevedore, virtualenvwrapper Running setup.py install for virtualenvwrapper ... done Successfully installed appdirs-1.4.4 distlib-0.3.1 filelock-3.0.12 pbr-5.5.0 six-1.15.0 stevedore-3.2.2 virtualenv-20.0.33 virtualenv-clone-0.5.4 virtualenvwrapper-4.8.4 Create a virtual environment using Python from pyenv At this point you can create the virtual environment based on Python 3.9.0 using this command mkvirtualenv -p $(pyenv which python) py39-test:\n1 2 3 4 5 6 7 8 9 10 11 mkvirtualenv -p $(pyenv which python) py39-test created virtual environment CPython3.9.0.final.0-64 in 1394ms creator CPython3Posix(dest=/Users/andrea/.virtualenvs/py39-test, clear=False, global=False) seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/Users/andrea/Library/Application Support/virtualenv) added seed packages: pip==20.2.3, setuptools==50.3.0, wheel==0.35.1 activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/py39-test/bin/predeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/py39-test/bin/postdeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/py39-test/bin/preactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/py39-test/bin/postactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/py39-test/bin/get_env_details Check you are using the correct Python version 1 2 (py39-test) ‚ûú ~ python --version Python 3.9.0 As you can see from the above output, we have created a new virtualenv using Python 3.9.0 which has been installed through pyenv.\n","date":"2020-10-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/install-python-with-pyenv-create-virtual-environment-with-specific-python-version/","title":"Using pyenv to install Python and create a virtual environment"},{"content":"Contact Tracing in Italia Negli ultimi giorni non si fa che parlare di Immuni, la app che il Governo Italiano avrebbe scelto, come soluzione di contact tracing per il COVID-19, e vengono sollevati molti dubbi (si va da quelli legittimi a quelli che rasentano il complottismo) al riguardo.\nPer \u0026ldquo;contact tracing\u0026rdquo; si intende una soluzione che, mediante l\u0026rsquo;uso della tecnologia, ci permetta di creare una traccia di tutti i nostri contatti e fare in modo che quando uno di essi dichiarera\u0026rsquo; di essere positivo al COVID-19, le persone che sono entrate in contatto con lui/lei ricevano una notifica.\nPrima che proseguiate nella lettura, mi sento in dovere di fare una doverosa premessa: da oltre 20 anni mi occupo di sviluppo software ed ho esperienza di utilizzo di svariate tecnologie anche in ambiti in cui di solito e\u0026rsquo; l\u0026rsquo;uomo a prendere una decisione. La cosa piu\u0026rsquo; importante pero\u0026rsquo; e\u0026rsquo; che non sono ne\u0026rsquo; un virologo, ne\u0026rsquo; un epidemiologo, ne\u0026rsquo; un medico. Mi limitero\u0026rsquo; quindi ad un\u0026rsquo;analisi dei fatti, rimanendo nell\u0026rsquo;ambito delle mie competenze.\nLa mia personale opinione (tuttavia irrilevante) e\u0026rsquo; che una soluzione tecnologica possa essere di aiuto nelle prossime fasi della pandemia, ma dovra\u0026rsquo; essere accompagnata da un\u0026rsquo;accurata verifica manuale dei risultati.\nI dubbi al momento I maggiori dubbi al momento riguardando l\u0026rsquo;efficacia della soluzione scelta, la sicurezza dei dati sensibili che verranno raccolti e quelli sulla privacy delle persone.\nRitengo tutti questi punti molto importanti, ma sono dell\u0026rsquo;idea che prima di tutto questo si debba fare un punto sulla trasparenza.\nIl Governo e la task force Alcune settimane fa il Governo ha annunciato la creazione di una task force di tecnici, che avrebbe dovuto produrre un report con suggerimenti e linee guida, in modo che il governo potesse effettuare una scelta ragionata. Molti di questi nomi sono noti a chi e\u0026rsquo; del settore (ne conosco personalmente alcuni) e ritengo personalmente che fosse un ottimo punto di partenza.\nIl problema pero\u0026rsquo; e\u0026rsquo; che l\u0026rsquo;intera task force e\u0026rsquo; stata messa sotto Non Disclosure Agreement, che tradotto in termini semplici significa che a nessuno di loro e\u0026rsquo; permesso di rilasciare commenti o dichiarazioni in pubblico, ne\u0026rsquo; di rivelare alcuna informazione su quanto prodotto.\nIl report della task force Il report, ad oggi, non e\u0026rsquo; stato reso pubblico: in che modo possiamo valutare i criteri utilizzati per scegliere la soluzione, se non ci e\u0026rsquo; permesso di leggere il report?\nCome facciamo a verificare che il Governo abbia effettivamente seguito le indicazioni dei tecnici o se abbia preferito fare di testa propria?\nLa soluzione scelta: quali criteri? Al momento non esiste un \u0026ldquo;white paper\u0026rdquo; che ci descriva la soluzione proposta e adottata. In base a quali criteri e\u0026rsquo; stata scelta proprio questa soluzione?\nQuali conseguenze dopo una notifica? Supponiamo di ricevere una notifica che ci avvisa che il giorno X siamo stati per un certo periodo di tempo vicini ad un\u0026rsquo;altra persona che si e\u0026rsquo; poi dichiarata positiva. Quale sara\u0026rsquo; la diretta conseguenza?\nA) Qualcuno verra\u0026rsquo; a farci un tampone di verifica il prima possibile B) Ci verra\u0026rsquo; imposto un periodo di quarantena senza alcuna verifica C) Potremo ignorare la notifica Se le conseguenze di questa importante notifica non vengono stabilite a priori, molti non vorranno rischiare di essere costretti in casa, magari per un falso negativo.\nNota: le possibilita\u0026rsquo; di un falso positivo sono davvero molte. Basandosi sul raggio di azione del Bluetooth, in teoria potremmo essere a 1 metro di distanza da una persona infetta, ma essere nella stanza accanto (e quindi in totale sicurezza). Oppure potremmo passare accanto ad una persona infetta mentre siamo in macchina con il finestrino chiuso. Per non parlare poi degli operatori sanitari: in alcuni casi, loro hanno la certezza di trovarsi nei paraggi di persone infette. Verrebbero considerati infetti anche loro? E quando la sera tornano a casa dai loro coniugi e familiari, sarebbero anche essi considerati positivi dalla app?\nClosed Source Nonostante le raccomandazioni della commissione Europea, pare che il codice sorgente della app non sara\u0026rsquo; pubblico (ma verra\u0026rsquo; rilasciato solo al Governo Italiano). Questo significa che non sara\u0026rsquo; possibile un controllo da parte di terze parti, e non ci sara\u0026rsquo; alcuna garanzia su quello che la app possa fare con i nostri dati (ne\u0026rsquo; sara\u0026rsquo; facile scovare e segnalare bug di sicurezza).\nAggiornamento (21/04/2020): il governo ha annunciato in un aggiornamento, che la app verra\u0026rsquo; rilasciata sotto licenza Open Source (MPL 2.0).\nConclusioni Qualsiasi strada si decida di prendere, e\u0026rsquo; fondamentale che il processo decisionale che ha portato a tale scelta sia quanto piu\u0026rsquo; trasparente possibile. Solo in questo modo si potra\u0026rsquo; ottenere la fiducia del maggior numero di persone e cercare di raggiungere l\u0026rsquo;effetto desiderato. Per il momento, tutta questa trasparenza non c\u0026rsquo;e\u0026rsquo; stata.\n","date":"2020-04-20T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/contact-tracing-non-solo-un-problema-di-privacy/","title":"Contact Tracing: non e' solo un problema di privacy o di sicurezza"},{"content":"Introduction In this period of COVID-19 emergency, many countries are publishing COVID related data that is being used by many existing projects and researchers.\nThe main problem with these data is that they are being released in CSV format on some GitHub repository. While we fully appreciate the opennes of this format, unfortunataly it can introduce an additional work to be done (downloading the data, cleaning it, importing the data into a database, keeping it updated etc\u0026hellip;) before someone can consume and analyse the data.\ncovid-api covid-api project is a free and open source API service which automatically imports the data from various sources (at the moment we support the John Hopkins CSSE data source) and makes it available as a REST API.\nThe service is still under development, but an initial version (with regularly updated data) is already available at https://api.covid19data.cloud.\nHow to use the data To consume the API you don\u0026rsquo;t need an account nor you need to authenticate in any way. You just need to request the right endpoint using the supported parameters.\nHere is an example for Python language:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 In [1]: import requests In [2]: response = requests.get(\u0026#39;https://api.covid19data.cloud/v1/jh/daily-reports?last_update_from=2020-04-01\u0026amp;last_update_to=2020-04-03\u0026amp;country=Italy\u0026#39;) In [3]: response.json() Out[3]: [{\u0026#39;id\u0026#39;: 35343, \u0026#39;country_region\u0026#39;: \u0026#39;Italy\u0026#39;, \u0026#39;province_state\u0026#39;: None, \u0026#39;fips\u0026#39;: None, \u0026#39;admin2\u0026#39;: None, \u0026#39;last_update\u0026#39;: \u0026#39;2020-04-01T21:58:34\u0026#39;, \u0026#39;confirmed\u0026#39;: 110574, \u0026#39;deaths\u0026#39;: 13155, \u0026#39;recovered\u0026#39;: 16847}, {\u0026#39;id\u0026#39;: 37895, \u0026#39;country_region\u0026#39;: \u0026#39;Italy\u0026#39;, \u0026#39;province_state\u0026#39;: None, \u0026#39;fips\u0026#39;: None, \u0026#39;admin2\u0026#39;: None, \u0026#39;last_update\u0026#39;: \u0026#39;2020-04-02T23:25:14\u0026#39;, \u0026#39;confirmed\u0026#39;: 115242, \u0026#39;deaths\u0026#39;: 13915, \u0026#39;recovered\u0026#39;: 18278}] Further API documentation is available at https://api.covid19data.cloud/docs\nNext steps While we keep polishing the code and improving the existing data import procedure, we are planning to support additional data sources. The next one we are going to support is the Italian Protezione Civile.\nIf you are aware of an additional data source that you would like to see covered, please let us know (creating a new Issue on GitHub) or send us a pull request.\nContribute to the project If you are a Python developer and would like to contribute to the project, my advice is to first have a look at the main documentation available in the README.\nThen I suggest to have a look at the existing Issues and see where help is needed or in alternative you can open a new Issue or send a pull request with fixes and improvements.\nI also recommend to become familiar with our Code of Conduct before sending any contribution.\nSponsors and Thanks I want to thank Heroku for accepting to sponsor the hosting of this service.\nI also want to thank all the volunteers involved in the project for their help and contributions.\nDisclaimer We are doing our best to keep the available data updated, clean (removing duplicates), and to provide a reliable service, but we are not in any way responsible for the accuracy of the data nor for the availability of the service itself. Please use it at your own risk.\nAbuse notice: we are currently not requiring any registration or authentication to use this service because we would like to keep it as simple as possible. Please do not abuse the service or you will force us to require a registration (subject to approval) to continue using it.\n","date":"2020-04-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/covid-api-free-and-open-source-api-service-for-covid19-data/","title":"covid-api - a free and open source API service for COVID-19 data"},{"content":"What is going on As you may have heard already, because of brexit, Google is moving UK citizens data from the Northern Ireland data controller to the US one (Google LLC). Leaving the EU, UK citizens are not protected anymore by GDPR, and while this may be unfair, Google is legally allowed to do it.\nThe problem Even if I\u0026rsquo;m an Italian citizen and I live in Italy, a few days ago I received this email from them:\n{ width=90% }\nWhat\u0026rsquo;s wrong with it? The point is that I\u0026rsquo;m an Italian citizen, living in Italy. I have nothing to do with UK (even if I lived there for a few years in the past, my account was created from Italy).\nWhy do they mention \u0026ldquo;UK leaving EU\u0026rdquo; to me, if I don\u0026rsquo;t live in UK?\nI tried to contact them multiple times on their @Google account on Twitter, but I got no reply at all. I tried to search online and it looks like I\u0026rsquo;m not alone, they are doing this to many other people: https://support.google.com/accounts/thread/29317992?hl=en\u0026amp;authuser=1\nLooking for help What should I do? Is this legally allowed?\nIf there was an easy way to complain with them, I would have done it already, but I\u0026rsquo;ve tried to search on their website (even googling it\u0026hellip; no pun intended) but I couldn\u0026rsquo;t find a single contact form to report this issue and of course they are ignoring both Twitter and that forum I linked previously.\nShould I report them to the Privacy Authority? If yes, how?\nFull text of the email Here is the full text of the email I received:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 We‚Äôre improving our Terms of Service and making them easier for you to understand. The changes will take effect on 31 March 2020, and they won‚Äôt impact the way that you use Google services. And, because the United Kingdom (UK) is leaving the European Union (EU), Google LLC will now be the service provider and the data controller responsible for your information and for complying with applicable privacy laws for UK consumer users. For more details, we‚Äôve provided a summary of the key changes and Frequently asked questions. And the next time that you visit Google, you‚Äôll have the chance to review and accept the new Terms. At a glance, here‚Äôs what this update means for you: ‚Ä¢ Improved readability: While our Terms remain a legal document, we‚Äôve done our best to make them easier to understand, including by adding links to useful information and providing definitions. ‚Ä¢ Better communication: We‚Äôve clearly explained when we‚Äôll make changes to our services (like adding or removing a feature) and when we‚Äôll restrict or end a user‚Äôs access. And we‚Äôll do more to notify you when a change negatively impacts your experience on our services. ‚Ä¢ Adding Google Chrome, Google Chrome OS and Google Drive to the Terms: Our improved Terms now cover Google Chrome, Google Chrome OS and Google Drive, which also have service-specific terms and policies to help you understand what‚Äôs unique to those services. ‚Ä¢ Your service provider and data controller is now Google LLC: Because the UK is leaving the EU, we‚Äôve updated our Terms so that a United States-based company, Google LLC, is now your service provider instead of Google Ireland Limited. Google LLC will also become the data controller responsible for your information and complying with applicable privacy laws. We‚Äôre making similar changes to the Terms of Service for YouTube, YouTube Paid Services and Google Play. These changes to our Terms and privacy policy don‚Äôt affect your privacy settings or the way that we treat your information (see the privacy policy for details). As a reminder, you can always visit your Google Account to review your privacy settings and manage how your data is used. If you‚Äôre the guardian of a child under the age required to manage their own Google Account and you use Family Link to manage their use of Google services, please note that when you accept our new Terms, you do so on their behalf as well, and you may want to discuss these changes with them. And of course, if you don‚Äôt agree to our new Terms and what we can expect from each other as you use our services, you can find more information about your options in our Frequently asked questions. Thank you for using Google‚Äôs services. Your Google team ","date":"2020-02-25T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/google-is-moving-eu-citizens-data-to-us/","title":"Google is moving some EU citizens data to US"},{"content":"Since I created my blog with a static pages generator, I\u0026rsquo;ve been using TravisCI to automate the pages build and deployment. My desire to learn something new (we are using CircleCI at work, but I never configured it from scratch) and the recent news about TravisCI acquisition and employees layoff, led me to think about moving to a different service.\nGithub Pages Every account on Github can use a special repository to publish static pages. In my case, since I have github.com/andreagrandi, my special repository is named github.com/andreagrandi.github.io. Once I publish my pages there, they will be accessible from https://andreagrandi.github.io.\nYou will need to use the master branch of the special repository directly and not the gh-pages branch which is available to each repository.\nCircleCI CircleCI is a very flexible and powerful continuous integration tool, which is also free for open source projects. As long as your static website is located on a public repository on Github, you won\u0026rsquo;t have to pay anything to use it. In my case, the surce code of this website is available at https://github.com/andreagrandi/andreagrandi.it\nConfiguration You can find the complete configuration at this address. The only value you won\u0026rsquo;t find is GH_TOKEN. You need to generate this token on Github, at this address: https://github.com/settings/tokens. Give it a nice description like \u0026ldquo;CircleCI deployment token\u0026rdquo;, select repo scope and finally click Generate token button. This token will be used to git push... your pages once they are built. Please remember to keep this token secret and not to publish it anywhere.\nIn my configuration you may notice that I\u0026rsquo;m using Pelican static websites generator, but apart from a few changes, the structure of the configuration should be very similar even if you use Jekill, Hugo etc\u0026hellip; it doesn\u0026rsquo;t really matter how you generate the pages, the deployment phase will be the same.\nDeployment script You will notice that there is a complete bash script embedded in the CircleCI configuration. This script configures git, fetches the existing andreagrandi.github.io repository, and sync the built pages with the existing ones (this avoid creating a commit which contains all the pages so it will contain just the added content). Once the commit is made, the script will finally push the changes to the repository.\nPlease note: regardless of CircleCI settings, the deployment will only happens if we are pushing (or merging a pull request) to master (if [ \u0026quot;${CIRCLE_BRANCH}\u0026quot; = \u0026quot;master\u0026quot; ]; then) and it will actually commit and push pages only if there is something new to commit (if git commit -m \u0026quot;CircleCI build $CIRCLE_BUILD_NUM pushed to Github Pages\u0026quot; ; then). For example if I\u0026rsquo;m just updating something in the CircleCI configuration, which doesn\u0026rsquo;t change anything in the content, the pages won\u0026rsquo;t be deployed again.\nConclusion My first impression of CircleCI is that is faster than TravisCI and this means that I can publish my content more quickly. The possibility of using Docker containers as base image is really powerful and in more complex scenarios we can reproduce the building environment locally on our machine. If you have any advices about how to improve my build script, feel free to leave a comment here.\n","date":"2019-02-24T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-deploy-static-website-github-pages-circleci/","title":"How to deploy a static website to Github Pages using CircleCI"},{"content":"Sometimes we want to run certain tests only on a specific version of Python.\nSuppose you are migrating a large project from Python 2 to Python 3 and you know in advance that certain tests won\u0026rsquo;t run under Python 3.\nChances are that during the migration you are already using the six library. The six libraries have two boolean properties which are initialised to True depending on the Python version which is being used: PY2 when running under Python 2 and PY3 when running under Python 3.\nThis library, combined with the skipIf method of unittest library can be used to easily skip tests when using Python 3:\n1 2 3 4 5 6 7 8 9 10 11 import six import unittest class MyTestCase(unittest.TestCase): @unittest.skipIf(six.PY3, \u0026#34;not compatible with Python 3\u0026#34;) def test_example(self): # This test won\u0026#39;t run under Python 3 pass Credits Thanks to my colleague Nicola for giving me the inspiration to write this post.\n","date":"2019-02-21T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/skipping-tests-depending-python-version/","title":"Skipping tests depending on the Python version"},{"content":"Every time I need to install Python on MacOS or whenever a colleague asks for help, I have to search fo the most updated instructions on Google, and every time I find different ways of doing the exact same thing.\nTired of this, I decided to write down my own notes. Please note that I don\u0026rsquo;t claim this to be the best way of installing Python on MacOS. It works fine for me so use it at your own risk.\nRequirements To follow these instructions you need to at least have installed brew on MacOS. Please follow the instructions on the official website: https://brew.sh\nInstalling Python 3.7.x and Python 2.7.x Even if I strongly suggest to start every new project with Python 3 (since Python 2 will only be supported until the end of 2019), there may be use cases when version 2 is still required, so I will give you the instructions to install both.\nInstalling Python 3.7.x 1 brew install python This will install Python 3 by default.\nInstalling Python 2.7.x 1 brew install python@2 This will install version 2 of Python.\nAdd the Python locations to PATH Edit your .bashrc or .zshrc and add this:\n1 export PATH=\u0026#34;/usr/local/opt/python/libexec/bin:/usr/local/bin:$PATH\u0026#34; You will need to close your terminal and reopen it for the changes to be applied. Once you have done it, you can verify if Python 3 and Python 2 have been installed correctly:\n1 2 python --version Python 3.7.1 and\n1 2 python2 --version Python 2.7.15 Install virtualenv and virtualenvwrapper When working with Python, it\u0026rsquo;s a good thing not to install packages system wide, but confine them in virtual environments. A good and well tested way of doing that is to use virtualenv (and its companion virtualenvwrapper) which makes the most common operations easier.\n1 2 pip install virtualenv pip install virtualenvwrapper Those (and only those) two packages will be installed system wide, because we will need them to be available outside of a virtual environment.\nConfigure virtualenv Edit again your .bashrc (or .zshrc) and add these lines:\n1 2 export WORKON_HOME=~/.virtualenvs [ -f /usr/local/bin/virtualenvwrapper.sh ] \u0026amp;\u0026amp; source /usr/local/bin/virtualenvwrapper.sh This will configure the default location where to store your virtual environments and will run a command every time you open a new terminal, to make sure virtualenvwrapper can work correctly.\nTest if the installed tools are working To make sure everything has been configured correctly, please close and reopen your terminal and let\u0026rsquo;s try to create a new virtual environment:\n1 mkvirtualenv test which should output something like this:\n1 2 3 4 5 6 7 8 9 10 11 Using base prefix \u0026#39;/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7\u0026#39; New python executable in /Users/andrea/.virtualenvs/test/bin/python3.7 Also creating executable in /Users/andrea/.virtualenvs/test/bin/python Installing setuptools, pip, wheel... done. virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/predeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/postdeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/preactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/postactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/get_env_details (test) ‚ûú ~ If you see something similar, it means that the virtual environment has been created correctly. Please note that by default this command will create an environment base on Python 3. Do you need to create one for Python 2? No problem, you just need to do the following:\n1 mkvirtualenv -p /usr/local/bin/python2 test which should output this:\n1 2 3 4 5 6 7 8 9 10 11 Running virtualenv with interpreter /usr/local/bin/python2 New python executable in /Users/andrea/.virtualenvs/test/bin/python2.7 Also creating executable in /Users/andrea/.virtualenvs/test/bin/python Installing setuptools, pip, wheel... done. virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/predeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/postdeactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/preactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/postactivate virtualenvwrapper.user_scripts creating /Users/andrea/.virtualenvs/test/bin/get_env_details (test) ‚ûú ~ Conclusion That\u0026rsquo;s all you have to do to install and configure Python and virtualenv on MacOS. If you have problems, comments or questions, feel free to leave a comment on this post.\n","date":"2018-12-19T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/installing-python-and-virtualenv-on-osx/","title":"Installing Python and virtualenv on MacOS"},{"content":"Exercism (https://exercism.io) is a platform that has been created to help people improving their coding skills, thanks to the volunteers mentoring the students. There are tracks for almost all the popular languages and each track has coding tests that the students can download, solve offline using their preferred editor, and test the solution against the provided unit tests. Once the solution is ready to be reviewed (or even if it\u0026rsquo;s not complete but the student needs help), it can be submitted to the website and it will go in a queue where the first available mentor will pick it and start mentoring.\nThe service is free to use for all the students and the mentors are all volunteers (this doesn\u0026rsquo;t mean that the platform doesn\u0026rsquo;t have any costs. If you are curious about the resources needed to keep the platform alive, you can give a look at this answer on Reddit.\nWhen I found out about the platform, I decided to use it (as student) to improve my Go coding skills. I must say that I\u0026rsquo;ve been learning a lot from the mentors and some of them are putting a lot of effort to give you all the possible advices to improve your coding style. In a single exercise once, I learnt at least five things about Go I didn\u0026rsquo;t know before!\nI\u0026rsquo;ve been a Python developer (professionally) for the last 5 years, but I\u0026rsquo;ve never considered myself an \u0026ldquo;expert\u0026rdquo;. I decided to give it a try with mentoring, because I felt I wanted to give something back to the community, so I registered as mentor too and started mentoring in the Python track.\nThe first surprise has been that mentoring other students, I was probably learning more than how much I was teaching. First of all, once you already know how to solve a problem, it\u0026rsquo;s always interesting to look at other possible solutions. I\u0026rsquo;ve found sometimes that students were providing better (more concise and readable) solutions than mine. Last but not least, before advising someone about conding style or a more idiomatic solution, I always double check things from different sources. There is nothing wrong making mistakes, especially if you are learning\u0026hellip; but it would be damaging for the student if I was teaching them something wrong, so I need to be sure about what I say. This of course makes me study, even the basic things, again and again and at the end of the day, my skills are better too.\nOnce you join the mentors group, you are invited to a private Slack where you can count on the help of other mentors (we have channels for each track/language) or ask questions. So, if you are not sure about something, you can always ask around.\nIf my story and experience convinced you, Exercism is looking for more mentors! The more we have available, the less time the students have to wait in a queue to be mentored. You can find all the instructions at this address https://mentoring.exercism.io\n","date":"2018-11-04T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/why-i-mentor-on-exercism/","title":"Why I mentor on Exercism.io"},{"content":"Python 3.7.x introduced a new method to insert a breakpoint in the code. Before Python 3.7.x to insert a debugging point we had to write import pdb; pdb.set_trace() which honestly I could never remember (and I also created a snippet on VS Code to auto complete it).\nNow you can just write breakpoint() that\u0026rsquo;s it!\nNow\u0026hellip; the only problem is that by default that command will use pdb which is not exactly the best debugger you can have. I usually use ipdb but there wasn\u0026rsquo;t an intuitive way of using it\u0026hellip; and no, just installing it in your virtual environment, it won\u0026rsquo;t be used by default.\nHow to use it then? It\u0026rsquo;s very simple. The new debugging command will read an environment variable named PYTHONBREAKPOINT. If you set it properly, you will be able to use ipdb instead of pdb.\n1 export PYTHONBREAKPOINT=ipdb.set_trace At this point, any time you use breakpoint() in your code, ipdb will be used instead of pdb.\nReferences https://hackernoon.com/python-3-7s-new-builtin-breakpoint-a-quick-tour-4f1aebc444c ","date":"2018-10-16T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-ipdb-with-python-37-breakpoint/","title":"Using ipdb with Python 3.7.x breakpoint"},{"content":"Using PGP can be quite hard, even if you have a lot of experience with computers. By the way encryption is what gives us privacy and permits us to safely transmit information and for this reason it should be easy to use, for everyone.\nKeybase really makes encryption easy to use.\nPGP identity When Keybase was launched it was mainly a wrapper for PGP commands to encrypt and decrypt a message for a certain user, but it also introduced a very nice chain of trust.\nIn Keybase it\u0026rsquo;s possible to either generate a new PGP key or import an existing one but the most important thing is being able to verify our own identity using multiple proofs.\nMany of us have a personal blog, a Twitter or Facebook accounts, a GitHub account etc\u0026hellip; All these accounts combined together make our online identity.\nEvery Keybase account can be verified by other online identities. In Keybase you don\u0026rsquo;t just say \u0026ldquo;I\u0026rsquo;m Andrea Grandi, this is my PGP key\u0026hellip;\u0026rdquo;. In Keybase you can link your existing online accounts to your Keybase account and show additional proofs of your identity.\nUnless an attacker controls all your social accounts, they cannot impersonate and verify themselves as if they were you.\n{ width=100% }\nOnce you are on Keybase, other users can look for you even using your GitHub or Twitter username without having to know your email address or Keybase username. This concept can be very useful in some situations, we will see it later.\nEncrypted Filesystem One of the first features launched by Keybase was their encrypted filesystem. There is a virtual folder located at /keybase (on OSX/Linux or k:\\keybase on Windows) where you will find at least three other folders: public, private, team.\nPublic folders Anything you place inside the /public folder can be accessed by any Keybase user and it\u0026rsquo;s automatically signed. Every user public folder/file can be accessed using their Keybase username, like for example /keybase/public/andreagrandi/hello.txt but you can also use any other identity like /keybase/public/andreagrandi@github/hello.txt or /keybase/public/andreagrandi@twitter/hello.txt\nNote: This is very useful if you only know a person on Twitter (or GitHub etc\u0026hellip;) and you want to share a file with them (or send a message, as we will see later) but you don\u0026rsquo;t follow each other and you can\u0026rsquo;t reach them privately.\nThis is a public folder example of one of the Keybase developers:\n{ width=60% }\nYou can put whatever you want in these folders: your public PGP key, your official avatar, your Signal fingerprint etc\u0026hellip; the other users will access these files with the assurance they haven\u0026rsquo;t been changed by anyone else in the middle.\nNote: please keep in mind that Keybase doesn\u0026rsquo;t work like Dropbox or similar. Files are not synced between your devices and Keybase servers. Files are streamed on demand, so you won\u0026rsquo;t be able to access these files without a working Internet connection.\nPrivate folders Hey but\u0026hellip; where is the encryption here?! Whatever you put inside your private folder can only be read by you and only you. Not even Keybase employees can access the content of your files, because they are encrypted before leaving your devices and decrypted on demand when you want to access them.\nDo you want to share files with anotheruser? No problem. Just create a file inside /keybase/private/andreagrandi,anotheruser (the folder andreagrandi,anotheruser will implicitely exist already) and that file will only be readable by you and anotheruser.\nSecurity and other information Keybase employes only have access to: 1) your top level folder names (like: \u0026ldquo;andreagrandi,anotheruser\u0026rdquo;), 2) when and for how long you are reading/writing, 3) how much space you are using.\nThey won\u0026rsquo;t be able to access the content of your files and not even the files or folders names.\nEvery user initially had 10GB quota available, but a few hints (including one of their recent screenshots) say that now users have 250GB available to store their files.\nYou can find more technical information about Keybase encrypted folders in this article: https://keybase.io/docs/kbfs\nEncrypted Chat A few months ago Keybase introduced the encrypted chat. Messages between users are end to end encrypted and cannot be read by anyone else, not even having access to Keybase servers.\n{ width=100% }\nA better address book When we use services like WhatsApp or Signal, we are forced to share our telephone number if we want the other person to be able to contact us.\nOn Keybase I don\u0026rsquo;t need to share my telephone number. Anyone can reach me using one of my online identities: andreagrandi@twitter, andreagrandi@github etc\u0026hellip;\nYou can even send a message to a person who is not on Keybase yet: if you send a message to randomuser@twitter, when randomuser joins Keybase and verify their Twitter account, the message will be encrypted for them and will be safely delivered.\nSecurity Keybase doesn\u0026rsquo;t use PGP to encrypt chat or files. Transmitting the key across all devices wouldn\u0026rsquo;t be safe so each message is encrypted using the public key of every device connected to the account.\nCommand line Keybase works from the command line too. There is no need to use the graphic client to send a message to another user, you can do something like this:\n1 keybase chat send andreagrandi \u0026#34;Hello mate!\u0026#34; You can integrate messages in any script and it\u0026rsquo;s even available a JSON API:\n1 keybase chat help api For more details you can have a look a this blog post on their website: https://keybase.io/blog/keybase-chat\nTeams Keybase has recently introduced Teams feature. The Chat becomes more similar to Slack, but with the difference that only team members can read the content of messages and files: the server only knows about team names and users, nobody else can access the content.\n{ width=100% }\nIt\u0026rsquo;s important to mention that in Keybase there aren\u0026rsquo;t private channels like there are in Slack: if a team wants to have channels accessible only from a restricted group of users, the admin needs to create a sub team. For example if you have a team called keybaselovers you can create a sub team for admins only called keybaselovers.admins\nTeams have a dedicated encrypter folder that you will find under /keybase/team/keybaselovers\nAt the moment the features available from the UI are quite limited and are only available from the command line. In the next weeks these features will be available from the UI too. In the mean time you can have a look at the commandline help:\n1 2 keybase team --help # for admin\u0026#39;ing teams keybase chat --help # for admin\u0026#39;ing chat channels Create a Team 1 keybase team create keybaselovers Add a user to a Team 1 keybase team add-member keybaselovers --user=alice --role=writer For more information you can have a look at the official announcement page: https://keybase.io/blog/introducing-keybase-teams\nGit Sometimes we have the need to store private information in a safe way and we want to be sure that nobody else is able to access these information.\nLatest feature that has been added to Keybase is encrypted Git repositories. They are like normal GitHub repositories, but their content is stored in a safer way.\n{ width=100% }\nPrivacy and Security What is the difference with GitHub private repositories? In GitHub a private repository is used to store information that only our account can access, but the files are accessible in plain text by GitHub employees. With encrypted Git repositories instead, the information are encrypted before they leave our device and they are stored encrypted. Nobody, without having our private key can read them, not even Keybase employees.\nTeams and Quota Encrypted Git repositories are of course available for teams too. Creating a team repository, it will be available to all the members of the team.\nBoth teams and single users have 100GB of space available (which is separate from Folders quota).\nUsage If I create my personal repository called documents all I have to do to clone it and use it is:\n1 git clone keybase://private/andreagrandi/documents and I can use it as a normal git repository. Every time I commit and push something, the content will be signed and encrypted and only available to the repository owner (which is me) or to the whole team if it\u0026rsquo;s a team repository.\nFor more information, please have a look at the official announcement here: https://keybase.io/blog/encrypted-git-for-everyone\nConclusion Keybase is still in continuous development but it already offers a few interesting features which can help people in their every day life. I strongly advise anyone to get an account, play with the available features and report any bug so the developers will be able to fix them and build an even better product. I can\u0026rsquo;t wait to see the features they will announce in the next months!\n","date":"2017-10-21T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/keybase-pgp-encryption-made-easy/","title":"Keybase: PGP encryption made easy"},{"content":"I\u0026rsquo;ve recently bought a YubiKey 4 and decided to use it for GnuPG too, other than using it as hardware 2FA.\nI\u0026rsquo;ve also decided to make my GnuPG configuration much more safe, generating the master key on an offline computer (in my case a simple RaspberryPi not connected to Internet) and generating a subkey that will be moved to my YubiKey.\nDisclaimer Always think about what your threat model is before deciding something is 100% safe for you. I\u0026rsquo;m not claiming this setup/configuration is bullet proof. If you want to protect your GnuPG key from most of the hackers, keyloggers and if you want to use it on different computers without ever compromising your secret key, this setup can be what you are looking for. If you think you may be victim of a targeted state sponsored attack, I\u0026rsquo;m not sure this setup could be enough.\nWhy keeping offline the master key? If you only use your master key on a computer that never connects to Internet (I reckon you will want to update/patch it from time to time, that\u0026rsquo;s why we are going to keep the master key on an external USB key) you are at least safe from remote attacks.\nWhy using subkeys? Your GnuPG master key is also your \u0026ldquo;identity\u0026rdquo; among every PGP user. If you loose your master key or if your key is compromised you need to rebuild your identity and reputation from scratch. Instead, if a subkey is compromised, you can revoke the subkey (using your master key) and generate a new subkey.\nHow a YubiKey makes things safer? If you always use your subkey from a YubiKey, it\u0026rsquo;s very unlikely that your private key can be stolen: it\u0026rsquo;s impossible to read it from the YubiKey and if you loose your YubiKey or if it\u0026rsquo;s physically stolen, the attacker will still need your passphrase and your YubiKey PIN.\nRequirements 1 YubiKey 4 2 USB keys (in theory you only need one, but I strongly suggest you have another one as backup) 1 offline computer (a simple RaspberryPi with no Internet connection will be fine) Initial setup From now on, I will assume that you have prepared a computer for offline use (in my case I\u0026rsquo;m using a RaspberryPi 2 with Raspbian) and you will type the next commands there and only there.\nPlug one of the USB key (you can format it with VFAT for simplicity) in the offline computer and wait for the system to mount it. At this point it should be mounted in a path like this: /media/AABB-BAAC\nNow set the GnuPG working directory and create it:\n1 2 user@debian:~$ export GNUPGHOME=/media/AABB-BAAC/gnupghome user@debian:~$ mkdir $GNUPGHOME Second disclaimer If you think your threat model doesn\u0026rsquo;t include someone can hack your computer from remote, you can ignore my advice and type these commands on your main laptop (at your own risk).\nNote For my own convenience, to write this tutorial I reproduced all these steps on my MacBook because it was easier to copy/paste commands and outputs but I\u0026rsquo;ve tested it with the exact setup I\u0026rsquo;m describing, and it should be compatible with OSX and Linux. When you see something has been masked it\u0026rsquo;s just to hide (from spam) things like my email or to protect the serial number of my YubiKey. Last but not least, the output shown here could not match exactly the one you get on your own PC and this also depends on the GnuPG version you are using.\nGenerating the master key The master key must be generated using the advanced mode, because by default when a new master key is generated, also a new subkey is created with all the capabilities (Authentication + Signing + Encryption), while we want something different.\nNote: PGP keys up to 4096 bits are only supported in YubiKey 4 models. If you have a YubiKey NEO you must use a 2048 bits key because it\u0026rsquo;s the maximum size supported. Here you will create a PGP key with only the Authentication capability. If your GnuPG version doesn\u0026rsquo;t allow this, choose \u0026ldquo;sign only\u0026rdquo;, just don\u0026rsquo;t create the encryption capability at this time.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 user@debian:~$ gpg --expert --gen-key gpg (GnuPG) 2.0.30; Copyright (C) 2015 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. gpg: directory `/media/AABB-BAAC/gnupghome\u0026#39; created gpg: new configuration file `/media/AABB-BAAC/gnupghome/gpg.conf\u0026#39; created gpg: WARNING: options in `/media/AABB-BAAC/gnupghome/gpg.conf\u0026#39; are not yet active during this run gpg: keyring `/media/AABB-BAAC/gnupghome/secring.gpg\u0026#39; created gpg: keyring `/media/AABB-BAAC/gnupghome/pubring.gpg\u0026#39; created Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) (7) DSA (set your own capabilities) (8) RSA (set your own capabilities) Your selection? 8 Possible actions for a RSA key: Sign Certify Encrypt Authenticate Current allowed actions: Sign Certify Encrypt (S) Toggle the sign capability (E) Toggle the encrypt capability (A) Toggle the authenticate capability (Q) Finished Your selection? s Possible actions for a RSA key: Sign Certify Encrypt Authenticate Current allowed actions: Certify Encrypt (S) Toggle the sign capability (E) Toggle the encrypt capability (A) Toggle the authenticate capability (Q) Finished Your selection? e Possible actions for a RSA key: Sign Certify Encrypt Authenticate Current allowed actions: Certify (S) Toggle the sign capability (E) Toggle the encrypt capability (A) Toggle the authenticate capability (Q) Finished Your selection? q RSA keys may be between 1024 and 4096 bits long. What keysize do you want? (2048) 4096 Requested keysize is 4096 bits Please specify how long the key should be valid. 0 = key does not expire \u0026lt;n\u0026gt; = key expires in n days \u0026lt;n\u0026gt;w = key expires in n weeks \u0026lt;n\u0026gt;m = key expires in n months \u0026lt;n\u0026gt;y = key expires in n years Key is valid for? (0) 2y Key expires at Wed 25 Sep 18:39:49 2019 BST Is this correct? (y/N) y GnuPG needs to construct a user ID to identify your key. Real name: Andrea Grandi Email address: user@email.com Comment: You selected this USER-ID: \u0026#34;Andrea Grandi \u0026lt;user@email.com\u0026gt;\u0026#34; Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? o You need a Passphrase to protect your secret key. We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. gpg: /media/AABB-BAAC/gnupghome/trustdb.gpg: trustdb created gpg: key 2240402E marked as ultimately trusted public and secret key created and signed. gpg: checking the trustdb gpg: 3 marginal(s) needed, 1 complete(s) needed, PGP trust model gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u gpg: next trustdb check due at 2019-09-25 pub 4096R/2240402E 2017-09-25 [expires: 2019-09-25] Key fingerprint = 7D4C 4090 DB50 1693 4614 F6FC 6206 9DE9 2240 402E uid [ultimate] Andrea Grandi \u0026lt;user@email.com\u0026gt; Note: please remember to save your passphrase in a safe place. Choose something you can remember because you will need it every time you need to sign, encrypt or decrypt something.\nCreating a revocation certificate It\u0026rsquo;s very important to create a revocation certificate to be used if and when in the future you want to change your master key and revoke the existing one:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 user@debian:~$ gpg --gen-revoke 2240402E \u0026gt; 2240402E-revocation-certificate.asc sec 4096R/2240402E 2017-09-25 Andrea Grandi \u0026lt;user@email.com\u0026gt; Create a revocation certificate for this key? (y/N) y Please select the reason for the revocation: 0 = No reason specified 1 = Key has been compromised 2 = Key is superseded 3 = Key is no longer used Q = Cancel (Probably you want to select 1 here) Your decision? 3 Enter an optional description; end it with an empty line: \u0026gt; Reason for revocation: Key is no longer used (No description given) Is this okay? (y/N) y You need a passphrase to unlock the secret key for user: \u0026#34;Andrea Grandi \u0026lt;user@email.com\u0026gt;\u0026#34; 4096-bit RSA key, ID 2240402E, created 2017-09-25 ASCII armored output forced. Revocation certificate created. Please move it to a medium which you can hide away; if Mallory gets access to this certificate he can use it to make your key unusable. It is smart to print this certificate and store it away, just in case your media become unreadable. But have some caution: The print system of your machine might store the data and make it available to others! Creating Encryption subkey To create a subkey we need to edit the existing key (please note that 2240402E is the last 8 chars from the fingerprint of the previously generated master key) and specify we want to create an Encryption only key.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 user@debian:~$ gpg --edit-key 2240402E gpg (GnuPG) 2.0.30; Copyright (C) 2015 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Secret key is available. pub 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 usage: C trust: ultimate validity: ultimate [ultimate] (1). Andrea Grandi \u0026lt;user@email.com\u0026gt; gpg\u0026gt; addkey Key is protected. You need a passphrase to unlock the secret key for user: \u0026#34;Andrea Grandi \u0026lt;user@email.com\u0026gt;\u0026#34; 4096-bit RSA key, ID 2240402E, created 2017-09-25 Please select what kind of key you want: (3) DSA (sign only) (4) RSA (sign only) (5) Elgamal (encrypt only) (6) RSA (encrypt only) Your selection? 6 RSA keys may be between 1024 and 4096 bits long. What keysize do you want? (2048) 4096 Requested keysize is 4096 bits Please specify how long the key should be valid. 0 = key does not expire \u0026lt;n\u0026gt; = key expires in n days \u0026lt;n\u0026gt;w = key expires in n weeks \u0026lt;n\u0026gt;m = key expires in n months \u0026lt;n\u0026gt;y = key expires in n years Key is valid for? (0) 2y Key expires at Wed 25 Sep 18:47:21 2019 BST Is this correct? (y/N) y Really create? (y/N) y We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. pub 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 usage: C trust: ultimate validity: ultimate sub 4096R/01731555 created: 2017-09-25 expires: 2019-09-25 usage: E [ultimate] (1). Andrea Grandi \u0026lt;user@email.com\u0026gt; gpg\u0026gt; save Export a backup of the secret keys It\u0026rsquo;s very important to export a backup of the secret keys at this point. Writing the secret subkey to the YubiKey is a destructive process: keys are moved to the YubiKey, they are not copied.\n1 user@debian:~$ gpg --export-secret-key 2240402E \u0026gt; 2240402E-secret.pgp Note: this backup includes both the secret master key and the secret subkey. Please remember to save a backup of this key on a couple of separate USB keys: you will need this keys to generate future subkeys and/or to revoke the existing ones.\nProgramming the YubiKey with all GnuPG keys We have previously created the master key and the encryption subkey. Now we will create the authentication and signing keys directly on the YubiKey (we don\u0026rsquo;t need to have a copy of these keys) and we will move the secret encryption key to the YubiKey.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 user@debian:~$ gpg --edit-key 2240402E gpg (GnuPG) 2.0.30; Copyright (C) 2015 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Secret key is available. pub 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 usage: C trust: ultimate validity: ultimate sub 4096R/01731555 created: 2017-09-25 expires: 2019-09-25 usage: E [ultimate] (1). Andrea Grandi \u0026lt;user@email.com\u0026gt; gpg\u0026gt; addcardkey Signature key ....: [none] Encryption key....: [none] Authentication key: [none] Please select the type of key to generate: (1) Signature key (2) Encryption key (3) Authentication key Your selection? 1 What keysize do you want for the Signature key? (4096) Key is protected. You need a passphrase to unlock the secret key for user: \u0026#34;Andrea Grandi \u0026lt;user@email.com\u0026gt;\u0026#34; 4096-bit RSA key, ID 2240402E, created 2017-09-25 Please specify how long the key should be valid. 0 = key does not expire \u0026lt;n\u0026gt; = key expires in n days \u0026lt;n\u0026gt;w = key expires in n weeks \u0026lt;n\u0026gt;m = key expires in n months \u0026lt;n\u0026gt;y = key expires in n years Key is valid for? (0) 2y Key expires at Wed 25 Sep 18:50:42 2019 BST Is this correct? (y/N) y Really create? (y/N) y pub 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 usage: C trust: ultimate validity: ultimate sub 4096R/01731555 created: 2017-09-25 expires: 2019-09-25 usage: E sub 4096R/771B0554 created: 2017-09-25 expires: 2019-09-25 usage: S [ultimate] (1). Andrea Grandi \u0026lt;user@email.com\u0026gt; gpg\u0026gt; addcardkey Signature key ....: 6FAB DC46 1847 3550 3769 2D32 0DE1 36B4 771B 0554 Encryption key....: [none] Authentication key: [none] Please select the type of key to generate: (1) Signature key (2) Encryption key (3) Authentication key Your selection? 3 What keysize do you want for the Authentication key? (4096) Key is protected. You need a passphrase to unlock the secret key for user: \u0026#34;Andrea Grandi \u0026lt;user@email.com\u0026gt;\u0026#34; 4096-bit RSA key, ID 2240402E, created 2017-09-25 Please specify how long the key should be valid. 0 = key does not expire \u0026lt;n\u0026gt; = key expires in n days \u0026lt;n\u0026gt;w = key expires in n weeks \u0026lt;n\u0026gt;m = key expires in n months \u0026lt;n\u0026gt;y = key expires in n years Key is valid for? (0) 2y Key expires at Wed 25 Sep 18:54:51 2019 BST Is this correct? (y/N) y Really create? (y/N) y pub 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 usage: C trust: ultimate validity: ultimate sub 4096R/01731555 created: 2017-09-25 expires: 2019-09-25 usage: E sub 4096R/771B0554 created: 2017-09-25 expires: 2019-09-25 usage: S sub 4096R/A9B5334C created: 2017-09-25 expires: 2019-09-25 usage: A [ultimate] (1). Andrea Grandi \u0026lt;user@email.com\u0026gt; gpg\u0026gt; toggle sec 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 ssb 4096R/01731555 created: 2017-09-25 expires: never ssb 4096R/771B0554 created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 ssb 4096R/A9B5334C created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 (1) Andrea Grandi \u0026lt;user@email.com\u0026gt; gpg\u0026gt; key 1 sec 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 ssb* 4096R/01731555 created: 2017-09-25 expires: never ssb 4096R/771B0554 created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 ssb 4096R/A9B5334C created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 (1) Andrea Grandi \u0026lt;user@email.com\u0026gt; gpg\u0026gt; keytocard Signature key ....: 6FAB DC46 1847 3550 3769 2D32 0DE1 36B4 771B 0554 Encryption key....: [none] Authentication key: BD26 3AD8 985E CAB0 9F32 7307 DF7C F7C0 A9B5 334C Please select where to store the key: (2) Encryption key Your selection? 2 You need a passphrase to unlock the secret key for user: \u0026#34;Andrea Grandi \u0026lt;user@email.com\u0026gt;\u0026#34; 4096-bit RSA key, ID 01731555, created 2017-09-25 sec 4096R/2240402E created: 2017-09-25 expires: 2019-09-25 ssb* 4096R/01731555 created: 2017-09-25 expires: never card-no: 0006 05672181 ssb 4096R/771B0554 created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 ssb 4096R/A9B5334C created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 (1) Andrea Grandi \u0026lt;user@email.com\u0026gt; gpg\u0026gt; save Check public keys Just to verify everything has been created correctly, we check the public keys. We should see one pub key and three sub:\n1 2 3 4 5 6 7 8 user@debian:~$ gpg -k /media/AABB-BAAC/gnupghome/pubring.gpg -------------------------------- pub 4096R/2240402E 2017-09-25 [expires: 2019-09-25] uid [ultimate] Andrea Grandi \u0026lt;user@email.com\u0026gt; sub 4096R/01731555 2017-09-25 [expires: 2019-09-25] sub 4096R/771B0554 2017-09-25 [expires: 2019-09-25] sub 4096R/A9B5334C 2017-09-25 [expires: 2019-09-25] Check private keys When we check the private keys we should see that one key is still local, marked as sec (it\u0026rsquo;s the private key of the master key), while three other keys are marked as ssb\u0026gt; which means they have been moved to the YubiKey:\n1 2 3 4 5 6 7 8 user@debian:~$ gpg -K /media/AABB-BAAC/gnupghome/secring.gpg -------------------------------- sec 4096R/2240402E 2017-09-25 [expires: 2019-09-25] uid Andrea Grandi \u0026lt;user@email.com\u0026gt; ssb\u0026gt; 4096R/01731555 2017-09-25 ssb\u0026gt; 4096R/771B0554 2017-09-25 ssb\u0026gt; 4096R/A9B5334C 2017-09-25 Import back secret keys from backup (only for multiple YubiKeys) As previously said, when we write the encryption subkey to the YubiKey, the key is moved and not just copied, so we need to import back the secret key into the keyring. It\u0026rsquo;s important to have a backup of the subkey too, not because we need it in case the key is compromised etc\u0026hellip; but because we need it in case we want to write multiple YubiKeys with the same encryption key, so that we have a backup key to use.\n1 user@debian:~$ gpg --import \u0026lt; 2240402E-secret.pgp Completely remove secret keys from laptop Once you have programmed the YubiKey and you are sure the secret keys are backed up on a couple of USB keys, you are ready to remove the secret keys from your laptop.\nNote: you don\u0026rsquo;t need to remove anything if you have conducted the whole setup on a spare offline PC (or on a RaspberryPi) because that\u0026rsquo;s not your every day computer.\n1 user@debian:~$ gpg --delete-secret-key 2240402E Exporting the public PGP key As you know, PGP keys are composed by a secret part and a public one. The public one must be distributed publicly and it\u0026rsquo;s the one people will use to encrypt messages directed to you.\n1 user@debian:~$ gpg --armor --export 2240402E \u0026gt; 2240402E.asc If you have a personal blog/website I suggest to upload it there (for example mine can be found here https://www.andreagrandi.it/2240402E.asc)\nChange YubiKey PINs and complete configuration Every YubiKey is sold with a certain default configuration: there is a user PIN that is required every time we need to use the key to sign/decrypt something (in addition to our passphrase) and there is an admin PIN that is required every time we change certain settings on the YubiKey.\nThe default values are:\nuser PIN: 123456 admin PIN: 12345678 I strongly recommend you to change them following this example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 user@debian:~$ gpg --card-edit Reader ...........: Yubico Yubikey 4 OTP U2F CCID Application ID ...: D000000000000000000000000000000000 Version ..........: 2.1 Manufacturer .....: Yubico Serial number ....: 012345678 Name of cardholder: [not set] Language prefs ...: [not set] Sex ..............: unspecified URL of public key : [not set] Login data .......: [not set] Signature PIN ....: not forced Key attributes ...: rsa4096 rsa4096 rsa4096 Max. PIN lengths .: 127 127 127 PIN retry counter : 3 0 3 Signature counter : 3 Signature key ....: 6FAB DC46 1847 3550 3769 2D32 0DE1 36B4 771B 0554 created ....: 2017-09-25 17:50:37 Encryption key....: FC6F 40BC 4173 8D13 2D7C E958 BCDC EA84 0173 1555 created ....: 2017-09-25 17:47:09 Authentication key: BD26 3AD8 985E CAB0 9F32 7307 DF7C F7C0 A9B5 334C created ....: 2017-09-25 17:54:49 General key info..: sub rsa4096/0DE136B4771B0554 2017-09-25 Andrea Grandi \u0026lt;user@email.com\u0026gt; sec# rsa4096/62069DE92240402E created: 2017-09-25 expires: 2019-09-25 ssb\u0026gt; rsa4096/BCDCEA8401731555 created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 ssb\u0026gt; rsa4096/0DE136B4771B0554 created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 ssb\u0026gt; rsa4096/DF7CF7C0A9B5334C created: 2017-09-25 expires: 2019-09-25 card-no: 0006 05672181 gpg/card\u0026gt; admin Admin commands are allowed # Change the PIN and Admin PINs gpg/card\u0026gt; passwd gpg: OpenPGP card no. D000000000000000000000000000000000 detected 1 - change PIN 2 - unblock PIN 3 - change Admin PIN 4 - set the Reset Code Q - quit Your selection? 1 PIN changed. 1 - change PIN 2 - unblock PIN 3 - change Admin PIN 4 - set the Reset Code Q - quit Your selection? 3 PIN changed. 1 - change PIN 2 - unblock PIN 3 - change Admin PIN 4 - set the Reset Code Q - quit Your selection? q # Make sure the PIN is entered before signing gpg/card\u0026gt; forcesig # Set the URL where the OpenPGP public key can be found. gpg/card\u0026gt; url URL to retrieve public key: https://www.andreagrandi.it/2240402E.asc # Fetch the public key into the local keyring gpg/card\u0026gt; fetch gpg/card\u0026gt; quit Note: when you want to use your YubiKey on any computer (for example your work laptop) you need to at least import your public PGP key into the keyring. If the key is not read automatically, you may need to give it a refresh using this command:\n1 user@debian:~$ gpg --card-status Careful with PINs Please remember that you can only digit a wrong user PIN for a maximum of three times. After three time you will need to edit the YubiKey (with gpg \u0026ndash;card-edit) become admin and use the unblock PIN option. If you digit the wrong admin PIN for three time, you will have to follow a quite complicated procedure (explained at this address: https://developers.yubico.com/ykneo-openpgp/ResetApplet.html) and your YubiKey will be reset with factory settings, deleting your PGP keys from it.\nReferences To write this tutorial I originally followed other articles online. The main ones are:\nhttps://www.esev.com/blog/post/2015-01-pgp-ssh-key-on-yubikey-neo/ https://blog.josefsson.org/2014/06/23/offline-gnupg-master-key-and-subkeys-on-yubikey-neo-smartcard/ https://wiki.debian.org/Subkeys https://www.paulfurley.com/gpg-for-humans-preparing-an-offline-machine/ https://spin.atomicobject.com/2013/11/24/secure-gpg-keys-guide/ https://rnorth.org/gpg-and-ssh-with-yubikey-for-mac Amazon Association disclaimer I\u0026rsquo;m trying a little experiment with the Amazon Association program. Basically, if you click on any of the YubiKey links and decide to buy it, I will get a little commission from it. I\u0026rsquo;ve never tried this before and I\u0026rsquo;ve no idea if it works or not. I\u0026rsquo;m writing this here just for the sake of transparency.\n","date":"2017-09-30T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/configuring-offline-gnupg-masterkey-subkeys-on-yubikey/","title":"Configuring an offline GnuPG master key and subkeys on YubiKey"},{"content":"When we need to create an EC2 resource on AWS using Terraform, we need to specify the AMI id to get the correct image. The id is not easy to memorise and it changes depending on the zone we are working one. On every new release the id changes again. So, how can we be sure to get the correct ID for our region, of the latest image available for a given Linux distribution?\nGetting latest Ubuntu AMI id In this example I will show how to get the ID for the latest version of Ubuntu 16.04 server, for the London region and create an EC2 instance using that ID.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 variable \u0026#34;aws_region\u0026#34; { default = \u0026#34;eu-west-2\u0026#34; } # London provider \u0026#34;aws\u0026#34; { region = \u0026#34;${var.aws_region}\u0026#34; access_key = \u0026#34;youraccesskey\u0026#34; secret_key = \u0026#34;yoursecretkey\u0026#34; } data \u0026#34;aws_ami\u0026#34; \u0026#34;ubuntu\u0026#34; { most_recent = true filter { name = \u0026#34;name\u0026#34; values = [\u0026#34;ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-*\u0026#34;] } filter { name = \u0026#34;virtualization-type\u0026#34; values = [\u0026#34;hvm\u0026#34;] } owners = [\u0026#34;099720109477\u0026#34;] # Canonical } resource \u0026#34;aws_instance\u0026#34; \u0026#34;web\u0026#34; { ami = \u0026#34;${data.aws_ami.ubuntu.id}\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; tags { Name = \u0026#34;HelloUbuntu\u0026#34; } } output \u0026#34;image_id\u0026#34; { value = \u0026#34;${data.aws_ami.ubuntu.id}\u0026#34; } After we have initialised our script using terraform init if we run it, we will get the AMI id and the instance will be created:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 ‚ûú example1$: terraform apply data.aws_ami.ubuntu: Refreshing state... aws_instance.web: Creating... ami: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;ami-03998867\u0026#34; associate_public_ip_address: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; availability_zone: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; ebs_block_device.#: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; ephemeral_block_device.#: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; instance_state: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; instance_type: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;t2.micro\u0026#34; ipv6_address_count: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; ipv6_addresses.#: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; key_name: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; network_interface.#: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; network_interface_id: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; placement_group: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; primary_network_interface_id: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; private_dns: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; private_ip: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; public_dns: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; public_ip: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; root_block_device.#: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; security_groups.#: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; source_dest_check: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;true\u0026#34; subnet_id: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; tags.%: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;1\u0026#34; tags.Name: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;HelloUbuntu\u0026#34; tenancy: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; volume_tags.%: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; vpc_security_group_ids.#: \u0026#34;\u0026#34; =\u0026gt; \u0026#34;\u0026lt;computed\u0026gt;\u0026#34; aws_instance.web: Still creating... (10s elapsed) aws_instance.web: Still creating... (20s elapsed) aws_instance.web: Still creating... (30s elapsed) aws_instance.web: Creation complete (ID: i-0f58f8bd55b3a7e38) Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Outputs: image_id = ami-03998867 That\u0026rsquo;s all we need to spin up an EC2 instance on AWS using latest Ubuntu image available.\n","date":"2017-08-25T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/getting-latest-ubuntu-ami-with-terraform/","title":"Getting latest Ubuntu AMI with Terraform"},{"content":"In the previous part of the tutorial we implemented details management, relations between models, nested APIs and a different level of permissions. Our API is basically complete but it is working properly? Is the source code free of bugs? Would you feel confident to refactor the code without breaking something? The answer to all our question is probably no. I can\u0026rsquo;t be sure if the code behaves properly nor I would feel confident refactoring anything without having some tests coverage.\nAs I mentioned previously, we should have written tests since the beginning, but I really didn\u0026rsquo;t want to mix too many concepts together and I wanted to let the user concentrate on the Rest Framework instead.\nTest structure and configuration Before beginning the fourth part of this tutorial, make sure you have grabbed the latest source code from https://github.com/andreagrandi/drf-tutorial and you have checked out the previous git tag:\n1 git checkout tutorial-1.14 Django has an integrated test runner but my personal choice is to use pytest, so as first thing let\u0026rsquo;s install the needed libraries:\n1 pip install pytest pytest-django As long as we respect a minimum of conventions (test files must start with test_ prefix), tests can be placed anywhere in the code. My advice is to put them all together in a separate folder and divide them according to app names. In our case we are going to create a folder named \u0026ldquo;tests\u0026rdquo; at the same level of manage.py file. Inside this folder we need to create a __init__.py file and another folder called catalog with an additional __init__.py inside. Now, still at the same level of manage.py create a file called pytest.ini with this content:\n1 2 [pytest] DJANGO_SETTINGS_MODULE=drftutorial.settings Are you feeling confused? No problem. You can checkout the source code containing these changes.\n1 git checkout tutorial-1.15 You can check if you have done everything correctly going inside the drftutorial folder (the one containing manage.py) and launching pytest. If you see something like this, you did your changes correctly:\n1 2 3 4 5 6 7 8 9 10 (drf-tutorial) ‚ûú drftutorial git:(master) pytest ============================================================================================================================= test session starts ============================================================================================================================== platform darwin -- Python 2.7.13, pytest-3.0.6, py-1.4.32, pluggy-0.4.0 Django settings: drftutorial.settings (from ini file) rootdir: /Users/andrea/Projects/drf-tutorial/drftutorial, inifile: pytest.ini plugins: django-3.1.2 collected 0 items ========================================================================================================================= no tests ran in 0.01 seconds ========================================================================================================================= (drf-tutorial) ‚ûú drftutorial git:(master) Writing the first test To begin with, I will show you how to write a simple test that will verify if the API can return the products list. If you remember we implemented this API in the first part of the tutorial. First of all create a file called test_views.py under the folder drftutorial/tests/catalog/ and add this code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 import pytest from django.urls import reverse from rest_framework import status from rest_framework.test import APITestCase class TestProductList(APITestCase): @pytest.mark.django_db def test_can_get_product_list(self): url = reverse(\u0026#39;product-list\u0026#39;) response = self.client.get(url) self.assertEqual(response.status_code, status.HTTP_200_OK) self.assertEqual(len(response.json()), 8) before being able to run this test we need to change a little thing in the catalog/urls.py file, something we should have done since the beginning. Please change the first url in this way, adding the name parameter:\n1 2 3 urlpatterns = [ url(r\u0026#39;^products/$\u0026#39;, views.ProductList.as_view(), name=\u0026#39;product-list\u0026#39;), ... at this point we are able to run our test suite again and verify the test is passing:\n1 2 3 4 5 6 7 8 9 10 11 12 (drf-tutorial) ‚ûú drftutorial git:(test-productlist) ‚úó pytest -v ============================================================================================================================= test session starts ============================================================================================================================== platform darwin -- Python 2.7.13, pytest-3.0.6, py-1.4.32, pluggy-0.4.0 -- /Users/andrea/.virtualenvs/drf-tutorial/bin/python2.7 cachedir: .cache Django settings: drftutorial.settings (from ini file) rootdir: /Users/andrea/Projects/drf-tutorial/drftutorial, inifile: pytest.ini plugins: django-3.1.2 collected 1 items tests/catalog/test_views.py::TestProductList::test_can_get_product_list PASSED =========================================================================================================================== 1 passed in 0.98 seconds =========================================================================================================================== To checkout the source code at this point:\n1 git checkout tutorial-1.16 Explaining the test code When we implement a test, the first thing to do is to create a test_* file and import the minimum necessary to write a test class and method. Each test class must inherit from APITestCase and have a name that start with Test, like TestProductList. Since we use pytest, we need to mark our method with @pytest.mark.django_db decorator, to tell the test suite our code will explicitly access the database. We are going to use the client object that is integrated in APITestCase to perform the request. Before doing that we first get the local url using Django\u0026rsquo;s reverse function. At this point we do the call using the client:\n1 response = self.client.get(url) and then we assert a couple of things that we expect to be true:\n1 2 self.assertEqual(response.status_code, status.HTTP_200_OK) self.assertEqual(len(response.json()), 8) We check that our API returns the 200 status code and that in the returned JSON there are 8 elements.\nIt\u0026rsquo;s normally a good practice to create test data inside the tests, but in our case we previously created a data migration that creates test data. Migrations are run every time we run tests so when we call our API, the data will be already there.\nWrapping up I\u0026rsquo;ve written a few tests for all the views we have implemented until now and they are available if you checkout this version of the code:\n1 git checkout tutorial-1.17 I\u0026rsquo;ve only tested the views but it would be nice to test even the permission class, for example. Please remember to write your tests first, if possible: implementing the code will be much more natural once the tests are already in place.\n","date":"2017-08-17T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/creating-a-production-ready-api-with-python-and-django-rest-framework-part-4/","title":"Creating a production ready API with Python and Django Rest Framework ‚Äì part 4"},{"content":"As you may have noticed, my website looks very different compared to a few days ago. It\u0026rsquo;s just a different theme or template, I completely changed how the pages are generated and I\u0026rsquo;m hosting it in a completely different way.\nA brief history When I started this blog 10 years ago, I was hosting it on a shared hosting service and it was based on WordPress. I then decided to keep WordPress as backend (I don\u0026rsquo;t like PHP very much but I wasn\u0026rsquo;t even good at front end development at the time, so using a tool that allowed me to concentrate on the content rather than on design was a natural choice for me) but to move my website to a VPS on DigitalOcean, where I\u0026rsquo;ve self-hosted Nginx + PHP + MySQL and even Postfix for email aliases until a few days ago.\nWhy moving to a static website? In these three or four years I\u0026rsquo;ve been using a VPS, I must say I\u0026rsquo;ve been good enough (or maybe lucky?) at keeping \u0026ldquo;bad people\u0026rdquo; out of my server, but it\u0026rsquo;s true that maintaining a VPS can be very time consuming and you can never be sure that your website is always safe. I\u0026rsquo;ve heard about static website before, but I was a bit skeptic because I had not spent enough time investigating all the possibilities (search and comments are still possible, thanks to external services and plugins).\nAnother advantage of a static website is that I can perfectly \u0026ldquo;run\u0026rdquo; (preview) on my local computer without publishing it online. Pages can be rendered locally and will appear in the browser exactly as they will appear once published online.\nIf you use a tool like WordPress, you need to be constantly connected to Internet to write any change. With static pages I can write my content offline (so I can do it while commuting on the train or while I\u0026rsquo;m flying somewhere) and publish it once I\u0026rsquo;m back online.\nPelican The tool that I\u0026rsquo;m using to generate this website is called Pelican. There are many static website generators, the reason why I chose Pelican is because it\u0026rsquo;s written in Python, so if I need to do any change I can do them and because its templates use Jinja2 which I\u0026rsquo;m already familiar with. It can also import posts from WordPress (and I had over 180 posts to import from my previous website) so if you are migrating from it it\u0026rsquo;s a good choice. Please note that the import script is not perfect and that you may have to adjust some formatting here and there.\nA new deployment pipeline When you use WordPress your website is already online and all you have to do is to login, use the integrated editor, write content and finally publish it. A static website doesn\u0026rsquo;t have any admin tool, it\u0026rsquo;s just static pages. How do you publish content then? There are of course multiple solutions available. In my case my website source code is hosted in a repository on GitHub. When I commit on master branch there is a webhook that triggers a build job on TravisCI. TravisCI fetches the latest source code, installs Pelican on the CI and builds the static pages. Once the build is finished, a bash script is used to publish the generated pages on the static website hosting service.\nHosting a static website The good thing about hosting a static website is that you don\u0026rsquo;t need a database so you can host it almost anywhere at a cheaper price or even for free. In my case I\u0026rsquo;ve decided to use GitHub pages, mainly for simplicity. Every GitHub user can have a static website hosted at \u0026lt;yourusername\u0026gt;.github.io for free. To start using it, you just have to create a repository named \u0026lt;yourusername\u0026gt;.github.io under your GitHub account. In my case the repository is https://github.com/andreagrandi/andreagrandi.github.io. My deploy script simply takes the generated content that is in the output/ folder and git push it on this repository. Once the website has been pushed to git, it\u0026rsquo;s immediately available at https://andreagrandi.github.io\nCloudFlare GitHub Pages service has a little limitation: you can either have your website served from a URL similar to the one I\u0026rsquo;ve just mentioned, including SSL support or you can use your own domain, but you can\u0026rsquo;t have both things (SSL + custom domain). To workaround this, you can instruct your domain registrar (in my case is Gandi.net) to let CloudFlare manage your domain and just enabling \u0026ldquo;Full SSL\u0026rdquo; support will do the trick. I won\u0026rsquo;t repeat here how to use CloudFlare since they have a very nice tutorial explaining how to configure their service to be used with GitHub Pages: https://blog.cloudflare.com/secure-and-fast-github-pages-with-cloudflare/. Remember to include a CNAME file containing your domain name and let your static generetor put it on the root of your website, otherwise GitHub pages won\u0026rsquo;t serve the pages correctly.\nWhy not Amazon S3? While I was looking for instructions about how to host a static websites, I found many examples of websites using Amazon S3. There is nothing wrong with using this service (just keep in mind that it\u0026rsquo;s not free, Amazon charges you for space usage and requests, so keep an eye on the AWS bill) but the way these websites were using it was completely wrong. The most common error I noticed was the fact they were enabling the flexible SSL option on CloudFlare: this means that the connection between the visitor and CloudFlare was encrypted (and visitor could see the the SSL enabled) but the connection between CloudFlare and Amazon S3 was being served with HTTP only, meaning that potentially the pages could have been modified before being served. Infact Amazon doesn\u0026rsquo;t serve the S3 website buckets with SSL, they use plain HTTP (Why are you doing this Amazon?!). To use the S3 bucket correctly one should also configure Route 53 (to manage DNS) and CloudFront (the Amazon equivalent of CloudFlare service, beware because this is also charged separately depending on usage/traffic), making the whole setup a bit more complicated.\nConclusion I finally moved away from my VPS and from now on I will be able to concentrate my time on content only instead of spending part of it to maintain my server. Last but not least, the possibility to write my content offline, will hopefully allow me to write from places (train, airplane) where I\u0026rsquo;ve never written from before. If you have any suggestion or if if you notice any error, feel free to leave a comment here below. In alternative, since now this blog is completely open source and on GitHub, you can fork it and make a pull request!\n","date":"2017-07-02T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/migrating-from-wordpress-to-static-generated-website/","title":"Migrating from WordPress to a static generated website"},{"content":"In the previous part we implemented authentication, permissions and the possibility to POST new products for admins. In this new episode we will see how to implement details management, relations between models, nested APIs and a different level of permissions.\nIf you haven\u0026rsquo;t completed the previous parts or if you want to begin from this one, checkout the right code first:\n1 git checkout tutorial-1.10 Handling Product Details Our current API methods allow us to list all the products we have in our catalog and to create a new one (if we have admin permissions), but what if we wanted to delete or update a single one? What if we wanted to get only a specific product? We need to handle details.\nAs first thing we need to change the ProductSerializer to return the id of the product. Edit catalog/serializers.py and change the class in this way:\n1 2 3 4 class ProductSerializer(serializers.ModelSerializer): class Meta: model = Product fields = (\u0026#39;id\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;description\u0026#39;, \u0026#39;price\u0026#39;) After changing the serializer we need to implement a new view called ProductDetail. Edit catalog/views.py and add the following imports:\n1 2 3 4 from django.http import Http404 from rest_framework.response import Response from rest_framework.views import APIView from rest_framework import status and the following class:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class ProductDetail(APIView): def get_object(self, pk): try: return Product.objects.get(pk=pk) except Product.DoesNotExist: raise Http404 def get(self, request, pk, format=None): product = self.get_object(pk) serializer = ProductSerializer(product) return Response(serializer.data) def put(self, request, pk, format=None): product = self.get_object(pk) serializer = ProductSerializer(product, data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) def delete(self, request, pk, format=None): product = self.get_object(pk) product.delete() return Response(status=status.HTTP_204_NO_CONTENT) let\u0026rsquo;s connect the new view to the urls, editing catalog/urls.py and changing the code in this way:\n1 2 3 4 urlpatterns = [ url(r\u0026#39;^products/$\u0026#39;, views.ProductList.as_view()), url(r\u0026#39;^products/(?P\u0026lt;pk\u0026gt;[0-9]+)/$\u0026#39;, views.ProductDetail.as_view()), ] If we try to PUT, DELETE or GET a product like /products/1/ we can now update, delete or retrieve an existing item, but there is a little problem: we haven\u0026rsquo;t set any permission on this class, so anyone can do it. The previous view was also more compact, why don\u0026rsquo;t we use a generic view to perform these basic operations? Let\u0026rsquo;s refactor ProductDetail with a RetrieveUpdateDestroyAPIView generic class. Open catalog/views.py and change the class code in this way:\n1 2 3 4 class ProductDetail(generics.RetrieveUpdateDestroyAPIView): queryset = Product.objects.all() serializer_class = ProductSerializer permission_classes = (IsAdminOrReadOnly, ) That\u0026rsquo;s it! With just three lines of code we have now implemented the same feature of the previous class, plus we have set the correct permissions.\nTo checkout the code at this point:\n1 git checkout tutorial-1.12 Reviews - Relations between models As many online catalogs already have, it would be nice if our API had an endpoint where it is possible to leave a review for a product and get a list of reviews for a specific product. To implement this feature we need to add a new model to our application. Edit catalog/models.py adding this import:\n1 from django.contrib.auth.models import User and this Django model:\n1 2 3 4 5 6 class Review(models.Model): product = models.ForeignKey(Product, related_name=\u0026#39;reviews\u0026#39;) title = models.CharField(max_length=255) review = models.TextField() rating = models.IntegerField() created_by = models.ForeignKey(User) after creating the model, please remember to create the related DB migration:\n1 $ ./manage.py makemigrations catalog When the model is ready, we have to do some changes to the serializers. First of all we need to write a new one, for our new Review model. Then we have to change our ProductSerializer so that it will return its related reviews. Each Product can have multiple Review. And each Review will be always linked to a specific Product. Edit catalog/serializers.py and change it in this way:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from .models import Product, Review from rest_framework import serializers class ReviewSerializer(serializers.ModelSerializer): created_by = serializers.ReadOnlyField(source=\u0026#39;created_by.username\u0026#39;) class Meta: model = Review fields = (\u0026#39;id\u0026#39;, \u0026#39;title\u0026#39;, \u0026#39;review\u0026#39;, \u0026#39;rating\u0026#39;, \u0026#39;created_by\u0026#39;) class ProductSerializer(serializers.ModelSerializer): reviews = ReviewSerializer(many=True, read_only=True) class Meta: model = Product fields = (\u0026#39;id\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;description\u0026#39;, \u0026#39;price\u0026#39;, \u0026#39;reviews\u0026#39;) Note: in ReviewSerializer when we serialise the user contained in created_by field, return the username instead of the id (to make it more human readable). Another important thing to notice is that the value of the related_name we have set in the Review model must match with the field name we have added in ProductSerializer fields property. In this case we have set it to reviews.\nAt this point we need to add a new view. Edit catalog/views.py and add the following imports:\n1 2 3 from rest_framework.permissions import IsAuthenticatedOrReadOnly from .models import Product, Review from .serializers import ProductSerializer, ReviewSerializer then add this class:\n1 2 3 4 5 6 7 8 9 class ReviewList(generics.ListCreateAPIView): queryset = Review.objects.all() serializer_class = ReviewSerializer permission_classes = (IsAuthenticatedOrReadOnly, ) def perform_create(self, serializer): serializer.save( created_by=self.request.user, product_id=self.kwargs[\u0026#39;pk\u0026#39;]) As you can notice, I had to customise the perform_create method because the default one doesn\u0026rsquo;t know anything about the fact we want to set the created_by and product_id fields. Finally we need to bind this new view to a specific url, so we need to edit catalog/urls.py and add this:\n1 2 3 ... url(r\u0026#39;^products/(?P\u0026lt;pk\u0026gt;[0-9]+)/reviews/$\u0026#39;, views.ReviewList.as_view()), ] At this point any authenticated user should be able to POST a review for a product and anyone should be able to get the list of reviews for each product. If you have any problem with the code and want to move to this point, please checkout this:\n1 git checkout tutorial-1.13 Nested APIs details To complete our API endpoints for Review, we need to add an additional feature¬†that will let users to edit/delete their own review. Before implementing the new view, we need a little bit of refactoring and a new permission class. Edit catalog/permissions.py and add this new class:\n1 2 3 4 5 6 class IsOwnerOrReadOnly(BasePermission): def has_object_permission(self, request, view, obj): if request.method in SAFE_METHODS: return True return obj.created_by == request.user Basically this will permit changes to the review only to its author. Now we are going to add new urls and doing some refactoring at the same time. Edit catalog/urls.py and change the urls in this way:\n1 2 3 4 5 6 7 8 9 10 11 12 urlpatterns = [ url(r\u0026#39;^products/$\u0026#39;, views.ProductList.as_view()), url(r\u0026#39;^products/(?P\u0026lt;product_id\u0026gt;[0-9]+)/$\u0026#39;, views.ProductDetail.as_view()), url( r\u0026#39;^products/(?P\u0026lt;product_id\u0026gt;[0-9]+)/reviews/$\u0026#39;, views.ReviewList.as_view() ), url( r\u0026#39;^products/(?P\u0026lt;product_id\u0026gt;[0-9]+)/reviews/(?P\u0026lt;review_id\u0026gt;[0-9]+)/$\u0026#39;, views.ReviewDetail.as_view() ), ] You may have noticed that I substituted pk with product_id. In the latest url I added, we need to be able to identify two primary keys: the one for the product and the one for the review. I renamed the previous ones for consistency. Now it\u0026rsquo;s time to add the new view for Review details. Edit catalog/view.py and add this class:\n1 2 3 4 5 6 7 8 class ReviewDetail(generics.RetrieveUpdateDestroyAPIView): serializer_class = ReviewSerializer permission_classes = (IsAuthenticatedOrReadOnly, IsOwnerOrReadOnly) lookup_url_kwarg = \u0026#39;review_id\u0026#39; def get_queryset(self): review = self.kwargs[\u0026#39;review_id\u0026#39;] return Review.objects.filter(id=review) What are we doing here? You may have noticed that we set a new property called lookup_url_kwarg. That property is being used to determine the keyword in urls.py to be used for the primary key lookup.\nYou will also need to do some refactoring to the other views, to adapt them to the changes we just did to the urls. I suggest you to have a look at the diffs here:¬†https://github.com/andreagrandi/drf-tutorial/compare/tutorial-1.13...tutorial-1.14 or you can have a look at the whole file here¬†https://github.com/andreagrandi/drf-tutorial/blob/541bf31c11fd1dbf2bcc1d31312086995e3e5b48/drftutorial/catalog/views.py\nIn alternative, you can fetch the whole source code at this point:\n1 git checkout tutorial-1.14 Wrapping Up In this third part of the tutorial you learned how to handle model details in the API and how relations between different model work. In the next part of the tutorial we will do something we should have done since the beginning: adding tests to our code and learn how to properly test the API.\nFeedback Please If you enjoyed this tutorial, please leave me some feedback! I really want to improve my work, based on the users feedback so any little advice will be appreciated, thanks!\n","date":"2017-03-12T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/creating-a-production-ready-api-with-python-and-django-rest-framework-part-3/","title":"Creating a production ready API with Python and Django Rest Framework ‚Äì part 3"},{"content":"In the first part of this tutorial we have seen how to create a basic API using Django Rest Framework. This second part will explain how to implement POST methods and add different levels of permissions and authentication. If you are starting from part 2, you may want to checkout the source code at this exact point:\n1 git checkout tutorial-1.4 A step back Before showing how easy it is to implement a POST method for our existing API, I want to do a step back and show you the \u0026ldquo;manual way\u0026rdquo;, using just the APIView class. Edit the file catalog/views.py and change the code in this way:\n1 2 3 4 5 6 7 8 9 10 11 12 from django.http import HttpResponse from rest_framework.response import Response from rest_framework.views import APIView from .models import Product from .serializers import ProductSerializer class ProductList(APIView): def get(self, request, format=None): products = Product.objects.all() serializer = ProductSerializer(products, many=True) return Response(serializer.data) If we try to use the API again (from the browser of from the http client), it will still work in the same way. The difference here is that we are using the very basic APIView class and we have explicitly defined the GET method for it.\nImplementing a POST method with APIView An API is not being used at its full potential if it\u0026rsquo;s read only. We are going to implement a POST method for the existing view and testing it with httpie client again. First of all we need to add an import to catalog/views.py\n1 from rest_framework import status then we add this method to our ProductList class:\n1 2 3 4 5 6 def post(self, request, format=None): serializer = ProductSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) Now let\u0026rsquo;s test our POST method we just implemented:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ http --json POST http://127.0.0.1:8000/products/ name=\u0026#34;Salamino\u0026#34; description=\u0026#34;Salamino Piccante\u0026#34; price=\u0026#34;10.50\u0026#34; HTTP/1.0 201 Created Allow: GET, POST, HEAD, OPTIONS Content-Type: application/json Date: Thu, 29 Sep 2016 11:48:48 GMT Server: WSGIServer/0.1 Python/2.7.10 Vary: Accept, Cookie X-Frame-Options: SAMEORIGIN { \u0026#34;description\u0026#34;: \u0026#34;Salamino Piccante\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Salamino\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;10.50\u0026#34; } It works! In case something doesn\u0026rsquo;t work, try to fetch the source code at this point:\n1 git checkout tutorial-1.7 Implementing a POST method with ListCreateAPIView Do you remember when I mentioned at the beginning that there is an easy way to do the same thing? I wasn\u0026rsquo;t cheating. Let\u0026rsquo;s change again our old code in catalog/views.py but this time we will use a different base class:\n1 2 3 4 5 6 7 8 9 10 from django.http import HttpResponse from rest_framework import generics from rest_framework.response import Response from .models import Product from .serializers import ProductSerializer class ProductList(generics.ListCreateAPIView): queryset = Product.objects.all() serializer_class = ProductSerializer let\u0026rsquo;s test this again with httpie:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ http --json POST http://127.0.0.1:8000/products/ name=\u0026#34;Pecorino\u0026#34; description=\u0026#34;Pecorino Sardo\u0026#34; price=\u0026#34;7.00\u0026#34; HTTP/1.0 201 Created Allow: GET, POST, HEAD, OPTIONS Content-Type: application/json Date: Thu, 29 Sep 2016 15:21:20 GMT Server: WSGIServer/0.1 Python/2.7.10 Vary: Accept, Cookie X-Frame-Options: SAMEORIGIN { \u0026#34;description\u0026#34;: \u0026#34;Pecorino Sardo\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Pecorino\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;7.00\u0026#34; } We just POSTed some data on the API! How can it work? Well, we have changed the base class from ListAPIView to ListCreateAPIView. This particular class implements a generic POST method that will accept and validate all the fields through the specified serializer.\nAuthentication Now our API let us add products to the catalog, amazing! But\u0026hellip; is it exactly what we want? In a real scenario we don\u0026rsquo;t want any random user to be able to add products in our database, so we are going to protect the POST method allowing only Admin users.\nBefore digging into Django Rest Framework permissions, we need to setup an authentication system. For simplicity we will implement TokenAuthentication. As first step we need to edit settings.py and insert¬†rest_framework.authtoken in the INSTALLED_APPS:\n1 2 3 4 5 ... \u0026#39;rest_framework\u0026#39;, \u0026#39;rest_framework.authtoken\u0026#39;, \u0026#39;catalog\u0026#39;, ] after this, we need to add TokenAuthentication as default authentication class (append this in settings.py at the end):\n1 2 3 4 5 REST_FRAMEWORK = { \u0026#39;DEFAULT_AUTHENTICATION_CLASSES\u0026#39;: ( \u0026#39;rest_framework.authentication.TokenAuthentication\u0026#39;, ) } Finally we need to add a particular URL to the project so that clients will be able to call an endpoint passing username and password to get a token back. Edit drftutorial/urls.py and make it\u0026rsquo;s like this:\n1 2 3 4 5 6 7 8 9 from django.conf.urls import url, include from django.contrib import admin from rest_framework.authtoken.views import obtain_auth_token urlpatterns = [ url(r\u0026#39;^admin/\u0026#39;, admin.site.urls), url(r\u0026#39;^\u0026#39;, include(\u0026#39;catalog.urls\u0026#39;)), url(r\u0026#39;^api-token-auth/\u0026#39;, obtain_auth_token), ] Don\u0026rsquo;t forget to re-run the migrations, because TokenAuthorization needs to change a couple of tables:\n1 2 3 4 5 6 $ ./manage.py migrate Operations to perform: Apply all migrations: admin, auth, authtoken, catalog, contenttypes, sessions Running migrations: Applying authtoken.0001_initial... OK Applying authtoken.0002_auto_20160226_1747... OK In case you had any problem changing the code up to this point, you can always fetch the related git tag:\n1 git checkout tutorial-1.9 Testing the Authentication Before testing the authentication, make sure you created at least the Django superuser with:\n1 $ ./manage.py createsuperuser now let\u0026rsquo;s try to obtain the token we will need later for our API calls:\n1 2 3 4 5 6 7 8 9 10 11 $ http --json POST http://127.0.0.1:8000/api-token-auth/ username=\u0026#34;yourusername\u0026#34; password=\u0026#34;yourpassword\u0026#34; HTTP/1.0 200 OK Allow: POST, OPTIONS Content-Type: application/json Date: Fri, 30 Sep 2016 08:55:07 GMT Server: WSGIServer/0.1 Python/2.7.11 X-Frame-Options: SAMEORIGIN { \u0026#34;token\u0026#34;: \u0026#34;bc9514f0892368cfd0ea792a977aff55d53e3634\u0026#34; } We will need to pass this token in every API call we want to be authenticated. The token is being passed through the \u0026ldquo;Authentication\u0026rdquo; header parameter.\nAPI Permissions Authentication is something that identify the user with a particular system. Permissions instead are the level of things that are allowed or not allowed for a particular user. In our case we said we want to let Admin users to be able to POST new products and we want to let even anonymous users to GET the product list.\nDjango Rest Framework has some built-in classes that we can apply to our views to define the level of permissions. We could have used the IsAdminUser class, but it would not allow anonymous users to perform the GET request. Or we could have used IsAuthenticatedOrReadOnly class, but this would allow any registered user to add products (and we want to let only admins).\nOr\u0026hellip;we can define our own permission class and have exactly what we want. Create a new file catalog/permissions.py\n1 2 3 4 5 6 7 8 9 from rest_framework.permissions import BasePermission, SAFE_METHODS class IsAdminOrReadOnly(BasePermission): def has_permission(self, request, view): if request.method in SAFE_METHODS: return True else: return request.user.is_staff Just as a side note, SAFE_METHODS are GET, HEAD and OPTIONS. These method are considered \u0026ldquo;safe\u0026rdquo; because they don\u0026rsquo;t change any existing data. Open catalog/views.py again, import this at the beginning:\n1 from .permissions import IsAdminOrReadOnly and set this as permission_classes to ProductList:\n1 2 3 ... serializer_class = ProductSerializer permission_classes = (IsAdminOrReadOnly, ) Let\u0026rsquo;s now try to add a new product using the token we got before (you will have to use your own token of course, mine only works on my local db):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ http --json POST http://127.0.0.1:8000/products/ name=\u0026#34;Lardo\u0026#34; description=\u0026#34;Lardo di Colonnata\u0026#34; price=\u0026#34;8.50\u0026#34; \u0026#39;Authorization: Token bc9514f0892368cfd0ea792a977aff55d53e3634\u0026#39; HTTP/1.0 201 Created Allow: GET, POST, HEAD, OPTIONS Content-Type: application/json Date: Fri, 30 Sep 2016 13:04:13 GMT Server: WSGIServer/0.1 Python/2.7.11 Vary: Accept X-Frame-Options: SAMEORIGIN { \u0026#34;description\u0026#34;: \u0026#34;Lardo di Colonnata\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Lardo\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;8.50\u0026#34; } It worked! We have now protected our API so that not admin people can\u0026rsquo;t create any product. If you have any problem with the code, you can check it out with this tag:\n1 git checkout tutorial-1.10 Wrapping Up We have now implemented the POST method to add new products to our catalog. In the next episode we will see how to implement endpoints to get¬†a single product, to update or delete products and finally we will allow registered users to send a review for a specific product.\nFeedback Please I know, this blog doesn\u0026rsquo;t have any \u0026ldquo;comment\u0026rdquo; feature (I was tired of dealing with spam), but if you want to provide some feedback you can still do it by email. Just visit my About page, you will find my email there.\n","date":"2016-10-01T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/creating-a-production-ready-api-with-python-and-django-rest-framework-part-2/","title":"Creating a production ready API with Python and Django Rest Framework ‚Äì part 2"},{"content":"The aim if this tutorial is to show how to create a production ready solution for a REST API, using Python and Django Rest Framework. I will show you how to first create a very basic API, how to handle the authentication and permissions and I will cover deployment and hosting of images. The full source code of the tutorial is available at:¬†https://github.com/andreagrandi/drf-tutorial\nSummary of the complete tutorial Create the basic structure for the API\nAdd Authentication and POST methods```\nHandling details and changes to existing data```\nTesting the API\nSwitching from Sqlite to PostgreSQL\nHosting the API on Heroku\nAdd an Image field and save images to S3\nCreate the basic structure for the API For this tutorial I will assume you have correctly installed at least Python (I will use Python 2.7.x), virtualenv and virtualenvwrapper on your system and I will explain how to create everything else step by step.\nNote: at the time of writing, the tutorial has been based on Django 1.10.1 and Django Rest Framework 3.4.7\nCreating the main project structure 1 2 3 4 5 6 7 mkdir drf-tutorial mkvirtualenv drf-tutorial cd drf-tutorial pip install django djangorestframework django-admin.py startproject drftutorial . cd drftutorial django-admin.py startapp catalog Data Model We will create the API for a generic products catalog, using a very simple structure (to keep things simple). Edit the file catalog/models.py adding these lines:\n1 2 3 4 5 6 7 8 from __future__ import unicode_literals from django.db import models class Product(models.Model): name = models.CharField(max_length=255) description = models.TextField() price = models.DecimalField(decimal_places=2, max_digits=20) after creating the model, we need to add \u0026lsquo;catalog\u0026rsquo; application to INSTALLED_APPS. Edit settings.py and add the app at the end of the list:\n1 2 3 4 5 6 7 8 9 INSTALLED_APPS = [ \u0026#39;django.contrib.admin\u0026#39;, \u0026#39;django.contrib.auth\u0026#39;, \u0026#39;django.contrib.contenttypes\u0026#39;, \u0026#39;django.contrib.sessions\u0026#39;, \u0026#39;django.contrib.messages\u0026#39;, \u0026#39;django.contrib.staticfiles\u0026#39;, \u0026#39;catalog\u0026#39;, ] at this point the Django application will be recognised by the project and we can create and apply the schema migration:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 (drf-tutorial) ‚ûú drftutorial git:(235dfcc) ‚úó ./manage.py makemigrations Migrations for \u0026#39;catalog\u0026#39;: catalog/migrations/0001_initial.py: - Create model Product (drf-tutorial) ‚ûú drftutorial git:(235dfcc) ‚úó ./manage.py migrate Operations to perform: Apply all migrations: admin, auth, catalog, contenttypes, sessions Running migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying catalog.0001_initial... OK Applying sessions.0001_initial... OK API Serializer Serializers are those components used to convert the received data from JSON format to the relative Django model and viceversa. Create the new file catalog/serializers.py and place this code inside:\n1 2 3 4 5 6 7 8 from .models import Product from rest_framework import serializers class ProductSerializer(serializers.ModelSerializer): class Meta: model = Product fields = (\u0026#39;name\u0026#39;, \u0026#39;description\u0026#39;, \u0026#39;price\u0026#39;) In this case we are using a ModelSerializer. We need to create a new class from it, and specify the model attribute, that\u0026rsquo;s it. In this case we also specify the fields we want to return.\nAPI View The serializer alone is not able to respond to an API request, that\u0026rsquo;s why we need to implement a view. In this first version of the view (that we will improve soon) we will \u0026ldquo;manually\u0026rdquo; transform the data available in the serializer dictionary to a JSON response. In catalog/views.py add this code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from django.http import HttpResponse from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from .models import Product from .serializers import ProductSerializer class JSONResponse(HttpResponse): \u0026#34;\u0026#34;\u0026#34; An HttpResponse that renders its content into JSON. \u0026#34;\u0026#34;\u0026#34; def __init__(self, data, **kwargs): content = JSONRenderer().render(data) kwargs[\u0026#39;content_type\u0026#39;] = \u0026#39;application/json\u0026#39; super(JSONResponse, self).__init__(content, **kwargs) def product_list(request): if request.method == \u0026#39;GET\u0026#39;: products = Product.objects.all() serializer = ProductSerializer(products, many=True) return JSONResponse(serializer.data) At this point we need to tell our Django app to use this API view when a certain URL is requested. We first need to add this code in catalog/urls.py\n1 2 3 4 5 6 from django.conf.urls import url from . import views urlpatterns = [ url(r\u0026#39;^products/$\u0026#39;, views.product_list), ] and finally we need to add this to drftutorial/urls.py\n1 2 3 4 5 6 7 from django.conf.urls import url, include from django.contrib import admin urlpatterns = [ url(r\u0026#39;^admin/\u0026#39;, admin.site.urls), url(r\u0026#39;^\u0026#39;, include(\u0026#39;catalog.urls\u0026#39;)), ] Testing our work At this point we should be able to start our Django app:\n1 ./manage.py runserver Let\u0026rsquo;s install a tool that will help us to test the API:\n1 pip install httpie now we can use it to call our URL:\n1 2 3 4 5 6 7 8 $ http http://127.0.0.1:8000/products/ HTTP/1.0 200 OK Content-Type: application/json Date: Wed, 28 Sep 2016 09:54:50 GMT Server: WSGIServer/0.1 Python/2.7.11 X-Frame-Options: SAMEORIGIN [] It works! It\u0026rsquo;s an empty response of course, because we still don\u0026rsquo;t have any data to show, but we will see later how to load some example data in our database. If you have been able to follow the tutorial up to this point, that\u0026rsquo;s good. If not, don\u0026rsquo;t worry. You can checkout the code at exactly this point of the tutorial doing:\n1 git checkout tutorial-1.0 Improving the API View There is a quicker and more efficient way of implementing the same API view we have seen before. We can use a class based view, in particular the APIView class and also have the JSON response implemented automatically. Change the code inside catalog/views.py with this one:\n1 2 3 4 5 6 7 8 9 10 11 12 from django.http import HttpResponse from rest_framework.views import APIView from rest_framework.response import Response from .models import Product from .serializers import ProductSerializer class ProductList(APIView): def get(self, request, format=None): products = Product.objects.all() serializer = ProductSerializer(products, many=True) return Response(serializer.data) You will also have to change catalog/urls.py in this way:\n1 2 3 urlpatterns = [ url(r\u0026#39;^products/$\u0026#39;, views.ProductList.as_view()), ] You can check the source code for this step of the tutorial with:\n1 git checkout tutorial-1.1 There is also another way of writing the same view. Let\u0026rsquo;s try it with ListAPIView. Edit catalog/views.py again and substitute the code with this one:\n1 2 3 4 5 6 7 8 9 10 from django.http import HttpResponse from rest_framework import generics from rest_framework.response import Response from .models import Product from .serializers import ProductSerializer class ProductList(generics.ListAPIView): queryset = Product.objects.all() serializer_class = ProductSerializer With a ListAPIView we are basically creating a read-only API that is supposed to return a list of items. We need to specify a queryset and the serializer_class¬†parameters. Once again, you can get up to this point, checking out the related git tag:\n1 git checkout tutorial-1.2 Creating Initial Data An API that doesn\u0026rsquo;t return any data is not very useful, right? Also, at the moment we haven\u0026rsquo;t implemented yet any feature that let us insert any data. That\u0026rsquo;s why I\u0026rsquo;ve created a data migration for you that will insert some data for you. You may notice that the example data contains some Italian products\u0026hellip; out of the scope of this tutorial, I strongly advise you to google this products and if you ever happen to visit Italy, try them. You won\u0026rsquo;t regret!\nGoing back to our data migration, you first have to create an empty one with:\n1 ./manage.py makemigrations --empty catalog and then open the file that has been created under catalog/migrations/ named 0002_\u0026hellip;.. (your name will be different from mine, so just edit the one starting with 0002 and you will be fine) and fill it with this code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 from __future__ import unicode_literals from django.db import migrations def create_initial_products(apps, schema_editor): Product = apps.get_model(\u0026#39;catalog\u0026#39;, \u0026#39;Product\u0026#39;) Product(name=\u0026#39;Salame\u0026#39;, description=\u0026#39;Salame Toscano\u0026#39;, price=12).save() Product(name=\u0026#39;Olio Balsamico\u0026#39;, description=\u0026#39;Olio balsamico di Modena\u0026#39;, price=10).save() Product(name=\u0026#39;Parmigiano\u0026#39;, description=\u0026#39;Parmigiano Reggiano\u0026#39;, price=8.50).save() Product(name=\u0026#39;Olio\u0026#39;, description=\u0026#39;Olio Oliva Toscano\u0026#39;, price=13).save() Product(name=\u0026#39;Porchetta\u0026#39;, description=\u0026#39;Porchetta toscana cotta a legna\u0026#39;, price=7.50).save() Product(name=\u0026#39;Cantucci\u0026#39;, description=\u0026#39;Cantucci di Prato\u0026#39;, price=4).save() Product(name=\u0026#39;Vino Rosso\u0026#39;, description=\u0026#39;Vino Rosso del Chianti\u0026#39;, price=9.50).save() Product(name=\u0026#39;Brigidini\u0026#39;, description=\u0026#39;Brigidini di Lamporecchio\u0026#39;, price=3.50).save() class Migration(migrations.Migration): dependencies = [ (\u0026#39;catalog\u0026#39;, \u0026#39;0001_initial\u0026#39;), ] operations = [ migrations.RunPython(create_initial_products), ] to apply the migration we just created, just do:\n1 ./manage.py migrate If you try to test the API again from the command line, you will get these products back:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 $ http http://127.0.0.1:8000/products/ HTTP/1.0 200 OK Allow: GET, HEAD, OPTIONS Content-Type: application/json Date: Wed, 28 Sep 2016 12:29:36 GMT Server: WSGIServer/0.1 Python/2.7.11 Vary: Accept, Cookie X-Frame-Options: SAMEORIGIN [ { \u0026#34;description\u0026#34;: \u0026#34;Salame Toscano\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Salame\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;12.00\u0026#34; }, { \u0026#34;description\u0026#34;: \u0026#34;Olio balsamico di Modena\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Olio Balsamico\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;10.00\u0026#34; }, { \u0026#34;description\u0026#34;: \u0026#34;Parmigiano Reggiano\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Parmigiano\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;8.50\u0026#34; }, { \u0026#34;description\u0026#34;: \u0026#34;Olio Oliva Toscano\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Olio\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;13.00\u0026#34; }, { \u0026#34;description\u0026#34;: \u0026#34;Porchetta toscana cotta a legna\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Porchetta\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;7.50\u0026#34; }, { \u0026#34;description\u0026#34;: \u0026#34;Cantucci di Prato\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Cantucci\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;4.00\u0026#34; }, { \u0026#34;description\u0026#34;: \u0026#34;Vino Rosso del Chianti\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Vino Rosso\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;9.50\u0026#34; }, { \u0026#34;description\u0026#34;: \u0026#34;Brigidini di Lamporecchio\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Brigidini\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;3.50\u0026#34; } ] Again, you can get up to this point with:\n1 git checkout tutorial-1.3 One more thing\u0026hellip; No, we are not going to present a new amazing device, I\u0026rsquo;m sorry, but I want to show you a nice Django Rest Framework feature you can have without much additional work. Edit settings.py and add rest_framework to the list of INSTALLED_APPS:\n1 2 3 4 5 6 7 8 9 10 INSTALLED_APPS = [ \u0026#39;django.contrib.admin\u0026#39;, \u0026#39;django.contrib.auth\u0026#39;, \u0026#39;django.contrib.contenttypes\u0026#39;, \u0026#39;django.contrib.sessions\u0026#39;, \u0026#39;django.contrib.messages\u0026#39;, \u0026#39;django.contrib.staticfiles\u0026#39;, \u0026#39;rest_framework\u0026#39;, \u0026#39;catalog\u0026#39;, ] Now, if you are still running the Django app, try to visit this url from your browser:¬†http://127.0.0.1:8000/products/\nThat\u0026rsquo;s very nice, isn\u0026rsquo;t it? You can have browsable APIs at no cost.\nWrapping Up I\u0026rsquo;ve mentioned at the beginning that this is just the first part of my API tutorial. In the next part I will show you how to let the consumer of your API add some products and leave reviews (we will introduce a new model for this). Also, we will see how to set proper permissions to these new API methods so that only admin users will be able to add products while normal users will be able to add reviews. So, if you feel ready, you can begin to follow the second part of this tutorial\nReferences Some parts of this tutorial and a few examples have been taken directly from the original Django Rest Framework tutorial.\n","date":"2016-09-28T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/creating-production-ready-api-python-django-rest-framework-part-1/","title":"Creating a production ready API with Python and Django Rest Framework - part 1"},{"content":"If we try to use the usual ipdb commands from a Jupyter (IPython notebook)\n1 import ipdb; ipdb.set_trace() we will get a similar error:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 -------------------------------------------------------------------------- MultipleInstanceError Traceback (most recent call last) \u0026lt;ipython-input-1-f2b356251c56\u0026gt; in \u0026lt;module\u0026gt;() 1 a=4 ----\u0026gt; 2 import ipdb; ipdb.set_trace() 3 b=5 4 print a 5 print b /home/nnn/anaconda/lib/python2.7/site-packages/ipdb/__init__.py in \u0026lt;module\u0026gt;() 14 # You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/. 15 ---\u0026gt; 16 from ipdb.__main__ import set_trace, post_mortem, pm, run, runcall, runeval, launch_ipdb_on_exception 17 18 pm # please pyflakes /home/nnn/anaconda/lib/python2.7/site-packages/ipdb/__main__.py in \u0026lt;module\u0026gt;() 71 # the instance method will create a new one without loading the config. 72 # i.e: if we are in an embed instance we do not want to load the config. ---\u0026gt; 73 ipapp = TerminalIPythonApp.instance() 74 shell = get_ipython() 75 def_colors = shell.colors /home/nnn/anaconda/lib/python2.7/site-packages/traitlets/config/configurable.pyc in instance(cls, *args, **kwargs) 413 raise MultipleInstanceError( 414 \u0026#39;Multiple incompatible subclass instances of \u0026#39; --\u0026gt; 415 \u0026#39;%s are being created.\u0026#39; % cls.__name__ 416 ) 417 MultipleInstanceError: Multiple incompatible subclass instances of TerminalIPythonApp are being created. The solution is to use Tracer instead:\n1 2 from IPython.core.debugger import Tracer Tracer()() Source:¬†http://stackoverflow.com/questions/35613249/using-ipdb-to-debug-python-code-in-one-cell-jupyter-or-ipython\n","date":"2016-05-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-python-ipdb-from-jupyter/","title":"Using Python ipdb from Jupyter"},{"content":"PyPI is the Python Package Index, that archive that let you install a package using pip, for example: pip install Flask\nIn the past days I started writing a Python API client for Toshl expense manager and I decided to publish the library on PyPI. You can have a look at my library here¬†https://github.com/andreagrandi/toshl-python (please note: it\u0026rsquo;s still in development and Toshl API is not even public yet) in case you are not sure how to structure it.\nI found a nice guide but it wasn\u0026rsquo;t complete (for example it didn\u0026rsquo;t say how to sign packages) so I decided to rewrite it adding more information.\nCreate PyPI accounts To publish packages on PyPI you need to create two accounts: one for the production server and another one for the test server. When you register, please specify (if you have one, but I really hope you do) the PGP id of your public key. Once the accounts are created, you need to create a file named .pypirc in your $HOME folder containing the following configuration:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [distutils] index-servers = pypi pypitest [pypi] repository=https://pypi.python.org/pypi username=your_username password=your_password [pypitest] repository=https://testpypi.python.org/pypi username=your_username password=your_password Please substitute your_username and your_password with the details you sent during the registration.\nPreparing the package I assume you have structured your library in the proper way and have included a setup.py with all the configuration (it\u0026rsquo;s not something specific to PyPI so you should have done it already). If you haven\u0026rsquo;t I remember you can give a look at my library here¬†https://github.com/andreagrandi/toshl-python¬†in particular to the setup.py:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from setuptools import setup, find_packages setup( name=\u0026#39;toshl\u0026#39;, version=\u0026#39;0.0.3\u0026#39;, url=\u0026#39;https://github.com/andreagrandi/toshl-python\u0026#39;, download_url=\u0026#39;https://github.com/andreagrandi/toshl-python/tarball/0.0.3\u0026#39;, author=\u0026#39;Andrea Grandi\u0026#39;, author_email=\u0026#39;a.grandi@gmail.com\u0026#39;, description=\u0026#39;Python client library for Toshl API.\u0026#39;, packages=find_packages(exclude=[\u0026#39;tests\u0026#39;]), zip_safe=False, include_package_data=True, platforms=\u0026#39;any\u0026#39;, license=\u0026#39;MIT\u0026#39;, install_requires=[ \u0026#39;requests==2.9.1\u0026#39;, ], ) Upload the package to PyPI Test server The first time you upload the package you will need to register it:\n1 python setup.py register -r pypitest and then you will need to build the package and upload it (please note I\u0026rsquo;m using the \u0026ndash;sign to sign the package with PGP):\n1 python setup.py sdist upload --sign -r pypitest Upload the package to PyPI production server Once you have verified that you are able to build and upload the package to the test server (without getting any errors), you should upload it to the production server:\n1 2 python setup.py register -r pypi python setup.py sdist upload --sign -r pypi This is everything you need to do if you want to publish a Python package on PyPI. Happy coding!\n","date":"2016-04-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-publish-a-python-package-to-pypi/","title":"How to publish a Python package to PyPI"},{"content":"A light sensor is a small component with a particular characteristic: it is basically a resistor and its resistance decreases if the light is more intense. To use it with micro:bit we need to use one of the analogic ports. To build this circuit you will need a breadboard, 3 jumper wires, a 10k resistance and possibly a Kitronik breadboard kit.\nThe project I wanted to realise a simple project where, depending on the light intensity captured by the light sensor, the micro:bit shows an image of the Sun if the light is intense and an image of the Moon if the light is less intense.\nHere is the complete circuit scheme:\n{ width=40% }\n\u0026ldquo;Image Copyright ¬© Kitronik\u0026rdquo; and here is a picture of the finished project I created:\n{ width=40% }\nThe source code I needed is available here:\nand as a demo I realised this small **video**: ","date":"2016-02-08T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-a-light-sensor-with-bbc-microbit-and-micropython/","title":"Using a light sensor with BBC micro:bit and MicroPython"},{"content":"BBC micro:bit has a few IO pins that can be used to interact with external devices. The problem with the board is that it\u0026rsquo;s not easy to connect the classic jumper wires (those that we normally connect to a breadboard) to the micro:bit, unless using a crocodile clip and being limited to just 3 pins.\nKitronik breadboard kit solves this problem, offering an interface where the micro:bit can be plugged and all the pins are easily connectable to the breadboard using normal male/female jumper wires.\nI\u0026rsquo;ve built a very simple circuit following an example you can find on this manual¬†https://www.kitronik.co.uk/pdf/5603_inventors_kit_for_the_bbc_microbit_tutorial_book.pdf\n{ width=40% }\nTo build the circuit you also need 4 male/female jumper wires and two buttons. All this circuit does is to connect the buttons to the micro:bit pins that relate to those buttons. Basically pressing those buttons is the same as pressing button A or button B on the micro:bit board. Here you can see the schema in detail:\n{ width=40% }\n\u0026ldquo;Image Copyright ¬© Kitronik\u0026rdquo; I\u0026rsquo;ve also made a short video so that you can see it in action:\nAnd of course the source code is available too:\n","date":"2016-02-07T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/prototyping-bbc-microbit-projects-with-kitronik-breadboard-kit/","title":"Prototyping BBC micro:bit projects with Kitronik breadboard kit"},{"content":"In these days I\u0026rsquo;m having a bit of fun with BBC MicroBit board and I\u0026rsquo;m learning how to use the different sensors available. The latest one I wanted to try was the accelerometer. The board can \u0026ldquo;sense\u0026rdquo; if you are moving it in any of the 3 dimensional axes: X, Y, Z. According to the documentation there are four methods available that can be used to get these values:¬†microbit.accelerometer.get_values() will return you a tuple with all the 3 values, while¬†microbit.accelerometer.get_x(),¬†microbit.accelerometer.get_y(),¬†microbit.accelerometer.get_z() will give you the single values.\nThe documentation on the official website doesn\u0026rsquo;t explain much and for example I didn\u0026rsquo;t even know what was the range of the values I can get back from these methods (by the way it\u0026rsquo;s between -1024 and 1024), so I decided to play with the code directly and write a very simple example. The small example I wrote, shows a smile on the board display if you keep it straight and shows a sad face if you bend it.\nThis is the result:\nand this is all the needed code of the application:\nIn the next days I will try to play with more sensors and to publish other examples.\n","date":"2016-01-26T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-bbc-microbit-accelerometer-with-python/","title":"Using BBC MicroBit accelerometer with Python"},{"content":"Sometimes we need to test if our code also works with PyPy implementation of Python. Assuming you have already installed it in your system, first find out where it is installed:\n1 2 which pypy /usr/local/bin/pypy then you need mkvirtualenv to create a virtual environment that will use this runtime:\n1 2 3 4 5 6 7 8 9 mkvirtualenv -p /usr/local/bin/pypy pypy-test Running virtualenv with interpreter /usr/local/bin/pypy New pypy executable in pypy-test/bin/pypy Installing setuptools, pip, wheel...done. (pypy-test)‚ûú ~ python Python 2.7.10 (f3ad1e1e1d6215e20d34bb65ab85ff9188c9f559, Sep 01 2015, 06:26:30) [PyPy 2.6.1 with GCC 4.2.1 Compatible Apple LLVM 6.1.0 (clang-602.0.53)] on darwin Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt;\u0026gt; That\u0026rsquo;s it! You can now use this virtual environment to run your Python application using PyPy environment.\n","date":"2015-12-18T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-python-pypy-in-a-virtual-environment/","title":"Using Python PyPy in a virtual environment"},{"content":"A few days ago I had the great opportunity to attend an event organised in collaboration with Python Software Foundation, a few primary school teachers and hosted by Computing at School, in London. The meeting was organised by Yvonne Walker (from CAS) and Nicholas Tollervey (PSF).¬†The aim of the meeting was¬†for teachers and developers to meet and discuss the opportunities offered by¬†MicroPython on the BBC micro:bit. During the event a BBC¬†micro:bit board was loaned to each person for the purpose of developing Python scripts, MicroPython itself or educational resources for the BBC micro:bit. Nicholas made it very clear that there is an NDA in place until the device is delivered to the kids and explained what we could or couldn\u0026rsquo;t do.\n{width=100%}\nThe Board {width=100%}\nThe board is a¬†4 x 5 cm device with an ARM Cortex-M0 processor, accelerometer and magnetometer sensors, Bluetooth and USB connectivity, a display consisting of 25 LEDs, two programmable buttons, and can be powered by either USB or an external battery pack (source: https://en.wikipedia.org/wiki/Micro_Bit ).\nFlashing the firmware Once you get a new board, it probably doesn\u0026rsquo;t have a proper firmware and application flashed. I suggest you to download the Python MicroBit REPL from this repository:¬†https://github.com/ntoll/microrepl\nAll you need to do is to connect the board to your computer, using a micro-USB cable. The device will be mounted as a volume. At this point, drag \u0026amp; drop the file called firmware.hex into the mounted volume. The firmware will be flashed and during the operation you will see a yellow led flashing.\nUsing¬†MicroPython micro:bit REPL To start writing some Python code on micro:bit you first need to clone this repository\n1 git clone git@github.com:ntoll/microrepl.git once you have cloned the repository, you need to install the Python dependencies (I suggest you to do it from inside a virtualenv)\n1 pip install -r requirements.txt start the MicroPython REPL\n1 python microrepl.py and the Python shell will open, so you can start writing commands, like this one\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 (microbit)‚ûú microrepl git:(master) python microrepl.py Quit: Ctrl+] | Stop program: Ctrl+C | Reset: Ctrl+D Type \u0026#39;help()\u0026#39; (without the quotes) then press ENTER. \u0026gt;\u0026gt;\u0026gt; import this The Zen of MicroPython, by Nicholas H.Tollervey Code, Hack it, Less is more, Keep it simple, Small is beautiful, Be brave! Break things! Learn and have fun! Express yourself with MicroPython. Happy hacking! :-) \u0026gt;\u0026gt;\u0026gt; BBC micro:bit MicroPython Editor Typing all the Python commands directly into the shell can be a bit difficult. You can use a very nice and dedicated editor to write code and produce the compiled application for the micro:bit. All you need to do is clone this repository\n1 git clone git@github.com:ntoll/upyed.git Open the file named editor.html with your browser and start writing your code. When your code is done, you can generate the .hex file clicking on Download button. To load the compiled application you just need to drag \u0026amp; drop the .hex file to the mounted device, exactly like you did the first time to flash it. If you need a reference for all the methods and libraries available, you can consult the official documentation here¬†http://microbit-micropython.readthedocs.org/en/latest/index.html\nReferences https://github.com/ntoll/microrepl https://github.com/ntoll/upyed https://www.microbit.co.uk/ http://microbit-micropython.readthedocs.org/en/latest/index.html ","date":"2015-12-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/getting-started-with-bbc-microbit-and-python/","title":"Getting started with BBC MicroBit and Python"},{"content":"After having upgraded OSX to 10.11.2 on my MacBook, I noticed that my encfs volume didn\u0026rsquo;t mount after reboot. I tried to run the script manually and all I got was this error:\n1 2 3 4 dyld: Symbol not found: __ZN5boost7archive17xml_iarchive_implINS0_12xml_iarchiveEE13load_overrideERNS0_15class_name_typeEi Referenced from: /usr/local/Cellar/encfs/1.8.1/lib/libencfs.6.dylib Expected in: /usr/local/lib/libboost_serialization-mt.dylib in /usr/local/Cellar/encfs/1.8.1/lib/libencfs.6.dylib I quickly found that was a common problem caused by a new version of Boost being installed:¬†https://github.com/Homebrew/homebrew/issues/46254\nTo fix it, you just need to reinstall encfs using this command\n1 brew reinstall -s encfs ","date":"2015-12-09T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/fix-encfs-under-osx-after-upgrading-to-10-11-2/","title":"Fix encfs under OSX after upgrading to 10.11.2"},{"content":"Finally Letsencrypt went to public beta and I really couldn\u0026rsquo;t wait to use it on my VPS (where this blog is hosted). Until few days ago I was using a free SSL certificate from StartSSL. The service is nice and I\u0026rsquo;m grateful to them for this important resource they are providing for free, but it must be said that their renewal procedure isn\u0026rsquo;t¬†one of the most user friendly.\nFor people who don\u0026rsquo;t know the service yet, Letsencrypt not only gives¬†free SSL certificates, they also provide a command line tool that people can use to request a new certificate or to renew an existing one. This means that you don\u0026rsquo;t have to worry anymore if/when your certificate expires, you can set a crontab command and have the certificate automatically renewed for you.\nClient installation To request a SSL certificate you need to install their command line utility. Unless it has already been packaged for your distribution, for the moment it\u0026rsquo;s much easier to get it from git as they explain in their installation instructions:\n1 2 3 git clone https://github.com/letsencrypt/letsencrypt cd letsencrypt ./letsencrypt-auto Getting the SSL certificate There are a few different options available to request a certificate, but the easiest one is to use the \u0026ndash;webroot option, specifying the document root of your website so that the client will be able to put there a verification (temporary) file that will be served to the remote service and used as verification method. In my case I only needed this command:\n1 ./letsencrypt-auto certonly --webroot -w /var/www/andreagrandi.it/ -d www.andreagrandi.it -d andreagrandi.it --email myemail@myprovider.com --renew-by-default --agree-tos Please note that I had to specify both www.andreagrandi.it and andreagrandi.it as domains, otherwise it would have been invalid when requesting just andreagrandi.it resources.\nConfiguration files and certificates installation The command above will save all the configuration under /etc/letsencrypt/ and all the generated certificates under /etc/letsencrypt/live/www.andreagrandi.it/*.pem (all the *.pem files here are symbolic links to the current certificate). If you are using Nginx the only files you need are fullchain.pem and privkey.pem and you can set them in your Nginx configuration using these two parameters:\n1 2 ssl_certificate /etc/letsencrypt/live/www.andreagrandi.it/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/www.andreagrandi.it/privkey.pem; In case you want to have a look at my full Nginx configuration file, as reference, you can find it here¬†https://gist.github.com/andreagrandi/8b194c99cd3e77fdb5a8\nAutomatic renewal The last thing to be configured is a crontab rule to call the script every\u0026hellip; 2 months. Why 2 months? Letsencrypt SSL certificates expire in 3 months. Usually SSL certificates are valid at least for 1 year, but Letsencrypt decided to make it 3 months to incentivate the automation of the renewal. I set it to 2 months, so if anything goes wrong I still have plenty of time to do it manually. To edit crontab for root user execute crontab -e and add this line:\n1 0 3 1 */2 * /root/letsencrypt/letsencrypt-auto certonly --webroot -w /var/www/andreagrandi.it/ -d www.andreagrandi.it -d andreagrandi.it --email email@domain.com --renew-by-default --agree-tos \u0026amp;\u0026amp; service nginx reload Just a final note. You may have noticed that this website presents an SSL certificate issued by COMODO. That\u0026rsquo;s because I have CloudFlare in front of my website and that\u0026rsquo;s how their SSL strict option works (at least for free plans).\n","date":"2015-12-06T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/getting-a-free-ssl-certificate-from-letsencrypt-and-configuring-it-on-nginx-with-automatic-renewal/","title":"Getting a free SSL certificate from Letsencrypt and configuring it on Nginx with automatic renewal"},{"content":"With EncFS it\u0026rsquo;s possible to keep our data in almost any cloud (Dropbox, OneDrive, etc\u0026hellip;), having a good level of privacy and security. Infact EncFS encrypt and decrypt our data automatically. It\u0026rsquo;s available for Linux as well and using a commercial solution (that is currently unsupported) even on Windows.\nInstalling EncFS EncFS can be installed from brew. If you don\u0026rsquo;t have brew package manager installed on OSX you can install it using this command:\n1 ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; After brew, you need to install OSXFuse from this website¬†http://osxfuse.github.io\nFinally you can install encfs using this command:\n1 brew install homebrew/fuse/encfs Configuring the encrypted folder Now that EncFS is installed, you can either mount an existing EncFS volume or create a new one. In both cases the command is the same:\n1 encfs ~/Dropbox/Private ~/Private If you are mounting an existing encrypted volume, you will be prompted for the password. If you are creating a new encrypted volume you will be asked some questions about EncFS parameters.\nNote: if it\u0026rsquo;s important for you to keep compatibility with BoxCryptor Classic (in case you want to use the same volume under Windows), please refer to this other article I wrote:¬†https://www.andreagrandi.it/2014/09/12/create-an-encfs-volume-compatible-with-boxcryptor-classic/\nMount the encrypted volume on startup First of all you need to save the volume\u0026rsquo;s password inside the OSX keychain. Open the app Keychain Access and create a new entry with name encfs and account value encfs, then write your password and click Add:\n{ width=60% }\nOnce the password is saved, open a text editor and paste this script and save it as encfs_mount.sh inside your $HOME folder:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/bin/bash # Secure EncFS Dropbox mounter by Daniel Widerin \u0026lt;daniel@widerin.net\u0026gt; SOURCE=~/Dropbox/Private TARGET=~/Private VOLUME_TITLE=Private KEYCHAIN_PASSWORD=\u0026#39;encfs\u0026#39; ENCFS=/usr/local/bin/encfs mount | grep $TARGET \u0026gt;/dev/null [[ \u0026#34;$?\u0026#34; -eq \u0026#34;0\u0026#34; ]] \u0026amp;\u0026amp; /usr/sbin/diskutil unmount $TARGET if [ ! -d $TARGET ]; then echo \u0026#34;Create new mountpoint $TARGET\u0026#34; mkdir $TARGET chmod 0700 $TARGET fi $ENCFS $SOURCE $TARGET --extpass=\u0026#34;security 2\u0026gt;\u0026amp;1 \u0026gt;/dev/null find-generic-password -gl \u0026#39;$KEYCHAIN_PASSWORD\u0026#39; |grep password|cut -d \\\\\\\u0026#34; -f 2\u0026#34; -ovolname=$VOLUME_TITLE Make it executable:\n1 chmod +x ~/encfs_mount.sh Open AppleScript editor and paste this text inside and save as an app in the $HOME folder:\n{ width=60% }\n1 do shell script \u0026#34;$HOME/encfs_mount.sh\u0026#34; Finally, open \u0026ldquo;System Preferences\u0026rdquo; -\u0026gt; \u0026ldquo;Users \u0026amp; Groups\u0026rdquo; and add the previously saved application.\n{ width=60% }\nFinal notes At this point encfs is configured to be mounted at startup and to save the encrypted files inside Dropbox. Please note: do not save anything directly on ~/Dropbox/Private, only read and save your files from ~/Private\nReferences https://www.maketecheasier.com/install-encfs-mac/ http://ninjatips.com/encrypt-dropbox-using-encfs/ ","date":"2015-10-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-configure-encfs-on-osx-10-10-yosemite/","title":"How to configure EncFS on OSX 10.10 (Yosemite)"},{"content":"Sometimes we need to reverse the order of the elements in a Python list. While there can be many different ways of implementing this task, I found three in particular that I appreciate for different reasons. Let\u0026rsquo;s define first a list of integers that we will reverse later.\n1 l = [1, 2, 3, 4, 5, 6] List slicing This method can be a bit obscure at first read, but basically it slices the whole list proceding in the reverse order:\n1 2 [input]: print l[::-1] [output]: [6, 5, 4, 3, 2, 1] Reversed method We use the reversed¬†method that returns an iterable object and a list comprehension to generate the new list\n1 2 [input]: print [x for x in reversed(l)] [output]: [6, 5, 4, 3, 2, 1] ###¬†Swapping values in place\nThis last method is more verbose and it basically divides the list in two parts and swaps the first with sixth, the second with fifth, etc\u0026hellip;\n1 2 3 4 5 6 [input]: for i in range(0, len(l) / 2): l[i], l[len(l) -1 -i] = l[len(l) -1 -i], l[i] print l [output]: [6, 5, 4, 3, 2, 1] ","date":"2015-10-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/reversing-a-list-in-python/","title":"Reversing a List in Python"},{"content":"A decorator is a Python function that takes a function object as an argument and returns a function as a value. Here is an example of decorator definition:\n1 2 3 4 5 6 def foo(function): # make a new function def new_function(): # some code return new_function To apply a decorator to an existing function, you just need to put @decorator_name in the line before its definition, like this example:\n1 2 3 @foo def hello(): print \u0026#39;Hello World\u0026#39; This decorator doesn\u0026rsquo;t do anything, so let\u0026rsquo;s think about a more concrete problem we could solve using decorators.\nFibonacci¬†sequence By definition, the first two numbers in the Fibonacci sequence are either 1 and 1 or 0 and 1. All the other numbers are the sum of the previous two numbers of the sequence. Example:\n0, 1: the third number is 1 0, 1, 1: the fourth number is 2 0, 1, 1, 2: the fifth number is 3 0, 1, 1, 2, 3: the sixth number is 5 etc\u0026hellip; If we wanted to give a math definition of the sequence, we could describe it in this way:\nF(0): 0 F(1): 1 F(n): F(n-1) + F(n-2) In Python we could have a recursive function like the following one:\n1 2 3 4 5 def fib(n): if n \u0026lt; 2: return n else: return fib(n-1) + fib(n-2) What\u0026rsquo;s the problem with this implementation? The code works as expected, but it\u0026rsquo;s very inefficient. The next picture will explain what happens when we will try, for example, to calculate the 5th number of the sequence:\n{ width=60%}\nFib(5) is Fib(4) + Fib(3), but Fib(4) itself is Fib(3) + Fib(2), and\u0026hellip; the picture just tell us that we have calculated Fib(3) 2 times, Fib(2) 3 times, Fib(1) 5 times! Why are we repeating the same operation every time if we already calculated the result?\nMemoization In computing, memoization is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again.\nWe need to store values of the sequence we have already calculated and get them later when we need them. Let\u0026rsquo;s implement a simple memoization decorator:\n1 2 3 4 5 6 7 8 9 10 11 def memoize(function): cache = {} def decorated_function(*args): if args in cache: return cache[args] else: val = function(*args) cache[args] = val return val return decorated_function The decorator defines a dict at the beginning that is used as a cache. When we want to find the n number of the sequence, it first checks if the value was already calculated and that value is returned instead of being calculated again. If the value is not found, then the original function is being called and then the value is store in the cache, then returned to the caller.\nUsing the memoize decorator How much this decorator can speed up our fib method? Let\u0026rsquo;s try to benchmark the execution using Python timeit module.\n1 2 3 4 5 6 7 8 9 10 11 12 # First example, not using the memoize decorator import timeit def fib(n): if n \u0026lt; 2: return n else: return fib(n-1) + fib(n-2) t1 = timeit.Timer(\u0026#34;fib(35)\u0026#34;, \u0026#34;from __main__ import fib\u0026#34;) print t1.timeit(1) The required time to calculate the 35th number of the Fibonacci sequence on my laptop is:¬†4.73480010033\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Second example, using the memoize decorator import timeit from memoize import memoize # For convenience I put my decorator # in a module named memoize.py @memoize def fib(n): if n \u0026lt; 2: return n else: return fib(n-1) + fib(n-2) t1 = timeit.Timer(\u0026#34;fib(35)\u0026#34;, \u0026#34;from __main__ import fib\u0026#34;) print t1.timeit(1) The required time to calculate the 35th number of the Fibonacci sequence on my laptop is:¬†0.000133037567139\nQuite faster, don\u0026rsquo;t you think? I will let you try how long does it take to calculate the 60th number of the sequence with and without using the decorator. Hint: grab a cup of coffee before beginning!\n","date":"2015-08-31T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/understanding-python-decorators-optimizing-a-recursive-fibonacci-implementation/","title":"Understanding Python decorators optimizing a recursive Fibonacci implementation"},{"content":"Working on Django projects I find very often that many developers access the values that are defined in settings in this way\n1 2 3 from django.conf import settings my_value = settings.MY_SETTING What happens if MY_SETTING¬†has not been defined in settings.py? The code will raise an error and crash, of course. How can we make the code more reliable? We could try/except the code block that tries to read the value and maybe set a value if we get an exception, but this would not be a clean way to do this job.\nA cleaner way to do it is to use getattr in this way:\n1 2 3 from django.conf import settings my_value = getattr(settings, \u0026#39;MY_SETTING\u0026#39;, \u0026#39;my-default-value\u0026#39;) getattr will try to read MY_SETTING value from settings.py, if the value doesn\u0026rsquo;t exist my_value will be assigned with 'my-default-value'\n","date":"2015-08-29T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/django-notes-read-values-from-settings-in-a-safe-way/","title":"Django Notes: read values from settings in a safe way"},{"content":"To understand how a Django Middleware works we need to remember that the basic architecture of Django is composed by a request and a response. A middleware is something that stays in the middle. Let\u0026rsquo;s give a look to the next diagram, taken from official Django documentation:\n{ width=100% }\nImportant things to know There are four¬†important things to know about middlewares:\nYou need to write a class that just inherit from object The order where you place your middleware in settings.py is important: middlewares are processed from top to bottom during a request and from bottom to top during a response. You don\u0026rsquo;t need to implement all the available methods of a middleware. For example you can just implement¬†process_request and¬†process_template_response If you implement process_request¬†and you decide to return an HttpResponse, all the other middlewares, views etc\u0026hellip; will be ignored and only your response will be returned Writing a middleware In my example I wanted to implement a feature that saves the time when a request is made and the time when a request has been processed, then calculates the time delta and exposes this value in the context so that is accessible from our templates. How to implement a similar feature using a middleware? Here is my example:\n1 2 3 4 5 6 7 8 9 10 11 from datetime import datetime class BenchmarkMiddleware(object): def process_request(self, request): request._request_time = datetime.now() def process_template_response(self, request, response): response_time = request._request_time - datetime.now() response.context_data[\u0026#39;response_time\u0026#39;] = abs(response_time) return response Please don\u0026rsquo;t care about how¬†I calculated the time. I\u0026rsquo;m aware that there are better ways to do it, but I just wanted to keep it simple and show how to implement a simple middleware.\nIf you want to see a complete example of a project that includes and uses this middleware, here you can find the complete source code:¬†https://github.com/andreagrandi/benchmark-middleware-example\nReferences https://docs.djangoproject.com/en/1.8/topics/http/middleware/ http://agiliq.com/blog/2015/07/understanding-django-middlewares/ http://code.runnable.com/UrSGolK00ygpAAAQ/creating-a-custom-middleware-for-python-and-django ","date":"2015-08-23T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-write-a-custom-django-middleware/","title":"How to write a custom Django Middleware"},{"content":"I must admit it, there was a time when I was not using HTTPS, not even to protect the admin section of the website. This means that anyone could have intercepted the password and published (or deleted) things in my name. Since a couple of years ago I started protecting my admin sectio using an SSL certificate. I haven\u0026rsquo;t done it before for a couple of reason: my hosting was on a provider that required a lot of money (something like 100$/year) to enable SSL support, plus an SSL certificated costed at least 100-120$/year.\nWhen I migrated my website on my own VPS on DigitalOcean I finally discovered that StartSSL was giving free class 1 certificates and I immediately got one. I made the mistake to just serve the admin pages using HTTPS, not all the website. I regretted about this decision after readin a couple of articles that were explaining how some internet providers where changing served HTTP pages injecting their own ads or banner. That was unacceptable to me and I swicthed the whole website to HTTPS.\nBasically, if you don\u0026rsquo;t serve even your personal website using HTTPS, someone could change the page while it\u0026rsquo;s being transfered to the requester. Imagine if you have (like me) a page on your blog that let people download your public PGP key. Users could be served with a different key, so someone else would be able to decrypt a message intended for you only. Scary, isn\u0026rsquo;t it?\nIf you need more informations about how to request a StartSSL certificate and how to install it on Nginx/Apache, I can suggest this nice tutorial:¬†https://konklone.com/post/switch-to-https-now-for-free\nIf you need to serve a WordPress website, that configuration is not enough. In that case you may want to have a look at my own Nginx configuration, available at this address:¬†https://gist.github.com/andreagrandi/5de9dc9c4eb7e732764c\np.s: if you are you curious to try how Digital Ocean VPS works and fancy 10$ credit (enough for 2 months if you choose the basic droplet) for free, use this link and enjoy it¬†https://www.digitalocean.com/?refcode=cc8349e328a5\n","date":"2015-08-22T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/why-i-completely-switched-this-website-to-https-and-why-you-should-do-the-same/","title":"Why I completely switched this website to HTTPS (and why you should do the same)"},{"content":"This won\u0026rsquo;t be a full post, but just a quick note (probably the first one of a serie) about development with Django.\nWhen we write a TestCase test, if we have defined a setUp method, it will be called before the execution of each test. One could think that the database is completely reset after each test, but this is not true (not like I was thinking). After each test, whatever we wrote on the database is rolled back. If we create a \u0026ldquo;Client\u0026rdquo; row (assuming we have a model called Clients) in our setUp, when we call it the second time the ID won\u0026rsquo;t be 1 as someone (me included) could expect. It will be 2 instead, because the database has not completely deleted and created from scratch.\nThis means that we can\u0026rsquo;t assume that our Client ID will always be 1 for each test and we should rather reference to it in a dinamic way like: self.client.id\nThis could be a trivial thing for many people but I was not 100% sure about this so I asked for a confirmation on #django IRC room and people (expecially apollo13) was kind enough to explain me how it works.\n","date":"2015-07-23T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/django-notes-tests-setup-method-and-db-data/","title":"Django Notes: tests, setUp method and db data"},{"content":"I\u0026rsquo;m a big fan of Soma.fm (a 25+ channels streaming radio based in San Francisco) and during the years I\u0026rsquo;ve been writing clients for this radio for different mobile platforms (Maemo, MeeGo, Harmattan, Windows Phone, BlackBerry 10, Jolla). I love in particular their \u0026ldquo;Indie Pop Rock\u0026rdquo; channel that during these years made me discover some very good artists.\nWhen Spotify finally was available in Italy (I\u0026rsquo;m still using it right now that I live in the UK), something that I always missed was a radio with the same good music. Why not just listening to Soma.fm? Because I like to listen to the music while I commute and in the London Underground it\u0026rsquo;s nearly impossible to have signal.\nSo I was thinking: it would be nice to have a Spotify playlist with Soma.fm tracks. Wait a moment\u0026hellip;. I can do it!\n{ width=60% }\nSoma.fm publishes the tracks history with all the tracks streamed during the last hour http://somafm.com/indiepop/songhistory.html so I just needed something to parse this list for me and return me a well formatted version.\nThanks to import.io (it\u0026rsquo;s a service that takes a web page as input, parse the data and generates a RESTful API to access this data) I was able to easily get the data I needed. At this point I only needed to be able to loop through the list, search each track on Spotify and add it to my playlist.\nThe source code is fully available here https://github.com/andreagrandi/spotisoma\nNote: you can\u0026rsquo;t just get the code and run it. You will need to get your own import.io api key, generate your import.io api url, get a Spotify application key (the old/deprecated one, since it was nearly impossible for me to use oauth in a simple Python script due to the fact I didn\u0026rsquo;t have an endpoint to receive the token back. You can get more informations here: https://pyspotify.mopidy.com/en/latest/quickstart/#application-keys) and set your env variables with your Spotify username and password. Last but not least: the old Spotify library only works with Premium accounts.\n","date":"2015-07-12T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/soma-fm-spotify-import-io-python-mashup/","title":"Soma.fm + Spotify + import.io + Python mashup: automatically create a Spotify playlist with Soma.fm tracks"},{"content":"To briefly explain what Goenv is, I will assume you have previously worked with Python. Basically it\u0026rsquo;s what Virtualenv is for Python. Goenv (and it\u0026rsquo;s wrapper goof) creates a folder for a new project and set the $GOPATH env variable to that folder path. At this point every¬†time you do go get, the libraries will be installed in that specific $GOPATH.\nIt\u0026rsquo;s very important to use separate $GOPATH for each project, because this allow us to use different library versions for each project and avoid version conflicts.\nInstallation 1 2 3 4 5 git clone https://bitbucket.org/ymotongpoo/goenv cd goenv go build -o goenv *.go chmod +x goenv sudo cp goenv /usr/bin Goenv is now installed, we will now install its wrapper goof:\n1 sudo cp shellscripts/goenvwrapper.sh /usr/bin Edit .bashrc (or .zshrc if you use zsh) and append these lines:\n1 2 export GOENVHOME=$HOME/goenvs source /usr/bin/goenvwrapper.sh How to use it To create a new go environment use make:\n1 2 3 4 goof make go-test Do you want to create all parental directory of \u0026#39;/Users/andrea/goenvs/go-test\u0026#39;? [y/N]: y Environment /Users/andrea/goenvs/go-test created! (go:go-test) ‚ûú go-test To exit the go environment use deactivate:\n1 2 (go:go-test) ‚ûú go-test deactivate go-test To use an environment use workon:\n1 2 go-test goof workon go-test (go:go-test) ‚ûú go-test To show available environments use show:\n1 2 (go:go-test) ‚ûú go-test goof show go-test Goenv itself is not enough to manage Go packages. It would be like using Virtualenv only and not using pip and requirements. In a future post I will explain how to use Godep.\n","date":"2015-04-19T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/goenv-go-environment-manager/","title":"Goenv - Go Environment Manager"},{"content":"In Go it\u0026rsquo;s possible to define methods on struct types. The syntax needed for it can be a bit strange for people that are used to define classes and methods in Java, C# etc\u0026hellip; but once you learn it it\u0026rsquo;s quite easy to use.\nIn my case for example I needed something that could contain a Timer object, a string and a method that could start the timer and call a method at the end of the Timer execution. I implemented it in this way:\n1 2 3 4 5 6 7 8 9 type DeviceTimer struct { DeviceID string DeviceTimer *time.Timer } func (timer DeviceTimer) startTimer() { \u0026lt;-timer.DeviceTimer.C notifyDeviceTimerExpired(timer.DeviceID) } The key point is row 6 func (timer DeviceTimer) startTimer() { ... } where I defined a method called startTimer and I specify timer DeviceTimer inside the func definition. This basically \u0026ldquo;extends\u0026rdquo; the struct DeviceTimer adding that method to it. This means that I can call that method in this way:\n1 2 3 timer := time.NewTimer(time.Millisecond * 300) device_timer := DeviceTimer{\u0026#34;abc123\u0026#34;, timer} go device_timer.startTimer() This is all you need to do. If you want to read more about this subject, I can suggest to read these two articles:\nGo by Example: Methods https://gobyexample.com/methods Inheritance and subclassing in Go - or its near likeness http://golangtutorials.blogspot.co.uk/2011/06/inheritance-and-subclassing-in-go-or.html 1 2 3 4 5 **Note:** I\u0026#39;m not a Go expert and these are just my personal notes I\u0026#39;m taking during my learning experience. I\u0026#39;m very keen to share my notes with everyone, but please don\u0026#39;t take them as notes from an expert Go developer. ","date":"2015-03-16T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/go-defining-methods-on-struct-types/","title":"Go: defining methods on struct types"},{"content":"Before I start, let me confirm to you that official Docker images for PostgreSQL already exist and are available here:¬†https://registry.hub.docker.com/_/postgres/¬†so this howto wants to be a guide to explain how to create these images and talk about¬†some of the Docker features.\nI will assume that you have already installed Docker on your machine. I have tested these instructions both on Ubuntu Linux and OSX (OSX users will need to install boot2docker, instructions are not available in this guide).\nDockerfile To create a Docker image we need to create a text file named Dockerfile and use the available commands and syntax to declare how the image will be built. At the beginning of the file we need to specify the base image we are going to use and our contact informations:\n1 2 FROM ubuntu:14.04 MAINTAINER Andrea Grandi \u0026lt;nospamthanks@gmail.com\u0026gt; In our case we are using Ubuntu 14.04 as base image. After these instructions we need to add PostgreSQL package repository and GnuPG public key:\n1 2 RUN apt-key adv --keyserver keyserver.ubuntu.com --recv-keys B97B0AFCAA1A47F044F244A07FCC7D46ACCC4CF8 RUN echo \u0026#34;deb http://apt.postgresql.org/pub/repos/apt/ precise-pgdg main\u0026#34; \u0026gt; /etc/apt/sources.list.d/pgdg.list then we need to update the packages available in Ubuntu and install PostgreSQL:\n1 2 RUN apt-get update \u0026amp;\u0026amp; apt-get -y -q install python-software-properties software-properties-common \u0026amp;\u0026amp; apt-get -y -q install postgresql-9.3 postgresql-client-9.3 postgresql-contrib-9.3 We are installing version 9.3 of PostgreSQL, instructions would be very similar for any other version of the database.\nNote: it\u0026rsquo;s important to have apt-get update and apt-get install commands in the same RUN line, else they would be considered two different layers by Docker and in case an updated package is available it won\u0026rsquo;t be installed when the image is rebuilt.\nAt this point we switch to postgres user to execute the next commands:\n1 2 3 4 USER postgres RUN /etc/init.d/postgresql start \u0026amp;\u0026amp; psql --command \u0026#34;CREATE USER pguser WITH SUPERUSER PASSWORD \u0026#39;pguser\u0026#39;;\u0026#34; \u0026amp;\u0026amp; createdb -O pguser pgdb We switch to root user and we complete the configuration:\n1 2 3 USER root RUN echo \u0026#34;host all all 0.0.0.0/0 md5\u0026#34; \u0026gt;\u0026gt; /etc/postgresql/9.3/main/pg_hba.conf RUN echo \u0026#34;listen_addresses=\u0026#39;*\u0026#39;\u0026#34; \u0026gt;\u0026gt; /etc/postgresql/9.3/main/postgresql.conf We expose the port where PostgreSQL will listen to:\n1 EXPOSE 5432 We setup the data and shared folders that we will use later:\n1 2 RUN mkdir -p /var/run/postgresql \u0026amp;\u0026amp; chown -R postgres /var/run/postgresql VOLUME [\u0026#34;/etc/postgresql\u0026#34;, \u0026#34;/var/log/postgresql\u0026#34;, \u0026#34;/var/lib/postgresql\u0026#34;] Finally we switch again to the postgres user and we define the entry command for this image:\n1 2 USER postgres CMD [\u0026#34;/usr/lib/postgresql/9.3/bin/postgres\u0026#34;, \u0026#34;-D\u0026#34;, \u0026#34;/var/lib/postgresql/9.3/main\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;config_file=/etc/postgresql/9.3/main/postgresql.conf\u0026#34;] The full Dockerfile is available here¬†https://github.com/andreagrandi/postgresql-docker/blob/master/Dockerfile\nBuilding Docker image Once the Dockerfile is ready, we need to build the image before running it in a container. Please customize the tag name using your own docker.io hub account (or you won\u0026rsquo;t be able to push it to the hub):\n1 docker build --rm=true -t andreagrandi/postgresql:9.3 . Running the PostgreSQL Docker container To run the container, once the image is built, you just need to use this command:\n1 docker run -i -t -p 5432:5432 andreagrandi/postgresql:9.3 Testing the running PostgreSQL To test the running container we can use any client, even the commandline one:\n1 psql -h localhost -p 5432 -U pguser -W pgdb When you are prompted for password, type: pguser\nPlease note that localhost is only valid if you are running Docker on Ubuntu. If you are an OSX user, you need to discover the correct ip using: boot2docker ip\nPersisting data You may have noticed that once you stop the container, if you previously wrote some data on the DB, that data is lost. This is because by default Docker containers are not persistent. We can resolve this problem using a data container. My only suggestion is not to do it manually and use a tool like fig to orchestrate this. Fig is a tool to orchestrate containers and its features are being rewritten in Go language and integrated into Docker itself. So if you prepare a fig.yml configuration file now, you will be able, hopefully, to reuse it once this feature will be integrated into Docker. Please refer to fig website for the instructions to install it (briefly: under Ubuntu you can use pip install fig and under OSX you can use brew install fig).\n1 2 3 4 5 6 7 8 9 10 11 12 dbdata: image: andreagrandi/postgresql:9.3 volumes: - /var/lib/postgresql command: true db: image: andreagrandi/postgresql:9.3 volumes_from: - dbdata ports: - \u0026#34;5432:5432\u0026#34; Save this file as fig.yml in the same folder of the Dockerfile and spin up the container using this command: fig up\n1 2 3 4 5 6 7 8 9 10 11 12 andreas-air:postgresql-docker andrea [master] $ fig up Recreating postgresqldocker_dbdata_1... Recreating postgresqldocker_db_1... Attaching to postgresqldocker_db_1 db_1 | 2015-02-21 19:01:07 UTC [6-1] LOG: database system was interrupted; last known up at 2015-02-21 17:46:10 UTC db_1 | 2015-02-21 19:01:07 UTC [6-2] LOG: database system was not properly shut down; automatic recovery in progress db_1 | 2015-02-21 19:01:07 UTC [6-3] LOG: redo starts at 0/1782F68 db_1 | 2015-02-21 19:01:07 UTC [6-4] LOG: record with zero length at 0/1782FA8 db_1 | 2015-02-21 19:01:07 UTC [6-5] LOG: redo done at 0/1782F68 db_1 | 2015-02-21 19:01:07 UTC [6-6] LOG: last completed transaction was at log time 2015-02-21 17:46:10.61746+00 db_1 | 2015-02-21 19:01:07 UTC [1-1] LOG: database system is ready to accept connections db_1 | 2015-02-21 19:01:07 UTC [10-1] LOG: autovacuum launcher started If you try to write some data on the database and then you stop (CTRL+C) the running containers and spin up them again, you will see that your data is still there.\nConclusion This is just an example of how to prepare a Docker container for a specific service. The difficoult part is when you have to spin up multiple services (for example a Django web application using PostgreSQL, RabbitMQ, MongoDB etc\u0026hellip;), connect them all together and orchestrate the solution. I will maybe talk about this in one of the next posts. You can find the full source code of my PostgreSQL Docker image, including the fig.yml file in this repository¬†https://github.com/andreagrandi/postgresql-docker\n","date":"2015-02-21T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-create-a-docker-image-for-postgresql-and-persist-data/","title":"How to create a Docker image for PostgreSQL and persist data"},{"content":"I\u0026rsquo;ve been recently concerned about the future of Google Talk service and all the implications related to recent changes to the existing service. What has been a nice implementation of the Jabber/XMPP protocol once, now is just a closed and proprietary service. The main problem with these changes are:\nJabber/XMPP users of other services won\u0026rsquo;t be able to talk anymore to Google Talk users Google is killing some of their native clients (like the Windows one) and forcing users to Chrome or Android/iOS versions Google has disabled the possibility to turn off chat recording (you can still do it individually, for each contact) So, what are the alternatives to Google Talk? Luckly you have at least three options.\nUsing an existing Jabber/XMPP service This is surely the easiest way to get a Jabber/XMPP account. There is a list of free services available here:¬†https://xmpp.net/directory.php¬†registering a new account is usually very easy. Most of the clients have an option that let you register the account while you are configuring it. For example if you are using Pidgin and you want to register an account with DukGo service, you can configure it in this way:\nUsing an hosted Jabber/XMPP service with your domain A service called HostedIM offer a very nice service. Basically if you already have a domain, you can register an account on hosted.im, setup your DNS following their instructions and create an account directly on their dashboard. You can create up to 5 accounts for free. If you need more, they offer a paid service for that. In my case all I had to do was updating my DNS with the following configuration:\n1 2 3 4 5 6 _xmpp-client._tcp.andreagrandi.it. IN SRV 10 0 5222 xmpp1.hosted.im. _xmpp-client._tcp.andreagrandi.it. IN SRV 20 0 5222 xmpp2.hosted.im. _xmpp-server._tcp.andreagrandi.it. IN SRV 20 0 5269 xmpp2.hosted.im. _xmpp-server._tcp.andreagrandi.it. IN SRV 10 0 5269 xmpp1.hosted.im. _jabber._tcp.andreagrandi.it. IN SRV 20 0 5269 xmpp2.hosted.im. _jabber._tcp.andreagrandi.it. IN SRV 10 0 5269 xmpp1.hosted.im. Hosting your own Jabber/XMPP service If you have a VPS and some syasdmin skills, why not hosting your own XMPP server? There are different options available, but I can suggest you three in particular:\nOpenFire ejabberd Prosody I haven\u0026rsquo;t tried any of these personally, because for the moment I\u0026rsquo;m using the service offered by hosted.im. I\u0026rsquo;m curious anyway to configure at least one of them and when I will do it I will publish a dedicated tutorial about it.\nConclusion Given the recent changes that Google is doing to all their services, I\u0026rsquo;m more than happy when I can abandon one of them, because I personally don\u0026rsquo;t like to rely (and bind myself) to a single company, expecially if that company closes a service whenever they want and try to lock you inside their ecosystem.\n","date":"2015-02-20T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/moving-away-from-google-talk-to-a-real-jabberxmpp-service/","title":"Moving away from Google Talk to a real Jabber/XMPP service"},{"content":"If you use docker.io (or any similar service) to build your Docker containers, it may be possible that, once the new image is generated, you want your Docker host to automatically pull it and restart the container.\nDocker.io gives you the possibility to set a web hook after a successful build. Basically it does a POST on a defined URL and send some informations in JSON format.\ndocker-puller listens to these web hooks and can be configured to run a particular script, given a specific hook. It\u0026rsquo;s a very simple service I wrote using Python/Flask. It\u0026rsquo;s also my first Flask application, so if you want to improve it, feel free to send me a pull request on GitHub.\nNote: this is not the only existing service that is able to do this task. I took inspiration from this article¬†http://nathanleclaire.com/blog/2014/08/17/automagical-deploys-from-docker-hub/ and I really tried to customize¬†https://github.com/cpuguy83/dockerhub-webhook-listener for my own needs, but the problem is that dockerhub-webhook-listener is not ready to be used as is (you have to customize it) and I\u0026rsquo;m not very good with Golang¬†(yet) to be able to do it in little time. This is why I rewrote the service in Python (that is my daily language). I want to thank Brian Goff for the idea and all the people in #docker @ FreeNode for the support.\nHow to use docker-puller Setting up the service should be quite easy. After you clone the repository from https://github.com/glowdigitalmedia/docker-puller there is a config.json file where you define the host, port, a token and a list of hooks you want to react to. For example:\n1 2 3 4 5 6 7 8 { \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 8000, \u0026#34;token\u0026#34;: \u0026#34;abc123\u0026#34;, \u0026#34;hooks\u0026#34;: { \u0026#34;hello\u0026#34;: \u0026#34;scripts/hello.sh\u0026#34; } } Create a bash script (in this case it was called hello.sh) and put it under script folder and write the instructions to be executed to pull the new image and restart the container (example):\n1 2 3 4 docker pull andreagrandi/test:latest docker stop test docker rm test docker run --name test -d -p 8000:80 andreagrandi/test:latest Once configured, I suggest you to setup a Nginx entry (instructions not covered here) that for example redirect yourhost.com/dockerpuller to localhost:8000 (I would advise to enable SSL too, or people could be able to sniff your token). The service can be started with: \u0026ldquo;python app.py\u0026rdquo; (or you can setup a Supervisor script).\nAt this point docker-puller is up and running. Go to docker.io automatic build settings and setup a webhook like this: http://yourhost.com/dockerpuller?token=abc123\u0026hook=hello\nEvery time docker.io finishes building and pushing your image to the docker registry, it will POST on that URL. docker-puller will catch the POST, check for a valid token, get the hook name and will execute the relative script.\nThat\u0026rsquo;s all! I hope this very simple service can be useful to other people and once again, if you want to improve it, I will be glad to accept your pull requests on GitHub.\n","date":"2014-10-25T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/automatically-pull-updated-docker-images-and-restart-containers-with-docker-puller/","title":"Automatically pull updated Docker images and restart containers with docker-puller"},{"content":"If you are planning to share an encrypted volume between Linux/OSX and Windows (I will assume you are sharing it on Dropbox, but you could use any similar service) and you are using EncFS under Linux/OSX and BoxCryptor under Windows, there are some specifig settings to use when you create the EncFS volume. Infact even if BoxCryptor claims to be \u0026ldquo;encfs compatible\u0026rdquo;, it\u0026rsquo;s not 100%.\nSuppose you want to create an encrypted volume located at $HOME/.TestTmpEncrypted and mounted at $HOME/TestTmp you need the following command:\n1 encfs ~/.TestTmpEncrypted ~/TestTmp answer \u0026ldquo;Y\u0026rdquo; when you are asked if you want to create the folders:\n1 2 The directory \u0026#34;/home/andrea/.TestTmpEncrypted/\u0026#34; does not exist. Should it be created? (y,n) y The directory \u0026#34;/home/andrea/TestTmp\u0026#34; does not exist. Should it be created? (y,n) y At this point you will need to select between default paranoia mode or advanced mode. Please choose the advanced one (x):\n1 2 3 4 5 6 Creating new encrypted volume. Please choose from one of the following options: enter \u0026#34;x\u0026#34; for expert configuration mode, enter \u0026#34;p\u0026#34; for pre-configured paranoia mode, anything else, or an empty line will select standard mode. ?\u0026gt; x Manual configuration mode selected.\n1 2 3 4 5 6 7 8 9 10 11 12 13 Select AES as cypher algorithm: The following cypher algorithms are available: 1. AES : 16 byte block cipher -- Supports key lengths of 128 to 256 bits -- Supports block sizes of 64 to 4096 bytes 2. Blowfish : 8 byte block cypher -- Supports key lengths of 128 to 256 bits -- Supports block sizes of 64 to 4096 bytes Enter the number corresponding to your choice: 1 Selected algorithm \u0026#34;AES\u0026#34; Select 256 as key size:\n1 2 3 4 5 6 7 Please select a key size in bits. The cypher you have chosen supports sizes from 128 to 256 bits in increments of 64 bits. For example: 128, 192, 256 Selected key size: 256 Using key size of 256 bits Choose 1024 as block size:\n1 2 3 4 5 6 7 Select a block size in bytes. The cypher you have chosen supports sizes from 64 to 4096 bytes in increments of 16. Alternatively, just press enter for the default (1024 bytes) filesystem block size: Using filesystem block size of 1024 bytes Select Stream as filename encoding:\n1 2 3 4 5 6 7 8 The following filename encoding algorithms are available: 1. Block : Block encoding, hides file name size somewhat 2. Null : No encryption of filenames 3. Stream : Stream encoding, keeps filenames as short as possible Enter the number corresponding to your choice: 3 Selected algorithm \u0026#34;Stream\u0026#34;\u0026#34; Do NOT enable¬†filename initialization vector chaining:\n1 2 3 4 5 Enable filename initialization vector chaining? This makes filename encoding dependent on the complete path, rather then encoding each path element individually. The default here is Yes. Any response that does not begin with \u0026#39;n\u0026#39; will mean Yes: no Do NOT enable¬†per-file initialization vectors:\n1 2 3 4 5 6 Enable per-file initialization vectors? This adds about 8 bytes per file to the storage requirements. It should not affect performance except possibly with applications which rely on block-aligned file io for performance. The default here is Yes. Any response that does not begin with \u0026#39;n\u0026#39; will mean Yes: no Do NOT enable external chained IV:\n1 2 3 4 5 6 7 8 9 External chained IV disabled, as both \u0026#39;IV chaining\u0026#39; and \u0026#39;unique IV\u0026#39; features are required for this option. Enable block authentication code headers on every block in a file? This adds about 12 bytes per block to the storage requirements for a file, and significantly affects performance but it also means [almost] any modifications or errors within a block will be caught and will cause a read error. The default here is No. Any response that does not begin with \u0026#39;y\u0026#39; will mean No: no Do NOT enable random bytes to each block header:\n1 2 3 4 5 6 7 Add random bytes to each block header? This adds a performance penalty, but ensures that blocks have different authentication codes. Note that you can have the same benefits by enabling per-file initialisation vectors, which does not come with as great a performance penalty. Select a number of bytes, from 0 (no random bytes) to 8: 0 Enable file-hole pass-through:\n1 2 3 4 Enable file-hole pass-through? This avoids writing encrypted blocks when file holes are created. The default here is Yes. Any response that does not begin with \u0026#39;n\u0026#39; will mean Yes: yes Finally you will see:\n1 2 3 4 5 6 7 Configuration finished. The filesystem to be created has the following properties: Filesystem cypher: \u0026#34;ssl/aes\u0026#34;, version 3:0:2 Filename encoding: \u0026#34;nameio/stream\u0026#34;, version 2:1:2 Key Size: 256 bits Block Size: 1024 bytes File holes passed through to ciphertext. At this point set a passphrase for your new volume:\n1 2 3 4 5 6 7 Now you will need to enter a password for your filesystem. You will need to remember this password, as there is absolutely no recovery mechanism. However, the password can be changed later using encfsctl. New Encfs Password: Verify Encfs Password: You should be able to mount this volume using BoxCryptor.\n","date":"2014-09-12T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/create-an-encfs-volume-compatible-with-boxcryptor-classic/","title":"Create an EncFS volume compatible with BoxCryptor Classic"},{"content":"noip.com is one of the few dynamic DNS free services that are reliable to use. If you have, like in my situation, a RaspberryPi connected to your home DSL and you want it to be always reachable without knowing the current IP address (the IP could change if you have a normal DSL service at home), you need a dynamic DNS service.\nTo update the noip.com one you just need ddclient a tool that is available in Raspbian/Debian repository. You can install it with this command:\n1 sudo apt-get install ddclient then you just need to edit /etc/ddclient.conf\n1 2 3 4 5 6 protocol=dyndns2 use=web, web=checkip.dyndns.com/, web-skip=\u0026#39;IP Address\u0026#39; server=dynupdate.no-ip.com login=yourusername password=yourpassword yourhostname.no-ip.org and restart the client:\n1 sudo /etc/init.d/ddclient restart That\u0026rsquo;s all! Please remember that noip.com free accounts have a limitation: they need to be confirmed every 30 days (you will receive an email and you need to click on the link contained to update your DNS).\n","date":"2014-09-02T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/configuring-ddclient-to-update-your-dynamic-dns-at-noip-com/","title":"Configuring ddclient to update your dynamic DNS at noip.com"},{"content":"If you want to connect your RaspberryPi to your home network and you want to avoid cables, I suggest you to use the Edimax wifi adapter. This device is quite cheap (around ¬£8 on Amazon) and it\u0026rsquo;s very easy to configure on Raspbian (I assume you are using a recent version of Raspbian. I\u0026rsquo;m using the one released on 20/06/2014).\n{ width=100% }\nConfigure the wifi adapter Edit /etc/network/interfaces and insert these configuration values:\n1 2 3 4 5 6 7 8 9 10 auto lo iface lo inet loopback iface eth0 inet dhcp allow-hotplug wlan0 auto wlan0 iface wlan0 inet dhcp wpa-ssid¬†YOURESSID wpa-psk YOURWPAPASSWORD Power management issue There is a known \u0026ldquo;issue\u0026rdquo; with this adapter default configuration that makes it to turn off if the wlan interface is not in use for some minutes. To avoid this you have to customize the parameters used to load the kernel module. First check that your adapter is using 8192cu module:\n1 2 sudo lsmod | grep 8192 8192cu 551136 0 Create the file¬†/etc/modprobe.d/8192cu.conf and insert the following lines inside:\n1 2 # prevent power down of wireless when idle options 8192cu rtw_power_mgnt=0 rtw_enusbss=0 I also suggest to create a little entry in crontab to make the RaspberryPi ping your router every minute. This will ensure that your wifi connection will stay alive. To edit crontab just type (from pi user, you don\u0026rsquo;t need to be root):\n1 crontab -e and insert this line at the end:\n1 */1 * * * * ping -c 1 192.168.0.1 where¬†192.168.0.1 is the IP of your router (of course substitute this value with the ip of your router).\nKeep Alive Script I created a further script to keep my WIFI alive. This script will ping the router (change the IP using the one of your router) every 5 minutes and if the ping fails it brings down the wlan0 interface, the kernel module for the wifi and bring them up again.\nJust put this script in **/root/wifi\\_recover.sh** and then execute from **root** user: 1 2 chmod +x wifi_recover.sh crontab -e Insert this line inside the crontab editor:\n1 */5 * * * * /root/wifi_recover.sh Conclusion The configuration is done. Just reboot your RaspberryPi and enjoy your wifi connection.\n","date":"2014-09-02T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-configure-edimax-ew-7811un-wifi-dongle-on-raspbian/","title":"How to configure Edimax EW-7811UN Wifi dongle on Raspbian"},{"content":"I have recently migrated my website from a shared hosting to a dedicated VPS on Digital Ocean. Having a VPS surely gives you unlimited possibilities, compared to a shared hosting, but of course you have to manage some services by yourself.\nIn my case I only needed: SSH access, LEMP configuration (Nginx + MySQL\nPHP) to serve my WordPress blog and Postfix to use email forwarding from my aliases to my personal email. Configuring DNS on Digital Ocean Understanding how to properly configure the DNS entries in the panel could be a bit tricky if it\u0026rsquo;s not your daily bread. In particular there is a Digital Ocean configuration that assumes certain things about your droplet, so it\u0026rsquo;s better to configure it properly.\nFor example the droplet name should not be casual, but it should match your domain name: I initially called my host \u0026ldquo;andreagrandi\u0026rdquo; and I had to rename it to \u0026ldquo;andreagrandi.it\u0026rdquo; to have the proper PTR values.\nYou will need to create at least a \u0026ldquo;mail\u0026rdquo; record, pointing to your IP and an \u0026ldquo;MX\u0026rdquo; record pointing to mail.yourdomain.com. (please note the dot at the end of the domain name). Here is the configuration of my own droplet (you will notice also a CNAME record. You need it if you want www.yourdomain.com to correctly point to your ip.\n{ width=100% }\nConfiguring Postfix In my case I only needed some aliases that I use to forward emails to my GMail account, so the configuration is quite easy. First you need to install Postfix:\n1 sudo apt-get install postfix Then you need to edit**¬†/etc/postfix/main.cf** customizing myhostname with your domain name and add virtual_alias_maps and virtual_alias_domains parameters. Please also check that mynetworks is configured exactly as I did, or you will make your mail server vulnerable to spam bots. You can see my complete configuration here:\nAdd your email aliases Edit /etc/postfix/virtual file and add your aliases, one per line, like in this example:\n1 2 info@yourdomain.com youremail@gmail.com sales@yourdomain.com youremail@gmail.com At this point update the alias map and reload Postfix configuration:\n1 2 sudo postmap /etc/postfix/virtual sudo /etc/init.d/postfix reload Conclusion As you can see, configuring Postfix is quite easy, you just need to be careful when you configure the DNS records in the control panel. Are you curious to try how Digital Ocean VPS works? Fancy 10$ credit (enough for 2 months if you choose the basic droplet) for free? Use this link and enjoy it https://www.digitalocean.com/?refcode=cc8349e328a5\n","date":"2014-08-31T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/getting-started-with-digital-ocean-vps-configuring-dns-and-postfix-for-email-forwarding/","title":"Getting started with Digital Ocean VPS: configuring DNS and Postfix for email forwarding"},{"content":"Developing a large web application or before deploying some code is very important to verify the quality of the code itself, check if we have introduced any regression or bug and have something that tell us if we are increasing or decreasing the quality of the code.\nSuppose we are in an organization or a company where the basic rule is: master branch is always ready/stable to be deployed. In a team usually people work on personal branches, then when the code is stable it\u0026rsquo;s merged with master.\nHow do we check if the code is stable and ready to be merged? First of all we need to cover all our code with proper tests (I won\u0026rsquo;t go in details about unit testing here, I assume that the reader knows what I\u0026rsquo;m talking about), then we need to actually run them, possibly in an isolated environment that is similar to the production one, and check if they all pass. If they do, we are quite safe to merge our code with master branch.\nHow can we ensure that all the developers remember to run tests when they push some new code? To make things a bit more real, let\u0026rsquo;s take the example of a Python/Django product (or even a library) that currently supports Python 2.6, 2.7, 3.3 and Django 1.4.x, 1.5.x, 1.6.x. The whole matrix consists of 9 possible combinations. Do we have to manually run tests on 9 configurations? No, we don\u0026rsquo;t.\nTravis-ci.org Travis is a continuous integration tool that, once configured, takes care of these tasks and let us save lot of time (that we can use to actually write code). Travis-ci.org is an online service that works with GitHub (it requires we use GitHub as repository for our code), and once we have connected the two accounts and configured a very simple file in our projects, it\u0026rsquo;s automatically triggered when we push on our GitHub repository.\nThe configuration consists of adding a file named .travis.yml in the root of our project. A working example is available here https://github.com/andreagrandi/workshopvenues/blob/master/.travis.yml (all the env variables I set are not required normally, but that\u0026rsquo;s where I save the values of my configuration, so they need to be initialized before I can run tests).\nThe service supports most of the languages that are commonly used and even a good number of PAAS, making it very easy to automatically deploy our code. If it should not be enough for your needs, they also expose a public API. I suggest you to give a look at the official documentation that will explain everything in details http://docs.travis-ci.com\nOnce everything is configured, we will have something like this on our console https://travis-ci.org/andreagrandi/workshopvenues/jobs/19882128\n{ width=90% }\nIf something goes wrong (if tests don\u0026rsquo;t pass for example) we receive a notification with all the informations about the failing build, and if we had configured an automatic deployment of course the code would not be deployed in case of a failing build.\nTravis-ci.org is completly free for opensource projects and has also a paid version for private repositories.\nCoveralls.io There is a nice tool available for Python called coverage. Basically it runs tests and checks the percentage of the source code that is covered by tests, producing a nice report that shows us the percentage for every single file/module and even the lines of code that have been tested.\nThanks to Coveralls.io and the use of Travis, even these tasks are completly automatized and the results are available online like in this example https://coveralls.io/builds/560853\nThe configuration is quite easy. We need to connect our Coveralls.io profile with GitHub, like we did for Travis-ci.org and then enable the repository. To trigger Coveralls after a successful Travis build, we need to have these lines at the end of our .travis.yml file\n1 2 after_success: - coveralls { width=90% }\nEven Coveralls.io is completly free for opensource projects and offers a paid version for private repositories.\nHeroku I use Heroku to host and run my web application. Normally to deploy on Heroku you so something like this: git push heroku master\nAdding these settings to the .travis.yaml file, I can automatically deploy the application on Heroku, if the build was successful:\n1 2 3 4 5 6 7 8 9 10 deploy: provider: heroku api_key: secure: R4LFkVu1/io9wSb/FvVL6UEaKU7Y4vfen/gCDe0OnEwsH+VyOwcT5tyINAg05jWXhRhsgjYT9AuyB84uCuNZg+lO7HwV5Q4WnHo5IVcCrv0PUq/CbRPUS4C2kDD7zbA1ByCd224tcfBmUtu+DPzyouk23oJH+lUwa/FeUk0Yl+I= app: workshopvenues on: repo: andreagrandi/workshopvenues run: - \u0026#34;python workshopvenues/manage.py syncdb\u0026#34; - \u0026#34;python workshopvenues/manage.py migrate\u0026#34; Not only the code is deployed, after deployment the South migrations are executed.\nConclusion These two tools are saving me lot of time and are ensuring that the code I release for a project I\u0026rsquo;m working on (WorkshopVenues) is always tested when I push it on my repository.\n","date":"2014-03-02T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/travis-ci-org-and-coveralls-io-qa-made-easy/","title":"Travis-ci.org and Coveralls.io: Continuous Integration and QA made easy"},{"content":"I recently prepared a presentation about Factoryboy, a Python library that automates lot of the work when a developer needs to create some data for unit testing.\nI\u0026rsquo;ve been using this library since a couple of months, both in the company where I work and on a personal open source project I\u0026rsquo;m working on. I will give a presentation about this library in an internal workshop in my company and I\u0026rsquo;m available to give it in any Python/Django related event around London, if anyone is interested.\nThe slides are already available:\n","date":"2014-01-30T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/factoryboy-creating-data-for-unit-tests-in-an-easy-way/","title":"Factoryboy: Creating data for unit tests in an easy way"},{"content":"After upgrading from OSX 10.8.x to 10.9 (Mavericks), encfs recipe is broken. First of all you have to fix a problem with a library header:\n1 sudo ln -s /usr/include/sys/_endian.h /usr/include/sys/endian.h then you can install encfs using this remote brew recipe:\n1 brew reinstall¬†https://gist.github.com/ghibble/7297078/raw/cae1ff000a5e1cfc670f5b7a611279ed494b63af/encfs.rb It\u0026rsquo;s also possible that you have to fix fuse4x installation before being able to use encfs (I had to do it):\n1 2 sudo /bin/cp -rfX /usr/local/Cellar/fuse4x-kext/0.9.2/Library/Extensions/fuse4x.kext /Library/Extensions sudo chmod +s /Library/Extensions/fuse4x.kext/Support/load_fuse4x That\u0026rsquo;s it! Please note that this is just a workaround (thanks to Giovanni Bajo for suggesting me the symlink fix). Please also note that this recipe uses fuse4x library and not the most updated osxfuse (but it works, anyway). Some other users reported me that there is a fix for the original brew recipe, and this one uses osxfuse. You can find it here¬†https://gist.github.com/defunctzombie/7324625 but I haven\u0026rsquo;t tested it yet.\nUpdate: to fully integrate encfs with OSX, I also suggest to follow this nice guide http://www.maketecheasier.com/install-encfs-mac/\n","date":"2013-11-08T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-fix-encfs-installation-on-osx-10-9-mavericks-and-brew/","title":"How to fix encfs installation on OSX 10.9 (Mavericks) and brew"},{"content":"I admit. This website, like thousands of others, has been hacked! I still have to identify the precise source of the attack, but I\u0026rsquo;ve found out that is very common. I was able to discover about the attack just because the dashboard of WordPress stopped working. I decided to investigate and I found this strind on top of every .php file http://pastebin.com/k0iQymRy\nJust googling I discovered that I was not alone http://stackoverflow.com/questions/16963818/server-hacked-on-wordpress-files\nHow to fix this? The best solution would be to restore the files with a valid backup, but sometimes this is not possible. Here comes an handy bash solution (note: you need to be able to access your hosting with a SSH shell to execute this command): http://pastebin.com/V3nFwwtZ\n","date":"2013-06-22T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-fix-a-wordpress-websitet-hacked-by-zend_framework-malware/","title":"How to fix a WordPress website hacked by zend_framework malware"},{"content":"Using the same computer with Windows 8 and Ubuntu I noticed that the sound was worse in Ubuntu and I discovered why soon: subwoofer doesn\u0026rsquo;t work out of the box!\nHow to fix it The fix is quite easy to apply (but it was not easy to find the right one!). First of all edit¬†/etc/pulse/default.pa and add this line at the end:\n1 load-module module-combine channels=6 channel_map=front-left,front-right,rear-left,rear-right,front-center,lfe then edit¬†/etc/pulse/daemon.conf, modify the line enable-lfe-remixing: no to enable-lfe-remixing: yes, then uncomment it (remove the semicolon in front of it). Reboot your PC and enjoy the subwoofer!\nReferences http://forums.gentoo.org/viewtopic-t-859769.html http://askubuntu.com/questions/53802/subwoofer-sound-preferences-problem ","date":"2013-06-22T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-make-subwoofer-work-in-ubuntu/","title":"How to make subwoofer work in Ubuntu"},{"content":"The pip utility distributed with Debian 6.0 has a bug once you upgrade it with¬†pip install -U pip. You will easily get this error when you try to install a new package with it:\n1 2 3 4 5 root@worker2:~# pip install setproctitle Traceback (most recent call last): File \u0026#34;/usr/bin/pip\u0026#34;, line 8, in from pip.baseparser import parser ImportError: cannot import name parser Luckly there is a very easy workaround:\n1 2 3 4 easy_install pip rm /usr/bin/pip ln -sv /usr/local/bin/pip-2.6 /usr/bin/pip pip install pip --upgrade Reference: http://blog.102web.ru/tag/virtualenvs/\n","date":"2013-05-02T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-fix-pip-under-debian-6-0-squeeze-importerror-cannot-import-name-parser/","title":"How to fix pip under Debian 6.0 (squeeze): ImportError: cannot import name parser"},{"content":"Developing Python applications sometimes it\u0026rsquo;s useful to be able to test the code with different environments, for example a particular version of Python or a specific Django version etc\u0026hellip; Setting up many different virtual machines would be really too much work and even using a chroot environment is not what you need in some cases. Thanks to virtualenv is it possible to create a self contained Python environment with all the specific libraries you may need. Using virtualenv is very easy:\nCreating the virtual environment: virtualenvmyenv¬†--no-site-packages Entering the virtual environment: source myenv/bin/activate Deactivating the virtual environment: deactivate That\u0026rsquo;s it! Once you\u0026rsquo;re inside the virtual environment you will be using the Python libraries inside it. I suggest you to install all the Python libraries you need using pip.\n","date":"2013-04-25T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-virtualenv-to-manage-multiple-pythondjango-environments-in-the-same-machine/","title":"Using virtualenv to manage multiple Python/Django environments in the same machine"},{"content":"When last week Canonical announced the usual UDS was not going to happen I was a bit shocked and disappointed: starting from the next UDS (that is going to happen tomorrow!) the event will be online only and every 3 months. During these days I\u0026rsquo;ve been thinking a lot about this move and I will tell you what are the pros and cons, in my opinion, followed by some final thoughts.\nPros Having 4 UDS every year, instead of 2, is surely a better thing. I\u0026rsquo;m a big fan of Scrum methodology, so I think that iterating more often is better than iterating less. If there are any mistakes you can correct them and iterating again before releasing the final product.\nPotentially more people can partecipate to the event (even the opposite is true and I will explain why). People won\u0026rsquo;t need to move from home, travel, pay any expense etc\u0026hellip; they just need a computer and a good Internet connection.\nIt\u0026rsquo;s cheaper for everyone: I can just imagine how expensive could be for Canonical to organize a similar event. Booking a big hotel, paying travel and expenses to near one houndred of community people. People who didn\u0026rsquo;t get any sponsorization had to pay all the travel expenses to attend the event.\nCons Potentially less people can partecipate to the event. Yes, like I said before even this sentence is true and I will explain why. First of all, using Google+ there are at least three countries that will be cut out: China, Thailand and Vietnam. Google+ is not available in those countries.\nAre you sure that special people will be able to follow the event? For example blind people won\u0026rsquo;t be able to chat or to ask question in the chat.\nOnly 10 people will be able to talk. In normal UDS sessions more people could raise the hand and ask a question or interact with the track leaders. Who will choose the 10 people with audio+video streaming rights?\nWe will completly miss the social aspect of the UDS. If you think this was only a secondary part, please go on. I felt more committed to work and collaborate with people I met in person than with someone I\u0026rsquo;ve never met before.\nAnnouncing an event, even if online, just one week before it happens. Really? Some people had already taken vacation from work, booked flights etc\u0026hellip; not counting many people that can\u0026rsquo;t take 2 days off from work just with 1 week notice period. It\u0026rsquo;s also almost impossible that community members have the time to schedule a blueprint and be able to discuss about a subject.\nFinal thoughts From a cutting costs point of view I really can\u0026rsquo;t say anything. Organizing UDS was surely very expensive for Canonical and nobody can blame them if they decided to spend those money in a different way.\nWhat really concerns me: is UDS still useful? My opinion is that at least since latest 2 or 3 UDS the presence of the Community was not so relevant, because I had the clear sensation that the most important decisions were made by Canonical before the UDS and then there was just some details tuning. Another proof of my thoughts is the today announcement: despite the fact that I 100% agree with Unity switching to Qt/QML (I already proposed this 2 years ago during Budapest UDS, but nobody listened to me) I completly disagree with the way the decision was made: not a single involvement or discussion with the community.\nI would apreaciate more openness and honesty from Canonical. Do you want to take all the decisions? That\u0026rsquo;s fine, but at least state it clearly.\n","date":"2013-03-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/uds-happening-online-only-pros-and-cons/","title":"UDS happening online only: pros and cons"},{"content":"I\u0026rsquo;ve decided to write this post as a note to myself. I\u0026rsquo;m still learning Node.js and digging into Express/Jade, but I\u0026rsquo;ve read many people using the nice Twitter Bootstrap and I was wondering if there was a way to integrate all these technologies. The short answer is: yes, we can!\nNote: once again, I\u0026rsquo;m not a Node.js expert and surely there are other ways to achieve this task (for example there is a Node.js module called twitter-bootstrap, but I haven\u0026rsquo;t tried it). This tutorial is based on another tutorial I found, but it was not very updated and it had a more complicated way to install Bootstrap, so I decided to write a new one basing it on the original¬†http://www.rs.au.com/31/how-to-install-bootstrap-v2-0-2-in-expressjs-v3-0-0\nPreparing the environment I will assume that you\u0026rsquo;re running any Linux distribution (in my case I\u0026rsquo;m using Ubuntu 12.10, but feel free to use your own distribution). Be sure to have installed a recent version of nodejs and npm packages (I\u0026rsquo;m using Node.js 0.8.20 and npm 1.2.11).\nCreate a project folder and install the required dependencies 1 2 3 4 mkdir node-bootstrap cd node-bootstrap npm install express npm install jade Create the basic project structure with Express 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 andrea@andrea-Inspiron-660:~/Documents/sviluppo/nodejs/node-bootstrap$ node_modules/express/bin/express nodebootstrap create : nodebootstrap create : nodebootstrap/package.json create : nodebootstrap/app.js create : nodebootstrap/public create : nodebootstrap/public/javascripts create : nodebootstrap/public/images create : nodebootstrap/public/stylesheets create : nodebootstrap/public/stylesheets/style.css create : nodebootstrap/routes create : nodebootstrap/routes/index.js create : nodebootstrap/routes/user.js create : nodebootstrap/views create : nodebootstrap/views/layout.jade create : nodebootstrap/views/index.jade install dependencies: $ cd nodebootstrap \u0026amp;\u0026amp; npm install run the app: $ node app You should already have installed all the needed dependencies, even without executing npm install, anyway executing it won\u0026rsquo;t hurt.\nDownload and install Bootstrap Download Twitter Boostrap from the official website¬†http://twitter.github.com/bootstrap/assets/bootstrap.zip and unzip it under the¬†nodebootstrap/public folder.\nBootstrap integration with Jade template system At this point you need to edit the views/layout.jade file and include the references to Bootsrap\n1 2 3 4 5 6 7 8 9 10 html head title= title link(rel=\u0026#39;stylesheet\u0026#39;, href=\u0026#39;/bootstrap/css/bootstrap.min.css\u0026#39;) link(rel=\u0026#39;stylesheet\u0026#39;, href=\u0026#39;/bootstrap/css/bootstrap-responsive.min.css\u0026#39;) link(rel=\u0026#39;stylesheet\u0026#39;, href=\u0026#39;/stylesheets/style.css\u0026#39;) script(src=\u0026#39;https://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js\u0026#39;) script(src=\u0026#39;/bootstrap/js/bootstrap.min.js\u0026#39;) body block content Test the Bootstrap integration At this point we will modify views/index.jade that is the default template used to render the index\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 extends layout block content div.top form.form-horizontal(method=\u0026#34;post\u0026#34;, id=\u0026#34;loginForm\u0026#34;) label Username input.span3(id=\u0026#34;username\u0026#34;, type=\u0026#34;text\u0026#34;, name=\u0026#34;User\u0026#34;, placeholder=\u0026#34;Enter your username\u0026#34;) label Password input.span3(id=\u0026#34;password\u0026#34;, type=\u0026#34;password\u0026#34;, name=\u0026#34;Password\u0026#34;) input.btn(type=\u0026#34;submit\u0026#34;, value=\u0026#34;Log In\u0026#34;) div.container div.content table.table.table-striped thead tr th Table th Heading tbody tr td Blah td Test tr td Hello td World div.footer Now go back to the terminal and execute the app:\n1 2 andrea@andrea-Inspiron-660:~/Documents/sviluppo/nodejs/node-bootstrap/nodebootstrap$ node app.js Express server listening on port 3000 Open your favourite browse and visit http://localhost:3000 to see your first Bootstrap + Node.js application app and running.\n","date":"2013-02-24T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-twitter-bootstrap-with-node-js-express-and-jade/","title":"Using Twitter Bootstrap with Node.js, Express and Jade"},{"content":"Developing CuteSoma and maintaining it for three different platforms (Nokia N9, Windows Phone, BlackBerry 10) is really taking me a lot of time. I\u0026rsquo;ve many features in mind to add but I can\u0026rsquo;t dedicate much spare time to them and to do it I should take time from other paid projects. I\u0026rsquo;ve also discarded the idea to make CuteSoma a paid app, because it\u0026rsquo;s been always free (except the Windows Phone one that was non-free for just a month, but only 6 people \u0026ldquo;SIX\u0026rdquo; bought the app).\nSo I decided to open a fundraising campaign on Indiegogo that is a service like KickStarter, but it\u0026rsquo;s available all around the world (not just in USA and UK like Kickstarter).\nWhat do I Need \u0026amp; What You Get I would like to raise at least 5.000‚Ç¨ to be able to keep maintaining the existing features and to implement new one. Developing for 3 different platforms really takes a lot of time. I also need to find a way to get a Windows Phone 8 device because at the moment I cannot test some features using just the emulator.\nWhat the application currently does:\nYou can view the list of Soma.fm channels You can listen any channel Features I would like to add:\nScrobbling song to Last.fm Write a new MediaSource for Windows Phone (the default one is quite bugged and I need to implement one from scratch) Port the BlackBerry10 version to the native CascadesUI The Impact Funding the development of CuteSoma you will make thousands of people really happy, because they will be able to listen to Soma.fm on their Nokia N9, Windows Phone and BlackBerry 10 devices. You will also make me feel apreciated for all the hours I\u0026rsquo;m spending to write the code :)\nCompletly Opensource Yes. CuteSoma is completly¬†opensource. I keep my source code on GitHub and BitBucket and it\u0026rsquo;s always updated. All the CuteSoma versions are released under the¬†GPL license.\nCuteSoma for Nokia N9 - source code:¬†https://github.com/andreagrandi/CuteSoma CuteSoma for BlackBerry 10 - source code:¬†https://github.com/andreagrandi/CuteSoma/tree/bb10 CuteSoma for Windows Phone - source code:¬†https://bitbucket.org/andreagrandi/cutesoma/src Other Ways You Can Help If you want to contribute but you can\u0026rsquo;t or you don\u0026rsquo;t want to send money, you could help me in the following ways:\n1) Download¬†and use the application:\nNokia N9:¬†http://store.ovi.com/content/205737 Windows Phone:¬†http://www.windowsphone.com/en-us/store/app/cutesoma/387185ca-1328-4d1c-a4c2-45568cf06470 BlackBerry 10:¬†http://appworld.blackberry.com/webstore/content/20200430/ 2) Tweet/Blog¬†about this fund raising campaign:¬†http://www.indiegogo.com/projects/cutesoma-soma-fm-client/x/2353169\n","date":"2013-02-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/fundraising-for-cutesoma-soma-fm-mobile-client-development/","title":"Fundraising for CuteSoma (Soma.fm mobile client) development"},{"content":"If you develop with Node.js and you want to be sure to have the latest stable version, luckly there is a PPA for it. All you need is to follow these instructions:\n1 2 3 4 sudo apt-get install python-software-properties python g++ make sudo add-apt-repository ppa:chris-lea/node.js sudo apt-get update sudo apt-get install nodejs npm That\u0026rsquo;s it!\nReference:¬†https://github.com/joyent/node/wiki/Installing-Node.js-via-package-manager\n","date":"2013-02-08T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/how-to-install-latest-stable-node-js-on-ubuntu/","title":"How to install latest stable Node.js on Ubuntu"},{"content":"This morning when I started my Windows Phone 8 emulator to test an application, the emulator refused to work, giving me this error \u0026ldquo;The Windows Phone Emulator wasn‚Äôt able to connect to the Windows Phone operating system\u0026rdquo;. Luckly it\u0026rsquo;s very easy to fix. It\u0026rsquo;s caused by the virtual network interface that has been disabled for some reason (well\u0026hellip; in my case it must depend on the other day when I tryed to trick WP7 firmware upgrade and used the disconnect trick, but this is another story).\nI searched on Google for a solution and I landed on this page¬†http://pauliom.com/2012/12/20/the-windows-phone-emulator-wasnt-able-to-connect-to-the-windows-phone-operating-system/\nAll you have to do is going to \u0026ldquo;Network and Internet \u0026ndash;\u0026gt; Network Connections\u0026rdquo;, right click on \u0026ldquo;vEthernet (Internal Ethernet Port) Windows Phone Emulator\u0026rdquo; and Enable it.\n{ width=100% }\n","date":"2013-02-03T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/the-windows-phone-emulator-wasnt-able-to-connect-to-the-windows-phone-operating-system-how-to-fix-it/","title":"The Windows Phone Emulator wasn‚Äôt able to connect to the Windows Phone operating system: how to fix it"},{"content":"QtCreator is a very flexible IDE and can really be adapted for a lot of things. I usually use it to develop mobile applications for Nokia N9 and BlackBerry 10, but it can be used for more generic tasks. In my case I wanted to be able to develop a Qt application using my desktop PC, deploy it and run on a remote (actually it\u0026rsquo;s on the same desk) Linux machine running Xubuntu.\nDoing this is quite easy and you don\u0026rsquo;t need any specific plugin on QtCreator, but be sure to have at least version 2.6.x. Other than QtCreator you also need two Linux based PC (I used Ubuntu 12.10 for my development machine and Xubuntu 12.10 for the remote netbook) and an SSH account on the remote PC.\nAdd the remote device to QtCreator { width=100% }\nTo add the remote Linux device on QtCreator, use the Tools-\u0026gt;Options menu and click on \u0026ldquo;Devices\u0026rdquo; item. At this point click on \u0026ldquo;Add\u0026rdquo; button and fill the fields using values similar to the screenshot. In particular specify a name for the device, the IP of the remote machine and a username and password that must already exist (I just created the user \u0026ldquo;andrea\u0026rdquo; on the Xubuntu machine and used the same password). I also had to set the timeout to 20 seconds, because I had some connection problems and the connection kept dropping after 10 seconds trying. To verify if everything is working fine, just click on Test button.\nAdd a specific Qt version { width=100% }\nTo write your application you may need a specific Qt version that is different from the one distributed by your Linux distribution. There\u0026rsquo;s no problem, QtCreator let you add different Qt versions without any conflict. In my case I installed the Qt5 version distributed by Canonical Qt5 Edgers Team:¬†https://launchpad.net/~canonical-qt5-edgers\nOnce it\u0026rsquo;s installed, just click on \u0026ldquo;Add\u0026rdquo; button and select the qmake specific to the version you want to add (in my case it was in /opt/qt5/bin/qmake ).\nAdd a Qt Kit { width=100% }\nQtCreator permits to add new Kit (development configurations) and these kits are used during project creation to specify what you want to target. In my example I added a new kit choosing an appropriate name \u0026ldquo;Qt5 Ubuntu\u0026rdquo;, the device type, the actual device previously configured and finally the Qt version that we added before. With a kit I have a complete \u0026ldquo;toolchain\u0026rdquo; that allow me to write applications for a particular device, with a specific Qt version.\nPutting the pieces together At this point you just have to create a new \u0026ldquo;Qt Quick 2\u0026rdquo; application, and select the new kit you just created instead of the \u0026ldquo;Desktop\u0026rdquo; one. Please note that there is a little problem that I haven\u0026rsquo;t fixed yet (but I\u0026rsquo;m working on it): if you create, for example, a project named \u0026ldquo;QtTest1\u0026rdquo; it will be deployed to the folder /opt/QtTest1/ on the remote machine. By default your user doesn\u0026rsquo;t have read+write permissions for that folder so I manualy created the folder and I gave a chmod 777 on it, just for testing. There are two possible ways to fix this: you could create a specific user that has read+write permissions on /opt/ or you could modify the deployment configuration to have the app deployed to the user /home (I will investigate on this possibility and I will write something in one of the next posts).\nFinal thoughts What all of this could be useful for? Well, do 2+2 and you\u0026rsquo;ll easily guess ;) In the next weeks I will post more specific informations and I will update everyone with my progresses. Any comment is welcome! If you want to contribute to this you\u0026rsquo;re welcome too of course.\n","date":"2013-01-17T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-qtcreator-to-deploy-and-run-a-qt-application-to-a-remote-linux-device/","title":"Using QtCreator to deploy and run a Qt application to a remote Linux device"},{"content":"If you upgrade Spotify for Linux to 0.8.8.x version and you have some network connection problems (for example you\u0026rsquo;re behind a company firewall and need to set a proxy\u0026hellip;) the application will crash/hang without letting you doing anything (neither setting Proxy informations)\n{ width=100% }\nThis is caused by a deadlock in the GUI and you can view the complete debugging informations here¬†http://pastebin.com/zcKgXEqz\nTo fix this, you just need to open this file ~/.config/spotify/prefs and add these two lines:\n1 2 network.proxy.addr=\u0026#34;123.123.123.123:1234@https\u0026#34; network.proxy.mode=2 of course substituting 123.123.123.123:1234 with your proxyip:proxyport.\n","date":"2013-01-06T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/spotify-0-8-8-for-linux-crashes-if-it-cannot-connect-to-internet-how-to-fix-it/","title":"Spotify 0.8.8 for Linux crashes if it cannot connect to Internet: how to fix it"},{"content":"Django is becoming very popular for dynamic websites development (actually it already is) so I decided to start learning it, with the help of a good book. To develop Django web applications you need a good IDE and an environment that support at least Python and a database (SQL Lite, MySQL etc\u0026hellip;). If you have multiple machines and you alternate from multiple operating systems, the best thing is using an environment that you can use everywhere, from your favourite browser.\nHere comes Cloud9, a very nice service that you could define as the \u0026ldquo;Google Docs\u0026rdquo; for developers. C9 offers you a shared, always available on the cloud, environment to write your code. They also offer access to a Linux terminal (so you can install applications, like Django) and your websites are istantly available online for remote testing.\n{ width=100% }\nInstalling and using Django on C9 is very easy. You just need to open a new terminal tab (ALT+T) in C9 and execute these commands\n1 2 3 easy_install django python ./../bin/django-admin.py startproject myproject python ./myproject/manage.py runserver $OPENSHIFT_INTERNAL_IP:$PORT After these commands, your Django website will be live and accessible using http://projectname.username.c9.io (where projectname is the name of the project you just created and username is your C9 user name).\nsource:¬†http://support.cloud9ide.com/entries/21830983-django-development-in-c9\n","date":"2013-01-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-cloud9-ide-to-develop-django-applications/","title":"Using Cloud9 IDE to develop Django applications"},{"content":"During these Christmas holidays I\u0026rsquo;ve ported the N9 version of CuteSoma to BlackBerry10 platform, thanks to the BB10 Alpha device that RIM gave to me and thanks in particular to my friend Cornelius Hald that helped me with porting.\nThe porting itself was quite easy after all: if you have a Qt application that uses MeeGo Qt components, you have to switch to Symbian components (they\u0026rsquo;re more portable and support higher resolutions) and to do it I suggest you follow the informations on this blog post¬†http://www.johanpaul.com/blog/2011/12/porting-meego-qt-components-apps-to-symbian/\nIf you need more detailed informations about Symbian Qt Components, you can also read this nice blog post from Cornelius Hald¬†http://kodira.de/2012/12/qt-components-on-blackberry-10/\nHow does it look So, what\u0026rsquo;s the result of my porting? Well, first of all a couple of screenshots\n{ width=\u0026ldquo;180\u0026rdquo; height=\u0026ldquo;300\u0026rdquo; }¬†{ width=\u0026ldquo;180\u0026rdquo; height=\u0026ldquo;300\u0026rdquo; }\nSource Code And finally the source code:¬†https://github.com/andreagrandi/CuteSoma/tree/bb10\nThe application will be published soon in the BlackBerry App World and you will have it available in time for the BlackBerry 10 launch!\n","date":"2013-01-03T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/cutesoma-soma-fm-client-ported-to-blackberry10/","title":"CuteSoma (Soma.fm client) ported to BlackBerry10"},{"content":"It\u0026rsquo;s a pleasure for me to announce the first public release of CuteSoma for Windows Phone (WP7 and WP8). CuteSoma is a mobile client for the amazing Soma.fm radio¬†a listener-supported, commercial-free, underground, alternative radio broadcasting over 20 unique channels from San Francisco. This is my first application for WP platform, and unlike the N9 version that was completly free of charge, I\u0026rsquo;ve decided to release this version in two ways: a free trial version with just 3 (and other 3 coming with the next imminent upgrade) radio channels available and a full version with all Soma.fm channels for just 0.99 ‚Ç¨. I don\u0026rsquo;t think it\u0026rsquo;s too expensive, right? Consider all the time I\u0026rsquo;ve spent coding it and if you like the trial version, please support the development of this application and purchase the full one.\n{ width=30% } { width=30% }\nInstall CuteSoma Press Search button on your Nokia Lumia (or any other Windows Phone) and tap vision button\nScan the following QrCode\n{ width=30% }\n3.¬†Tap on the link when it appears on the screen 4.¬†Install the application from the Windows Phone Store 5. Enjoy!\nPlease consider also donatingto Soma.fm if you like their music: Soma.fm is donation supported and they need your \u0026ldquo;love\u0026rdquo; to pay their bills :)\n","date":"2012-12-14T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/cutesoma-soma-fm-client-for-windows-phone-available/","title":"CuteSoma (Soma.fm client) for Windows Phone available"},{"content":"\nAfter a very pleasant experience in Finland (Tampere), I\u0026rsquo;ve finally come back to Italy. I had the opportunity to work for three months in Nokia as \u0026ldquo;Qt Expert\u0026rdquo; in \u0026ldquo;Nokia Developer Forum\u0026rdquo; and it\u0026rsquo;s been an amazing job!\nTo be more precise I left Finland on August 31th, but I didn\u0026rsquo;t have much time to blog about this. Finally I can use my desktop PC again and I\u0026rsquo;m not anymore limited to my small netbook. Trust me\u0026hellip; spending 3 months with a 11\u0026rsquo;\u0026rsquo; netbook and pretending to work normally is really frustrating.\nNow I have more spare time (too much :\\ ) to contribute to Ubuntu and to play with some new technologies: I\u0026rsquo;m working on a project that uses Arduino, Android and some \u0026ldquo;robotic\u0026rdquo; parts, with people of Pistoia Linux User Group and it\u0026rsquo;s really an amazing learning experience!\nTalking about Ubuntu, if you have never contributed to it and you would like to start with something easy, I suggest you this interesting initiative¬†https://wiki.ubuntu.com/UbuntuDevelopment/BugFixingInitiative\nIn the mean time I\u0026rsquo;m also looking for new opportunities and challenges (aka = looking for a new job), so if you think you may be interested in me, take a couple of minutes to give a look to my LinkedIn profile¬†http://www.linkedin.com/in/andreagrandi\nI will attend next UDS in Copenaghen (99% sure) and I already have a couple of topics I would like to work with, but I will talk about these later, first I want to properly create a blueprint in Launchpad so we will have a starting point.\n","date":"2012-09-13T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/leaving-finland-and-nokia-coming-back-to-italy/","title":"Leaving Finland (and Nokia), coming back to Italy!"},{"content":"During the last UDS party, I had an idea to improve Ubuntu¬†development, but I didn\u0026rsquo;t know if it could be a good idea or a stupid¬†one, so I talked to Daniel Holbach and David Planella about it and¬†they were happy to hear about it and Daniel told me to talk about this¬†directly to Mark (and I did it).\nLet\u0026rsquo;s explain the basic idea.\nFrom an UDS and the next one, it would be useful to have a development¬†sprint where people can talk about assigned UDS blueprints, at which¬†point they are on their tasks, if they have any problems and if they¬†will finish them within the next UDS.\nOf course Canonical cannot organize another meeting, it would be very¬†expensive, so the idea is: why don\u0026rsquo;t we use Google Hangout to organize¬†the sprint? I has a limit of 10 people, I know, but we could select¬†(for example) 5 from the community and 5 from Canonical. There would¬†be parallel meeting and tracks, we would use the same blueprints used¬†during the last UDS and we would add further notes. The attendees¬†would be able to listen and watch the stream and make questions¬†through the available chat.\nI\u0026rsquo;ve also created a wiki page with more informations and you can find¬†it here: https://wiki.ubuntu.com/UbuntuReleaseSprint\nWhat do you think about? I know that Canonical is already organizing¬†sprints and this could be a way to involve more the Ubuntu Community. Maybe we should schedule a session at next UDS to talk about this?\nI hope to get some feedback from you.\n","date":"2012-08-17T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-release-sprint-calling-for-feedback/","title":"Ubuntu Release Sprint: calling for feedback!"},{"content":"Social Connect is a library written in Qt that allows applications to easily connect to services like Facebook and Twitter. Recently I had the opportunity to work on this library improving it and adding support for Instagram (work is still in progress but it\u0026rsquo;s almost finished).\nThe main features of this library are:\nOut-of-the-box support for Facebook and Twitter Integrated authentication implementation Simplified common interface for all supported services Provides interfaces for native API calls Design enabling easy addition of new services e.g. LinkedIn If you are writing an application that needs to access these services, this could be the library for you. It can be extended to support even other services like LinkedIn, Flickr etc\u0026hellip; and I would like to invite people to contribute to the code. The library has been tested with¬†Qt 4.8.1¬†on¬†Ubuntu Linux 12.04¬†but it should be compatible with any other versions/platforms.\nFor more informations about getting started with the library, I suggest you to give a look at this page¬†https://projects.developer.nokia.com/socialconnect/wiki/GettingStarted\n","date":"2012-08-13T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/social-connect-qml-plugin-access-facebook-twitter-from-your-qtqml-applications/","title":"Social Connect QML plugin: access Facebook, Twitter from your Qt/QML applications"},{"content":"Yesterday, during the final UDS party, I had an idea to improve Ubuntu development, but I didn\u0026rsquo;t know if it could be a good idea or a stupid one, so I talked to Daniel Holbach and David Planella about it and they were happy to hear about it and Daniel told me to talk about this directly to Mark (and I did it).\nLet\u0026rsquo;s explain the basic idea. From an UDS and the next one, it would be useful to have a development sprint where people can talk about assigned UDS blueprints, at which point they are on their tasks, if they have any problems and if they will finish them within the next UDS. Of course Canonical cannot organize another meeting, it would be very expensive, so the idea is: why don\u0026rsquo;t we use Google Hangout to organize the sprint? I has a limit of 10 people, I know, but we could select (for example) 5 from the community and 5 from Canonical. There would be parallel meeting and tracks, we would use the same blueprints used during the last UDS and we would add further notes. The attendees would be able to listen and watch the stream and make questions through the available chat.\nI don\u0026rsquo;t want to write more details here because I don\u0026rsquo;t think it\u0026rsquo;s the right place (and probably it\u0026rsquo;s not the moment to write a similar blog post, since I\u0026rsquo;m still in th SFO Airport), my idea is to create a wiki page to explain all the details, so everyone would be able to add more ideas and see if it\u0026rsquo;s doable or not.\nSo, what do you think about? I think we should try, it doesn\u0026rsquo;t cost anything except some hours in the week we\u0026rsquo;ll organize it. I wait for your comments then.\n","date":"2012-05-12T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-release-sprint-a-proposal-to-improve-ubuntu-development/","title":"Ubuntu Release Sprint: a proposal to improve Ubuntu development"},{"content":"\nAfter upgrading my desktop PC to Ubuntu 12.04 (actually my main machine) I started experimenting many Xorg crashes and instability issues. I reported the bug, but I had to find a solution or I should have rolled back to Ubuntu 11.10. The problem (from my point of view) is of the new Nvidia 295.40 binary drivers. I also tried an older version (295.33) experiencing the same problems. I then decided to give the Nouveau opensource drivers a try.\nI must say that in over 24 hours I didn\u0026rsquo;t have a single Xorg crash. My desktop is very stable and Nouveau drivers are pretty fast: I can watch a 1080p video on Youtube in full screen without having any problem. The only problem with my machine is that I\u0026rsquo;m using a VGA Switcher to share my monitor wit Xbox (see this old post), so my monitor capabilities cannot be detected automatically and I had to do some manually tuning of the Xorg configuration.\nFirst of all I had to resolve a very annoying problem: the screen was blinking every 10 seconds and this really hurted my eyes. To fix this I had to add a kernel parameter:¬†**drm_kms_helper.poll=0\n**you need to add this string in /etc/default/grub to the¬†GRUB_CMDLINE_LINUX_DEFAULT parameter. After this your line should look like this one:¬†GRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;quiet splash drm_kms_helper.poll=0\u0026quot;\nDon\u0026rsquo;t forget to execute: sudo update-grub¬†from the command line.\nThen I had to create a proper xorg.conf setting my resolution (1680x1050) manually:\n1 2 3 4 5 6 7 8 9 10 11 12 13 Section \u0026#34;Monitor\u0026#34; Identifier \u0026#34;DVI-I-1\u0026#34; VendorName \u0026#34;Asus\u0026#34; ModelName \u0026#34;Ancor Communications Inc VW222\u0026#34; Modeline \u0026#34;1680x1050R\u0026#34; 119.00 1680 1728 1760 1840 1050 1053 1059 1080 +hsync -vsync Option \u0026#34;PreferredMode\u0026#34; \u0026#34;1680x1050R\u0026#34; EndSection Section \u0026#34;Screen\u0026#34; Identifier \u0026#34;Screen0\u0026#34; Monitor \u0026#34;DVI-I-1\u0026#34; EndSection How do you generate the Modeline line? It\u0026rsquo;s very simple. Just execute: \u0026ldquo;cvt -r 1680 1050\u0026rdquo; in the command line and you\u0026rsquo;ll get a line similar to the one I added (of course substitute those numbers with the resolution you want).\nYou have to save this file in /etc/X11/xorg.conf and reboot your system to use all the new settings. Now my system runs nicely and very fast! I\u0026rsquo;m really enjoying the new Ubuntu 12.04 Precise Pangolin. I just hope that Nvidia guys will fix the sta\nbility issues of their driver as soon as possible, so I\u0026rsquo;ll be able to choose again between the opensource driver and the closed source one (faster with 3D stuff, but more unstable as you can see).\nA big thanks to everyone in #nouveau IRC channel on Freenode. They were very kind to help me configuring their opensource driver.\n","date":"2012-04-27T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-12-04-nvidia-8800-gs-and-nouveau-drivers/","title":"Ubuntu 12.04, Nvidia 8800 GS and Nouveau drivers"},{"content":"With BlackBerry PlayBook you can now use Qt libraries to develop your applications. The problem is that QML components are not available yet (they will be available with CascadesUI in the near future), but you can use Symbian qt-components to develop your application UI. This should also make the porting of an existing Symbian Qt application easier.\nWe suppose you have already built and installed QtQNX under this directory: ~/QtQNX/ARM/ (please change it matching the folder where you installed it).\nAt this point you have to get qt-components sources using this command:\n1 2 git clone git://gitorious.org/qt-components/qt-components.git qt-components Now enter the directory you just checked and compile the components:\n1 2 3 4 cd qt-components QTDIR=\\~/QtQNX/ARM/ ./configure -symbian make Whend you complete all the previous operations, you\u0026rsquo;ll have two directories inside qt-components/imports, please copy them inside the QtQNX installation directory:\n1 2 cp -R imports/Qt \\~/QtQNX/ARM/imports/ cp -R imports/com \\~/QtQNX/ARM/imports/ That\u0026rsquo;s all for now. In the next posts I\u0026rsquo;ll show you how to use these components, providing a small code example. In the mean time you can find more informations here¬†http://supportforums.blackberry.com/t5/Native-SDK-for-BlackBerry-Tablet/QML-symbian-qt-components-for-PlayBook/td-p/1574275\n","date":"2012-03-30T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-qml-qt-components-with-qtqnx-for-blackberry-playbook/","title":"Using QML qt-components with QtQNX for BlackBerry PlayBook"},{"content":"Yesterday in Pistoia (Italy) we had the Ubuntu Global Jam and about 15 people attended the event. We began with an introductive talk by Paolo Sammicheli about the Italian Ubuntu Community and how it is possible to contribute to Ubuntu. We divided in two small groups, one translating from English to Italian (coordinated on IRC by the people of the community) and another group leaded by Marco Trevisan, learning how to implement automatic tests in Unity code (in particular he introduced us Autopilot, more information here:¬†https://wiki.ubuntu.com/Unity/QA/Autopilot¬†). Next time I would like to ask people to register to Launchpad and sign the Code of Conduct before attending the global jam. We wasted a lot of time with this task.\nAt the end of the day me and the other people from Pistoia, took the other people for a quick tour around the city where we had the possibility to eat some tasty food. It was a very amazing day and people who started collaborating for the first time were very happy! I think this has been a successful day, at least for us. I hope the other LoCo are having a good Jam as well and I really can\u0026rsquo;t wait for the next Ubuntu Global Jam.\n","date":"2012-03-04T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-global-jam-italy-pistoia-a-quick-review/","title":"Ubuntu Global Jam Italy (Pistoia): a quick review"},{"content":"Few days ago I decided to move my Xbox 360 from the room where is the TV to the room where I have my desktop PC. I wanted to avoid wasting precious space on my desk, so I decided to share my 22\u0026rsquo;\u0026rsquo; monitor with the Xbox and I bought a VGA Switcher. With this product you can easily switch the VGA signal between your PC and the Xbox and also the audio signal.\nThe problem with this solution is the fact that your monitor is not anymore attached directly to your graphic card and this causes problems detecting the monitor capabilities. Please note that the switcher doesn\u0026rsquo;t reduce the resolution you can have, it just make the graphic card impossible to detect the correct resolution.\nIf you have an Nvidia graphic card you can use the nvidia-settings tool to manually set the configuration and to save it to a file, so during the next boot even if Ubuntu won\u0026rsquo;t be able to detect the proper resolution for your monitor, it will simply apply the configuration found in xorg.conf\nPlease remember to also set the refresh rate of the monitor (I was having a very bad resolution until I didn\u0026rsquo;t choose 60 Hz in the settings window). If you don\u0026rsquo;t have a Nvidia graphic card (and the proper tool) to generate a xorg.conf file or if you just want to give a look at my configuration here you have a copy:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # nvidia-settings: X configuration file generated by nvidia-settings # nvidia-settings: version 280.13 (buildd@rothera) Thu Aug 11 17:28:49 UTC 2011 Section \u0026#34;ServerLayout\u0026#34; Identifier \u0026#34;Layout0\u0026#34; Screen 0 \u0026#34;Screen0\u0026#34; 0 0 InputDevice \u0026#34;Keyboard0\u0026#34; \u0026#34;CoreKeyboard\u0026#34; InputDevice \u0026#34;Mouse0\u0026#34; \u0026#34;CorePointer\u0026#34; Option \u0026#34;Xinerama\u0026#34; \u0026#34;0\u0026#34; EndSection Section \u0026#34;Files\u0026#34; EndSection Section \u0026#34;InputDevice\u0026#34; # generated from default Identifier \u0026#34;Mouse0\u0026#34; Driver \u0026#34;mouse\u0026#34; Option \u0026#34;Protocol\u0026#34; \u0026#34;auto\u0026#34; Option \u0026#34;Device\u0026#34; \u0026#34;/dev/psaux\u0026#34; Option \u0026#34;Emulate3Buttons\u0026#34; \u0026#34;no\u0026#34; Option \u0026#34;ZAxisMapping\u0026#34; \u0026#34;4 5\u0026#34; EndSection Section \u0026#34;InputDevice\u0026#34; # generated from default Identifier \u0026#34;Keyboard0\u0026#34; Driver \u0026#34;kbd\u0026#34; EndSection Section \u0026#34;Monitor\u0026#34; # HorizSync source: edid, VertRefresh source: edid Identifier \u0026#34;Monitor0\u0026#34; VendorName \u0026#34;Unknown\u0026#34; ModelName \u0026#34;Ancor Communications Inc VW222\u0026#34; HorizSync 31.0 - 81.0 VertRefresh 56.0 - 75.0 Option \u0026#34;DPMS\u0026#34; EndSection Section \u0026#34;Device\u0026#34; Identifier \u0026#34;Device0\u0026#34; Driver \u0026#34;nvidia\u0026#34; VendorName \u0026#34;NVIDIA Corporation\u0026#34; BoardName \u0026#34;GeForce 8800 GS\u0026#34; EndSection Section \u0026#34;Screen\u0026#34; Identifier \u0026#34;Screen0\u0026#34; Device \u0026#34;Device0\u0026#34; Monitor \u0026#34;Monitor0\u0026#34; DefaultDepth 24 Option \u0026#34;TwinView\u0026#34; \u0026#34;0\u0026#34; Option \u0026#34;TwinViewXineramaInfoOrder\u0026#34; \u0026#34;CRT-0\u0026#34; Option \u0026#34;metamodes\u0026#34; \u0026#34;1680x1050\\_60 +0+0; nvidia-auto-select +0+0\u0026#34; SubSection \u0026#34;Display\u0026#34; Depth 24 EndSubSection EndSection Remember to save the file in /etc/X11/xorg.conf and on next boot you will have the right resolution even with your VGA Switcher in use.\n","date":"2012-02-26T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/sharing-your-pc-monitor-with-your-xbox-using-a-vga-switcher/","title":"Sharing your PC monitor with your Xbox using a VGA Switcher"},{"content":"Using more than one computer, often it would be useful to have a way to synchronize settings among multiple computers. For example you change the desktop wallpaper on your office PC and you want to find the same wallpaper when you go back home on your personal PC or on your laptop. Language settings, online accounts, privacy settings ecc\u0026hellip; are only few examples of settings you could want to have synchronized.\nUbuntu One already gives you 5 Gb space for free and it\u0026rsquo;s available for everyone activating it. It\u0026rsquo;s a perfect place for storing a shared folder with all those settings. Of course not a simple folder, a special one. Applications use settings taken from usual ~/.appName and a daemon takes care of synchronizing data once you\u0026rsquo;re connected to Internet. Just like Ubuntu One does with your documents.\nHow do I choose which settings to synchronize? First of all you have to activate an Ubuntu One account, if you don\u0026rsquo;t have already done it, then you just have to choose the settings you want using this tool available in Ubuntu System Settings\nWhat? A mockup?! Isn\u0026rsquo;t this tool available yet??!! Exactly :) This tool is not available yet, but I think it would be an interesting feature to talk about for the next (not precise, I mean 12.10) Ubuntu release. What do you think about?\n","date":"2012-02-21T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-syncronizing-settings-among-multiple-pc-using-ubuntu-one/","title":"Ubuntu: synchronizing settings among multiple computers using Ubuntu One"},{"content":"\nEven this time Pistoia Linux User Group decided to join the international event \u0026ldquo;Ubuntu Global Jam\u0026rdquo; organizing it in collaboration with Ubuntu-it Community. The international event will be on March 2nd, 3rd and 4th and we have decided for March 3rd (saturday) from 15:00 CET to 19:00 CET. This event will be organized in a room made available by Circolo ARCI Bonelle. We\u0026rsquo;ll have a room capable of about 100 people and a smaller one with 4 PC and a big table for people who want to bring their own laptop. Wifi internet connection will be available for everyone.\nThe event will be introduced by a talk made by Paolo Sammicheli of the Ubuntu-it Community and then we will divide in some smaller groups that will dedicate to different tasks. One will be coordinated by Paolo Sammicheli and will be dedicated to testing and bug triaging. Another group will do some translations from english to italian and will collaborate directly with italian translation team talking with them on a dedicated IRC channel. The last group will be leaded by a very good Unity rockstar\u0026hellip;.. (suspance)\u0026hellip;\u0026hellip; Marco Trevisan! People collaborating directly with him will try to help fixing some bugs or at least they will learn how to get started to bug fixing (probably we will pick a bitesize bug and we will fix it together).\nWe\u0026rsquo;ve created an event on Facebook and invited all our friends to attend. We really hope that many people will partecipate to this opportunity to make the next Ubuntu version more\u0026hellip; \u0026ldquo;precise\u0026rdquo;!\n","date":"2012-02-19T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-global-jam-march-3rd-2012-pistoia-tuscany-italy/","title":"Ubuntu Global Jam - March 3rd 2012: Pistoia (Tuscany), Italy."},{"content":"CuteSoma (Soma.fm client for Nokia N9) has been available for 4 months now and it\u0026rsquo;s the right time to publish some interesting statistics about downloads. First of all I didn\u0026rsquo;t expect so much interest and I wasn\u0026rsquo;t sure to have so many downloads, due to the fact that Nokia never advertised this device properly. But luckly lot of people don\u0026rsquo;t care about advertising and buy a product anyway if they know it\u0026rsquo;s one of the best available on the smartphone market.\nI\u0026rsquo;m really happy to notice that the number of downloads is growing each month, this motivates me to continue with development (well\u0026hellip; when my N950 comes back from Nokia, since I had to send it because it was broken).\nI want to thank all the 3658 people that downloaded CuteSoma until now and all the people that are sending me their feedback, ideas and patches (yes Cornelius Hald, I\u0026rsquo;m talking about you :D ) you\u0026rsquo;re giving me a big opportunity to learn C++/Qt/QML.\n","date":"2012-02-03T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/cutesoma-worldwide-downloads-statistic-for-nokia-n9/","title":"CuteSoma - worldwide downloads statistic for Nokia N9"},{"content":"If you try to install Nokia QtSDK on Ubuntu using the Nokia installer (that provides a newer version than the one distributed in Ubuntu Software Center) you could get an error like this:\n1 2 3 (Qt_SDK_Lin32_offline_v1_1_3_en.run:3126): Gtk-CRITICAL **: IA__gtk_widget_style_get: assertion `GTK_IS_WIDGET (widget)` failed to fix it, you need to run the installer with a specific parameter:\n1 ./Qt_SDK_Lin32_offline_v1_1_4_en.run -style cleanlooks and everything should work!\n","date":"2012-01-12T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/nokia-qtsdk-installer-crash-on-ubuntu-how-to-fix-it/","title":"Nokia QtSDK installer crash on Ubuntu: how to fix it"},{"content":"I\u0026rsquo;ve been a Flickr pro user for 4 years, but the pro account costs 24,95$/year and I was looking for something cheaper. Anyway I was thinking that after all, even if I don\u0026rsquo;t renew my account, I can always access to all my pictures\u0026hellip;. wrong! If you don\u0026rsquo;t renew your pro Flickr account you can only access to the low resolution version of your own pictures. That\u0026rsquo;s not acceptable for me, so I decided to download all my pictures and upload them somewhere else. Here comes the second disappointment: there is no automatic way to download all your pictures.\nI simply had no time to write an application by myself, so I started searching on Google to see if there was something available to do this simple task. At the beginning I only found abandoned tools (closed source, the API was expired ecc\u0026hellip;), paid tools, Windows only tools ecc\u0026hellip; but finally I found this post¬†http://hivelogic.com/articles/backing-up-flickr/\nThere is a Python script that automatically downloads all your Flickr pictures getting the highest resolution available, you can download the script from here¬†https://github.com/dan/hivelogic-flickrtouchr\nThe usage is very simple\n1 2 mkdir FlickrBackupFolder python flickrtouchr.py FlickrBackupFolder A browser\u0026rsquo;s window will be opened and you\u0026rsquo;ll be prompted for authorization. After that, all you pictures will be downloaded.\n","date":"2012-01-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/backing-up-all-your-flickr-photos-using-linux/","title":"Backing up all your Flickr photos using Linux"},{"content":"{ width=60% }\nIn questo periodo diversi conoscenti mi stanno facendo domande su come siano gli ebook e se valga la pena farne uso rispetto ai normali libri cartacei. Recentemente ho avuto modo di acquistare il lettore Kindle di Amazon e devo ammettere di essere rimasto molto soddisfatto. Ho cercato di raccogliere le principali domande che mi sono state fatte al riguardo, sperando di fornire una panoramica completa sui libri in formato elettronico e sui relativi lettori.\nNon √® scomodo leggere sul Kindke? Assolutamente no. Non dovete immaginare il Kindle come un tablet (anzi, chi cerca un qualcosa che funzioni anche come tablet ha proprio sbagliato prodotto. Kindle √® fatto per leggere libri.), lo schermo infatti non √® un normale LCD come quelli dei tablet o dei portatili, ma una speciale superficie dove le parole vengono disegnate tramite l\u0026rsquo;e-ink. Lo schermo del Kindle non √® retroilluminato e per leggere, cos√¨ come per un libro normale, c\u0026rsquo;√® bisogno o della luce del sole o di stare vicino ad una lampada. Gli occhi quindi non si stancano ed √® possibile andare avanti a leggere per ore, senza notare differenze rispetto alla lettura di un libro normale.\nQuanto costano i libri in formato elettronico? Di solito il costo √® di 3-4‚Ç¨ in meno rispetto alla versione cartacea. Potrebbero costare molto meno se la legge italiana (ancora una volta cieca di fronte alle innovazioni) non equiparasse gli ebook a dei prodotti elettronici. L\u0026rsquo;IVA sugli ebook √® infatti del 21% e non viene assolta come per i libri cartacei. Va detto anche che moltissimi libri, per i quali sono ormai scaduti i diritti di autore, sono disponibili gratuitamente. Volete leggere La Divina Commedia, Pirandello, I Promessi Sposi ecc\u0026hellip;?! Benissimo. Questi e molti altri libri sono scaricabili gratuitamente. Kindle al momento offre \u0026ldquo;soltanto\u0026rdquo; 16.000 titoli in italiano, ma √® ovviamente possibile accedere anche a tutti gli altri titoli disponibili in lingua straniera, per un totale di quasi un milione di libri a disposizione.\nQuali sono i vantaggi per chi scrive? Gli scrittori, grazie agli ebook, hanno un modo ancora piu\u0026rsquo; facile e redditizio per pubblicare i propri libri. Attualmente, se uno scrittore vuole pubblicare un libro, deve trovare un editore che lo reputi interessante e decida di investire per pubblicarlo. Visto che l\u0026rsquo;editore di assume un rischio molto alto, la maggior parte del compenso va a lui. Con Amazon invece √® possibile pubblicare un proprio libro in modo economico e veloce. Non c\u0026rsquo;√® necessit√† di stampare migliaia di copie di un libro, cos√¨ come avviene per il cartaceo. I compensi inoltre sono molto alti: il 70% del ricavato va a chi scrive il libro, non all\u0026rsquo;editore. Su un libro da 10‚Ç¨ quindi, all\u0026rsquo;autore rimangono 7‚Ç¨.\nRiassumiamo i vantaggi degli ebook\neconomici (costano 3-4‚Ç¨ in meno, molti sono persino gratuiti) ecologici (non c\u0026rsquo;√® bisogno di stampare migliaia di copie) maggiori introiti per chi scrive i libri un e-reader √® leggero, pu√≤ contenere oltre 1000 libri, ottima autonomia con batterie che durano 1 mese comodit√† di poter acquistare un libro direttamente da casa ed averlo in pochi minuti nessun pericolo di acquistare un libro che non ci piace: con Kindle √® possibile avere una copia dei primi capitoli del libro, senza spendere niente, in modo da valutare se il libro valga veramente la pena di essere letto Se posso aggiungere un vantaggio, del tutto soggettivo, ma che personalmente √® il piu\u0026rsquo; importante: gli ebook mi hanno fatto tornare anche la voglia di leggere!\n","date":"2011-12-30T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ebook-valgono-la-pena-rispetto-ai-libri-cartacei-lesempio-amazon-kindle/","title":"ebook: valgono la pena rispetto ai libri cartacei? L'esempio Amazon Kindle"},{"content":"\nTomorrow Ubuntu 11.10 (Oneiric Ocelot) will be released officially and I decided to test the RC (release candidate) version on my desktop PC. Being involved in Unity-2D development I used only that desktop environment on my development virtual machine so I didn\u0026rsquo;t have much time to test Unity (3D version).\nI must admit that there have been a lot of improvements from 11.04 (Natty Narval) release, but also a lot of bugs and regressions have been introduced. I\u0026rsquo;ve noted all the problems I found in every day use and as soon as possible I\u0026rsquo;ll also submit proper bug report on Launchpad for each of them. In the mean time you can give a look to the following list.\nBugs and regressions Notifications broken: on Ubuntu Natty when an application wants to notify of a new message it popups an icon from the Launcher, then displays a small blue triangle in the top-left corner of the screen. Oneiric doesn‚Äôt have the small blue triangle anymore. In this way, if the user is looking away when he gets a notification, he can miss it for hours. There‚Äôs no way to know that there is a notify without manually going with mouse to the left and making the launcher to appear.\nLauncher visibility: on Ubuntu Natty when the user moves the mouse in the top-left corner the Launcher is shown. Oneiric doesn‚Äôt show Launcher if you move the mouse in the top-left corner. You can‚Äôt use the top 30-40 pixels (the height of the panel).\nNotify area icons: often in Oneiric when you click an icon in the notify area (for example the volume icon, the network manager icon ecc\u0026hellip;) the popup is shown and suddenly hidden. You have to click a second time to view it.\nNotify icon - Empathy: in Oneiric you cannot open Empathy from the notify area. If you click on ‚ÄúChat‚Äù Empathy is open and visible on the Launcher but not on the screen. You have to move to mouse to the launcher then click on it to view the application window.\nEmpathy: ‚ÄúAutomatically connect on startup‚Äù doesn‚Äôt work. If you enable this option in Empathy it doesn‚Äôt start anyway when the system start.\nLauncher doesn‚Äôt work as expected: sometimes when you move the mouse on the left, Launcher is not shown. You can try it many times and it still doesn‚Äôt appear. I‚Äôve to SUPER+D a couple of times (to show/hide Desktop) to show view it. Even the opposite problem happens: sometime you cannot hide the Launcher.\nBoot failing: every time I boot Oneiric the first boot fails. I cannot know what happens because nothing is shown on video. I press CTRL+ALT+CANC, the system reboot and then boot normally.\nShowing Skype: on Natty you just need to double-click on Skype icon in the notify bar to show it, now you need to click once on the icon, choose ‚ÄúActivate‚Äù from menu and you show it. Why the need to complicate an easy thing?\nWebcam problems with Skype: with Natty I could¬†use my webcam with Skype without any problem. Now I can still use it but if I activate the view of myself during a videcall, the video completly locks and it doesn‚Äôt work anymore. Skype is always the same version, so probably there is a problem with the new driver used.\nWindow manager: sometimes moving an application window doesn‚Äôt work. You drag a window around the screen then suddenly the window stop moving and the mouse icon starts vibrating. You have to release and click again to move the window and stop mouse icon vibrating.\nConclusion In the next days I\u0026rsquo;ll work on checking for these bugs on Launchpad to see if they\u0026rsquo;re already submitted and if not I\u0026rsquo;ll submit them, hoping they will be fixed as soon as possible before end users start bothering about them.\n","date":"2011-10-12T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-oneiric-11-10-problems-and-regressions/","title":"Ubuntu Oneiric 11.10 problems and regressions"},{"content":"CuteSoma is a client of Soma.Fm streaming radio that I wrote using Qt/QML for Nokia N9 and Nokia N950. Previously it was available as a .deb only, now you can install it directly from the OVI Store. It\u0026rsquo;s only a 0.1 version and even if it\u0026rsquo;s quite stable it may contains some bugs: please report me any bug so I can try to fix them as soon as possible.\nCuteSoma is opensource and released under the GPL v.3 license. You can find the complete source code here:¬†https://github.com/andreagrandi/CuteSoma\nThere is a poll available to let the final users choose the new icon for this application, you can find it here:¬†http://forum.meego.com/showthread.php?t=4619\nI asked for help to design a new icon and I received two, so I\u0026rsquo;m letting the final users choose which one they like most.\nTo get this application you need to search \u0026ldquo;cutesoma\u0026rdquo; on OVI Store client or visit this link¬†http://store.ovi.com/content/205737\nPlease remember that CuteSoma is free, but if you want you can make me a donation or offer me a beer using the \u0026ldquo;Donazione\u0026rdquo; button on the right column.\n","date":"2011-09-30T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/cutesoma-soma-fm-client-for-nokia-n9n950-now-available-on-ovi-store/","title":"CuteSoma: Soma.Fm client for Nokia N9/N950 now available on OVI Store"},{"content":"{ width=60% }\nIntroduction Even if it\u0026rsquo;s not a new model, the HTC Desire is still a very good Android device, thanks to its 1Ghz CPU and 512 Mb RAM,¬†but one of the biggest problems of this phone is that it comes with only 148Mb available in the ROM. Once the operating system is installed (ROM I mean), after installing few useful applications you\u0026rsquo;ll end the available space very soon. There are many apps available, like App2SD that move your applications to the SD card, but it\u0026rsquo;s not enough because only the application is moved, not the data. To move the data to the SD card, there is a very nice utility called Data2SD. Please note that this procedure requires you to reflash your device and partition your SD card, so please do a complete backup before proceding.\nWhat you need a rooted HTC Desire (you need to have a rooted phone with a recovery already installed) a 4Gb (or bigger) microSD, at least class 4 (class 6 is even better while class 10 is reported not working with this phone) a microSD card reader CyanogenMod 7:¬†http://download.cyanogenmod.com/get/update-cm-7.0.3-Desire-signed.zip Data2SD:¬†Data2SDInstallerX1.zip and Data2SDReInstallerX1.zip Google Apps:¬†http://wiki.cyanogenmod.com/wiki/Latest_Version#Google_Apps GParted: you can use the version available on Ubuntu Linux or you can download a live Linux image with GParted installed:¬†http://gparted.sourceforge.net/livecd.php Backup your data Before following these instructions, please do a complete backup of your microSD, of your original ROM (using Nandroid or similar) ecc\u0026hellip;\nPrepare the microSD card Open GParted on your Ubuntu Linux or use the GParted Live CD/USB. Delete all partitions on this microSD Create the first one using FAT32 filesystem, leaving 2Gb (2047Mb) available at the end. Create a second partition using ext4 filesystem. Confirm your changes Copy CyanogenMod7 rom, Data2SD installers and Google Apps on FAT32 partition CyanogenMod 7 installation Reboot your phone into Recovery (turn it off then press volume down + power) WIPE all data (userdata, cache ecc\u0026hellip;) Choose \u0026ldquo;Install from SD card\u0026rdquo; and select CyanogenMod7 installation zip when finished reboot your phone Enter your Wifi settings, language ecc\u0026hellip;. DO NOT enter your Google account settings. reboot your phone Data2SD installation Boot into Recovery again Choose \u0026ldquo;Install from SD card\u0026rdquo; and select¬†Data2SDInstallerX1.zip (please note, you may have to turn off the signature verification in Other-\u0026gt;Turn off ecc\u0026hellip;) when finished reboot your phone now you should see 1,97Gb if you go in Settings-\u0026gt;Storage-\u0026gt;Internal Storage-\u0026gt;Total space Google Apps installation Reboot your phone into Recovery Choose \u0026ldquo;Install from SD card\u0026rdquo; and select the Google Apps zip file reboot your phone Conclusion You now have 1,97Gb total space available instead of 148Mb. Enjoy your HTC Desire!\nUpdate Aug 1, 2012: since December 2011 I don\u0026rsquo;t have an HTC Desire anymore. These informations could be still valid but in any other case I don\u0026rsquo;t have the possibility to help you more. ","date":"2011-08-13T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/howto-extend-htc-desire-internal-memory-to-2gb-using-cyanogenmod-7-and-data2sd/","title":"HowTo extend HTC Desire internal memory to 2Gb using CyanogenMod 7 and Data2SD"},{"content":"\nI left from Firenze with my friend Marco Trevisan, to go to Ubuntu Developer Summit in Budapest. We changed flight in Rome where we met also Andrea Azzarone. Unluckly Alitalia losts Marco\u0026rsquo;s baggage, so he\u0026rsquo;s still waiting for it.\nWe arrived at the hotel at 20:00 more or less where we met other people of the community. There are lot of italians at UDS. Most work for Canonical, other were sponsored by.\nI met Marianna Raffaele (one of the UDS organizer\u0026hellip; yeah, she\u0026rsquo;s italian too!), I had to explain her a little problem I had with my booking (nothing bad) and she managed to help me. She also gave me a very nice guitar plettre with Ubuntu logo. Thank you Marianna for this!\nWe went out with Jorge Castro to drink some beers (he offered me one, thanks Jorge!!!) and we met lot of other Ubuntu people. A really amazing start!\n","date":"2011-05-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/uds-day-0/","title":"UDS day-0"},{"content":"\nMy day started at 7:30 with a very nice breakfast! I was alone with just another guy this morning, in a very big breakbast room.\nAfter it I grabbed my badge to avoid queue later and went back to my room to wake up Marco Trevisan (he was still sleeping :P ).\nThe keynote was opened by Jono Bacon (the Ubuntu Community manager), followed by Ubuntu founder Mark Shuttleworth. The most interesting (and tweeted) part of the keynote was \u0026ldquo;how to prounounce Oneiric\u0026rdquo; (Oeniric will be the next Ubuntu release).\nThe keynote finished with a bit late, so all the other tracks were shifted forward. I followed \u0026ldquo;Unity 2D Oneiric Improvements\u0026rdquo;, it was interesting because there were some Nokia/Qt guys and they looked very interested in helping the Unity 2D team and collaborating with them.\nNow following \u0026ldquo;Shaping a strategy for Ubuntu user assistance\u0026rdquo;, I just had the possibility my involvement into helping people that require Ubuntu assistance.\nThe lunch has been very tasty, I had the possibility to eat some local recipes, not bad at all.\nAfter lunch we had a short session on Qt. The version 4.8 is going to be released in a couple of months, while 5.0 is announced to be released in 1 year from now: it will be almost code-compatible with 4.x, it will have an improved support for Qt Quick and QML.\nAs last track of the day I decided to follow \u0026ldquo;Personal Cloud\u0026rdquo;. Not a perfect track, since the person who should have been here was only talking with us using Skype and it was more difficoult to hear what he said.\nAt the end of this day there was the \u0026ldquo;Meet \u0026amp; Greet\u0026rdquo; party, sponsored by Freescale and Openstack. They offered a dinner and we had some good music after it.\n","date":"2011-05-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/uds-day-1/","title":"UDS day-1"},{"content":"\nThis day at UDS started a bit late for me, since i woke up pretty sick (damn air conditioned!!!). I did not follow any conferences in the morning. I relly wanted to follow the Wayland one, but when I arrived the room was already full and it was almost impossible to enter, so I decided not to enter.\nI attended \u0026ldquo;What\u0026rsquo;s wrong with UDS and how we can fix it\u0026rdquo; session before having lunch. We discussed the possibility to improve all the session in general,¬†for example giving them a proper order so that a team can first discuss some API interface, then another team can discuss how to design them.\nWe had another wonderful and tasty lunch, even if I didn\u0026rsquo;t eat so much, but food was very good anyway.\nDuring the afternoon I followed an interesting track: \u0026ldquo;Recommend music based on current song playing or on users media library\u0026rdquo;. We discussed the possibilities to implement a music suggestion service, based on user\u0026rsquo;s tastes.\nI spent the rest of theconference time writing these blog posts and uploading pictures.\nAfter the sessions we had the Linaro Showcase: lot of demo running on Linaro and ARM processors. I was really impressed by a robot with Kinect that was able to follow people recognizing their faces. During the showcase there was a very nice dinner.\nAfter dinner I went out with my friend Manrique Lopez who is here in Budapest for another conference, so we decided to meet for a good beer.\nBefore coming back to the hotel me, Marco Trevisan and Andrea Azzarone had a nice talk with Jorge Castro. He really make us feel part of the Ubuntu family!\n","date":"2011-05-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/uds-day-2/","title":"UDS day-2"},{"content":"\nEven this morning I didn\u0026rsquo;t wake up early because I still felt sick (I already know this sore throath won\u0026rsquo;t abandon me untile I go back home).\nI had a light breakfast at 10:30 and then I finishes uploading some pictures and published articles on my blog I already had written before.\nWhile waiting to attend a session, I found Mark Shuttleworth around and I congratulated with him for the effort he is putting into Ubuntu. Without a similar distribution, I\u0026rsquo;m pretty sure that Linux would not be so popular today.\nWe had lunch at 13:00 as usual and after that I attended a couple of presentation. The first one on Eucalyptus, then \u0026ldquo;Cooking Recipes\u0026rdquo; for Ubuntu and another one dedicated to Wine. The Wine session was so funny! They had a little problem with video projector and all the images appeared with a blur effect so that you could think to be drunk ;)\nAfter these sessions I had to go back to my room since I didn\u0026rsquo;t feel very well, but I was able to attend \u0026ldquo;Unity\u0026rsquo;s relations and dependancies on GNOME\u0026rdquo; thanks to audio streaming, IRC for asking questions and etherpad to take notes.\nI attended also \u0026ldquo;desktop-dx-o-unity-a11y\u0026rdquo; where there was a discussion about the state of Unity and what can be improved before Oneiric release. Lot of work has to be done yet, in particular about accessibility.\nLast session of this day, a Q+A with Mark Shuttleworth. The session was very interesting! He replied to all questions coming from the public and from IRC.\n","date":"2011-05-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/uds-day-3/","title":"UDS day-3"},{"content":"\nA few days ago I received an email from¬†Jorge O. Castro of the Ubuntu Community, announcing me that my request of sponsorization for Ubuntu Developer Summit has been accepted. I have never attended an UDS before, so I must admit I feel a bit disoriented at the moment and maybe I\u0026rsquo;m missing some important informations, but at least I\u0026rsquo;m a good test for the situation of a community member approaching it for the first time.¬†Since I would like to actively help the organization of the Summit, I started looking for the right place to do it. I\u0026rsquo;ve a good experience about events organization and during these years I helped, for example, in the organization of Maemo Summit and MeeGo Conference, so I\u0026rsquo;d like to share my experience with the Ubuntu Community too.\nUSD Website The Ubuntu Developer Summit website is¬†http://uds.ubuntu.com/. It looks nice at first view, but it\u0026rsquo;s missing a lot of important informations and it contains some errors. The Travel section, for example should be¬†named \u0026ldquo;Travel and Accomodation\u0026rdquo; and should contains not only information about the main hotel where the Summit will take place, but also useful informations about cheap hotels/hostels for Community people who are not sponsored. The Tracks section is still empty. Is it possible that when less than 1 month is missing, official tracks are not available yet? I don\u0026rsquo;t mean categories, I mean tracks inside them. The Schedule is still empty too. Clicking any track take to a page containing an error: I would like to submit this bug, but where? Even worse, clicking on Schedule takes the visitor to a different website and there is no ways to navigate back (except clicking the back button on browser).\nForum I wasn\u0026rsquo;t able to find any section in the official Ubuntu forum where to talk about Ubuntu Developer Summit. I think it would be useful to have a dedicated section to talk about UDS or about generic Ubuntu related events. It would be useful for people to be able to meet/know each other before attending. I was lucky to meet Marco Trevisan, from the Ubuntu Italian Community, so we will travel together (thanks to a Twitter message I sent!).\nIRC The #ubuntu-uds channel on FreeNode is not much populated and a couple of times I visited it nobody wrote anything. We should keep at least 2-3 people, in turns, always available to answer any question about UDS, it would be easier for people to find the informations they look for.\nWiki It would be nice to have a page on the wiki to organize better the event. We could write a list of tasks to do and each Community member could pick one and help with it. In this way we could divide the jobs. I know there is a lot to do when we organize these kind of events and the help of the Community is something we cannot risk to miss.\nMedia We should give some informations to people who will attend UDS to be sure they will use proper tags when they will publish pictures, tweets, blog entries ecc\u0026hellip; Do we have a tag to use on Flickr? What is the right tag to use on Twitter? What keywords should we use when we will blog about the Summit? All these informations are important if we want to be sure other people will find our posts in an easy way.\nMailing List Ubuntu has a lot of mailing lists, but it looks like none dedicated to events discussion. There is one called ubuntu-events-planners but nobody is using it since months ago. We should use a mailing list to discuss about events organization and/or create a dedicated one for UDS.\n","date":"2011-04-09T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/some-ideas-to-improve-community-collaboration-for-ubuntu-developer-summit/","title":"Some ideas to improve Community collaboration for Ubuntu Developer Summit"},{"content":"MeeGo Conference Updates We have 315 registrants as of today for the conference, so numbers are looking good without having any agenda published yet! A good portion of sessions should be approved by April 8th, this Friday and you will receive an email when/if your session has been approved yet. Not all the sessions will be approved by Friday though so if you do not hear from the committee then do not worry they are probably just working through it. The program committee is tenatively planning to have a first draft of the Agenda up by April 15th. Sponsored Travel attendees should start receiving approvals during next week and approvals will continue through April 25th.\nWarm-up You can follow the updates and planning on the Warm-up at http://wiki.meego.com/MeeGo_Conference_Spring_2011#MeeGo_Conference_Warm-Up\nT-shirt design contest For anyone who didn\u0026rsquo;t see it on the mailing list this morning from Brian the winner of the T-shirt contest will receive sponsored airfare and hotel for the event in San Francisco. The contest closes next Friday, so get drawing!\nMeeGo Summit FI update MeeGo Summit FI (15-16th Apr). Summit will be 2-day developer oriented event as planned. Program contains keynotes, three tracks, meegathon competition, AR.Drone fun, evening party, Intel AppUp Lab, BoFs and more. http://summit.meegonetwork.fi\nInterest towards summit has been huge, beyond our expectations. We were fully booked after one week. We have ~350 participants (limited by facilities and other details), over 140 are (still) in queue for cancellation seat.\nMeeGo Corporate Guidelines and Regional and Local Assets and Guidelines We in conjunction with Jarkko and the Finland team, the many contributors from the community, the Linux foundation, the events team, and the Caffelli design team have pulled together the guidelines for MeeGo Events. Thank you all for your contributions in putting these together! The Guidelines and Collateral Assets are posted on the Event\u0026rsquo;s page at http://wiki.meego.com/Events#MeeGo_Conferences we would like your feedback and input so please email me amy.l.leeland@intel.com please send us things that you think we missed or things we could change to make the guidelines better.\nNote: you can find the original log here¬†http://trac.tspre.org/meetbot/meego-meeting/2011/meego-meeting.2011-04-05-17.00.html\n","date":"2011-04-06T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/meego-events-meeting-april-4th-2011-notes/","title":"MeeGo Events Meeting - April 4th 2011 - Notes"},{"content":"{ width=60% }\nIn questo periodo le regioni stanno inviando a casa di ogni cittadino la nuova versione della Carta Sanitaria Europea, simile a quella che potete vedere nella foto. Questa nuova carta, oltre a conservare gli stessi utilizzi di quella vecchia, comprende anche un micro chip che permette di utilizzarla con i comuni lettori di smartcard.\nMa a cosa serve poter utilizzare la CSE con un lettore di smartcard? Ad esempio ad accedere al proprio fascicolo sanitario tramite il sito della regione, che ci permetter√† di vedere alcuni nostri dati come ad esempio: medicine prese, esenzioni, ricoveri in ospedale, ricoveri al pronto soccorso, risultati delle analisi ecc\u0026hellip;\nPer accedere all\u0026rsquo;area riservata non viene utilizzato il classico metodo di username/password, ma bens√¨ l\u0026rsquo;autenticazione tramite smartcard.\nInstallazione del lettore di smartcard { width=60% }\nPrima di utilizzare la carta su Ubuntu Linux √® necessario intanto procurarsi un lettore di smartcard (vi consiglio di acquistare il kit che vendono dove siete andati ad attivare la vostra CSE, poich√® viene venduto ad un prezzo vantaggioso di 4,20‚Ç¨ mentre se provate a comprare il lettore altrove non lo troverete a meno di 15-20‚Ç¨) e poi installare sul proprio sistema alcuni pacchetti necessari al suo funzionamento.\nIl lettore, una volta inserito nel proprio PC dovrebbe essere identificabile tramite la seguente stringa:\n1 2 3 andrea@centurion:\\~\\$ lsusb Bus 002 Device 004: ID 072f:90cc Advanced Card Systems, Ltd ACR38 SmartCard Reader Per installare il software necessario, occorre eseguire il seguente comando da terminale:\n1 sudo apt-get install pcsc-tools pcscd libccid dopo di che dovrete procurarvi il driver del lettore, che potete trovare a questo indirizzo ed installarlo con il seguente comando (dopo aver scompattato l\u0026rsquo;archivio in una cartella a piacimento):\n1 sudo dpkg -i libminilector38u-bit4id.deb Se tutto √® stato eseguito correttamente, utilizzando il programma pcsc_scan da terminale, dovreste ottenere un output simile a questo:\n1 2 3 4 5 6 7 8 9 10 11 12 andrea@centurion:\\~\\$ pcsc_scan PC/SC device scanner V 1.4.16 (c) 2001-2009, Ludovic Rousseau \u0026amp;lt;ludovic.rousseau@free.fr\u0026amp;gt; Compiled with PC/SC lite version: 1.5.3 Scanning present readers... 0: ACS ACR 38U-CCID 00 00 Thu Nov 11 14:08:37 2010 Reader 0: ACS ACR 38U-CCID 00 00 Card state: Card inserted, ATR: 3B DF 18 00 81 31 FE 7D 00 6B 15 0C 01 81 01 11 01 43 4E 53 10 31 80 E8 Configurazione di Firefox Prima di poter configurare Firefox √® necessario installare un\u0026rsquo;ultima libreria che permetter√† al browser di poter interagire con il lettore di smartcard. Dobbiamo scaricare l\u0026rsquo;archivio presente a questo indirizzo, scompattarlo e poi copiare uno dei due file presenti (a seconda che si utilizzi un sistema a 32 o 64 bit) all\u0026rsquo;interno della cartella /usr/lib ed infine digitare il comando sudo ldconfig per aggiornare l\u0026rsquo;elenco delle librerie.\nA questo punto bisogna aprire Firefox ed andare su Modifica\u0026ndash;\u0026gt;Preferenze\u0026ndash;\u0026gt;Avanzate\u0026ndash;\u0026gt;Cifratura\u0026ndash;\u0026gt;Dispositivi di Sicurezza cliccare su Carica e specificare come descrizione \u0026ldquo;CSE\u0026rdquo; e come percorso quello dove avete copiato la libreria installata nel passo precedente (che ad esempio potr√† trovarsi in /usr/lib/libaseCnsP11.so ).\nPer verificare che tutto funzioni correttamente √® sufficiente fare click su Accedi e se ci verr√† chiesto di inserire la \u0026ldquo;password\u0026rdquo; (che nel nostro caso sar√† il PIN della smartcard) vorr√† dire che tutto sta funzionando nel modo corretto.\nPer avere maggiori informazioni sulla Carta Sanitaria Europea e per conoscere tutti i servizi disponibili, vi consiglio di visitare la seguente pagina presente sul sito della Regione Toscana: http://www.regione.toscana.it/cartasanitaria/cse/cose/index.html\n","date":"2010-11-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/utilizzare-la-carta-sanitaria-europea-su-ubuntu-linux/","title":"Utilizzare la Carta Sanitaria Europea su Ubuntu Linux"},{"content":"\nIntroduction It would be nice to organize a weekend like the Barcelona Long Weekend we (the Maemo Community) organized on October 2009. These two days should be completly organized by the community and for the community. No formal conferences or talks, but interactive activities and hacking sessions where you, the participant, are the main actor.\nWhat about the content of these two days? We could have (for example) programming tutorials, Qt tutorials, hacking sessions on a specific task, round tables where a developer explains his difficoulties implementing a feature and the others help him, ecc\u0026hellip;\nThe first thing to do is spreading this and asking people (users, developers ecc\u0026hellip;) what they would like to find during these two days. Once we\u0026rsquo;ve gathered some nice ideas we can organize them better.\nWhen and Where The basic idea is to organize these two days on November 13th, 14th. About the location that will host us we still have no idea. Probably it will be possible to use the same hotel used for the MeeGo Conference, but this must be confirmed yet.\nIdeas for the program structure Active participation in the event - less talk, more code. No powerpoints - just you, the editor and the compiler. Be productive!```\nA two-day Hackathon: Start putting your ideas into fresh code, or finish a project that has been on the back burner for some time```\nParticipants are encouraged to share their progress at the end of each day - what they accomplished, where they need further help, etc.```\nA short but intensive indroduction to Qt/C++ (something like 3-4 hours course, offered by some expert developer)```\nRound tables to discuss about UI improvements or features implementation: a developer could have found some difficoult implementing the UI for his application or to provide a particular feature. Other expert developers could try to help him with his problem.```\nA workshop for x86 developers on getting started with MeeGo development for ARM - end goal: By the end of the session, everyone has a sample application running in an emulator on their laptop```\nDeveloper tools training - a half day on using git, valgrind, oprofile\n1 2 3 4 5 6 7 8 9 10 ## Discussion resources The official place where I would like to take this discussion forward is the MeeGo Forum. The official thread is available here: \u0026lt;http://forum.meego.com/showthread.php?t=1342\u0026gt; We also have started a discussion on Maemo Forum and you can find it here: \u0026lt;http://talk.maemo.org/showthread.php?t=61708\u0026gt; The official page with all informations available is on MeeGo Wiki: \u0026lt;http://wiki.meego.com/MeeGo_Conference_2010/Early_Bird_Events\u0026gt; ","date":"2010-09-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/meego-conference-2010-early-bird-events/","title":"MeeGo Conference 2010 / Early Bird Events"},{"content":"I\u0026rsquo;ve decided to candidate myself again (yes, I wasn\u0026rsquo;t elected last time) for the Maemo Council elections. During these months I\u0026rsquo;ve tried to help more the Maemo Community and I\u0026rsquo;ve started working to two Qt/C++ projects. Here you can find something more about me.\nName: Andrea Grandi\nmaemo.org profile: Andy80 - http://maemo.org/profile/view/andy80/\nCorporate affiliation: none\nIntroduction My name is Andrea Grandi, I live in Italy and I\u0026rsquo;m a Computer Science student. I\u0026rsquo;ve worked for some years as a software developer, then I started university. I\u0026rsquo;m part of the Maemo Community since 2007. Since then I like to help new users, organizing events, developing applications for Maemo. During this year I\u0026rsquo;ve started developing applications using Qt/C++ for N900, to be ready when MeeGo for handled devices will be out. I really like to collaborate with other community members to build together the best product ever.\nMy life in the Community May 2008: PyMaemo: Python for Nokia Internet Tablet @ PyCon Italia 2 - http://www.pycon.it/conference/talks/pymaemo-python-i-nokia-internet-tablet\nSeptember 2008: ESBox and Pluthon Eclipse plugins: how to use Eclipse to develop Maemo applications @ Maemo Summit 2008 - http://wiki.maemo.org/Maemo_Summit_2008\nSummer 2009: I worked to python-mafw bindings, during a stage in Igalia.\nOctober 2009: python-mafw: MAFW framework for Python developers @ Maemo Summit 2009 - http://wiki.maemo.org/Maemo_Summit_2009\nMay 2010: PySide: Python Bindings for the Qt Framework @ PyCon Italia 4 - http://www.pycon.it/conference/talks/qt-mobile-pyside-bindings\nCurrent Activities I\u0026rsquo;m currently working to two Maemo/MeeGo projects. The first one is mSoma, a Soma.Fm client that I\u0026rsquo;m developing with Lorenzo Bettini. The other one is LastGo, a Last.fm client. Both applications are written in Qt/C++ and are using QtMobility as multimedia libraries.\nmSoma: http://gitorious.org/msoma - http://maemo.org/packages/view/msoma LastGo: http://gitorious.org/lastgo - http://maemo.org/packages/view/lastgo Motivations I really would like to be able to do more for the community and one of the best way could be to be part of the council, to help both users/developers to explain their requests to Nokia and Nokia to understand the requests from the community. There are a lot of fantastic ideas coming from the community that could improve what we are doing: the key is to organize them and giving them more attention. This is what I\u0026rsquo;ve always looked for: working together to build something great! This will be probably the last Maemo Council, since now we (Maemo) and them (Moblin) are all part of the same community: MeeGo, and I\u0026rsquo;d like to help Maemo people to feel the most comfortable possible in our new Community.\n","date":"2010-08-27T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/announcing-my-standing-for-the-maemo-council-q3-2010/","title":"Announcing my standing for the Maemo Council Q3-2010"},{"content":"What is Maemo Coding Competition? This competition has been organized by Maemo Community for the Maemo Community. Developer can work to an application and submit it for one of the six categories available: Desktop, System \u0026amp; Utilities, Games, Graphics \u0026amp; Multimedia, Location \u0026amp; Navigation, Other. Another category is available too, and it\u0026rsquo;s for beginner developers. The competition entry has now ended, but voting is open. You can find more information about the competition, in the official wiki page: http://wiki.maemo.org/Maemo_Coding_Competition_1\nHow can I vote?** Voting is available using a forum\u0026rsquo;s poll for each category. Every t.m.o. user can give one vote for each category. Here\u0026rsquo;s the complete list of polls:\nDesktop: http://talk.maemo.org/showthread.php?p=760304 System \u0026amp; Utilities: http://talk.maemo.org/showthread.php?p=764039 Games: http://talk.maemo.org/showthread.php?t=58990 Graphics \u0026amp; Multimedia: http://talk.maemo.org/showthread.php?p=763679 Location \u0026amp; Navigation: http://talk.maemo.org/showthread.php?t=58964 Other: http://talk.maemo.org/showthread.php?t=59038 Beginners: http://talk.maemo.org/showthread.php?t=59074 p.s: I partecipate in the Graphics \u0026amp; Multimedia category with two applications: LastGo and mSoma. Please at least test them and let me know what do you think about!\n","date":"2010-07-26T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/maemo-coding-competition-voting-open/","title":"Maemo Coding Competition: voting open!"},{"content":"While I\u0026rsquo;m still working to mSoma with Lorenzo Bettini, I decided to start writing another application. I needed to write something from scratch to learn better how to use C++ and Qt libraries, so I decided to write a client for Last.fm service. The application is still in full development, but you can already taste it if you have extras-devel repository enabled on your N900. At the moment it only supports basic radio features: tuning user\u0026rsquo;s radio, playing a song, skipping a song and displaying song informations.\nOther basic Last.fm features like scrobbling, marking a song as loved or banned ecc.. are not supported yet, but of course they\u0026rsquo;re planned for the stable release. Please not that the application is still a bit unstable even if it works for normal tasks.\nIf you are a Last.fm subscriber and you want to test it, please install it from extras-devel repository and send me your feedback.\nNote: since it\u0026rsquo;s not allowed to use Last.fm API from a mobile phone (due to API license restrictions) I cannot distribute a valid api key with the application. I\u0026rsquo;m writing this software mainly to learn C++ and Qt and for the future tablets and netbooks that will be based on MeeGo. If you feel to assume the responsability, you can download the api key file and import it using \u0026ldquo;Import Api Key\u0026rdquo; that you can find in the application menu.\n","date":"2010-07-16T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/announcing-lastgo-maemomeego-client-for-last-fm/","title":"Announcing LastGo: Maemo/MeeGo client for Last.fm"},{"content":"SomaFM is a streaming radio with near 16 different channels, available for free. Even if it\u0026rsquo;s possible to copy-paste their streaming URLs to N900 Media Player, we (me and Lorenzo Bettini) decided to create a custom application, to make channels switching easier for the end user and to be able to add more features. We decided to take advantage of the new Nokia SDK and write the application in Qt/C++. Source code is available on Gitorious and it\u0026rsquo;s always updated with latest version we\u0026rsquo;re working on. If someone want to test the application, it\u0026rsquo;s available in extras-devel repository¬†(\u0026ldquo;msoma\u0026rdquo; under Multimedia section) of N900.\nThe UI is still in development as you can see. The application is already usable, but of course we have to work hard on the user interface. Feel free to test/use it and send us any feedback. If you want to contribute to our project (coders are welcome) please send us a patch with your code or ask us to be added to mSoma development team in Gitorious.\n","date":"2010-07-03T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/announcing-msoma-maemomeego-client-for-somafm/","title":"Announcing mSoma: Maemo/MeeGo client for SomaFM"},{"content":"Introduction My name\u0026rsquo;s Andrea Grandi, I\u0026rsquo;m italian and I\u0026rsquo;m a Maemo user/lover/contributor since the Nokia 770. I love Python as development language and few months ago I also gave some contributions to the PyMaemo project.\nIn these days I had the idea to start writing a Twitter client for Maemo with a precise direction in my mind. I\u0026rsquo;ll try to explain all my reasons here. First of all I\u0026rsquo;ve to thank the author of Mauku client. I use it since its first version and I\u0026rsquo;m quite happy with it. Then, why do I want to write another one?\nMaemo (MeeGo) is moving to Qt and for this reason I\u0026rsquo;m going to use Qt, while Mauku uses Gtk.```\nI\u0026rsquo;m learning Qt and what is better than writing a complete (but not too complex) application to learn better?```\nMauku is not free as lot of people could think. Reading the source codeyou find this \u0026ldquo;You are NOT allowed to modify or redistribute the source code.\u0026rdquo;, while I want to write a client and release it under GPL2 or GPL3 license.```\nMauku is not updated since some months and we have no news about it.\nI love Python and I like to write free software in this language.\nI want to give to Maemo a stronger contribute.\nMy request for help Before lot of people start writing their own client resulting in 4-5 twitter clients for Maemo, why don\u0026rsquo;t we join our strength and work to a common project? I\u0026rsquo;m not a Python expert nor a Qt one, but I\u0026rsquo;ve some experience as project/team leader and since this is not a complex project, I would be glad to lead it. So, I\u0026rsquo;m looking for Python developers, Qt developers, UI designers and whoever want to contribute to this project. I still have to find a good name and logo for this application.\nWho want to help me?\n","date":"2010-02-22T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/twitter-client-for-maemo-in-qt-python-call-for-developers-and-ui-designers/","title":"Twitter client for Maemo in Qt + Python: call for developers and UI designers"},{"content":"Few days ago I published some notes about my personal experience with PR 1.1.1 firmware upgrade in Nokia N900. In particular my device got an infinite reboot loop after upgrading the firmware and I had to flash the firmware image from scratch to fix the problem. Today I was kindly contacted by Max Waterman (I suppose he works for Nokia) and he explained me what was the problem. It was caused by a little bug in Harmattan UI demo and they fixed it (the fix is already available in extras-devel).\nNo surprise for me: extras-devel contains unstable packages and if user enables it, he does at his own risk. The most important thing is the fact that the official firmware without any unstable application doesn\u0026rsquo;t suffer of this problem at all. The thing that really impressed me so much (in a positive sense) it\u0026rsquo;s that I was contacted privately by a Nokia developer apologizing for the bug (no problem man, it\u0026rsquo;s part of the game if someone want to test extras-devel software) and explaining that they already fixed it.\nThis is what I like of Maemo (or should I already call it MeeGo?), I really feel to be a part of it!\n","date":"2010-02-20T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/nokia-n900-reboot-loop-after-pr-1-1-1-upgrade-is-not-a-firmware-bug/","title":"Nokia N900: reboot loop after PR 1.1.1 upgrade is not a firmware bug"},{"content":"I don\u0026rsquo;t know if it\u0026rsquo;s just a case or if I\u0026rsquo;m the only one who had these problems, but I\u0026rsquo;ll report them anyway, maybe somebody had my same problem and we could try to prepare a proper bug report to make the Maemo team fix them.\nInfinite boot loop after upgrade First of all I have to say that before upgrading to PR 1.1.1 I checked if I had enough space on the rootfs. I only had 27 Mb and so I decided to remove some unused applications, deleted some *.deb in /var/cache/apt/archives and disabled extras repositories. Of course I also did a backup of all my configuration. After the cleaning operation I had near 60 Mb free on rootfs, enough to install the upgrade.\nI closed all running applications, started the application manager and began the upgrade. After the upgrade was completed, the device did a reboot\u0026hellip; then another one, then again, again\u0026hellip;. until I had to remove the battery to stop it.\nConclusion: I had to re-flash the device with the latest image to make it work again.\nmafw-dbus-wrapper taking all the CPU I was watching a video (using subtitles) and after some minutes the whole UI became unresponsive. Strange because I already did this before without having any problem. I tried to check the problem using \u0026ldquo;top\u0026rdquo; utility from terminal and I saw that there was a mafw process (mafw-dbus-wrapper) that was taking 80-90% of CPU. My fault is that normally there are at least 3-4 , mafw-dbus-wrapper processes and I didn\u0026rsquo;t check which one was causing the problem. Anyway I made a screenshot, just in case it can help.\nI hope this short report can be useful to help Maemo team to fix or at least investigate what happened. Just leave a comment or contact me if you need more informations.\n","date":"2010-02-17T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/nokia-n900-some-problems-with-latest-pr-1-1-1-firmware/","title":"Nokia N900: some problems with latest PR 1.1.1 firmware"},{"content":"Nokia has published a demo application for N900, available in extras-devel repository, that shows a preview of Maemo 6 (Harmattan) user interface. Here there are some screenshots of the demo:\nDemo application main window\nQuestion dialog\nText entry dialog\nProgress indicator\nInformation banner\nEvent banner\nPlease note that installing this demo will also install Qt 4.6.2 on the N900 and about 52 Mb are required.\n","date":"2010-02-16T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/maemo-6-harmattan-ui-screenshots/","title":"Maemo 6 (Harmattan) UI Screenshots"},{"content":"Introduction As many of you already know, Fon is a spanish company that some years ago had the interesting idea of creating a wifi community to share the Internet connection. The idea is quite simple: each \u0026ldquo;fonero\u0026rdquo; buy a Fonera (the router sold by Fon), register it on the Fon system and get a username/password. If the fonero travels around the world he\u0026rsquo;s able to connect to wifi signal of other foneras and browse the web for free.\nWhen I bought my first fonera few years ago, I was one of the first people in my city. I bought it because I was really beliving in this project. During these years Fon produced new models of fonera and I bought each of them (the WRT54 router, Fonera, Fonera+, Fonera 2.0g, Fonera 2.0n ecc\u0026hellip;.). Since first year, the Fon community has grown a lot and now there are a lot of foneros around the world.\n##¬†Actual situation\nFew months ago Fon launched a very interesting product: Fonera 2.0g. Thats\u0026rsquo;s not only a router. Fonera 2 is capable of managing torrents, rapidshare downloads, uploading photo on Facebook and Flickr, and much more. Whats\u0026rsquo;s wrong with this product? It\u0026rsquo;s very unstable! There are a lot of users that bought this router when it was anounced and they\u0026rsquo;re still waiting for a lot of bugs to be fixed by Fon developers team (composed by only ONE person!). Why users had to wait so long?\nSimple! They were working to Fonera 2.0n! Wow! Faster router, more RAM, 4 ethernet port, wonderful! But\u0026hellip; another very unstable router! And with unstable I mean: it disconnects/reboots often, connection is unstable, applications don\u0026rsquo;t work ecc\u0026hellip;. I\u0026rsquo;m talking about a 79‚Ç¨ router, not about something that users had as preview product. Me and other users were still waiting for an uograde when\u0026hellip; Fon announced a new product! Yes, another one!\nFon priority is not to fix a product that thousand of users have already bought. Fon priority is to produce and sell a new product!\nConclusion It could be only my opinion, but I don\u0026rsquo;t trust you anymore Fon! I\u0026rsquo;m really disappointed about your behaviour you had with your customers. I\u0026rsquo;ve already spent (wasted) a lot of money with your not-working products and I\u0026rsquo;m not going to buy your products anymore! I\u0026rsquo;m tired of being illuded by your promises: how long are you going to play tricks on users?\n","date":"2010-02-13T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/fon-how-long-are-you-going-to-play-tricks-on-users/","title":"Fon: how long are you going to play tricks on users?"},{"content":"Being one of the developers who received the discount to buy a N900, during these days I contacted the DDP customer care to have more informations and details. I\u0026rsquo;ll publish here both my original question and the official reply.\n1) The price of N900 is 250‚Ç¨ and I\u0026rsquo;ve read of people who paid it this price. Anyway here you say that the VAT is not included:\nhttps://pro.forum.nokia.com/site/global/tech_resources/discounted_devices/l_ddp.jsp\nso it should costs 300‚Ç¨ not 250‚Ç¨, right?\nThe VAT applies only for Finnish developers, for the others the price is the price they see in the eStore, no VAT is added to that.\nSo, all non-finnish european people, will pay 250‚Ç¨ for the N900.\n2) How much time can I wait before ordering it? In this moment I\u0026rsquo;m in Valencia (Spain) and I won\u0026rsquo;t come back to Italy before Christmas. I\u0026rsquo;d like the order to be shipped to my home in Italy (I registered as italian user and I want italian keyboard layout), but I\u0026rsquo;d like to wait to order it, because since there\u0026rsquo;s no warranty and I need to tell you about any problem within a week, if I order it now I will be able to check it only at the end of december when I\u0026rsquo;ll come back to Italy.\nI guess this should not be a problem.\nThis part is not confirmed yet, since Quim told us to hurry up to buy it.\n3) How many devices can I buy at that price? Here you say I can buy two: https://pro.forum.nokia.com/site/global/tech_resources/discounted_devices/l_ddp.jsp\nbut here you say I can buy one: https://pro.forum.nokia.com/showProduct.do?product_id=5096\nI don\u0026rsquo;t want two devices, but another friend of mine, who help me in a project for the Maemo Community, would like to be able to buy one for the same price (he wasn\u0026rsquo;t able to get the discount because his karma is still low).\nAs far as I know, you can only purchase 1x device per person, regarding MAEMO N900.\n4) Where can we find the new firmware? In the FAQ you say: DDP does not flash devices. It\u0026rsquo;s ok, I can do it, but there\u0026rsquo;s no public firmware for N900 at the moment.\nTo update N900, can possibly be using NSU. Nokia software updater.\n5) Is it possible to have a device with localized keyboard (for example italian one) ?\nAll N900 will have EURO variant, Italian language is one option.\nNote: even these replies come from the official customer care, I don\u0026rsquo;t assume any responsability if they shouldn\u0026rsquo;t be all exact. If you have any doubt, please contact them directly at DDP.program@nokia.com\n","date":"2009-11-12T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/questionsanswers-about-nokia-n900-and-discounted-device-program/","title":"Questions/Answers about Nokia N900 and Discounted Device Program"},{"content":"Quim Gil just confirmed the UX hackfest in Barcelona for 4, 5, 6 december: http://talk.maemo.org/showthread.php?t=33719\nWhat is UX hackfest? It\u0026rsquo;s a three days meeting for Maemo developers, UX experts and people who want to learn about designing good user interfaces.\nWhen?** On 4, 5, 6 december 2009\nWhere? Barcelona, Spain. The exact location has still to be confirmed, but it should be http://citilab.eu\n##¬†How many people invited?**\nAbout 50 people invited (Maemo developers, UX experts, ecc\u0026hellip;.)\nIf you are a Maemo developer and you have good user interface designer skills, this is the place for you.\nIf you are a Maemo developer and you are not a UX expert, this IS anyway the place for you: you\u0026rsquo;ll have the possibility to talk with experts and improve your knowledge about UI design.\nAnyone interested, please join the discussion here: http://talk.maemo.org/showthread.php?t=33719\nUpdate 3/11/2009 - 16:00: a wiki page with all information has been created here: http://wiki.maemo.org/Maemo-Barcelona_Long_Weekend\nplease add your name/data to the page if you requested to join the UX hackfest.\n","date":"2009-11-03T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ux-meets-code-hackfest-in-december-barcelona-confirmed/","title":"UX meets Code hackfest in December @ Barcelona: confirmed!"},{"content":"{ width=20% }\nDuring next Maemo Summit we will have at least 2 hours (one on saturday and another one on sunday) of lightning talks, about 20 talks where people will try to explain or present something in just 5 minutes.\nLast year, during Maemo Summit 2008, I did a lightning talk too and I must admit: even if I knew a lot about the subject of my talk and even if I had already done many other talks, I think it wasn\u0026rsquo;t so good as I expected.\nThis year I\u0026rsquo;ve been selected again (more details will follow) to give a 5 minutes talk and with this great news the kind Dave Neary also suggested me a link with an article about some best practices when giving lightning talks. I\u0026rsquo;ll try to resume the most important points, hoping this will be useful for people who is going to give a short presentation at Summit.\nGo straight to the point Five minutes finish sooner than you can expect. You have to talk about the main topic of your talk within the two first minutes, else you risk to talk too much about the rest and you couldn\u0026rsquo;t have the time for the most important thing.\nLeave details away People will never remember too many details explained in so little time. It\u0026rsquo;s better to leave them away and put them in a more detailed blog post that you can link within your slides.\nSlides For a five minute talk you can avoid preparing slides, but if this can help you to concentrate on points you have to talk about, please prepare them. Two or three slides can be useful to introduce yourself, to write any reference of what you\u0026rsquo;re talking about many other things. Another important thing, make sure your slides are ready before starting your presentation: people don\u0026rsquo;t want to wait 20-30 seconds it takes to start Open Office or any other similar application.\nConsider any eventuality The presentation file could be damaged (be sure to have a copy of it, better in PDF format), your laptop could have no more battery (make sure you\u0026rsquo;ve a copy of your slides in a USB key), aliens could take you away, ecc\u0026hellip; (ok, this last eventuality is remote).\nConcluding your talk Don\u0026rsquo;t worry if you finish one or two minutes before, people won\u0026rsquo;t bother about it. It\u0026rsquo;s better to finish one minute before than 30 seconds later. If you want to leave an URL where people can find more details, how to contact you, put it in every slide so people will be able to take note of it from the first minute.\nI hope to have resumed the most important points of the original article. If you think there are any other important things to say, please leave me a comment and I\u0026rsquo;ll add them. I really hope you will enjoy Maemo Summit and its lightning talks!\n","date":"2009-09-03T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/giving-lightning-talks/","title":"Giving Lightning Talks"},{"content":"In the last post of this series, we saw how to write a simple binding and we finished to build and install it manually. This is of course not a good way to manage the building/installation procedure.\nIn Python we can use a library called distutils that let us to automatize the building and installing process. I\u0026rsquo;ll use the foo source code to create the package, so it will be easier to understand.\nUsing distutils All we have to do is to write a setup.py file similar to this one:\n1 2 3 4 5 6 7 8 9 10 from distutils.core import setup, Extension foomodule = Extension(\u0026#39;foo\u0026#39;, sources = [\u0026#39;foo.c\u0026#39;]) setup ( name = \u0026#39;Foo\u0026#39;, version = \u0026#39;1.0\u0026#39;, description = \u0026#39;This is a package for Foo\u0026#39;, ext_modules = [foomodule] ) As you can see, we have to first import needed modules with: from distutils.core import setup, Extension\nthen we create an entry for each module we have (in this case just one, \u0026ldquo;foomodule\u0026rdquo;). We then call the setup() method passing it all the parameters and our setup.py is complete.\nBuilding and installing To test it we can try to build the package in this way:\n1 python2.5 setup.py build if we want to install the module in our system:\n1 python2.5 setup.py install References Official Python documentation: http://docs.python.org/extending/building.html ","date":"2009-08-13T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/writing-python-bindings-of-existing-c-libraries-building-and-installing-with-distutils/","title":"Writing Python bindings of existing C libraries ‚Äì (3) ‚Äì Building and Installing with distutils"},{"content":"The PyMaemo team is pleased to announce the second beta release of PyMaemo for Fremantle!\nThis new release is available through the extras-devel repository, see installation instructions in\nhttp://pymaemo.garage.maemo.org/sdk_installation.html#fremantle\nWhat is it? Python for Maemo (PyMaemo for short) main objective is to make possible to use Python programming language as the scripting and development language for Maemo Platform, providing a better alternative for fast prototyping and programming in Maemo environment besides the C programming language.\nPython is for serious programming and to have fun. Python has a nice syntax, it is easy to learn and powerful enough for a vast range of applications, this is why we choose Python for Maemo.\nWhat has changed? New packages:\npython-mafw (0.1-1maemo1)\nPython bindings for the Media Application Framework [1]\nSupported API is very basic at the moment, and there are some bugs. Feedback is welcome!```\npython-hildondesktop (0.0.3-1maemo1)\nPython bindings for the home/status widgets API```\npython-notify (0.1.1-2maemo1)\nPython bindings for libnotify```\npyclutter (0.8.0-1maemo2)\nPython bindings for the Clutter API [2]\nExperimental package, waiting for developer feedback\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 **Updated packages:** - **gnome-python** (2.26.1-1maemo1) - major upgrade, matching current Debian testing release; - feedback on this is welcome, as it replaces a fairly old version (2.18).``` - **pygtk** (2.12.1-6maemo7) - Enable glade support.``` - **python2.5** (2.5.4-1maemo1) - Updated to latest upstream 2.5.x release. - add support to --install-layout=deb flag.``` - **python-central** (0.6.11.1maemo1) - dependency needed by the new python-setuptools version.``` - **python-defaults** (2.5.2-3maemo3) - Change PREVVER in debian/rules, avoiding old python2.5-minimal versions that had \u0026#34;/usr/bin/python\u0026#34; and thus conflicts with python-minimal.``` - **python-hildo**n (0.9.0-1maemo10) - lots of bug fixes``` - **python-setuptools** (0.6c9-1maemo1) - add support to --install-layout=deb flag. Bugs fixed: MB#4530 [3], MB#4450 [4], MB#4629 [5], MB#4628 [6],\nMB#4647 [7], MB#4632 [8], MB#4646 [9], MB#4750 [10],¬†MB#4749 [11],\nMB#4791 [12]\n##¬†Known issues\nMB#4782 [13]: osso.Context causes segmentation fault\nMB#4821 [14]: Cannot create HildonTouchSelector with single text column\nMB#4824 [15]: python-mafw: source_browsing.py example does not work\nMB#4839 [16]: python-mafw: mafw.Registry lacks list_plugins() method\nMB#4849 [17]: python-mafw: MafwPluginDescriptorPublic structure is missing\nWe will not migrate to python2.6 in fremantle due to a (unresolved) bug (MB#4734 [18]), where a core SDK package explicitly conflicts with python \u0026gt;= 2.6, preventing any further upgrades from the 2.5.x series.\nThis release is supposed to be compatible with previous releases. If you have any issues regarding building your Python application on Fremantle, feel free to report it on the pymaemo-developers mailing list [19].\nAcknowledgments Thanks to everybody who helped making this release possible.\nBug reports, as always, should go to our Bugzilla [20]. Use the pymaemo-developers mailing list for help, feedback or suggestions.\n##¬†References\n[1] https://garage.maemo.org/projects/mafw/\n[2] http://www.clutter-project.org/\n[3] https://bugs.maemo.org/show_bug.cgi?id=4530\n[4] https://bugs.maemo.org/show_bug.cgi?id=4450\n[5] https://bugs.maemo.org/show_bug.cgi?id=4629\n[6] https://bugs.maemo.org/show_bug.cgi?id=4628\n[7] https://bugs.maemo.org/show_bug.cgi?id=4647\n[8] https://bugs.maemo.org/show_bug.cgi?id=4632\n[9] https://bugs.maemo.org/show_bug.cgi?id=4646\n[10] https://bugs.maemo.org/show_bug.cgi?id=4750\n[11] https://bugs.maemo.org/show_bug.cgi?id=4749\n[12] https://bugs.maemo.org/show_bug.cgi?id=4791\n[13] https://bugs.maemo.org/show_bug.cgi?id=4782\n[14] https://bugs.maemo.org/show_bug.cgi?id=4821\n[15] https://bugs.maemo.org/show_bug.cgi?id=4824\n[16] https://bugs.maemo.org/show_bug.cgi?id=4839\n[17] https://bugs.maemo.org/show_bug.cgi?id=4849\n[18] https://bugs.maemo.org/show_bug.cgi?id=4734\n[19] https://garage.maemo.org/mailman/listinfo/pymaemo-developers\n[20] https://bugs.maemo.org/enter_bug.cgi?product=PyMaemo\nCredits This post was possible thanks to Anderson Lizardo, from PyMaemo team, who posted these informations on pymaemo-developers mailing list.\n","date":"2009-08-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/pymaemo-python-for-maemo-second-beta-release-for-fremantle/","title":"PyMaemo (Python for Maemo) second beta release for Fremantle"},{"content":"I must admit, I wasn\u0026rsquo;t using Maemo email client, because I did find it was simply unusable, at least with my GMail account.\nI tried both POP3 and IMAP, but having about 25.000+ messages in my account, downloading just the headers was a job that the client simply couldn\u0026rsquo;t manage.\nYesterday I knew about \u0026ldquo;recent mode\u0026rdquo; support in POP3, a functionality that GMail supports too. This mode allow you to download only last 30 days messages (in my case, no more than 1000)¬†so the client can manage them without any problem.\nAll you have to do to enable this mode is put the \u0026ldquo;recent:\u0026rdquo; string before the username. For example: if your username is \u0026ldquo;username@gmail.com\u0026rdquo; you have to write \u0026ldquo;recent:username@gmail.com\u0026rdquo;. Important: this mode only works with POP3, not with IMAP.\nTo conclude, let me say thank you to the kind guy who let me discover this mode. Thank you Sergio! Now there is another thing I can do with my tablet!\n","date":"2009-08-08T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/making-maemo-email-client-usable-with-gmail/","title":"Making Maemo email client usable with GMail"},{"content":"Introduction As I promised in the preceding post, I\u0026rsquo;ll provide a very easy example of a python binding. Let\u0026rsquo;s suppose we don\u0026rsquo;t want to use the methods included in Python to sum two integer values and we want to do it in C and then call the add method from a python script. I\u0026rsquo;ll write the complete source code first and then I\u0026rsquo;ll explain all the parts of it.\nSource Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026lt;Python.h\u0026gt; static PyObject *foo_add(PyObject *self, PyObject *args) { int a; int b; if (!PyArg_ParseTuple(args, \u0026#34;ii\u0026#34;, \u0026amp;a, \u0026amp;b)) { return NULL; } return Py_BuildValue(\u0026#34;i\u0026#34;, a + b); } static PyMethodDef foo_methods[] = { { \u0026#34;add\u0026#34;, (PyCFunction)foo_add, METH_VARARGS, NULL }, { NULL, NULL, 0, NULL } }; PyMODINIT_FUNC initfoo() { Py_InitModule3(\u0026#34;foo\u0026#34;, foo_methods, \u0026#34;My first extension module.\u0026#34;); } How it works First of all we have to include Python.h in our C file. This allows us to write an extension for Python language. To be able to include this header, we must have the python development packages installed in our system. For example in Debian based distributions we can install them with this command:\n1 sudo apt-get install python2.5-dev Every module has at least three parts. In the first part we write methods we want to call from the final python module: in this case we have a method called foo_add where \u0026ldquo;foo\u0026rdquo; is the name of the module and \u0026ldquo;add\u0026rdquo; the name of the method. Every method is declared as static PyObject. The method does anything particular except calling PyArg_ParseTuple to validate the input (we\u0026rsquo;ll discuss this later), adding the two passed numbers and returning the result.\nIn the second part we have something like a dictionary, defined as static PyMethodDef and called foo_methods (where \u0026ldquo;foo\u0026rdquo; again is the name of the module). For each method we want to expose in our python module, we have to add something like this:\n1 {\u0026#34;add\u0026#34;, (PyCFunction)foo_add, METH_VARARGS, NULL} where \u0026ldquo;add\u0026rdquo; is the name of the method we want to be visible in our module, (PyCFunction)foo_add is a pointer to our foo_add method, implemented in the C module, METH_VARARGS means that we want to pass some parameters to the function and the last one would be the description of the method (we can leave it NULL if we want).\nThird part allows us to register the defined method/s and the module:\n1 Py_InitModule3(\u0026#34;foo\u0026#34;, foo_methods, \u0026#34;My first extension module.\u0026#34;); Parsing Parameters The PyArg_ParseTuple function extracts arguments from the PyObject passed as parameter to the current method and follows almost the sscanf syntax to parse parameters (in this case we had \u0026ldquo;ii\u0026rdquo; for two integers). You can fin the complete reference here: http://docs.python.org/c-api/arg.html\n##¬†Building and installing\nTo build the module, we have to be in the source directory and execute this command:\n1 gcc -shared -I/usr/include/python2.5 foo.c -o foo.so then we\u0026rsquo;ve to copy the generated module to the python\u0026rsquo;s modules directory:\n1 cp foo.so /usr/lib/python2.5/site-packages/ ##¬†Testing our module\nTesting the module is really easy. We\u0026rsquo;ve to start a python shell or create a python script with the following source code:\n1 2 import foo print foo.add(2, 3) if all is working fine, the printed result should be 5\nReferences http://docs.python.org/extending/extending.html http://www.wrox.com/WileyCDA/WroxTitle/productCd-0764596543.html ","date":"2009-08-06T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/writing-python-bindings-of-existing-c-libraries-a-simple-example-of-binding/","title":"Writing Python bindings of existing C libraries ‚Äì (2) ‚Äì A simple example of binding"},{"content":"MAFW is a new multimedia framework that will be used in Fremantle.\nThe PyMaemo team is currently working on writing bindings for Python\nlanguage for this library and at the moment we\u0026rsquo;ve released a 0.1\nversion of python-mafw that you can install directly from Scratchbox\nrepository.\nNot all the methods are implemented (you can manage the Registry and\nthe Playlist, but nothing more), because even if we\u0026rsquo;re using codegen\nto generate bindings (and it\u0026rsquo;s helping us a lot), we\u0026rsquo;ve seen that at\nleast 30-40 methods have to be overridden by hand so it\u0026rsquo;s taking us\nmore time than we expected and we\u0026rsquo;re trying to organize how to\ncontinue this work.\nWe would like to get feedback from python application developers and\nalso from C application developers that are currently using MAFW so we\ncan work on a \u0026ldquo;roadmap\u0026rdquo; that reflects what developers want:\nWhat are the functionalities you\u0026rsquo;re using in your application that you think they cannot miss in the Python binding?```\nHave you already started using MAFW or even better python-mafw to develop something?```\nWhat is the currently missing method/methods you would like to be implemented first?\n1 2 Come on developers! We\u0026#39;re waiting for your feedback :) ","date":"2009-08-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/mafw-and-python-asking-for-developers-feedback/","title":"MAFW and Python: asking for developers feedback"},{"content":"This summer I\u0026rsquo;m having the pleasure of working in Igalia (a spanish free software company) for a couple of months and they assigned me to an interesting project: developing Python bindings for MAFW library (a Maemo multimedia library that will be used in Fremantle release).\nHaving the opportunity to work both with C (yes, Python bindings are almost C code) and Python (it\u0026rsquo;s a good practice to write unittest of all implemented methods) it\u0026rsquo;s a good way to improve my knowledges in both languages and since I wasn\u0026rsquo;t able to find much documentation about these kind of things, I\u0026rsquo;m going to share my own experiences.\nWhat is a Binding? A binding is a Python module, written in C language, that allows Python developers to call functions from existing C libraries from their python applications. It\u0026rsquo;s just like a \u0026ldquo;bridge\u0026rdquo; from C world to Python one.\nWhy writing bindings? There are a couple of reasons to write python bindings instead of writing a library in python language from scratch.\nFirst of all I don\u0026rsquo;t think is good duplicating code, so if a library already exists and it\u0026rsquo;s written in C, why writing it again in another language? There\u0026rsquo;s no reason. A lot of code already exist in C world and all we have to do is to create a bridge with python world.\nAnother good reason, in particular when a C library doesn\u0026rsquo;t exist yet, is the fact that python code is slower than C code for some tasks (for example multimedia codecs). In these cases is good to implement the core library in C language and then create a python binding for it.\nComing next As the title of this post says, this is only an introduction to the subjects I\u0026rsquo;m going to write about. If you have any particular request about any argument you would like to read, please feel free to leave me a comment. Next posts will talk about these things:\nA simple example of binding: I\u0026rsquo;ll write a simple library in C language and I\u0026rsquo;ll show how to create the relative python binding, providing complete source code and an example for python developers.```\nBuilding and installing python bindings with distutils: I\u0026rsquo;ll explain how to use distutils to build and install the binding (using the well know method \u0026ldquo;python setup.py install\u0026rdquo;).```\nDefining new types: this post will be about how to write new types in C language and being able to use them from python code.```\nUsing codegen to write bindings: I\u0026rsquo;ll explain how to use codegen utils to automate lot of tasks, to generate the most part of binding code and how to customize the generated code using overrides.\n","date":"2009-08-03T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/writing-python-bindings-of-existing-c-libraries-1-introduction/","title":"Writing Python bindings of existing C libraries - (1) - Introduction"},{"content":"This summer I\u0026rsquo;m working for 2 months at Igalia, a spanish free software company, and they assigned me the project of writing a Python binding for MAFW (a new multimedia library that will be included in Freemantle).\nAfter few days I discovered that PyMaemo team was already working to it, so I asked to join them and they accepted me!\nI really love Python language and since I think other developers love it too, I think we should provide good bindings for every library available in Maemo, so lot of developers can start writing their applications in this language.\nI\u0026rsquo;ll work to this project full time until the first week of september, so I hope to be able to learn a lot and to contribute as much as I can to this project.\nIf anyone else want to join PyMaemo team and help us to develop Python bindings, I think he will be welcome!\n","date":"2009-07-25T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/i-officially-joined-the-pymaemo-team/","title":"I officially joined the PyMaemo team"},{"content":"\nRegistration for the Maemo Summit 2009 has been opened.\nThe summit will have free entrance, but registration is required to grant you food, drinks, a maemo.org shirt and a seat. Please register as soon as possible, so we can get a clear picture of how many people are expected.\nThe registration form also has an option for sponsorship requests. Details about sponsorship will be published later and requests will be evaluated after this. You can always change your registration entry at a later point in time if needed.\nThe event location details and a list of participants can be found here.\nSee you all in Amsterdam at Maemo Summit 2009!\n","date":"2009-07-22T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/registration-to-maemo-summit-2009-open/","title":"Registration to Maemo Summit 2009 open!"},{"content":"Spesso capita di dover compiere azioni noiose e ripetitive su delle immagini, come ad esempio ridimensionarle o salvarle in formati diversi da quello originale. Queste operazioni possono richiedere moltissimo tempo, soprattutto se abbiamo a che fare con una grande quantit√† di immagini.\nPer chi usa Linux √® disponibile per√≤ l\u0026rsquo;utility ImageMagick, che unita ad un pizzico di script in bash ci permette di risolvere agevolmente il problema.\nPer prima cosa √® necessario installare il tool sulla propria distribuzione. Su Ubuntu (o in qualsiasi altra distribuzione basata su Debian) procedere nella seguente maniera:\n1 sudo apt-get install imagemagick A questo punto basta posizionarsi nella cartella dove si trovano le immagini (vi consiglio di crearvi una copia a parte delle immagini da modificare, visto che lo script andra\u0026rsquo; a lavorare direttamente su quelle originali) ed eseguire un comando come questo:\n1 find ./ -iname \u0026#39;*.JPG\u0026#39; -exec convert \u0026#39;{}\u0026#39; -resize \u0026#39;1024\u0026#39; \u0026#39;{}\u0026#39; \\; Questo comando convertir√† tutte le immagini .JPG che trova in un formato di 1024 pixel di larghezza, mantenendo ovviamente le proporzioni dell\u0026rsquo;immagine originale.\n","date":"2009-07-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ridimensionare-immagini-automaticamente-con-un-batch-e-imagemagick/","title":"Ridimensionare immagini automaticamente con un batch e ImageMagick"},{"content":"\nSe si prova a far girare la versione di Songbird scaricabile dal sito ufficiale su Ubuntu (ma il problema sembra riguardare anche altre distribuzioni visto che si tratta di un bug del driver Nvidia) si otterr√† quasi sicuramente un crash dell\u0026rsquo;applicazione stessa.\nPer risolvere il problema √® sufficiente disinstallare un plugin (libvisual-0.4-plugins) utilizzando il seguente comando: sudo apt-get remove libvisual-0.4-plugins\nUna nota negativa: questo bug √® presente fin dalla versione 8.10 di Ubuntu\u0026hellip; che aspettano a correggerlo invece di far ricorrere gli utenti a questi trucchetti?\n","date":"2009-06-24T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/risolvere-il-crash-allavvio-di-songbird-su-ubuntu/","title":"Risolvere il crash all'avvio di Songbird su Ubuntu"},{"content":"\nNon c\u0026rsquo;√® alcun errore nel titolo di questo post. Sebbene lo slogan originale di Last.fm fosse \u0026ldquo;The Social Music Revolution\u0026rdquo;, ho voluto modificarlo in questo modo, per sottolineare il recente cambiamento di rotta di un servizio che fino a pochi giorni fa ritenevo uno dei migliori, se non il migliore, del suo genere.\nFacciamo un passo indietro per spiegare cos\u0026rsquo;√® Last.fm. Si tratta di un servizio che permette, una volta registrati, di condividere le canzoni che ascoltiamo (titolo e autore, non il file audio) in modo che si possa essere messi in contatto con altre persone che ascoltano i nostri gruppi preferiti oppure di ricevere suggerimenti su gruppi simili a quelli che ascoltiamo. Grazie a questa funzione ho avuto la possibilit√† di conoscere ed apprezzare gruppi musicali di cui prima ignoravo l\u0026rsquo;esistenza.\nOltre a permettere lo scrobbling (invio del titolo della canzone) e la creazione automatica di classifiche, il sito mette a disposizione moltissimi strumenti che hanno permesso la creazione di una vasta community musicale. La community, grazie a questi strumenti, ha arricchito il sito web di moltissimi dati importanti: un wiki con i dati dei gruppi musicali, i tag su ogni canzone, gruppi di discussione e la creazione di eventi e ritrovi. Last.fm √® anche una \u0026ldquo;radio\u0026rdquo;, ma in un modo un po\u0026rsquo; diverso rispetto a quello a cui siamo abituati.\nNon esistono playlist valide per tutti gli utenti, ogni utente ha la propria playlist, in base ai brani ascoltati, ai gruppi simili ed ai suggerimenti degli amici. Oltre alle proprie playlista √® inoltre possibile ascoltare quelle dei \u0026ldquo;vicini\u0026rdquo;, degli amici e dei gruppi ai quali siamo iscritti. Se oggi Last.Fm √® diventata quello che tutti vediamo, √® in gran parte grazie al lavoro svolto dalla community musicale.\nChe cosa √® successo per portarmi alla decisione di eliminare il mio account, vecchio di 3 anni, con piu\u0026rsquo; di 30.000 brani ascoltati?\nCirca un mese fa i vertici di Last.fm hanno deciso che entro poco tempo il servizio di radio in streaming sarebbee diventato a pagamento, a causa dell\u0026rsquo;aumento dei costi di licenza imposti dalle major. Per continuare ad ascoltare la radio si dovranno pagare 3‚Ç¨ al mese. Quello che ha scatenato l\u0026rsquo;ira di moltissimi utenti e che mi ha fatto prendere la decisione di disiscrivermi, √® il fatto che USA, Inghilterra e Germania potranno continuare ad usufruire gratuitamente del servizio. Questa divisione in paesi di serie A e paesi di serie B non √® piaciuta proprio a nessuno, basta guardare le centinaia di commenti che sono arrivati sul blog ufficiale di Last.fm.\nIo mi associo al pensiero comune: se anche USA, Inghilterra e Germania pagassero, il costo potrebbe scendere a 1 o 2 euro al mese ed inoltre non ci sarebbero divisioni e/o discriminazioni a seconda del paese di provenienza. Avrei pagato volentier anche 3‚Ç¨/mese se non ci fossero state queste differenze. Perch√® gli altri paesi devono pagare pochi privilegiati?\nA mio parere Last.fm ha commesso un gravissimo errore facendo questa mossa e sono convinto che entro breve perder√† moltissimi utenti smettendo inoltre di essere una community ricca di contenuti creati dagli utenti stessi. Staremo a vedere se ci saranno inversioni di rotta o se continueranno a seguire questa strada.\n","date":"2009-05-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/lastfm-the-money-music-revolution/","title":"Last.fm: the money music revolution!"},{"content":"Fino ad ora, i possessori di Fonera 2.0 che volevano passare alla modalit√† \u0026ldquo;developer\u0026rdquo; (e quindi avere anche l\u0026rsquo;accesso via SSH) dovevano flashare la fonera con un\u0026rsquo;apposita immagine, facendo uso del cavo seriale oppure della procedura con il cavo di rete che utilizza Redboot.\nDa oggi √® disponibile un nuovo plugin che permette di passare automaticamente alla modalit√† developer, basta andare (ad esempio) su questa pagina del router: http://192.168.0.105/luci/fon_devices/fon_plugins\nLa Fonera passer√† a questo punto in modalit√† developer e dovremo effettuare due reboot affinch√® SSH sia attivato. Non dimenticatevi ovviamente di aprire l\u0026rsquo;accesso SSH nella configurazione del firewall della Fonera. Accedendo via SSH, vi troverete davanti questi messaggi:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 ssh root@192.168.0.105 The authenticity of host \u0026#39;192.168.0.105 (192.168.0.105)\u0026#39; can\u0026#39;t be established. RSA key fingerprint is e5:6e:fc:70:73:44:f6:cd:30:bd:ac:2d:53:d2:ab:a9. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;192.168.0.105\u0026#39; (RSA) to the list of known hosts. root@192.168.0.105\u0026#39;s password: BusyBox v1.11.1 (2009-04-17 12:45:57 CEST) built-in shell (ash) Enter \u0026#39;help\u0026#39; for a list of built-in commands. __ _.-~ ) _..--~~~~,\u0026#39; ,-/ _ .-\u0026#39;. . . .\u0026#39; ,-\u0026#39;,\u0026#39; ,\u0026#39; ) ,\u0026#39;. . . _ ,--~,-\u0026#39;__..-\u0026#39; ,\u0026#39; ,\u0026#39;. . . (@)\u0026#39; ---~~~~ ,\u0026#39; /. . . . \u0026#39;~~ ,-\u0026#39; /. . . . . ,-\u0026#39; ; . . . . - . ,\u0026#39; : . . . . _ / . . . . . `-.: . . . ./ - . ) . . . | _____..---.._/ ____ Seal _ ~---~~~~----~~~~ ~~ Flipper -------- Fonera 2.0 Firmware (v2.2.5.0) ----------- * Based on OpenWrt - http://openwrt.org * Powered by FON - http://www.fon.com ---------------------------------------------------- root@Fonera:~# uname -a Linux Fonera 2.6.26.2 #9 Tue Apr 21 11:32:31 CEST 2009 mips unknown root@Fonera:~# Cercher√≤ prossimamente, nel caso ci sia interesse, di scrivere qualche post piu\u0026rsquo; approfondito su questa nuova Fonera, in modo da mostrare le caratteristiche di questo dispositivo.\n","date":"2009-05-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/come-passare-dalla-modalita-enduser-alla-modalita-developer-su-fonera-2/","title":"Come passare dalla modalit√† enduser alla modalit√† developer su Fonera 2"},{"content":"\nCon l\u0026rsquo;uscita della versione 9.04 di Ubuntu Linux, questa distribuzione ha veramente fatto passi da gigante per quanto riguarda il supporto ai netbook. Oltre a rilasciare una versione specificatamente pensata per i piccoli device (che integra di default l\u0026rsquo;interfaccia Notebook Remix), sono stati inclusi nel kernel tutti i moduli necessari a far funzionare le periferiche di questi device.\nPer installare Ubuntu sull\u0026rsquo;EeePC dobbiamo per prima cosa procurarci la ISO dell\u0026rsquo;ultima versione e poi utilizzare una delle seguenti utility per preparare una chiavetta USB (da almeno 1 Gb) che ci permetter√† di effettuare l\u0026rsquo;installazione: USB Startup Disk Creator, disponibile a partire dalle ultime versioni di Ubuntu (si trova in System\u0026ndash;\u0026gt;Administration) oppure Unetbootin, che potete trovare a questo indirizzo: http://unetbootin.sourceforge.net/\nNel caso vogliate installare la versione NBR (Notebook Remix) di Ubuntu, che viene distribuita in formato .img dovete invece attenervi alle istruzioni che trovate su questa pagina: https://help.ubuntu.com/community/Installation/FromImgFiles\nUna volta preparata la chiavetta USB (o in alternativa va bene anche una memoria di tipo SD) dovrete utilizzarla per fare il boot (vi ricordo che per fare il boot da USB dovete premere ESC nei primi secondi di accensione dell\u0026rsquo;EeePC) e procedere all\u0026rsquo;installazione come se fosse un normale PC. Se posso darvi un consiglio su come partizionare, vi suggerisco di utilizzare il disco da 4 Gb per la root / e quello da 16 Gb (o 12 Gb a seconda dei modelli) per la /home.\nCompletata l\u0026rsquo;installazione, al riavvio dell\u0026rsquo;EeePC avrete una piacevole sorpresa: tutte le periferiche saranno perfettamente riconosciute! Questo dimostra l\u0026rsquo;ottimo lavoro che √® stato fatto per supportare questa fascia di dispositivi. E\u0026rsquo; necessaria tuttavia qualche altra piccola ottimizzazione per poter sfruttare al 100% il nostro netbook.\nPer prima cosa vi consiglio di installare gli script di elmurato che vi permetteranno di utilizzare correttamente tutti i tasti funzione (Fn+Fx). Perch√® possano funzionare dovrete anche installare sia un pacchetto presente nella Ubuntu, sia uno incluso nel tar.gz, seguendo le seguenti istruzioni:\n1 2 3 4 5 6 sudo apt-get install dkms sudo apt-get remove --purge nvidia-common tar xzvf Jaunty_Eeeasy-Scripts.tar.gz cd Jaunty_Eeeasy-Scripts sudo dpkg --install asus-eee-dkms_3.0_all.deb sudo ./eeeasy-scripts.sh` A questo punto non vi resta che riavviare il vostro EeePC e l\u0026rsquo;installazione sar√† completata. Se vogliamo essere precisi, ci sono ancora un paio di piccole cose da migliorare. Noterete infatti che il tasto per abilitare/disabilitare il bluetooth non funziona correttamente. Si tratta di un bug del kernel 2.6.28 che viene fortunatamente risolto con la versione 2.6.29 di cui elmurato fornisce i pacchetti .deb gi√† compilati: http://www.informatik.uni-bremen.de/~elmurato/EeePC/ (dovrete installare linux-headers-* e linux-image-* ).\nLa versione 2.6.29 del kernel include anche una versione aggiornata del modulo che fa funzionare la scheda wireless, permettendoci di avere un segnale piu\u0026rsquo; stabile.\nConsiglio infine di aggiungere la seguente stringa in fondo al file /etc/modprobe.d/options (createlo se non esistesse):\n1 options psmouse proto=imps questa opzione fa in modo che il touchpad funzioni meglio rispetto a come viene configurato di default.\n","date":"2009-04-26T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-904-jaunty-su-asus-eeepc-901/","title":"Ubuntu 9.04 (Jaunty) su Asus EeePC 901"},{"content":"\nI\u0026rsquo;ve just released PyngFM, a Python implementation of Ping.fm API. Ping.fm is a simple service that allow you to update multiple social networks (Facebook, Twitter, Jaiku ecc\u0026hellip;) with a single post. You can find complete source code and documentation on the official website: http://code.google.com/p/pyngfm/\nPlease contact me if you have any suggestion or if you find any bug in the code, so I\u0026rsquo;ll be able to fix it.\n","date":"2009-04-02T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/pyngfm-python-implementation-of-pingfm-api/","title":"PyngFM: Python implementation of Ping.fm API"},{"content":"\nDa tempo stavo cercando un servizio che mi offrisse un piccolo spazio online, sempre accessibile ed utilizzabile come una chiavetta USB, per poterci mettere i miei dati ed averli sempre disponibili ovunque andassi. In questi giorni, dopo aver sentito parlare molto bene di Dropbox da parte di un amico, mi sono deciso a provarlo.\nDropbox offre 2 Gb (espandibili fino a 5 Gb invitando altre persone ad usare il servizio) di spazio gratuito, da utilizzare come disco personale. La cosa interessante √® che non si tratta di una semplice cartella tipo FTP, ma tramite il loro client si integra perfettamente nel sistema operativo che stiamo utilizzando (Windows, OSX o Linux) e si occupa automaticamente di sincronizzare online le modifiche che facciamo ai file locali. I nostri file infatti si trovano sia sul nostro disco locale, sia in copia sul nostro spazio online.\nSe ad esempio abbiamo installato il client sul nostro PC fisso e lavoriamo a dei file, questi vengono automaticamente sincronizzati online. Immaginiamo adesso di installare il client anche sul nostro portatile, non appena accediamo ad Internet i file verranno automaticamente sincronizzati, quasi in tempo reale.\nTra le altre funzionalit√† che il servizio offre, c\u0026rsquo;√® anche quella di poter creare in automatico delle gallerie fotografiche. E\u0026rsquo; sufficiente creare una sotto cartella dentro la cartella Photos predefinita ed in automatico verr√† creata la fotogallery.\nPer quanto riguarda la sicurezza dei nostri file, quello che mettiamo su Dropbox rimane accessibile solo a noi, fatta eccezione per quello che viene messo nella sotto cartella Public. Il trasferimento dei file dal nostro PC allo spazio online inoltre avviene in modo cifrato. Nessuno per√≤ ci garantisce che i nostri documenti, uan volta sui server di Dropbox, non vengano sbirciati da qualcuno\u0026hellip; il mio consiglio quindi √® quello di crearsi una ulteriore sotto cartella, magari chiamandola Secure, e metterci dentro un file di Truecrypt sul quale andremo a montare la nostra cartella cifrata. In questo modo il file di Truecrypt sara' sincronizzato online, ma il suo contenuto sara\u0026rsquo; inaccessibile a chiunque, eccetto noi.\nUn\u0026rsquo;ulteriore doverosa precisazione: il client che installiamo sul nostro PC non √® opensource. A parte questo piccolo difetto, il servizio √® veramente valido! Per chi avesse bisogno di maggiore spazio, esiste anche una versione a pagamento del servizio, dove per 10$/mese vengono messi a disposizione 50 Gb di spazio.\nChi volesse provare il servizio, puo\u0026rsquo; iscriversi utilizzando questo link: https://www.getdropbox.com/referrals/NTgzNTM0MTk\nIn questo modo sia voi che io guadagneremo +250 Mb di spazio da aggiungersi ai 2 Gb che vengono dati di base.\n","date":"2009-03-29T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/dropbox-2gb-di-disco-online-che-si-integrano-con-windows-osx-e-linux/","title":"Dropbox: 2Gb di disco online che si integrano con Windows, OSX e Linux"},{"content":"After the suggestion from a member of this community (I don\u0026rsquo;t want to nominate him because I don\u0026rsquo;t want to influence anyone) I\u0026rsquo;ve decided to candidate myself for the Maemo Council. Here I\u0026rsquo;m! You can read something about me and about my motivations in the rest of this post.\nName: Andrea Grandi\nmaemo.org: Andy80 - http://maemo.org/profile/view/andy80/\nCorporate affiliation: none\nIntroduction My name is Andrea Grandi, I\u0026rsquo;m 28 and I live in Pistoia (Tuscany, ITALY). I\u0026rsquo;m a programmer, in particular very interested in Linux and opensource. I\u0026rsquo;ve been working for some years as computer programmer, then I decided to begin studing at university, and currently I\u0026rsquo;m attending at \u0026ldquo;Universit√† degli studi di Firenze\u0026rdquo; to get the Computer Science degree. I spend lot of my time to manage the Pistoia Linux User Group I founded in 2001.\nMy life in the community I\u0026rsquo;m part of the community since I bought my first Nokia 770. I started contributing to the mailing lists, I wrote some tutorials (in italian language, then I translated them to english) and I ported SPIM (a MIPS emulator) to Nokia 770. Later I had the possibility to buy a N810 and I was able to experiment more with the Maemo SDK. I was at the Maemo Summit in Berlin, doing a light talk about Maemo development using Eclipse, PluThon and EsBox plugins.\nMotivations I really would like to be able to do more for the community and one of the best way could be to be part of the council, to help both users/developers to explain their requests to Nokia and Nokia to understand the requests from the community. There are a lot of fantastic ideas comung from the community that could improve what we are doing: the key is to organize them and giving them more attention. This is what I\u0026rsquo;ve always looked for: working together to build something great!\n","date":"2009-02-28T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/announcing-my-standing-for-the-maemo-council/","title":"Announcing my standing for the Maemo Council"},{"content":"Paul Ferrill has written a serie of three articles about writing a GPS-aware application for the Nokia N810, using the Maemo SDK, Eclipse and PluThon plugin.\nHere is the complete serie:\nDevelop a GPS-aware application for the Nokia N810, Part 1: Development environment: Learn how to configure a development environment targeted at the Nokia N810 Internet Tablet, including setting up Eclipse on a target development machine for the Python language.```\nDevelop a GPS-aware application for the Nokia N810, Part 2: Consider your options: Discover the details of code design, library selection, unit testing, and user interface choices that make the most sense for you.```\nDevelop a GPS-aware application for the Nokia N810, Part 3: Finish the job: In this last of three installments, you\u0026rsquo;ll put the final touches to the GPS trip tracker and get it ready for release.\n","date":"2009-02-24T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/develop-a-gps-aware-application-for-the-nokia-n810/","title":"Develop a GPS-aware application for the Nokia N810"},{"content":"Se abbiamo dei file audio in formato .wma e li vogliamo convertire in formato .mp3 utilizzando Linux, √® sufficiente creare un piccolo script in bash che facendo uso di mplayer e lame provveda a convertire tutti i file che si trovano all\u0026rsquo;interno di una certa directory.\nCreiamo un file chiamato wma2mp3.sh con all\u0026rsquo;interno il seguente script:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/bin/bash current_directory=$( pwd ) #remove spaces for i in *.wma; do mv \u0026#34;$i\u0026#34; `echo $i | tr \u0026#39; \u0026#39; \u0026#39;_\u0026#39;`; done #remove uppercase for i in *.[Ww][Mm][Aa]; do mv \u0026#34;$i\u0026#34; `echo $i | tr \u0026#39;[A-Z]\u0026#39; \u0026#39;[a-z]\u0026#39;`; done #Rip with Mplayer / encode with LAME for i in *.wma ; do mplayer -vo null -vc dummy -af resample=44100 -ao pcm:waveheader $i \u0026amp;\u0026amp; lame -m s audiodump.wav -o $i; done #convert file names for i in *.wma; do mv \u0026#34;$i\u0026#34; \u0026#34;`basename \u0026#34;$i\u0026#34; .wma`.mp3\u0026#34;; done rm audiodump.wav a questo punto basta mettere lo script nella cartella dove ci sono i file .wma, dare i permessi di esecuzione a tale file (chmod +x wma2mp3.sh) ed eseguirlo con ./wma2mp3.sh\nFonte: http://www.linuxquestions.org/linux/answers/Applications_GUI_Multimedia/Convert_WMA_to_MP3* ","date":"2009-02-22T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/convertire-i-file-wma-in-mp3-sotto-linux/","title":"Convertire i file WMA in MP3 sotto Linux"},{"content":"\nIl precedente post che ho fatto mi aveva fatto veramente disperare. Come potete leggere dai comandi, √® necessario passare alcuni parametri utilizzando il doppio trattino.\nWordpress trasformava automaticamente il doppio trattino in un trattino singolo, facendo si che se qualcuno provava a fare il copia-incolla di quel comando ricevesse un errore di sintassi dal sistema.\nPoco dopo aver risolto un po\u0026rsquo; alla peggio, mi sono imbattuto in questo utilissimo post. In pratica si piega come evitare che Wordpress modifichi in automatico i caratteri all\u0026rsquo;interno dei blocchi di codice.\nE\u0026rsquo; sufficiente modificare il file functions.php del tema Wordpress che stiamo utilizzando ed aggiungere questa riga in fondo al file:\n1 \u0026lt;?php remove_filter(\u0026#39;the_content\u0026#39;, \u0026#34;wptexturize\u0026#34; ); ?\u0026gt; ","date":"2009-02-14T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/evitare-che-wordpress-modifichi-il-codice-da-copia-incollare/","title":"Evitare che Wordpress modifichi il codice da copia-incollare"},{"content":"\nUtilizzando i repository esterni su Ubuntu, capita spesso di non avere una procedura automatica per importare anche le relative chiavi pubbliche PGP, che ci permettono di avere la garanzia che i pacchetti che stiamo scaricando siano autentici e che quindi provengano dall\u0026rsquo;autore originale.\nSul sito web dei progetti che mettono a disposizione un repository, solitamente √® indicato anche l\u0026rsquo;ID della chiave pubblica PGP. Ad esempio sul sito del Blueman Development Team troviamo 6B15AB91951DC1E2.\nPer importare questa chiave pubblica dentro apt di Ubuntu, sono sufficienti i seguenti comandi da terminale:\n1 2 gpg --keyserver keyserver.ubuntu.com --recv 6B15AB91951DC1E2 gpg --export --armor 6B15AB91951DC1E2 | sudo apt-key add - Ovviamente dovrete sostituire l\u0026rsquo;ID della chiave PGP con quello che vi interessa aggiungere. Qui di seguito potete vedere un esempio completo dei messaggi di conferma che si ricevono quando si aggiunge la chiave:\n1 2 3 4 5 6 gpg --keyserver keyserver.ubuntu.com --recv 6B15AB91951DC1E2 gpg: requesting key 951DC1E2 from hkp server keyserver.ubuntu.com gpg: key 951DC1E2: public key \u0026#34;Launchpad PPA for Blueman Development Team\u0026#34; imported gpg: Total number processed: 1 gpg: imported: 1 (RSA: 1) gpg --export --armor 6B15AB91951DC1E2 | sudo apt-key add - OK ","date":"2009-02-14T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/importare-le-chiavi-pubbliche-pgp-in-apt-su-ubuntu/","title":"Importare le chiavi pubbliche PGP in apt su Ubuntu"},{"content":"\nThis year the Maemo community will try to join the Google Summer of code program again. Google Summer of code can be a very good opportunity for the Maemo Community, and can also give a lots of good things, like new projects/features and new people developing for Maemo.\nIn order to apply to Summer of code, we need help from the community, we need project ideas, mentors and interested students. The mentor organizations submissions starts in March 9.\nThere is a wiki page with some information regarding the Maemo participation in GSoC, feel free to add more information to the pages, especially for people that participated in previous editions of GSoC.\nIn 2007 some Nokia employee offered their help as mentors and backup mentors, will be fine if that happens this year too.\nNote: I reported this news thanks to Valerio Valerio who wrote this on maemo-community mailing list.\n","date":"2009-02-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/maemo-on-google-summer-of-code-2009/","title":"Maemo on Google Summer of Code 2009"},{"content":"\nGli utenti Linux che utilizzano Skype lo sanno: la versione disponibile per il pinguino non √® mai stata aggiornata come quella per Windows. Su Linux siamo ancora alla versione 2.0.0.72 da piu\u0026rsquo; di un anno, nonostante siano stati segnalati da tempo vari problemi sia con l\u0026rsquo;audio che con il video.\nPochi giorni fa uno degli sviluppatori della versione Linux di Skype, ha pubblicato sul proprio blog qualche aggiornamento su come sta procedendo lo sviluppo della versione Linux, in particolare:\nla libreria audio √® stata completamente riscritta e sono state risolte delle incompatibilit√† con gli auricolari bluetooth```\naggiornamenti anche alla libreria video in modo da renderla piu' stabile e compatibile con un maggior numero di webcam```\nl\u0026rsquo;interfaccia utente verr√† completamente ridisegnata ispirandosi alla versione 4.0 per Windows```\nverr√† aggiunto il supporto per un maggior numero di sistemi operativi, come ad esempio FreeBSD, OpenSolaris e le versione di Linux a 64 bit```\nsono stati assunti in questi mesi diversi sviluppatori esperti di Linux e delle librerie Qt e ne verranno assunti altri nei prossimi mesi\n1 2 3 A questo punto non ci resta che attendere, sperando di veder uscire una nuova versione almeno entro la fine dell\u0026#39;anno. ","date":"2009-02-07T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/nuove-versioni-di-skype-per-linux-qualcosa-si-muove/","title":"Nuove versioni di Skype per Linux: qualcosa si muove"},{"content":"\nGoogle ha appena lanciato il servizio Latitude che si integra con la nuova versione di Google Maps per cellulari, la 3.0 che √® appena stata rilasciata.\nSi tratta di una funzionalit√† che permette di localizzare i propri amici sulla mappa, persino in tempo reale. Gli amici che si possono localizzare vanno selezionati tra i propri contatti di Gmail, dopo di che √® possibile visualizzarli sulla mappa.\nNiente paura per la privacy: l\u0026rsquo;impostazione di default non attiva Latitude. E\u0026rsquo; necessario attivarlo manualmente e scegliere tra una delle seguenti modalit√† di aggiornamento:\nAutomatica: in questo modo Google Maps/Latitude cercher√† di rilevare automaticamente la nostra posizione utilizzando il GPS (se disponibile) oppure sfruttando le celle GSM (con una precisione meno accurata).```\nManuale: √® possibile selezionare manualmente la propria posizione sulla mappa.```\nNascosta: con questa modalit√† saremo invisibili a tutti i nostri i contatti sulla mappa.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Gli **amici** che possiamo vedere sulla mappa, inoltre, **devono autorizzarci esplicitamente**. Questo significa che senza una particolare autorizzazione, non saremo in grado di vedere tutti i nostri contatti di GMail sulla mappa. Al momento √® possibile utilizzare Google Maps e Latitude con i seguenti telefoni: - Android-powered devices, such as the T-Mobile G1 - iPhone and iPod touch devices (coming soon) - most color BlackBerry devices - most Windows Mobile 5.0+ devices - most Symbian S60 devices (Nokia smartphones) - many Java-enabled (J2ME) mobile phones, such as Sony Ericsson devices (coming soon) ","date":"2009-02-04T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/google-latitude-scopri-dove-sono-i-tuoi-amici-in-tempo-reale/","title":"Google Latitude: scopri dove sono i tuoi amici in tempo reale!"},{"content":"\nDal momento in cui ho acquistato l\u0026rsquo;Asus EeePC 901, ho rimosso la versione personalizzata di Xandros Linux che viene installata su questi modelli, ed ho installato una versione personalizzata di Ubuntu: Ubuntu-eee 8.04.1.\nQuesta versione, pensata appositamente per i netbook della Asus, √® davvero molto comoda perch√® integra di default un kernel con tutte le patch ed i driver per far funzionare l\u0026rsquo;EeePC, che invece non sono contenuti nel kernel distribuito dalla Ubuntu 8.04 standard. Ubuntu-eee installa anche l\u0026rsquo;interfaccia Netbook Remix che √® una particolare interfaccia grafica adatta per i netbook con schermi di ridotte dimensioni.\nL\u0026rsquo;idea di avere una distribuzione basata su Ubuntu che integra gi√† tutte le patch necessarie per farla funzionare mi √® sembrata subito una buona idea, tanto che ho anche pensato di inviare un piccolo contributo in denaro durante la campagna di raccolta fondi per finanziarne lo sviluppo.\nI problemi di Easy Peasy Dalla versione successiva alla 8.04.1, Ubuntu-eee ha dovuto cambiare nome (per non violare le regole del marchio \u0026ldquo;Ubuntu\u0026rdquo; di propriet√† di Canonical), e fin qui nulla di male. Quello che non mi √® affatto piaciuto √® che mentre per il logo √® stato fatto un apposito concorso e poi scelto il migliore, per il nome l\u0026rsquo;autore ha scelto a \u0026ldquo;gusto\u0026rdquo; proprio: Easy Peasy.\nDigerita la questione del nome, ho deciso di provarla sul mio EeePC. L\u0026rsquo;impressione √® stata a dir poco pessima. Tanto per cominciare si nota da subito che la distribuzione non √® stata minimamente testata: al primo riavvio dopo l\u0026rsquo;installazione, si presenta di nuovo l\u0026rsquo;installer, come se la dovessimo installare da zero. Il fix non √® ancora stato rilasciato, in compenso l\u0026rsquo;autore ha spiegato come risolverlo a mano.\nOltre a questo, leggendo il forum, saltano fuori almeno un\u0026rsquo;altra decina di problemi con la Easy Peasy. Tutti problemi che sarebbero stati facilmente risolvibili in fase di creazione della distribuzione personalizzata, se solo fosse stata minimamente testata. Che ci possano essere dei problemi su una distribuzione generica come ad esempio la Ubuntu (che √® pensata per girare su qualsiasi configurazione) lo posso anche capire.\nNon mi pare accettabile che possano esserci cos√¨ tanti problemi su una distribuzione che dovrebbe essere fatta appositamente per un certo modello di netbook.\n##¬†Ubuntu 8.10\nDeluso dalla versione personalizzata, ho deciso di provare ad installare la versione standardi di Ubuntu, sistemando a mano le cose che non andavano.\nInstallazione di base L\u0026rsquo;installazione di Ubuntu 8.10 √® identica a quella di Ubuntu-eee/EasyPeasy. E\u0026rsquo; sufficiente creare una versione di Ubuntu che faccia il boot da una chiavetta USB oppure da una memoria SD, utilizzando la comoda utility presente in Ubuntu 8.10 (System-\u0026gt;Administration-\u0026gt;Create a USB startup disk) oppure tramite Unetbootin.\nCompletata l\u0026rsquo;installazione, come gi√† accennato, molte periferiche (come ad esempio la webcam, la scheda wireless o i tasti funzione) non saranno riconosciuti, ma questo gi√† lo sapevamo. La scheda ethernet √® invece riconosciuta e configurata perfettamente da Ubuntu 8.10, quindi √® possibile utilizzare provvisoriamente il cavo per connettersi e completare l\u0026rsquo;installazione delle componenti mancanti.\nIl kernel ottimizzato per EeePC La prima cosa da installare √® il kernel personalizzato di Adam. Questo kernel integra tutte le patch necessarie al funzionamento di tutte le periferiche dell\u0026rsquo;EeePC. Non mi dilungher√≤ in questo post nella spiegazione di come si installa, rimandandovi invece all\u0026rsquo;howto originale, presente sul sito dell\u0026rsquo;autore: http://array.org/ubuntu/setup-intrepid.html\neee-control Questa utility ci permette di far funzionare tutti i tasti funzione del nostro EeePC (Fn+F*) e di tenere sotto controllo alcuni parametri di sistema come ad esempio la temperatura, la velocit√† della ventolina ed infine di disabilitare le periferiche che non utilizziamo sul momento (come ad esempio il bluetooth o la wifi) in modo da prolungare la durata della batteria.\nPer installarla √® sufficiente seguire le istruzioni sul sito dell\u0026rsquo;autore oppure scaricarla direttamente da questo indirizzo: http://greg.geekmind.org/eee-control/deb/eee-control_0.8.3_all.deb\nAltre ottimizzazioni Per ottenere il massimo dal proprio EeePC √® necessario effettuare ancora qualche piccolo aggiustamento. I consigli che seguono potrebbero applicarsi anche ad altri modelli di EeePC anche se personalmente ho avuto modo di testarli solo con l\u0026rsquo;EeePC 901.\nlaptop-mode Per abilitare alcune ottimizzazioni per i notebook, dobbiamo abilitare il laptop-mode all\u0026rsquo;interno del file /etc/default/acpi-support\nENABLE_LAPTOP_MODE=true\ninfine dobbiamo modificare il file /etc/laptop-mode/laptop-mode.conf\nENABLE_LAPTOP_MODE_ON_BATTERY=1\nnoatime E\u0026rsquo; consigliabile utilizzare l\u0026rsquo;opzione noatime al posto di relatime per fare il mount delle partizioni ext3. In questo modo si evita che vengano scritte su disco le informazioni relative all\u0026rsquo;ultimo accesso (anche in lettura) di un file. Dobbiamo modificare /etc/fstab in questo modo: UUID=dce586c1-db13-43c3-8e12-9e1aec67afce / ext3 noatime,errors=remount-ro 0 1\nN.B: questa riga non va copiata cos√¨ com\u0026rsquo;√®, va soltanto sostituito relatime con noatime in quella del proprio file.\nAltre ottimizzazioni possono essere trovate sul wiki di Ubuntu-eee: http://www.ubuntu-eee.com/wiki/index.php5?title=User_Guides\nConclusioni Ammetto che avere una distribuzione che integri di suo tutte queste modifiche potrebbe far risparmiare del tempo. Se questa distribuzione per√≤ non viene rilasciata con gi√† tutti i fix necessari a far funzionare il modello di netbook per cui √® stata fatta, a che serve? A quel punto tanto vale installare una distribuzione normale e cogliere l\u0026rsquo;occasione per imparare qualcosa, effettuando a mano le modifiche necessarie per farla funzionare.\n","date":"2009-02-02T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-linux-810-su-asus-eeepc-901/","title":"Ubuntu Linux 8.10 su Asus EeePC 901"},{"content":"A new update for Os2008 is available for Nokia N810. The released version is 5.2008.43.\nYou can upgrade it OTA (over the air):\nconnect to Internet open the Application Manager install updates Thats\u0026rsquo;s all! Enjoy and test the new updates!\n","date":"2008-12-17T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/os-2008-update-for-nokia-n810-5200843-released/","title":"OS 2008 update for Nokia N810: 5.2008.43 released"},{"content":"\nLo scanner Mustek ScanExpress 1248 USB √® pienamente compatibile con Linux, per√≤ purtroppo non basta connetterlo per farlo funzionare. Ubuntu Linux 8.10 non distribuisce il firmware necessario al suo funzionamento, per√≤ √® possibile reperirlo ed installarlo con molta facilit√†.\nPer prima cosa dobbiamo assicurarci di avere il modello esatto di questo scanner. Per scoprirlo √® sufficiente dare il comando lsusb da terminale. Dovremmo ottenere una stringa come la seguente:\n1 Bus 002 Device 003: ID 055f:021f Mustek Systems, Inc. SNAPSCAN e22 A questo punto possiamo scaricare il suo firmware da un sito che li raccoglie tutti (quelli che sono compatibili ovviamente): http://www.meier-geinitz.de/sane/gt68xx-backend/firmware/SBSfw.usb\nQuesto file va messo all\u0026rsquo;interno della cartella /usr/share/sane/gt68xx/ (occorrono i permessi di root per poterlo fare, quindi il file andra\u0026rsquo; copiato tramite il comando sudo cp SBSfw.usb /usr/share/sane/gt68xx/ ).\nInfine dobbiamo assicurarci di aver installato tutti i pacchetti necessari a farlo funzionare:\n1 sudo apt-get install sane libsane sane-utils libsane-extras xsane xsane-common Lo scanner √® adesso pronto per funzionare.\nNota:¬†nella Ubuntu 12.04 la directory¬†/usr/share/sane/gt68xx/ non √® presente di default e va creata manualmente con sudo mkdir¬†/usr/share/sane/gt68xx/\n","date":"2008-12-17T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/scanner-mustek-scanexpress-1248-usb-su-ubuntu-linux/","title":"Scanner Mustek ScanExpress 1248 USB su Ubuntu Linux"},{"content":"Google ha appena annunciato che metter√† a disposizione per gli sviluppatori, delle versioni particolari del G1, quello che tutti ormai conoscono come il nuovo telefono cellulare di Google. Il G1 per sviluppatori costa circa 399$ ed √® SIM-unlocked, rendendo quindi possibile l\u0026rsquo;utilizzo con qualsiasi operatore di telefonia mobile.\nIl dispositivo non sara\u0026rsquo; disponibile da subito in tutti i paesi, ma solo in 18 che Google ha selezionato: USA, Inghilterra, Germania, Giappone, India, Canada, Francia, Taiwan, Spagna, Australia, Singapore, Svizzera, Olanda, Austria, Svezia, Finlandia, Polonia e Ungheria.\nEbbene si: persino Polonia e Ungheria hanno avuto la precedenza rispetto all\u0026rsquo;Italia! Prima veniamo esclusi dal concorso per lo sviluppo di applicazioni per Android (a causa di problemi legati alla nostra burocrazia), e adesso questo.\nNoi poveri italiani cosa possiamo fare? Assolutamente niente, se non cercare di far acquistare il G1 a qualche amico che si trova all\u0026rsquo;estero. Questo per√≤ non porter√† mai alla creazione di una community italiana di sviluppatori per Android.\nUna piccola nota, che non c\u0026rsquo;entra specificatamente con l\u0026rsquo;Italia, ma che ci tengo a fare notare √® che Google, dal suo comunicato, sembra ammettere che sul G1 ufficiale possono girare solo le applicazioni che sono state scaricate dal Market di Android:\n\u0026ldquo;Note that Android Dev Phone 1 devices are not intended for non-developer end users. Since the devices can be configured with system software not provided by or supported by Google or any other company, end users operate these devices at their own risk.\u0026rdquo;\nOvvero (tradotto molto liberamente): i dispositivi per sviluppatori non sono destinati agli utenti finali. Su questi telefoni √® possibile installare software non fornito o supportato da Google o da altre compagnie, gli utenti li utilizzeranno a loro rischio e pericolo.\n","date":"2008-12-06T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/android-e-developer-device-program-come-al-solito-litalia-e-di-serie-b/","title":"Android e Developer Device Program: come al solito l'Italia √® di serie B"},{"content":"\nIntroduzione Il supporto per le webcam su Linux non √® mai stata una cosa molto semplice. I motivi principali per cui le webcam non sono ben supportate sono principalmente due: la scarsa collaborazione dei produttori di hardware, che dovrebbero fornire almeno le specifiche a chi sviluppa i driver per Linux e il quasi completo disinteresse di chi scrive le applicazioni per l\u0026rsquo;utente finale (in particolare Microsoft con MSN e Skype che utilizzano entrambi un protocollo proprietario e non documentato).\nDa diverso tempo si stanno diffondendo applicazioni scritte in Flash che permettono di utilizzare la webcam: dalle videochat, all\u0026rsquo;applicazione di Youtube che permette di pubblicare un video registrandolo direttamente, fino ai recenti servizi di streaming video come ad esempio JustinTV e UStream.\nIl plugin Flash della Adobe, purtroppo ha iniziato a supportare le webcam su Linux utilizzando il protocollo V4L1 quando ormai la maggior parte di esse funzionava solo con il nuovo protocollo V4L2.\nA partire dalla versione 10 di Flash, finalmente la Adobe ha iniziato a supportare il protocollo V4L2, anche se il supporto non √® ancora completo. Modelli differenti di webcam infatti utilizzano svariati formati di trasmissione video. Fortunatamente lo sviluppatore che lavora per Adobe si √® reso disponibile per ricevere il feedback da parte degli utenti e per implementare questi formati in modo da supportare il maggior numero possibile di webcam. Per chi volesse contribuire √® possibile seguire le istruzioni su questa pagina: http://blogs.adobe.com/penguin.swf/2008/07/paparazzi_v2_1.html\ngstfakevideo: un workaround per emulare V4L1 Visto che il supporto per le webcam che utilizzano V4L1 √® molto piu' stabile, l\u0026rsquo;ingegno della community Linux non √® stato ad aspettare con le mani in mano. Il metodo utilizzato √® basato su quello che veniva usato su Skype per supportare un maggior numero di webcam: in pratica viene creato un device virtuale V4L1 sul quale viene redirezionato l\u0026rsquo;output della webcam V4L2.\nIl codice originale purtroppo aveva bisogno di alcuni aggiustamenti, mi sono permesso quindi di modificarlo e di applicarli.\nLa compilazione non dovrebbe comportare particolari problemi: √® sufficiente eseguire make all\u0026rsquo;interno della cartella dei sorgenti.\nPer testare il funzionamento della webcam √® sufficiente esegurie lo script che si trova all\u0026rsquo;interno della cartella. Verr√† avviato Firefox con il supporto per le webcam V4L1. Visitando uno dei siti web che hanno un\u0026rsquo;applicazione Flash che utilizza la webcam citati all\u0026rsquo;inizio, sara\u0026rsquo; possibile verificarne il corretto funzionamento.\nRiferimenti: le istruzioni in questo post sono state in parte prese da questo sito web (in inglese): http://www.jtolds.com/newsletter/2008/7/27/how-to-get-v4l2-devices-to-work-with-flash\n","date":"2008-11-25T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/utilizzare-webcam-v4l2-con-flash-su-linux/","title":"Utilizzare webcam V4L2 con Flash su Linux"},{"content":"In these days I was thinking about: what could be done to improve Maemo Development and power user experience? There are some points that would need to be improved. This little list pretends to be just a starting point. I hope to get some feedback so we can discuss further in the maemo-developers mailing list.\nDocumentation: Maemo developers use different libraries and toolkit (GTK, libui, ecc\u0026hellip;). There is not a common place where I can look for documentation. I\u0026rsquo;ve to visit each library website and get it. It would be great to have a tool just like Qt Assistant, integrating all documentation, including examples and aggregating external articles using a \u0026ldquo;live RSS aggregator\u0026rdquo;.\nKinetic scrolling: I really love Mauku application because of its kinetic scrolling, thanks to the Miaouw library. It would be great to have this kind of scrolling to be part of Hildon UI. Of course I\u0026rsquo;d love to have Python bindings too :)\nEclipse Support: I think Eclipse support should be improved. I\u0026rsquo;d like to have a tool that makes .deb creation easier so developers can spend more time coding and not packaging applications. I\u0026rsquo;d like to see a GUI designer integrated into Eclipse (for \u0026ldquo;integrated\u0026rdquo; I mean something like Visual Studio GUI designer\u0026hellip;. not an external tool like Glade).\nQt Creator: Trolltech (Nokia) just released a preview release of their Qt Creator. A very powerfull IDE to develop Qt/C++ applications. It\u0026rsquo;s still in alpha release, but\u0026hellip; what about integrating Maemo development into it? (Supporting Python development too).\nMaemo SAS hosting: sometimes we (well.. me at least :D ) need to write an application that uses a server part too and need to expose some API. Maemo.org offers hosting for the project, but what about the server part of the application? It would be fine if developers had the possibility to have the server side hosted by Maemo.org or Nokia.\nBetter GPS support: the GPS unit shipped with N810 is something unusable yet. I\u0026rsquo;ve tried using A-GPS too, but position fixing time is still bad, compared to an external GPS/bluetooth receiver. I often have to use my external GPS receiver to use my N810 without problems.\nMore audio/video codecs: often I\u0026rsquo;m not able to listen to online radios, streamings ecc\u0026hellip; just because of a missing codec for the default Media Player.\nThese are just some ideas. Please feel free to comment them, I\u0026rsquo;d like to discuss them together.\n","date":"2008-11-17T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/what-i-expect-in-the-future-of-maemo-development/","title":"What I expect in the future of Maemo Development"},{"content":"\nIl 30 ottobre 2008 √® stata rilasciata la versione 8.10 di Ubuntu. Questa release presenta come al solito moltissime novit√† per l\u0026rsquo;utente finale, ma non √® esente da alcuni problemi che solitamente riguardano le distribuzioni appena uscite.\nQuesto articolo vuole essere un riferimento per chi sta utilizzando una versione precedente di Ubuntu Linux o per chi ci si avvicina per la prima volta, in modo che possa essere fatta una scelta in base agli effettivi vantaggi e svantaggi.\nNovit√† per l\u0026rsquo;utilizzo desktop Per l\u0026rsquo;utente desktop di, sono state introdotte alcune caratteristiche che possono facilitarne l\u0026rsquo;utilizzo in particolare a chi utilizza Ubuntu sui notebook, migliorando anche la sicurezza dei propri dati personali.\nSupporto alle connessioni 3G: la versione 0.7 del NetworkManager inclusa in questa release permette di gestire anche le connessioni GPRS/UMTS/HSDPA in maniera piu\u0026rsquo; semplice, sia che si utilizzi un modem interno, un dongle USB oppure che ci si connetta utilizzando il proprio cellulare tramite il bluetooth.\nInstallazione ed avvio da dischi USB: √® stato incluso un comodo tool che permette di installare Ubuntu su una chiavetta o un disco USB tramite una semplicissima interfaccia grafica. In questo modo sar√† possibile portarsi dietro la propria copia di Ubuntu ovunque si vada e avendo anche la possibilit√† di salvare le impostazioni ed i propri documenti.\nUtente Guest: adesso √® possibile lasciare in sospeso la propria sessione utente avviando temporaneamente una seconda sessione ospite per permettere ad esempio ad un nostro amico o collega di controllare la propria posta elettronica o di navigare sul web senza che questo possa curiosare nei nostri documenti o memorizzare file in maniera permanente.\nContenuti BBC: grazie ad un accordo fra la Canonical e la BBC √® stato sviluppato un plugin che permette agli utenti di accedere ai contenuti online della BBC tramite Totem Movie Player o Rhythmbox.\nGnome 2.24: questa versione di Gnome incorpora un nuovo client di instant-messaging, migliora il file manger Nautilus introducendo i tab come su Firefox, migliora il supporto ai monitor multipli ed aggiunge alcuni nuovi formati al gestore degli archivi compressi.\nCartella privata cifrata: √® possibile creare in maniera molto semplice una cartella privata che viene montata soltanto quando l\u0026rsquo;utente √® loggato nella propria sessione ed il cui contenuto viene cifrato. Questa funzionalit√† √® molto utile per chi ad esempio utilizza Linux in un portatile: in caso di smarrimento del portatile nessuno sarebbe in grado di accedere al contenuto di tale cartella.\nX.Org 7.4: questa nuova versione di X.Org consente il riconoscimento di mouse, tastiere e tavolette grafiche a caldo (nel senso che vengono riconosciute non appena si inseriscono, quando il sistema √® gi√† avviato).\nDKMS: si tratta di un tool sviluppato dalla Dell. Quando una nuova versione del kernel viene rilasciata, tutti moduli vengono automaticamente ricompilati.\nNovit√† per l\u0026rsquo;utilizzo server Le novit√† non mancano anche per chi utilizza Ubuntu come server. Sono stati introdotti sostanziali miglioramenti nel campo della virtualizzazione, per chi sviluppa in Java e nei tool della gestione di sistema.\nVirtualizzazione: la versione JeOS di Ubuntu √® stata integrata in Ubuntu Server. Si tratta di una versione ridotta di Ubuntu, adatta a girare all\u0026rsquo;interno delle macchine virtuali. Ubuntu Server √® anche ufficialmente supportata come sistema guest su Xen.\nJava: Apache Tomcat 6.0 e OpenJDK 6 sono completamente supportati ed incusi nel repository principale di Ubuntu.\nMail Server: sono stati integrati nel repository principale sia ClamAV che SpamAssassin. Questi due programmi permettono di integrare nel server di posta sia il controllo anti-virus che l\u0026rsquo;anti-spam.\nSupporto RAID: dalla versione 8.10 √® stato aggiunto il supporto che permette di fare il boot anche da un RAID degradato. Questo significa che se si dovesse rompere uno dei due dischi, verr√† chiesto all\u0026rsquo;utente se si vuole procedere ugualmente al boot, in modo da non dover per forza bloccare quella macchina.\nUncomplicated Firewall: √® stato migliorato il supporto al firewall semplificato. Adesso √® possibile specificare direttamente il nome del servizio che si vuole aprire o chiudere, senza dover specificare il numero della porta.\nI problemi della nuova Ubuntu 8.10 Come ho anticipato all\u0026rsquo;inizio, puo\u0026rsquo; capitare che una nuova release, oltre ad introdurre nuove funzionalit√†, abbia anche dei problemi sia perch√® viene distribuita con versioni piu\u0026rsquo; recenti dei vari pacchetti, sia perch√® non √® stata sufficientemente testata prima di essere rilasciata.\nCerchero\u0026rsquo; di riassumere quelli che sono i problemi principali di questa versione, in modo che ogni persona possa capire, a seconda dell\u0026rsquo;uso che ne fa del PC e a seconda dell\u0026rsquo;hardware sul quale andra\u0026rsquo; ad installare Ubuntu, se questi saranno o no un problema per l\u0026rsquo;utilizzo quotidiano.\nIl lettore CD/DVD mangia le dita (bug #283316): non allarmatevi! Non esce alcun mostro dal lettore a mangiare le vostre dita\u0026hellip; Si tratta semplicemente di un bug che fa si che il carrellino del lettore CD venga reinserito troppo velocemente quando si richiede che un CD venga fatto uscire. In pratica si ha meno di un secondo a disposizione per togliere il CD, in caso contrario il carrello verra\u0026rsquo; chiuso e dovremo premere manualmente il pulsante di eject.\nLa sessione di Gnome non viene memorizzata (bug #249373): a causa di un cambiamento nel protocollo utilizzato per salvare la sessione, la maggior parte delle applicazioni (come ad esempio Pidgin, Skype ecc\u0026hellip;) non sono piu\u0026rsquo; in grado di essere avviate automaticamente quando si salva la sessione. E\u0026rsquo; necessario avviarle manualmente dopo ogni login.\nLa ricezione e l\u0026rsquo;invio dei files tramite Bluetooth non funziona piu\u0026rsquo; con i normali tool (bug #290875): cercando di connettersi ad un dispositivo esterno tramite Bluetooth, per lo scambio dei files, si otterr√† un errore. Sono stati introdotti nuovi tool (che non sono ancora completi) ma non vengono installati di default.\nLe stampanti condivise con Samba non riescono a stampare quando non √® richiesta autenticazione (bug #283811): un bug di CUPS aggiunge ad ogni avvio una riga nel file di configurazione che obbliga a richiedere l\u0026rsquo;autenticazione per poter stampare e questo impedisce alle applicazioni di stampare.\nIl plugin UPnP di Rhythmbox non viene caricato (bug #160592): quando si tenta di abilitare questo plugin dentro Rhythmbox si ottiene un errore e non √® possibile quindi attivarlo. Per farlo funzionare occorre installare il pacchetto python-coherence.\nQuesti sono solo alcuni dei problemi noti della Ubuntu 8.10. Potete trovare la lista completa nella pagina delle release notes: http://www.ubuntu.com/getubuntu/releasenotes/810\nLa maggior parte di questi problemi riguardano solo alcune particolari configurazioni oppure hardware ben preciso, quindi se il vostro sistema non rientra in uno dei casi che vengono elencati, potete installare la nuova Ubuntu senza alcun timore.\nSoluzioni ai problemi della nuova Ubuntu La maggior parte dei problemi che ho citato sopra, sono stati nel frattempo corretti e sono stati rilasciati i pacchetti aggiornati che verranno inseriti poi nella prossima bug-fix release (presumibilmente la 8.10.1).\nPer testare in anteprima le patch che vengono rilasciate, occorre abilitare il repository intrepid-proposed tramite System-\u0026gt;Administration-\u0026gt;Software Sources-\u0026gt;Updates. E' opportuno specificare che si tratta di patch che sono ancora sotto fase di testing ma che nel 99% dei casi riescono a risolvere il problema.\nUn suggerimento che vorrei dare agli utenti con un minimo di esperienza, √® quello di non attendere che i bug vengano corretti standosene con le braccia incrociate. Esiste un comodissimo strumento che si chiama Launchpad che Ubuntu utilizza per raccogliere le segnalazioni dei bug nei programmi.\nE\u0026rsquo; fondamentale che piu\u0026rsquo; persone diano il loro feedback su un particolare problema, in modo da aiutare gli sviluppatori a correggerlo nel minor tempo possibile.\nConclusioni Volendo fare il punto della situazione, la Ubuntu 8.10 introduce interessanti novit√† per l\u0026rsquo;utente finale, ma anche diversi bug.\nSe si utilizza Ubuntu in ambienti critici, il mio consiglio √® quello di attendere almeno un mesetto prima di fare l\u0026rsquo;aggiornamento, in modo che almeno i problemi piu\u0026rsquo; gravi possano essere risolti.\nPer tutti gli altri problemi ricordo quanto sia importante dare il proprio contributo. Non √® necessario avere competenze tecniche da programmatori o hacker per migliorare una distribuzione. Occorre solo armarsi di pazienza e saper dialogare con gli sviluppatori per segnalare in tempi brevi i problemi ed attendere che vengano corretti.\nRiferimenti La recensione delle novit√† e dei problemi della nuova Ubuntu 8.10 √® stata possibile sia grazie all\u0026rsquo;utilizzo diretto (√® la distribuzione che uso sul PC fisso) sia grazie alla lettura di alcuni post e alle release notes ufficiali. Per approfondimenti:\nAvoiding feature regressions should be more important than (exact) time based releases: http://ernstfamily.ch/jonathan/2008/11/avoiding-feature-regressions/```\nUbuntu 8.10 Release Notes: http://www.ubuntu.com/getubuntu/releasenotes/810\nUbuntu Desktop Edition: http://www.ubuntu.com/news/ubuntu-8.10-desktop\nUbuntu Server Edition: http://www.ubuntu.com/news/ubuntu-8.10-server\n","date":"2008-11-07T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-810-novita-problemi-e-soluzioni/","title":"Ubuntu 8.10: novit√†, problemi e soluzioni"},{"content":"\nTrolltech ha appena rilasciato la preview release di Qt Creator. Si tratta di un\u0026rsquo;IDE pensato appositamente per lo sviluppo di applicazioni multi piattaforma tramite Qt e C++.\nTra le funzionalit√† piu\u0026rsquo; importanti ci sono sicuramente un\u0026rsquo;avanzato completamento del codice digitato, l\u0026rsquo;integrazione con QtDesigner ed il debugger integrato.\nMancano ancora alcune feature che siamo abituati a trovare su altri IDE, come ad esempio l\u0026rsquo;integrazione con SVN/CVS, templates per il codice sorgente, opzioni di personalizzazione della formattazione ecc\u0026hellip; tuttavia l\u0026rsquo;ambiente promette veramente bene, per essere una preview release. L\u0026rsquo;architettura a plugin che sta alla base dell\u0026rsquo;IDE, non esclude che funzionalit√† di questo tipo possano essere aggiunte in un secondo momento e rese disponibili anche da sviluppatori di terze parti.\nNonostante le librerie Qt stiano prendendo sempre piu\u0026rsquo; campo nei dispositivi portatili (palmari, cellulari ecc\u0026hellip;), non √® al momento supportato lo sviluppo di applicazioni per questo tipo di device. E\u0026rsquo; una funzionalit√† prevista per le future release, anche se al momento non sono noti i tempi esatti di rilascio.\nAl momento √® possibile scaricare l\u0026rsquo;IDE per tutte le principali piattaforme: Windows (Xp e Vista), Linux (32 e 64 bit), OSX. La disponibilit√† in futuro √® per√≤ limitata soltanto dalle piattaforme per le quali esiste un porting delle librerie Qt.\nLa versione definitiva di Qt Creator dovrebbe essere rilasciata poco dopo il rilascio delle Qt 4.5, ovvero entro la prima met√† del 2009. Cos√¨ come le librerie Qt, sara\u0026rsquo; rilasciato con una licenza GPL compatibile che permettera\u0026rsquo; di sviluppare sia applicazioni commerciali che opensource.\n","date":"2008-10-31T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/qt-creator-disponibile-la-preview-release-dellide-per-qtc-di-trolltech/","title":"Qt Creator: disponibile la preview release dell'IDE per Qt/C++ di Trolltech"},{"content":"\nDopo averne sentito tanto parlare, senza mai aver avuto occasione di provarla direttamente, mi sono deciso a costruire una mini antenna parabolica per potenziare il segnale del router wireless.\nDalle poche prove che ho potuto fare, in effetti il segnale viene potenziato abbastanza. Ad esempio ricercando le reti wireless con il palmare da camera mia al salotto, il segnale del router era di circa met√†. Avendo messo l\u0026rsquo;antenna nuova il segnale √® quasi pieno!\nConsiglio a tutti di provare questa soluzione, potrebbe potenziare molto il vostro segnale wireless e permettervi di avere un segnale molto piu\u0026rsquo; stabile in qualsiasi punto della casa.\n","date":"2008-10-29T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/mini-antenna-parabolica-per-potenziare-il-segnale-dei-router-wireless/","title":"Mini antenna parabolica per potenziare il segnale dei router wireless"},{"content":"\nIl Pistoia Linux User Group organizza un \u0026ldquo;install fest\u0026rdquo; sabato 22 novembre a partire dalle ore 15:00 fino alle ore 19:00, presso la propria sede al Centro Giovani (Via Nazario Sauro, 289 - Pistoia).\nDurante la giornata lo staff del PtLUG sar√† a disposizione per aiutare tutti coloro che vogliono installare Linux sul proprio PC (portatile o fisso).\nLa distribuzione che verr√† installata sara\u0026rsquo; principalmente la Ubuntu 8.10, per festeggiare la nuova versione che verr√† appunto rilasciata fra pochi giorni.\nSara\u0026rsquo; inoltre possibile richiedere una copia del CD di Ubuntu, sia facendoselo masterizzare sul momento, sia ordinandolo gratuitamente tramite il sito di Ubuntu.\nL\u0026rsquo;evento √® completamente gratuito ed aperto a tutti. E\u0026rsquo; necessario per√≤ iscriversi tramite il nostro sito web per prenotare l\u0026rsquo;installazione di Linux sulla propria macchina, in modo da assicurarci che ci siano abbastanza persone disponibili per le installazioni: http://www.ptlug.org/installfest\nVi aspettiamo!\n","date":"2008-10-28T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/install-fest-ubuntu-linux-810-a-pistoia/","title":"Install Fest Ubuntu Linux 8.10 a Pistoia"},{"content":"\nIl Collettivo di Matematica degli Studenti di Scienze dell‚ÄôUniversit√† di Firenze ha organizzato una 24 ore no-stop di lezioni da lunedi 27 ottobre alle ore 8:30 fino a martedi 28 ottobre alle ore 8:30.\nLe lezioni si terranno presso il dipartimento di Matematica a Firenze in Viale Morgagni (zona Careggi) nell\u0026rsquo;aula 3 del plesso Ulisse Dini.\nDurante la notte verr√† offerto gratuitamente caffe\u0026rsquo; a tutti i partecipanti. Sar√† possibile inoltre seguire le lezioni anche da casa, collegandosi alla diretta in streaming audio/video tramite VLC al seguente indirizzo: http://radio.math.unifi.it:8000/24hnostop.m3u\nQui di seguito il programma delle lezioni:\n08.30 Ricci: \u0026ldquo;Testa, croce o successioni\u0026rdquo;\n09.30 Primicerio: \u0026ldquo;Innovazione tecnologica: la risorsa matematica\u0026rdquo;\n10.30 Pepino: \u0026ldquo;La chimica nel piatto\u0026rdquo;\n11.30 Giachetti: \u0026ldquo;I fatti e le idee fondamentali che hanno dato origine alla meccanica quantistica\u0026rdquo;```\n12.30 Righini: \u0026ldquo;Il sole, la relazione terra sole e il clima terrestre\u0026rdquo;```\n13.30 Paolini: \u0026ldquo;Come imparare a risolvere il cubo di Rubik\u0026rdquo;\n14.30 Trosti: \u0026ldquo;La simmetria\u0026rdquo;\n15.30 Livi: \u0026ldquo;Aspetti elementari della complessit√†\u0026rdquo;\n16.30 Landi: \u0026ldquo;Reti neurali artificiali\u0026rdquo;\n17.30 Casalbuoni: \u0026ldquo;Radici quadrate e antimateria\u0026rdquo;\n18.30 Ottaviani: \u0026ldquo;Enriquez e Severi\u0026rdquo;\n19.30 Baracca: \u0026ldquo;Energia nucleare\u0026rdquo;\n20.30 Maggesi: \u0026ldquo;La meccanizzazione della matematica\u0026rdquo;\n21.30 Casolo: \u0026ldquo;La matematica in letteratura\u0026rdquo;\n22.30 Borsi:¬†\u0026ldquo;Modelli matematici per fluidi in mezzi porosi: dalla suola delle scarpe alle falde inquinate\u0026rdquo;```\n23.30 Gentili: \u0026ldquo;Che cos‚Äôe‚Äô la congettura di Poincar√®\u0026rdquo;\n00.30 Rubei: \u0026ldquo;Geometria tropicale\u0026rdquo;\n01.30 Vannini: \u0026ldquo;Chi ha paura di Darwin ovvero a cosa servono le zanzare\u0026rdquo;```\n02.30 Cupini: \u0026ldquo;Temperamento:un enigma musicale da Pitagora a Bach\u0026rdquo;\n03.30 Puglisi: \u0026ldquo;In cerca dei numeri primi\u0026rdquo;\n04.30 Cannicci: \u0026ldquo;Il contributo della zoologia nelle investigazioni scientifiche\u0026rdquo;```\n05.30 Romito: \u0026ldquo;Mentire con la statistica\u0026rdquo;\n06.30 Bagnoli: \u0026ldquo;La fisica sotto il naso\u0026rdquo;\n07.30 Casetti: \u0026ldquo;L‚Äôultimo lavoro di Fermi e i fondamenti della meccanica statistica\u0026rdquo;\n","date":"2008-10-27T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/24-ore-di-lezioni-no-stop-alluniversita-di-firenze/","title":"24 ore di lezioni no-stop all'Universit√† di Firenze"},{"content":"E\u0026rsquo; con estremo piacere che mi sento di dire che l\u0026rsquo;edizione di quest\u0026rsquo;anno del LinuxDay a Pistoia √® stata un successo senza precedenti! Si sono registrate all\u0026rsquo;evento circa 170 persone e, contando anche quelle che non si sono registrate, contiamo di aver raggiunto oltre le 200 presenze in tutta la giornata.\nUn ringraziamento particolare va fatto ai docenti dell\u0026rsquo;ITC Capitini di Agliana che hanno accompagnato due classi e agli studenti dell\u0026rsquo;ITIS Silvano Fedi che per qualche ora hanno rinunciato ad occupare il loro istituto per tenere fede all\u0026rsquo;impegno di partecipare al LinuxDay.\nLa manifestazione si √® svolta nella nuovissima Biblioteca SanGiorgio, messa gentilmente a disposizione dal Comune di Pistoia ed √® stata suddivisa in due target particolari: la mattina √® stata dedicata a scuole, pubblica amministrazione ed aziende, mentre il pomeriggio sono stati affrontati temi di carattere piu\u0026rsquo; generale. E' ovviamente disponibile il programma delle conferenze che si sono svolte e sempre sulla stessa pagina, sar√† possibile a breve scaricare le slides degli interventi.\nAll\u0026rsquo;esterno della sala conferenze erano state allestite 6 postazioni con Ubuntu e Fedora installate per permettere ai visitatori di provare Linux direttamente. Lo staff del PtLUG era a disposizione dei visitatori per rispondere a domande tecniche oppure per installare Linux direttamente sui PC.\nUna delle attrazioni che hanno suscitato piu\u0026rsquo; interesse √® stato il videogioco da sala giochi dentro il quale era stato posizionato un PC con il Mame, che permetteva di giocare a moltissimi videogiochi che hanno fatto la storia delle sale giochi.\nGrazie al supporto del personale della biblioteca, sono state effettuate le registrazioni sia audio che video di tutte le conferenze. Non appena ci verr√† consegnato il DVD avr√≤ cura di rippare i contenuti e di pubblicarli da qualche parte in modo che siano accessibili anche a chi non √® potuto essere presente fisicamente.\nLa giornata del LinuxDay ci ha permesso di entrare in contatto con diverse nuove persone che si sono dimostrate interessate a partecipare al PtLUG e a dare una mano per quanto riguarda i prossimi progetti che realizzeremo.\nCi auguriamo che il successo di quest\u0026rsquo;anno possa ripetersi anche nei prossimi anni, riuscendo a coinvolgere un numero sempre piu\u0026rsquo; grande di persone, per riuscire a diffondere in modo ancora piu\u0026rsquo; capillare la cultura del software libero e opensource.\n","date":"2008-10-27T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/linuxday-2008-a-pistoia-un-successo-strepitoso/","title":"LinuxDay 2008 a Pistoia: un successo strepitoso!"},{"content":"\nGrazie ad un\u0026rsquo;iniziativa di Davide Dozza (Presidente dell\u0026rsquo;Associazione PLIO) e Michele Dalla Silvestra (Presidente di Italian Linux Society), il Presidente della Repubblica Napolitano era stato invitato ufficialmente all\u0026rsquo;edizione di Roma del LinuxDay 2008.\nPurtroppo i suoi numerosi impegni non hanno reso possibile confermare la propria presenza all\u0026rsquo;evento, ma si √® comunque interessato di esprimere il proprio appoggio all\u0026rsquo;iniziativa ed ha inviato un cordiale saluto a tutti quelli che parteciperanno al LinuxDay 2008 in tutta Italia.\nDi seguito un estratto della lettera, di cui potete trovare la scansione a questo indirizzo.\nIl Presidente Napolitano esprime apprezzamento per l\u0026rsquo;iniziativa che, nel diffondere l\u0026rsquo;iniziativa del software libero, concorre a far conoscere e a rendere accessibile la cultura informatica e le sue tecnologie consentendo cos√¨ la piu\u0026rsquo; ampia fruibilit√† del nuovo sistema di comunicazione ed informazione che su di esso si basa.\n","date":"2008-10-19T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/il-presidente-della-repubblica-napolitano-esprime-il-proprio-apprezzamento-per-il-linuxday/","title":"Il Presidente della Repubblica Napolitano esprime il proprio apprezzamento per il LinuxDay"},{"content":"\nE\u0026rsquo; notizia di questi giorni il fatto che Google abbia previsto un meccanismo di \u0026ldquo;sicurezza\u0026rdquo; che consentir√† a loro stessi di rimuovere automaticamente, dai telefonini GPhone che verranno venduti, le applicazioni non ritenute sicure. Google avr√† quindi la possibilit√† di controllare i propri dispositivi da remoto, accedere alla memoria del telefono e rimuovere quello che non desidera ci sia installato: chi ci assicura che non si mettano a controllare pure il testo degli SMS che inviamo o riceviamo, magari per inviarci pubblicit√† mirata a seconda delle nostre esigenze?\nDella stessa pasta sono fatti anche i dispositivi della Apple, in particolare l\u0026rsquo;iPhone. Anche questo dispositivo incorpora infatti un chip che impedisce alle applicazioni non consentite di girare sul telefonino. L\u0026rsquo;unico modo per installare applicazioni sull\u0026rsquo;iPhone √® quello di scaricarle dall\u0026rsquo;Apple Store, ed ovviamente Apple si riserva il diritto di decidere quali applicazioni possano apparire nello store e quali invece no, ed una nota nella licenza che devono firmare gli sviluppatori di applicazioni per iPhone, si dice anche che essi non possono in alcun modo dire pubblicamente che una loro applicazione √® stata esclusa dallo store. Tutto questo in nome della nostra \u0026ldquo;sicurezza\u0026rdquo;.\n","date":"2008-10-18T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/trusted-computing-perche-fidarsi-di-chi-non-si-fida-di-noi/","title":"Trusted Computing: perch√® fidarsi di chi non si fida di noi?"},{"content":"\nIl servizio che Google offre per consultare le mappe di quasi tutto il mondo, non ha certo bisogno di presentazioni. Ormai integrato in qualsiasi tipo di dispositivo, Google Maps ci permette di ricercare velocemente un indirizzo oppure un\u0026rsquo;attivit√† commerciale e di poterlo visualizzare sulla cartina.\nAvere una mappa fatta da altri puo\u0026rsquo; essere utile a volte, ma spesso puo' capitare di avere l\u0026rsquo;esigenza di creare una propria mappa (inserendo i propri punti di interesse) per condividerla magari con amici.\nMappe Personalizzate Google da la possibilit√† di utilizzare la loro enorme banca dati per poter costruire una mappa personalizzata a seconda delle proprie esigenze. Facciamo l\u0026rsquo;esempio di una persona che voglia condividere con altri tutte le birrerie dov\u0026rsquo;√® andato fino ad ora, indicandole sulla cartina e scrivendo anche una piccola recensione.\nPer poter creare una mappa personalizzata occorre avere un account Google (va benissimo quello che si usa per la posta di GMail), andare sul sito di Google Maps e cliccare su \u0026ldquo;Crea una nuova mappa\u0026rdquo;.\nCi vengono richiesti un titolo, una descrizione ed in particolare se vogliamo che questa mappa sia pubblica oppure privata. Da sottolineare il fatto che per privata si intende soltanto una mappa che non compare nei risultati di ricerca, ma che non richiede alcun tipo di autorizzazione per essere consultata. Chi conosce l\u0026rsquo;URL esatto della mappa quindi puo\u0026rsquo; consultarla senza alcun problema.\nA questo punto la mappa √® pronta per essere personalizzata. Tra le informazioni che possiamo inserire ci sono i punti di interesse, tracciare linee di percorso personalizzate ed infine evidenziare delle aree.\n##¬†Condivisione Mappe\nRiuscire a personalizzare una mappa √® di sicuro una gran cosa, ma ancora piu\u0026rsquo; utile √® poterlo fare con l\u0026rsquo;aiuto di piu\u0026rsquo; persone. Tramite Maps infatti √® possibile permettere ad altri utenti (che abbiano un Google account) di modificare la nostra mappa, inserendo altri punti di interesse, annotazioni, foto ecc\u0026hellip;\nInserendo l\u0026rsquo;email della persona con la quale vogliamo condividere la mappa, faremo in modo che questa riceva una mail di invito per poter iniziare a personalizzare la mappa.\nConclusioni Il mio invito √® quello di provare a crearsi una mappa personalizzata e condividerla con amici. Vedendo la procedura scritta puo\u0026rsquo; sembrare tutto molto piu\u0026rsquo; complicato di quanto lo sia in realt√†. Vi assicuro che dopo qualche prova, creare mappe personalizzate e condividerle sar√† un\u0026rsquo;operazione semplicissima e che vi permettera\u0026rsquo; di realizzare cose che fino a ieri pensavate impossibili.\n","date":"2008-10-16T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/creare-mappe-personalizzate-e-condivise-con-google-maps/","title":"Creare mappe personalizzate e condivise con Google Maps"},{"content":"\nPer l\u0026rsquo;ottavo anno consecutivo il Pistoia Linux User Group, di cui faccio parte, organizza l\u0026rsquo;edizione di Pistoia del LinuxDay, che si terr√† sabato 25 ottobre dalle ore 9:00 fino a sera.\nIl LinuxDay √® una manifestazione che si svolge ogni anno inoltre 100 citt√† d\u0026rsquo;Italia con lo scopo di diffondere l\u0026rsquo;utilizzo del sistema operativo Linux ed il software libero. Ogni evento viene organizzato in maniera indipendente e promosso dai singoli LUG (Linux User Group) locali.\nL\u0026rsquo;evento di Pistoia si svolger√† nella prestigiosa Biblioteca San Giorgio di Pistoia, situata in via Pertini ed ha ottenuto il patrocinio di Regione Toscana, Comune di Pistoia e Comune di Monsummano Terme (PT).\nAbbiamo suddiviso la giornata in due momenti principali: la mattina verr√† dedicata (ma non in modo esclusivo) a scuole, aziende e pubblica amministrazione. Il pomeriggio sara\u0026rsquo; invece dedicato a tutti gli utenti che conoscono ancora poco Linux o a chi lo vuole conoscere per la prima volta.\nL\u0026rsquo;ingresso alla manifestazione √® ovviamente gratuito ed aperto a tutti. Si consiglia in ogni caso di registrarsi online in modo da agevolare gli organizzatori dell\u0026rsquo;evento e per avere la possibilit√† di vincere i premi messi in palio dai nostri sponsor:\n2 licenze ActiveState per Komodo IDE 3 abbonamenti alla rivista Linux\u0026amp;C 100 gagliardetti con il logo PtLUG messi a disposizione da Ricami Nerozzi 10 affiliazioni annuali a Manuali.Net 10 corsi online Ubuntu Linux di Manuali.Net 10 router wireless FON 50 copie della rivista LinuxPro Di seguito il programma ufficiale dell\u0026rsquo;evento di Pistoia:\nMattina 09:00/09:15 - Introduzione (Andrea Grandi)\n09:15/09:30 - Spazio riservato istituzioni (Assessore Tommaso Braccesi del Comune di Pistoia)```\n09:30/10:00 - Spazio riservato SIS Informatica (Gruppo CNA)\n10:00/10:30 - Presentazione Progetto Wireless (Andrea Grandi e Alessandro De Filippo)```\n10:30/11:00 - Progetti opensource all\u0026rsquo;ITIS\n11:00/11:30 - Linux per aziende (Alessandro De Filippo)\n11:30/12:00 - PostgreSQL (Gabriele Bartolini di ItPUG)\n12:00/12:30 - Italc (Andrea Cappelli)\n12:30/13:00 - Domotica (Alessandro De Filippo)\nPomeriggio 15:00/15:30 - Perch√® Opensource (Alessandro De Filippo) 15:30/16:00 - Presentazione Ubuntu (Andrea Grandi) 16:00/16:30 - Presentazione Fedora (Lorenzo Villani) 16:30/17:00 - Registrare musica con Linux (Carlo Ascani) 17:00/17:30 - Firefox (Enrico Sorcinelli) 17:30/18:00 - Wikimedia (Lorenzo Losa) 18:00/18:30 - Giocare con Linux (Simone Vassili) 18:30/18:45 - Conclusione dei lavori (Andrea Grandi) Per essere informati sulle ultime novit√†, vi consiglio di visitare il sito web ufficiale dell\u0026rsquo;evento, dove potrete trovare informazioni piu\u0026rsquo; approfondite e tutti i dettagli per partecipare.\n","date":"2008-10-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/linuxday-2008-a-pistoia/","title":"LinuxDay 2008 a Pistoia"},{"content":"\nQuando in questi giorni ho appreso la triste notizia che il progetto da consegnare per l\u0026rsquo;esame di Laboratorio di Reti avrebbe dovuto essere realizzato in PHP, sono stato preso un po\u0026rsquo; dallo sconforto.\nPer anni mi sono sempre rifiutato di imparare ed utilizzare questo linguaggio ed ho persino declinato diverse offerte di lavoro, visto che gi√† sulla carta ne avevo sempre sentito parlare male. Adesso √® arrivato il momento di ingollare il rospo ed imparare almeno il minimo indispensabile alla realizzazione del progetto.\nHo approfittato della situazione per documentarmi un po\u0026rsquo; sul PHP e per ribadire alcuni motivi che per anni mi hanno tenuto lontano da questo linguaggio. I punti che seguono prendono spunto sia da considerazioni personali, sia da un ottimo articolo di Edwin Martin.\n1. Ricorsione?! Chi era costei\u0026hellip; La ricorsione, come molti di voi sapranno, √® un meccanismo che permette ad una funzione di chiamare se stessa. Viene impiegata nell\u0026rsquo;implementazione di moltissimi algoritmi, come ad esempio il Quick Sort. Se vengono generate troppe chiamate ricorsive in PHP, il linguaggio va letteralmente in palla e non funziona piu\u0026rsquo; correttamente. Questa cosa √® stata segnalata come bug e la motivazione che √® stata data dagli sviluppatori √® che PHP utilizza lo stack al posto dell\u0026rsquo;heap per le chiamate ricorsive. Questo cosa c\u0026rsquo;entra? Mi viene da chiedere\u0026hellip; eppure in altri linguaggi la ricorsione funziona benissimo!\n2. Molti moduli PHP non sono thread safe Anche se tutti i moduli del core di PHP sono garantiti thread safe, la maggior parte degli altri moduli non lo sono. Questo rende completamente inutile il fatto che Apache 2 supporti la modalit√† multithreaded: gli sviluppatori di PHP sconsigliano pure di utilizzare questa versione di Apache.\n3. PHP √® azzoppato per motivi commerciali Vi sembra che PHP sia un po\u0026rsquo; lento? Non avete provato la versione commerciale di Zend PHP, che garantisce maggiori prestazioni! La versione gratuita di PHP infatti non ha alcuna ottimizzazione e a meno di non utilizzare un qualche meccanismo di cache (come ad esempio APC) le prestazioni saranno basse.\n##¬†4. Nessun supporto ai Namespace\nSe due moduli hanno una funzione che si chiama read, non possono essere utilizzati contemporaneamente. Era stata proposta una soluzione a questo problema in PHP5, ma alla fine non √® stata inclusa nella release definitiva. L\u0026rsquo;unico modo per evitare la collisione dei nomi dei metodi √® quello di nominarli aggiungendo il nome del modulo all\u0026rsquo;inizio. Ecco perch√® non √® strano trovare metodi che ad esempio si chiamano xsl_xsltprocessor_transform_to_xml che di sicuro non aumentano la leggibilit√† del codice.\n5. Caratteri di formattazione delle date non standard La maggior parte dei linguaggi di programmazione utilizza uno standard per quanto riguarda i caratteri di formattazione delle date, che deriva da Unix e dal linguaggio C. PHP utilizza un proprio formato, completamente incompatibile.\n##¬†6. Inconsistenza nei nomi delle funzioni\nQuando i nomi dei metodi contengono piu\u0026rsquo; di una parola, solitamente ci sono tre modi diversi per poterli scrivere. Prendiamo ad esempio un\u0026rsquo;ipotetica funzione che restituisce il numero dei file aperti. Potremmo chiamarla getnumberofopenfiles, get_number_of_open_files oppure getNumberOfOpenFiles. Quale metodo utilizza PHP? Tutti e tre ovviamente! Oltre a questo √® opportuno far notare che i nomi dei metodi e delle funzioni non sono case sensitive.\n7. Assenza di un framework integrato Il modello piu\u0026rsquo; corretto per sviluppare un\u0026rsquo;applicazione web, sarebbe quello chiamato MVC, dove la parte di visualizzazione, la business logic e la validazione dei dati ed infine l\u0026rsquo;interazione con il database, sono parti separate del progetto.\nNella maggior parte dei siti scritti in PHP √® molto comune trovare sorgenti che includono tutti e tre questi aspetti in un unico file! Poche righe sopra viene fatta la connessione al database, poi c\u0026rsquo;√® una parte di visualizzazione di alcuni dati, verso la met√† ci sono le funzioni di validazione ed infine di nuovo altro codice html di visualizzazione. Credo che questo sia il peggiore dei modi di realizzare un\u0026rsquo;applicazione web. Pensate che sia facile per un grafico dover apportare modifiche alla parte di visualizzazione senza toccare il codice PHP? E viceversa\u0026hellip; pensate che sia facile per un programmatore, aggiungere codice PHP senza rischiare di scombinare il layout della pagina?\nAltri linguaggi con Ruby o Python ci hanno ormai abituati a framework come Rails e Django, rispettivamente. Per fortuna le cose sono in miglioramento anche su PHP, grazie a framework come CakePHP o Symfony.\n8. Mancanza del supporto Unicode Questa lacuna forse potra\u0026rsquo; non riguardarci da vicino, visto che il set di caratteri che utilizziamo in Europa ed in America √® ampiamente supportato, ma non √® certo cos√¨ per Cina, Giappone ed altre nazioni dove viene utilzzato un set di caratteri e di simboli molto diverso dal nostro. Tramite Unicode √® possibile supportare anche questi caratteri. PHP avr√† il supporto per Unicode solo nella futura versione 6.\n9. Lentezza Pensate che il Java sia un linguaggio lento? Beh, niente a confronto di PHP! Leggendo questo report si mettono in evidenza le scarse prestazioni di questo linguaggio. Persino Rasmus Lerdorf, il creatore di PHP ammette che non c\u0026rsquo;√® modo di migliorare le prestazioni di PHP. Rasmus tra l\u0026rsquo;altro sconsiglia persino l\u0026rsquo;utilizzo dei frameworks sopra citati (CakePHP e Symfony) perch√® rallenterebbero inutilmente le prestazioni dei siti web.\n10. Estrema facilit√† di utilizzo Ammetto che questo ultimo punto possa essere non condiviso da molte persone, si tratta infatti di una mia personalissima opinione. Il fatto che un linguaggio di programmazione sia troppo facile da usare, secondo me puo\u0026rsquo; presentare anche degli svantaggi. Permette infatti anche a chi ha scarse conoscenze di programmazione, di cimentarsi in progetti, con il rischio poi di far abbassare notevolmente la qualit√† del codice che si trova in giro. Non √® difficile infatti imbattersi in programmi scritti in PHP che all\u0026rsquo;apparenza possono risultare gradevoli ed accattivanti (magari perch√® scritti da persone che principalmente si occupano di web design), ma che sotto sotto sono dei veri e propri pastoni di codice mal scritto.\nConclusioni A favore di PHP possiamo sicuramente dire che si tratti di un linguaggio molto semplice da imparare ed ampiamente supportato dalla maggior parte dei servizi di hosting in tutto il mondo. A parte queste due motivazioni per√≤, non mi sentirei in alcun modo di consigliarlo per sviluppare un\u0026rsquo;applicazione web.\nSicuramente qualcuno mi fara\u0026rsquo; notare che lo stesso blog sul quale sto scrivendo √® scritto in linguaggio PHP. Per l\u0026rsquo;utilizzo che ne devo fare, Wordpress va piu\u0026rsquo; che bene, almeno per le mie esigenze. Questo non toglie che PHP soffra ugualmente di tutti i problemi che sono stati esposti sopra.\nE\u0026rsquo; mia intenzione che questo articolo sia di avvertimento a chi si sta per avvicinare per la prima volta al PHP o chi gi√† lo utilizza. Ci tengo per√≤ al fatto che non contenga imprecisioni, perch√® credo che servirebbero solo a screditare la natura stessa dell\u0026rsquo;articolo. Invito quindi i lettori che rilevassero imprecisioni a segnalarmele, indicandomi dove poter trovare maggiori informazioni per verificare la validit√† di quanto riportato.\n","date":"2008-10-09T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/dieci-buoni-motivi-per-non-utilizzare-php/","title":"Dieci buoni motivi per non utilizzare PHP"},{"content":"\nLa versione di Linux che viene installata sugli EeePC (Xandros Linux) da Asus, sebbene sia l\u0026rsquo;ideale per chi non ha mai utilizzato Linux e desidera un netbook semplice da usare, tuttavia non permette di sfruttare pienamente le potenzialit√† che l\u0026rsquo;EeePC ha.\nPoco tempo dopo l\u0026rsquo;uscita dei primi modelli degli EeePC sono iniziate quindi ad essere rilasciate distribuzioni alternative alla Xandros, ottimizzate per il netbook di Asus. E\u0026rsquo; ovviamente possibile installare una qualsiasi distribuzione Linux, ma ovviamente il lavoro da compiere per far funzionare tutte le periferiche sar√† maggiore rispetto a quello necessario con una distribuzione realizzata ad hoc.\nLa distribuzione che ho deciso di installare sul mio EeePC 901 √® la Ubuntu Eee 8.04.1.\nPer installare la Ubuntu Eee √® necessario scaricarla dal sito web dedicato e poi trasferirla su una chiavetta USB o su un disco USB esterno (visto che l\u0026rsquo;EeePC non √® dotato di lettore CD/DVD) utilizzando una utility chiamata Unetbootin e seguendo le istruzioni presenti sul wiki.\nDopo aver trasferito l\u0026rsquo;installazione sulla chiavetta USB dobbiamo inserirla nell\u0026rsquo;EeePC ed avviare premendo piu\u0026rsquo; volte il tasto Esc. Quando compare il menu di avvio, dobbiamo selezionare il disco USB dalla lista e premere Invio per continuare.\nNel caso la Ubuntu Eee non si dovesse avviare, i motivi possono essere diversi. Per prima cosa dobbiamo controllare nella sezione Boot del BIOS se il disco USB √® al primo posto nell\u0026rsquo;ordine dei dischi da cui fare il boot. Se non dovesse avviarsi nemmeno in questo caso, √® possibile che la chiavetta USB non sia compatibile: a me √® successo di non essere in grado di utilizzare una chiavetta USB da 1 Gb che avevo e sono dovuto ricorrere ad un disco esterno USB.\nSe riusciamo ad avviare la Ubuntu Eee, saremo in grado di utilizzare l\u0026rsquo;installer grafico senza alcun problema. Il mio consiglio √® quello di scegliere il partizionamento manuale e di utilizzare il primo disco SSD da 4 Gb per la root / ed il disco SSD da 16 Gb per la /home.\nLe caratteristiche della Ubuntu Eee la rendono praticamente la distribuzione perfetta per gli EeePC:\nsupporto per gli Asus EeePC 701, 900, 900A, 901, 1000 e 1000H\noccupa 1.8 Gb di spazio\nKernel ottimizzato di Adam con supporto per tutte le periferiche degli EeePC```\ninterfaccia Notebook Remix predefinita (√® possibile cambiarla tramite un\u0026rsquo;apposita utility)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Sebbene il setup e la configurazione predefiniti di Ubuntu Eee siano quasi perfetti, tuttavia sono necessari ancora alcuni ritocchi per fare in modo che tutto funzioni regolarmente. Per prima cosa occorre **commentare** l\u0026#39;ultima riga di **/etc/fstab**, quella relativa al cdrom, altrimenti si otterr√† un errore durante la fase di mount quando si inserisce una chiavetta USB. Per ottenere il meglio dal **risparmio energetico**, consiglio di installare gli **script ACPI** di **Murat** che potete trovare a questo indirizzo: \u0026lt;http://www.informatik.uni-bremen.de/~elmurato/EeePC/Hardy_ACPI_scripts-EeePC_900A_901_1000.tar.gz\u0026gt; Gli script permettono di attivare/disattivare alcune periferiche come il bluetooth, la webcam, la wifi ecc... consentendo alla batteria di durare piu\u0026#39; a lungo. Per l\u0026#39;installazione sono sufficienti i seguenti passaggi: ```shell tar xfvz Ubuntu_ACPI_scripts-EeePC_900A_901_1000.tar.gz cd Ubuntu_ACPI_scripts-EeePC_900A_901_1000/ chmod +x install.sh sudo ./install.sh` In particolare le funzionalit√† che vengono aggiunte sono le seguenti (gli hotkey sono quei tasti hardware posizionati sopra ad i tasti F1, F2, ecc\u0026hellip;):\nFn+F1 Standby Fn+F2 WLAN-toggle Fn+F3/F4 Brightness Fn+F5 VGA-toggle Fn+F6 Taskmanager Fn+F7/F8/F9 Volume new hotkey Display-toggle (internal) new hotkey Bluetooth-toggle new hotkey CPU frequency control or user-defined new hotkey Webcam-toggle or user-defined Gli script di Murat purtroppo introducono un piccolo bug: viene disattivata la funzionalit√† \u0026ldquo;Dim when idle\u0026rdquo; del display (in pratica non viene abbuiato lo schermo quando non si usa l\u0026rsquo;EeePC). Per ripristinare questa funzionalit√† √® sufficiente eseguire questo comando:\n1 sudo cp /etc/acpi/backup/hal-system-lcd-set-brightness-linux /usr/lib/hal/scripts/linux/ A questo punto la configurazione dovrebbe essere al completo. Si consiglia di riavviare l\u0026rsquo;EeePC per rendere effettive tutte le modifiche. Per ulteriori trucchetti su come ottimizzare la configurazione, vi consiglio di visitare direttamente il wiki di Ubuntu Eee dove potrete trovare articoli piu\u0026rsquo; approfonditi.\n","date":"2008-10-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/installazione-e-configurazione-di-ubuntu-eee-8041-su-asus-eeepc-901/","title":"Installazione e configurazione di Ubuntu Eee 8.04.1 su Asus EeePC 901"},{"content":"\nL\u0026rsquo;aggiornamento del BIOS su un Asus EeePC puo\u0026rsquo; essere fatto in una maniera che √® completamente indipendente dal tipo di sistema operativo utilizzato.\nPer prima cosa occorre scaricare dal sito della Asus, nell\u0026rsquo;apposita pagina di supporto, l\u0026rsquo;ultima versione del BIOS, facendo ben attenzione a selezionare il modello di EeePC che possediamo.\nUna volta scaricato il file, dobbiamo decomprimerlo e copiarlo su una chiavetta USB o su un disco esterno USB, avendo cura di rinominarlo con il numero del modello del nostro EeePC. Se ad esempio possediamo l\u0026rsquo;Asus EeePC 901, dovremo rinominare il file in 901.ROM\nA questo punto dobbiamo inserire la chiavetta USB nel nostro EeePC e riavviare il computer, premendo ALT+F2 durante la fase iniziale di avvio.\nL\u0026rsquo;EeePC avvia l\u0026rsquo;utility di aggiornamento del BIOS che provvede a cercare sulla chiaveta USB il file \u0026ldquo;901.ROM\u0026rdquo;. Si consiglia di eseguire questa operazione alimentando l\u0026rsquo;EeePC tramite l\u0026rsquo;adattatore di corrente e di non affidarsi alla batteria perch√® se si dovesse improvvisamente scaricare durante l\u0026rsquo;aggiornamento, il BIOS rimarrebbe in uno stato inutilizzabile.\nDopo pochi minuti l\u0026rsquo;aggiornamento sara\u0026rsquo; completato ed il portatile verr√† riavviato. Al primo avvio sara\u0026rsquo; necessario riconfigurare nuovamente i parametri del BIOS, perch√® essi vengono cancellati quando si esegue l\u0026rsquo;aggiornamento.\nIl mio consiglio infine √® quello di far effettuare l\u0026rsquo;aggiornamento ad una persona esperta, perch√® in caso di errori l\u0026rsquo;EeePC diventerebbe inutilizzabile.\n","date":"2008-10-04T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/come-aggiornare-il-bios-dellasus-eeepc/","title":"Come aggiornare il BIOS dell'Asus EeePC"},{"content":"\nControlEee √® una piccola applicazione che ho scritto utilizzando Python/Qt4 e che permette di abilitare/disabilitare i dispositivi del bluetooth, della webcam e della wlan su un Asus EeePC.\nInstallando una versione personalizzata di Linux sugli EeePC (come ad esempio la Ubuntu-eee), non si ha la possibilit√† di attivare/disattivare questi dispositivi in maniera semplice (√® possibile farlo solo da riga di comando) e di conseguenza si rischia di tenere attivate queste periferiche anche se non le utilizziamo, con lo svantaggio di consumare inutilmente piu\u0026rsquo; batteria di quella di cui abbiamo bisogno.\nNon trovando niente di semplice di gi√† pronto in giro, mi sono deciso a scrivere questa utility. Al momento √® in hosting presso Google Code e la potete trovare a questo indirizzo: http://code.google.com/p/controleee/\nAl momento l\u0026rsquo;applicazione √® stata testata soltanto su un Asus EeePC 901 con la distribuzione Ubuntu-eee 8.04.1, non √® quindi garantito il funzionamento anche sugli altri modelli e/o utilizzando altre distribuzioni.\n","date":"2008-10-01T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/controleee-control-panel-for-eeepc/","title":"ControlEee - Control panel for EeePC"},{"content":"\nLa modalit√† RAID1 (detta anche modalit√† mirror) √® una particolare configurazione nella quale vengono utilizzati due hard disk al posto di uno, per leggere/scrivere gli stessi dati. Questo permette di avere un\u0026rsquo;esatta copia degli stessi dati su due dischi diversi, facendo in modo che se uno si dovesse rompere, l\u0026rsquo;altro conterrebbe una copia esatta dei dati, permettendoci quindi di sostituire il disco rotto senza alcuna perdita.\nQuello che ci si aspetta quando uno dei due dischi si rompe √® che il sistema continui a funzionare normalmente, magari avvisandoci della rottura di uno dei due dischi.\nIl comportamento di Ubuntu 8.04 purtroppo non segue questa procedura. Gli script di avvio sono infatti configurati in modo che venga impedito il boot di sistema se il RAID risulta degradato. Questo comportamento √® stato inizialmente segnalato come bug su launchpad.net e successivamente confermato e marcato come \u0026ldquo;risolto\u0026rdquo; per la prossima release di Ubuntu, la 8.10 che dovrebbe uscire alla fine di ottobre.\nLo sviluppatore che si √® occupato di risolvere il problema, Dustin Kirkland, ha anche creato un\u0026rsquo;apposita pagina sul wiki di Ubuntu dove spiega uno scenario reale e come il problema √® stato risolto.\nCi saremmo aspettati di veder incluso questo fix anche nell\u0026rsquo;attuale Ubuntu 8.04, visto che si tratta di una LTS (non tutti vorranno abbandonare una versione la cui stabilit√† e gli aggiornamenti sono mantenuti per almeno 3 anni) solo per risolvere un problema col RAID1, ma per adesso non sembra rientrare nei piani degli sviluppatori.\n","date":"2008-09-25T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-804-in-raid1-non-puo-fare-il-boot-con-un-solo-disco/","title":"Ubuntu 8.04 in RAID1 non pu√≤ fare il boot con un solo disco"},{"content":"\nSiete sviluppatori di applicazioni per iPhone e la Apple ha appena rifiutato di includere la vostra applicazione all\u0026rsquo;interno del proprio App Store? Da oggi non potete piu\u0026rsquo; lamentarvi pubblicamente, un NDA lo vieta esplicitamente.\nNei giorni precedenti, almeno un paio di sviluppatori si erano visti rifiutare da parte di Apple, l\u0026rsquo;inclusione della propria applicazione all\u0026rsquo;interno dello store e si erano pubblicamente lamentati perch√® ritenevano si trattasse di un\u0026rsquo;ingiustizia, visto che non avevano violato in alcun modo il regolamento che riguarda le applicazioni che si possono scrivere.\nNel primo caso era stata creata un\u0026rsquo;applicazione per scaricare i podcast direttamente sull\u0026rsquo;iPhone invece di ascoltarli in streaming come permette iTunes. Secondo Apple questa applicazione duplica le funzionalit√† che sono gi√† incluse in iTunes e pertanto non puo\u0026rsquo; essere accettata.\nNel secondo caso era stata invece creata un\u0026rsquo;applicazione che permetteva di controllare la posta su piu\u0026rsquo; account Gmail senza dover fare logout e login da ogni account per passare da un account all\u0026rsquo;altro. Anche in questo caso l\u0026rsquo;applicazione √® stata rifiutata da Apple.\nEntrambi gli autori, come potete leggere dai loro blog, si sono pubblicamente lamentati di questo rifiuto, e dopo qualche giorno la Apple ha aggiornato il messaggio che viene mandato agli sviluppatori ai quali viene rifiutata l\u0026rsquo;inclusione di un\u0026rsquo;applicazione nell\u0026rsquo;App Store, aggiungendo questo NDA: \u0026ldquo;THE INFORMATION CONTAINED IN THIS MESSAGE IS UNDER NON-DISCLOSURE\u0026rdquo;.\nApple quindi impedisce di fatto di rivelare (legalmente) che una propria applicazione sia stata rifiutata dall\u0026rsquo;App Store.\nPersonalmente trovo sempre piu\u0026rsquo; ridicola questa politica protezionista intrapresa da Apple, che non sta facendo altro che attirare critiche su di se e tener lontani ottimi sviluppatori che altrimenti sarebbero ben felici di scrivere applicazioni per l\u0026rsquo;iPhone. Staremo a vedere in che modo si comporter√† Google con il proprio repository online di applicazioni.\n","date":"2008-09-24T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/apple-vieta-agli-sviluppatori-di-lamentarsi-pubblicamente-per-app-store/","title":"Apple vieta agli sviluppatori di lamentarsi pubblicamente per App Store"},{"content":"\nSecondo quanto riportato sulla mailing list di sviluppo di Ubuntu, un bug presente nella versione 2.6.27 del kernel Linux potrebbe danneggiare irreparabilmente le schede ethernet dotate di chipset Intel GigE che utilizzano il driver e1000e.\nSecondo le prime analisi, il bug andrebbe a sovrascrivere la eprom di queste schede di rete, rendendole inutilizzabili.\nL\u0026rsquo;attuale alpha 6 di Ubuntu contiene questo bug, si consiglia quindi di non utilizzarla se si possiede tale scheda, ma di attendere almeno la prossima release (la beta dovrebbe uscire il 2 ottobre), dove il bug √® gi√† stato corretto.\n","date":"2008-09-24T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/un-bug-del-kernel-linux-2627-potrebbe-danneggiare-le-schede-ethernet-con-driver-e1000e/","title":"Un bug del Kernel Linux 2.6.27 potrebbe danneggiare le schede ethernet con driver e1000e"},{"content":"\nSecondo quanto dichiarato da Nokia (che negli ultimi device usciti addirittura visualizza un messaggio di avviso sul display quando il dispositivo √® completamente carico), √® stato calcolato che se anche solo tutti gli utenti Nokia scollegassero i loro carica batterie quando la carica √® completata, si potrebbe risparmiare energia per alimentare circa 100.000 case di media dimensione in tutta Europa.\nQuando si lascia il carica batterie inserito nella presa di casa infatti, viene ugualmente consumata una certa quantit√† di energia che noi riteniamo irrilevante o addirittura non esistente. A leggere i dati di Nokia non √® cos√¨.\nQuesto ovviamente non vale soltanto per i loro carica batterie, ma anche per quelli dei cellulari di altre marche. Se vogliamo dare il nostro piccolo contributo per il risparmio energetico mondiale, tutto quello che dobbiamo fare √® scollegare il carica batterie dalla parete una volta che abbiamo finito di ricaricare il cellulare.\n","date":"2008-09-23T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/scollegate-i-carica-batterie-quando-non-li-usate/","title":"Scollegate i carica batterie quando non li usate!"},{"content":"\nCon circa 30 minuti di ritardo (maledetto stinco di maiale della sera prima!) arriviamo al C-base. La sede del C-base √® veramente straordinaria: costruita sulle fondamenta di un vecchio edificio lungo le rive del fiume, ha al suo interno ben due bar, tre sale conferenza, e tantissime altre stanze dove vengono fatte altre attivit√† (una scuola di musica, una scuola di ballo ecc\u0026hellip;).\nDopo aver ritirato i nostri badge, ci accomodiamo nella sala principale dove Ari Jaaksi, il vice-presidente di Nokia, sta tenendo il talk introduttivo della giornata. La sala √® stracolma di persone e siamo quindi costretti a sistemarci in piedi in fondo alla sala.\nIl talk successivo √® a cura di Jay Sullivan, sviluppatore di del team di Mozilla. Non vengono annunciate particolari novit√†, il talk che seguir√† sar√† molto piu\u0026rsquo; interessante.\nHarri Kiljander di Nokia ci presenta alcune delle novit√† che saranno presenti in Maemo 5 e nei futuri device. Tra le cose piu' importanti che vengono messe in risalto, ci sar√† finalmente il supporto per il multi touch.\nDopo un altro paio di talk ed una breve pausa per riorganizzare le idee, arriva il momento tanto temuto: quello di tenere il talk! Il motivo per cui sono andato al Summit infatti era per tenere un talk (seppur breve) su due plugin (Pluthon e ESBox) per Eclipse che vengono utilizzati per sviluppare applicazione per Maemo. Nei cinque minuti messi a disposizione, riesco per fortuna a dire quelle poche cose che mi ero \u0026ldquo;preparato\u0026rdquo;. Onestamente non avevo preparato per√≤ alcuna slide, e questo non mi √® stato di grande aiuto. Ho pensato subito che se avessi avuto con me anche 5 o 6 slide che sintetizzavano quello che avrei dovuto dire, sarebbe stato tutto molto piu\u0026rsquo; facile. Oltretutto il talk doveva essere in inglese.\nFinalmente arriva l\u0026rsquo;ora di pranzo. Veniamo tutti dirottati in una sala al piano terra dove gli organizzatori hanno fatto arrivare vassoi di crostini, panini e schiacciatine di ogni tipo!\nUna volta mangiato qualcosa, ci trasferiamo tutti in un\u0026rsquo;altra zona del C-base, ovvero quella somigliante ad una stazione spaziale.\nIl C-base infatti, secondo una leggenda metropolitana, sarebbe costruito soprai resti di un\u0026rsquo;antica stazione spaziale.\nEntrando nel cuore del C-base in effetti sembra di entrare proprio all\u0026rsquo;interno di una stazione spaziale. Le poltrone sono fatte come le sedie di uno shuttle, al muro ci sono incastonati pezzi di schede madre, processori ed altri componenti hardware. La \u0026ldquo;stazione\u0026rdquo; ospita anche un bar dove viene venduta dell\u0026rsquo;ottima birra freschissima a soli 2‚Ç¨ a bottiglia!\nIl pomeriggio del summit prosegue con ben tre sessioni parallele di talk e a fine serata viene organizzata una festa all\u0026rsquo;interno del C-base. Questa volta la birra viene offerta gratuitamente! Ci sistemiamo tutti intorno ai tavoli, ognuno con il proprio tablet a parlare fra noi, chattare, leggere email e qualcuno a bloggare in tempo reale quello che succede intorno. Durante la serata ho avuto modo di conoscere meglio Alberto Garcia, uno sviluppatore spagnolo con il quale collaboro per il progetto Vagalume (un player Last.fm di cui curo la traduzione in italiano). Ho molto apprezzato inoltre che Quim Gil (marketing manager di Nokia per il progetto Maemo) sia venuto da ognuno di noi a chiederci le nostre impressioni, le nostre idee e tutto quello che potevamo dirgli sulla prima giornata del summit.\nDopo essere stati alla festa fino a circa mezzanotte, faccio rientro in albergo, visto che la mattina dopo ci sarebbe stata un\u0026rsquo;altra giornata intensa di conferenze e talk tecnici.\n","date":"2008-09-21T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/maemo-summit-berlino-giorno-2/","title":"Maemo Summit (Berlino) - giorno 2"},{"content":"Come da programma, sono arrivato a Berlino alle 16:30 circa e dopo aver raggiunto l\u0026rsquo;Hotel dove alloggio, ho cercato per prima cosa una connessione wireless da poter utilizzare in camera.\nL\u0026rsquo;Hotel dove mi trovo mette a disposizione una wireless a pagamento, alla \u0026ldquo;modica\u0026rdquo; cifra di 9 euro al giorno! Controllando bene ho visto che era disponibile anche un access point della T-Mobile (sempre a pagamento) che offriva una connessione senza limiti per 30 giorni a 29‚Ç¨. Pur dovendo rimanere soltanto 5 giorni ho optato per questa soluzione. Una piccola nota per chi si trovasse a volerla utilizzare: la velocit√† di upload √® quella di una normale ADSL, ed il tempo di ping √® attorno agli 80ms, la velocit√† di download per√≤ √® bassissima, con solo 300 kbps, sufficienti appena per utilizzare Skype e navigare.\nUna volta connesso mi sono messo in contatto con i miei colleghi del summit, in particolare con i due italiani che alloggiano nel mio stesso hotel. Dopo essermi ambientato, mi sono subito aggiornato sulle novit√† che riguardano Maemo, che erano state annunciate in questi giorni all\u0026rsquo;Osim:\nun nuovo device che verr√† fornito con un processore piu\u0026rsquo; potente di quello attuale, ovvero un OMAP3```\nsupporto HSPA di serie\nuna videocamera di qualit√† migliore\npiu\u0026rsquo; spazio di archiviazione sul dispositivo\nrilascio di Maemo 5\nQuello che ancora non √® stato detto √® se Maemo 5 sara\u0026rsquo; compatibile con gli attuali dispositivi N800/N810: Maemo 5 avra\u0026rsquo; il supporto per OpenGL che attualmente i dispositivi non hanno. Si pensa quindi che possa essere rilasciata una particolare versione del sistema, senza effetti grafici OpenGL, proprio per mantenere la compatibilit√† con questi dispositivi. In caso contrario gli utenti saranno costretti ad acquistare un nuovo dispositivo per poter godere delle nuove feature di Maemo 5.\nAll\u0026rsquo;ora di cena ho avuto modo finalmente di conoscere Daniele Maio, uno degli italiani presenti al summit. Devo dire che Berlino (e sopratutto la zona di Alexander Platz) ci ha abbastanza disorientati! Non √® stato cos√¨ facile come credevamo trovare un posto tipico dove poter cenare. Per la strada si incontravano diversi McDonald, Burger King, Doner Kebab ecc\u0026hellip; ma pochissimi pub tipici.\nFinalmente la nostra fatica √® stata ampiamente ripagata e ci siamo sistemati in una birreria dove abbiamo ordinato, oltre a due birre grandi, un ottimo stinco di maiale con crauti, patate, cetriolo e senape.\nFinita la cena siamo subito rientrati, visto che la mattina dopo alle ore 9:00 si sarebbero aperte le porte del C-base per le conferenze in programma.\n","date":"2008-09-20T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/maemo-summit-berlino-giorno-1/","title":"Maemo Summit (Berlino) - giorno 1"},{"content":"\nGrazie a Nokia, avr√≤ l\u0026rsquo;occasione fra pochi giorni di partecipare al Maemo Summit che si terr√† a Berlino. Si svolger√† nei giorni di venerdi 19 e sabato 20 settembre e sar√† ospitato nella splendida sede del C-base.\nIl Maemo Summit √® un meeting degli sviluppatori e appassionati di Maemo, la piattaforma utilizzata sugli internet tablet della Nokia. Sar√† un\u0026rsquo;occasione per conoscere di persona tantissima gente con la quale fino ad ora ho avuto a che fare soltanto tramite la mailing list o il canale IRC.\nNei prossimi giorni sper√≤ di riuscire a postare, quasi in tempo reale e connessione internet permettendo, un report dettagliato di quello che verr√† fatto all\u0026rsquo;interno del C-base. Non mancheranno ovviamente le fotografie, che avr√≤ cura di pubblicare su Flickr!\n","date":"2008-09-17T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/maemo-summit-sto-arrivando/","title":"Maemo Summit sto arrivando!"},{"content":"\nPer coloro che utilizzano Linux, spiegare cosa si un LUG mi pare una cosa quasi superflua, in ogni caso vi rimando all\u0026rsquo;apposita pagina di Wikipedia.\nCome saprete, in Italia ci sono piu\u0026rsquo; di 100 LUG che si occupano di diffondere l\u0026rsquo;utilizzo di Linux e del software opensource e di offrire supporto ai neofiti. Molti neo-utenti Linux per√≤ (chi trova Linux allegato ad una rivista in edicola, chi prende il cd da un amico ecc\u0026hellip;) non sanno che cosa sia un LUG e a cosa possa servire.\nDa questo \u0026ldquo;problema\u0026rdquo; √® nata l\u0026rsquo;idea: perch√® non sfruttare una delle distribuzioni piu\u0026rsquo; note al momento (e di sicuro la piu\u0026rsquo; utilizzata dai principianti) per diffondere maggiormente i LUG?\nIn pratica l\u0026rsquo;utente dovrebbe, una volta impostata durante l\u0026rsquo;installazione la citt√† dove vive, poter accedere tramite il menu Help ad un \u0026ldquo;Supporto live\u0026rdquo; che a sua volta dovrebbe aprire una finestrina con una mappa che gli mostrerebbe i LUG piu\u0026rsquo; vicini alla citt√† in cui vive.\nChe ne pensate? Se credete che l\u0026rsquo;idea possa essere interessante, non dovete far altro che votarla tramite questa pagina: http://brainstorm.ubuntu.com/idea/12932/\nLe idee piu\u0026rsquo; votate verranno prese in considerazione dal team di sviluppo di Ubuntu e probabilmente implementate ed inserite nella prossima versione.\n","date":"2008-09-08T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/vorreste-che-il-vostro-lug-fosse-integrato-nellhelp-di-ubuntu/","title":"Vorreste che il vostro LUG fosse integrato nell'Help di Ubuntu?"},{"content":"\nFennec is a particular version of Mozilla, designed for handled devices and internet tablets. With the latest development version, stability has been improved, but the application is still a bit slow and \u0026ldquo;memory hungry\u0026rdquo;. Speed an memory improvements are scheduled for the next release (Alpha1 - September 9, 2008).\nLatest available version, Fennec M7, has the following improvements:\nInitial Add-on Manager support has landed. Tap \u0026ldquo;+\u0026rdquo; button in the sidebar to display the Add-on Manager. Use it to install, view and remove add-ons. Use the application menu button to dismiss the panel. Clicking on an add-on XPI in a webpage will also display the manager. The current UX design is not final.```\nThe top URL bar has been changed to work as designed: The bar will scroll into view at the top of the web content or will float over content otherwise.```\nSupport for kinetic scrolling has been added to the web content.\nSupport for non-modal Password Manager UI was added.\nSome tabbed browsing fixes.\nSome zooming fixes.\nSome stability fixes.\nTo install it on your tablet, you\u0026rsquo;ve to configure Application Manager with the following parameters:\nWeb Address: ftp://ftp.mozilla.org/pub/mobile/\nDistribution: chinook (Note: The chinook builds work on diablo as well.)```\nComponents: release\nIf you\u0026rsquo;re not sure or if you want further instructions about installing Fennec, you can find a step by step guide on Mozilla website.\nNote: M7 supports the Maemo chinook \u0026amp; diablo distributions.\n","date":"2008-08-31T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/mozilla-fennec-on-nokia-n800810/","title":"Mozilla Fennec on Nokia N800/810"},{"content":"\nE\u0026rsquo; uscito il numero 16 di Full Circle Magazine, la rivista gratuita dedicata ad Ubuntu Linux.\nIn questo numero troverete:\nCommand and Conquer - Creating And Moving Files.\nHow-To: Create Your Own Ubuntu, Create Your Own Server Part 8, Using GIMP Part 5 and GNOME-Look Guide.```\nMy Story - Out With The New, In With The Old\nMy Opinion - GNOME And KDE Themes\nMOTU Interview - Jamie Strandboge\nTop 5 - Twitter Clients\nPotete scaricare la rivista (per adesso in inglese ma nelle prossime settimane sar√† disponibile anche la traduzione in italiano) da questo indirizzo: http://fullcirclemagazine.org/issue-16/\n","date":"2008-08-30T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/full-circle-magazine-16-disponibile-per-il-download/","title":"Full Circle Magazine #16 disponibile per il download"},{"content":"\nI Nokia Internet Tablet (N800/N810) che hanno l\u0026rsquo;ultimissimo firmware OS2008 (diablo release), non comprendono purtroppo un plugin Flash molto aggiornato. La versione 9.0r31 fornita con l\u0026rsquo;OS2008 risulta purtroppo un po\u0026rsquo; obsoleta per alcuni siti web (come ad esempio Facebook).\nGrazie alla community di MaemoApps.org √® stata creata una patch che permette di installare la versione 9.0r48 in modo molto semplice. E\u0026rsquo; sufficiente installare il seguente pacchetto sul proprio tablet: http://timeless.justdave.net/maemo/flash-player-r48-0.1.deb\nFonte: http://www.internettablettalk.com/forums/showthread.php?t=22862\n","date":"2008-08-18T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/installare-il-plugin-flash-90r48-sui-nokia-internet-tablet-os2008/","title":"Installare il plugin Flash 9.0r48 sui Nokia Internet Tablet (OS2008)"},{"content":"\nA new update for Nokia Os 2008 is available for Nokia N810 (and I suppose N800 too).\nAll you have to do is connect to Internet, refresh package list and install the updates.\nThe main application that have been updated are Mail client and web browser. Map application has been updated too.\nThe total size to download is about 19 Mb and for the first time, no re-flash is required to update N810 firmware. At the end of the installation you\u0026rsquo;re only required to restart the device.\nN.B: be sure to have at least 19Mb free on the device, else the upgrade will fail.\n","date":"2008-08-13T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/os-2008-4200830-available-ota/","title":"Os 2008 4.2008.30 available OTA"},{"content":"Chi l\u0026rsquo;ha detto che all\u0026rsquo;interno di un LUG vengono realizzati soltanto guide e howto tecnici? Anche i pinguini dovranno pur mangiare, non trovate?\nGrazie alla nostra pinguina Laura, il PtLUG √® lieto di presentarvi il \u0026ldquo;Crepes HowTo\u0026rdquo;, una video-guida che spiega come preparare le crepes alla Nutella!\nGustatevi il video\u0026hellip; e le crepes!\n","date":"2008-08-09T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/crepes-howto-come-preparare-le-crepes-alla-nutella/","title":"Crepes HowTo: come preparare le crepes alla Nutella!"},{"content":"Prendendo spunto da alcuni post apparsi sulla versione inglese di Planet Ubuntu, ho deciso di provare questo comando:\n1 history | awk \u0026#39;{a[$2]++ } END{for(i in a){print a[i] \u0026#34; \u0026#34; i}}\u0026#39; | sort -rn | head che dovrebbe stampare la lista dei comandi piu\u0026rsquo; digitati nella bash della vostra macchina Linux. Il risultato √® stato il seguente:\n1 2 3 4 5 6 7 8 9 10 11 history | awk \u0026#39;{a[$2]++ } END{for(i in a){print a[i] \u0026#34; \u0026#34; i}}\u0026#39; | sort -rn | head 4884 git 1023 eval 382 isort 381 docker-compose 379 nox 318 cd 305 ls 228 docker 224 pip 151 workon interessante, non trovate?!\n","date":"2008-08-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/quali-sono-i-comandi-bash-che-usate-di-piu/","title":"Quali sono i comandi bash che usate di piu'?"},{"content":"Secondo una denuncia fatta dal Washington Post e ripresa poi anche da un quotidiano italiano, la situazione privacy per chi viaggia negli Stati Uniti sta diventando sempre piu\u0026rsquo; critica.\nUn documento inviato a tutti i principali agenti di controllo (aeroporti, porti, frontiere ecc\u0026hellip;) contenente una policy di comportamento per quanto riguarda i controlli da fare a chi entra negli Stati Uniti, spiega che qualsiasi tipo di apparecchio elettronico puo\u0026rsquo; essere sequestrato ed esaminato senza che esista alcun sospetto particolare o ci sia una ragione precisa per farlo.\nLa policy prevede che possano essere sequestrati PC, notebook, cellulari, iPod, dischi USB e tutti quei dispositivi in grado di memorizzare informazioni, indistintamente a tutti i cittadini che entrano negli USA, senza che vi sia una ragione particolare.\nI dati acquisiti possono essere esaminati sul posto oppure trattenuti per essere verificati in altra sede. La policy purtroppo non dice nulla riguardo a cosa si debba fare dei dati sensibili delle persone (dati sanitari, finanziari ecc\u0026hellip;).\nVale davvero la pena andare a spendere i propri soldi in un paese che, con la scusa della sicurezza e della lotta al terrorismo, ficca il naso negli affari di tutti, facendo vivere le persone in un continuo stato di allerta e di terrore, piu\u0026rsquo; di quanto non facciano i veri terroristi?\nCapisco che in questo modo ci sia anche la possibilit√† di beccare veramente qualche malintenzionato, ed in questo caso non ci sarebbe niente di male, ma a che costo viene fatto tutto questo?\n","date":"2008-08-01T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/viaggiate-negli-usa-possono-sequestrarvi-il-pc-senza-motivo/","title":"Viaggiate negli USA? Possono sequestrarvi il PC, senza motivo"},{"content":"\nPremetto di non aver certo scoperto l\u0026rsquo;acqua calda, visto che si tratta di una feature di Java 5. Pochi giorni fa mi sono imbattuto in una funzionalit√† di Java che non avevo mai avuto modo di utilizzare. Si tratta della annotazioni standard.\nGrazie alla segnalazione di un amico ed al post che mi ha passato, ho potuto fare chiarezza su questo argomento.\nSi tratta di tre annotazioni che possiamo utilizzare nel codice Java: @Deprecated, @Override, @SuppressWarnings.\n@Deprecated: come il nome ci suggerisce, se utilizzato prima della definizione di un metodo o di una classe, fara\u0026rsquo; stampare un messaggio di avviso al compilatore Java che ci avviser√† che il metodo √® appunto obsoleto. Un esempio del suo utilizzo:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // class @Deprecated public class SomeClass { // field @Deprecated public int field; // constructor @Deprecated public SomeClass() { } // method @Deprecated public void method() { } } @Override: si utilizza per avvisare esplicitamente il compilatore che stiamo ridefinendo un metodo. Nel caso commettessimo un errore di digitazione nel scrivere il nome del metodo, il compilatore ci avviserebbe che nella classe padre non esiste un nome con quel metodo che abbiamo specificato. Un esempio del suo utilizzo:\n1 2 3 4 5 6 7 8 public class MyClass { // Won\u0026#39;t compile - there is no toStirng method on java.lang.Object. @Override public String toStirng() { return \u0026#34;MyClass toString implementation\u0026#34;; } } @SuppressWarnings: quest\u0026rsquo;ultima notazione invece, viene utilizzata per fare in modo che il compilatore \u0026ldquo;chiuda un occhio\u0026rdquo; su eventuali warnings rilevati nel codice.\n","date":"2008-07-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/utilizzare-la-annotazioni-standard-in-java/","title":"Utilizzare le annotazioni standard in Java"},{"content":"\nIl tanto atteso sistema operativo basato su Linux e Java, che Google sta sviluppando in questi mesi, √® stato portato sul dispositivo Nokia N810.\nGrazie al lavoro di alcune persone √® stato creato un installer che permette in pochi semplici passi di installare Android sul proprio tablet, senza ovviamente rendere il tablet inutilizzabile, ma permettendo una sorta di multi boot.\nL\u0026rsquo;installazione, come gi√† anticipato, √® davvero molto semplice: bisogna solo assicurarsi di avere almeno 135 Mb di spazio libero sulla memory card.\nPrima di procedere con l\u0026rsquo;installazione, dopo aver fatto un BACKUP COMPLETO dei dati presenti sul proprio tablet, dobbiamo scaricare sul nostro PC i seguenti file:\nImmagine compressa di Android (md5sum: 84c2ceb6164f8f5bf60ddbc1dbe8a62b)```\nInstaller di Android (md5sum: 23315b6a70ee249bc9d0dc398e5276e7)```\nKernel originale per N810 (diablo release) (md5sum: 9c30818ab139097ca60bef58671c41bf)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 A questo punto, tutto quello che dobbiamo fare per installare **Android** √® copiare il file **android.img.bz2** sulla memory card e poi installare il pacchetto **android-installer.deb** che provvedera\u0026#39; automaticamente all\u0026#39;installazione. Una volta completata l\u0026#39;installazione, noteremo che una voce √® stata aggiunta al menu Extra del nostro tablet. **Non avviate subito Android:** √® necessario effettuare un reboot del dispositivo prima di poter utilizzare Android. Quando avrete riavviato il tablet, vi coniglio di connettervi alla vostra rete wifi (Android non permette di configurare la connessione wireless) ed in seguito di lanciare Android. Quando si clicca sull\u0026#39;icona di Android il dispositivo sembra non rispondere piu\u0026#39; ai nostri comandi. E\u0026#39; necessario **attendere almeno 1 minuto** prima di veder comparire il boot animato ed infine la schermata di benvenuto. Di seguito alcune immagini del risultato finale: [![android n810 1](02072008561-300x225.jpg \u0026#34;android_n810_1\u0026#34;)]() [![android n810 2](02072008563-300x225.jpg \u0026#34;android_n810_2\u0026#34;)]() ","date":"2008-07-02T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/android-su-nokia-n810/","title":"Android su Nokia N810"},{"content":"\nInsieme alla nuova versione del firmware per Nokia N800/N810, Nokia ha rilasciato anche una utility che promette di migliorare notevolmente i tempi di fix per il GPS del N810.\nSi tratta di agps-ui ed √® disponibile sia nei repository \u0026ldquo;Maemo Extra\u0026rdquo;, sia nel sito Nokia Beta Labs. A-GPS sta per Assisted GPS e si tratta di una tecnica che \u0026ldquo;aiuta\u0026rdquo; il ricevitore GPS a sintonizzarsi con i satelliti in un tempo assai minore da quello richiesto normalmente.\nIn sintesi, sia triangolando la posizione grazie all\u0026rsquo;ausilio delle celle GSM, sia facendo indicare all\u0026rsquo;utente la posizione approssimativa di dove ci si trovi, il ricevitore GPS cerca di connettersi a quei satelliti che sa che sono visibili nella zona indicata, riducendo notevolmente il tempo richiesto per fare il fix della posizione.\n","date":"2008-06-27T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/a-gps-per-nokia-n810/","title":"A-GPS per Nokia N810"},{"content":"\nIl sito web √® stato aggiornato alla versione 2.5.1 di WordPress.\nDovrei aver seguito correttamente le istruzioni su questa pagina, per√≤ ho avuto pochissimo tempo per testare se tutto funziona correttamete come prima.\n","date":"2008-06-23T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/aggiornamento-del-sito-a-wordpress-251/","title":"Aggiornamento del sito a WordPress 2.5.1"},{"content":"\nChi volesse cimentarsi nell\u0026rsquo;apprendimento del framework per lo sviluppo web Rails, trover√† al momento, a parte qualche tutorial qua e la, solo manuali che trattano la versione 1.2 di Rails.\nDa fine dicembre 2007 √® uscita la versione 2.0 e da pochi giorni la 2.1. Le modifiche al framework e le differenze nella stesura del codice sono cos√¨ numerose da aver interrotto la compatibilit√† con la versione precedente.\nPer esperienza personale, avevo installato la versione 2.0.2 di Rails, seguendo un manuale che purtroppo era basato sulla 1.2. Ad ogni capitolo qualcosa non funzionava (rispetto a quanto spiegato nel libro) ed ero costretto a ricorrere a Google oppure ai forum dedicati per chiedere spiegazioni.\nA quel punto mi sono chiesto: ma non esiste un libro che sia basato su Rails 2.x ?! Per fortuna, dopo una breve ricerca ho scoperto l\u0026rsquo;esistenza di questo fantastico manuale: Agile Web Development with Rails, Third Edition.\nIl libro non √® ancora stato rilasciato in versione definitiva, tanto che uscira\u0026rsquo; d ottobre 2008. Come fare ad averlo in anteprima? Gli autori mettono a disposizione (a prezzo piuttosto ridotto) la versione beta in formato PDF e permettono di pre-ordinarela versione cartacea. Una volta acquistata la versione in PDF (al prezzo di circa 15‚Ç¨, grazie al cambio favorevole euro/dollaro) si ha diritto a tutti gli aggiornamenti che vengono rilasciati (ogni 2 o 3 settimane circa)¬†ed alla versione definitiva del PDF quando verr√† rilasciato il libro ad Ottobre.\nPer quello che posso dirvi, soprattutto avendo iniziato a leggere un manuale analogo che trattava la versione 1.2, si tratta di un ottimo prodotto che, anche se in versione beta, √® praticamente pronto per essere studiato con estremo profitto. Quasi tutti i capitoli sono stati gi√† rivisti e quindi ripensati per la sintassi e le funzionalit√† di Rails 2.x, in particolare quelli che trattano ActiveRecord.\n","date":"2008-06-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/agile-web-development-with-rails-imparare-rails-2x/","title":"Agile Web Development with Rails: imparare Rails 2.x"},{"content":"\nFinalmente sono riuscito a trovare una webcam che funzioni (dopo qualche ricerca su Google) abbastanza bene su Linux. Dopo aver provato una Logitech Quickcam for Notebook mi ero quasi perso d\u0026rsquo;animo, poi ho deciso di fare un ultimo tentativo con la Creative Live! Cam Notebook.\nPrima di proseguire nella lettura di questa guida, vi consiglio di verificare che il modello di \u0026ldquo;Creative Live Cam\u0026rdquo; che state cercando di installare, sia lo stesso che ho testato io. Potete verificarlo scrivendo in un terminale il comando lsusb:\n1 2 3 4 5 lsusb Bus 003 Device 001: ID 0000:0000 Bus 002 Device 001: ID 0000:0000 Bus 001 Device 018: ID 041e:4068 Creative Technology, Ltd Bus 001 Device 001: ID 0000:0000` Ovvero dovrete verificare che l\u0026rsquo;identificativo del vostro modello sia esattamente 041e:4068\nDevo dire che al primo tentativo (ovvero inserendo il cavo USB nel mio notebook e sperando che funzionasse) non ci sono riuscito, quindi mi sono deciso a fare una piccola ricerca su Google. Ho notato che molte persone hanno tentato (senza alcun successo) di far funzionare questa webcam con i driver spca5xx che solitamente supportano un gran numero di webcam. Proseguendo nella mia ricerca ho trovato i driver ov51x-JPEG che invece supportano il mio modello di webcam.\nL\u0026rsquo;installazione non √® difficile, dobbiamo per√≤ assicurarci di aver installato sulla nostra macchina tutto il necessario per poter ricompilare il modulo, quindi dovrete eseguire (da utente root oppure utilizzando sudo) questo comando:\n1 apt-get install build-essential linux-headers-$(uname -r) A questo punto dovrete scaricare i sorgenti del driver, da questo indirizzo:¬†http://www.rastageeks.org/downloads/ov51x-jpeg/ov51x-jpeg-1.5.7.tar.gz\n1 wget http://www.rastageeks.org/downloads/ov51x-jpeg/ov51x-jpeg-1.5.7.tar.gz Dobbiamo poi scompattarli con il seguente comando:\n1 tar xfvz ov51x-jpeg-1.5.7.tar.gz Infine dobbiamo compilare il modulo ed installarlo:\n1 2 3 cd ov51x-jpeg-1.5.7 make make install Se la compilazione e l\u0026rsquo;installazione del modulo sono andati a buon fine, possiamo finalmente caricare il modulo:\n1 modprobe ov51x-jpeg Prima di poter utilizzare la webcam con Skype, c\u0026rsquo;√® ancora una piccola cosa da aggiustare, per evitare problemi di incompatibilit√†. Dobbiamo modificare il file /etc/modprobe.d/options ed aggiungere la seguente riga:\n1 options ov51x-jpeg forceblock=1 ovviamente prima di caricare il modulo. A questo punto l\u0026rsquo;installazione dovrebbe essere completa. Se ci fossero problemi o difficolt√† potete scrivere lasciando un commento a questo post, in modo che anche altri possano poi leggere la domanda/risposta.\n","date":"2008-06-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/creative-live-cam-notebook-su-ubuntu-linux/","title":"Creative Live Cam Notebook su Ubuntu Linux"},{"content":"Se a qualcuno fosse capitato di recente di creare una semplice applicazione \u0026ldquo;Hello World\u0026rdquo; utilizzando il framework Ruby on Rails, avr√† notato che in fase di esecuzione si ottiene un errore di questo tipo:\n1 Can\u0026#39;t connect to local MySQL server through socket \u0026#39;/var/run/mysqld/mysqld.sock\u0026#39; (2) Perch√® un errore relativo a MySQL in un\u0026rsquo;applicazione che stampa semplicemente una stringa di testo? Nelle nuove versioni di RoR vengono caricati per default i moduli ActiveRecord, ActiveResource e ActionMailer. ActiveRecord in particolare si aspetta di trovare (per le impostazioni di default) un database MySQL funzionante.\nPer evitare questo errore √® sufficiente decommentare una riga all\u0026rsquo;interno di environment.rb che si trova in $PATH_APPLICAZIONE/config/environment.rb:\n1 2 3 # Skip frameworks you\u0026#39;re not going to use (only works if using vendor/rails). # To use Rails without a database, you must remove the Active Record framework config.frameworks -= [ :active_record, :active_resource, :action_mailer ] Fonte: http://www.swards.net/2008/02/ruby-on-rails-application-with-no.html\n","date":"2008-05-26T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/applicazioni-ruby-on-rails-che-non-utilizzano-database/","title":"Applicazioni Ruby On Rails che non utilizzano database"},{"content":"\nFinalmente una bella notizia. Microsoft ha confermato alla redazione di BetaNews che Microsoft Office 2007 Service Pack 2 includer√† il supporto per il formato ODF di OpenOffice e per il PDF di Adobe.\nGrazie a questa funzionalit√† sar√† possibile non solo aprire documenti in formato ODF o PDF, ma sar√† anche possibile salvarli in tali formati e scegliere una delle due estensioni come formato predefinito per il salvataggio dei propri documenti.\nNei piani di Microsoft c\u0026rsquo;√® anche il rilascio di una serie di API che permetteranno ai programmatori di scrivere add-in per Microsoft Office in modo da aggiungere il supporto per ulteriori formati.\nQuesto √® sicuramente un bel passo avanti sia per quanto riguarda l\u0026rsquo;interoperatibilit√† di sistemi diversi (Windows, Linux, OsX) sia per quanto riguarda la diffusione del formato ODF di OpenOffice.\nGli utilizzatori di OpenOffice non dovranno piu\u0026rsquo; preoccuparsi di salvare il proprio documento in formato .doc prima di inviarlo all\u0026rsquo;amico o all\u0026rsquo;azienda che magari non usa ancora OpenOffice. Il documento verr√† aperto e visualizzato in modo nativo, senza la necessit√† di installare ulteriori plugin.\nLa versione SP2 di Office verr√† rilasciata verso la met√† del 2009, ci auguriamo quindi che la promessa venga mantenuta e che le due suite possano finalmente scambiarsi i documenti in maniera ottimale.\n","date":"2008-05-21T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/microsoft-office-2007-sp2-con-supporto-openoffice-odf-e-pdf/","title":"Microsoft Office 2007 SP2 con supporto OpenOffice (ODF) e PDF"},{"content":"\nLo sapevate che i server di MSN censurano le vostre conversazioni, filtrando i messaggi che, secondo loro, sono ritenuti \u0026ldquo;potenzialmente pericolosi\u0026rdquo;?\nNon si tratta certo di una novit√†, purtroppo per√≤ molte persone ancora non sono a conoscenza di questo fatto e penso sia opportuno fare quanta piu\u0026rsquo; informazione possibile per mettere gli utenti MSN al corrente del comportamento di questo sistema di instant messaging.\nCome funziona la comunicazione fra utenti MSN? Quando ci si connette a MSN e si vuole inviare un messaggio ad un nostro amico nella lista dei contatti, il messaggio viene prima inviato ai server di MSN e poi viene successivamente inviato al nostro amico da parte del server.\nQuesto meccanismo fa si che la conversazione non sia diretta, ma passi attraverso qualcosa che √® in grado di fare qualsiasi cosa: registrarla, analizzarla e persino bloccarla.\nE\u0026rsquo; quello che √® accaduto in questi giorni con i link ai video di Youtube e quello che sta accadendo da sempre a moltissimi link ritenuti pericolosi da \u0026ldquo;mamma Microsoft\u0026rdquo;.\nProvate ad esempio ad inviare tramite MSN un link contenente la stringa \u0026ldquo;download.php\u0026rdquo; come ad esempio il link per scaricare OpenOffice (sar√† un caso?!):¬†http://www.plio.it/download.php?q=d\u0026product=OpenOffice.org\u0026os=winwjre\u0026lang=it\u0026version=2.4.0\nIl comportamento sar√† lo stesso per tutti, qualsiasi client si usi (anche se utilizziamo un client MSN-compatibile, tipo Pidgin, su un altro sistema operativo), visto che il filtro avviene a livello di server: il messaggio non verr√† recapitato alla persona alla quale abbiamo tentato di inviarlo.\nCome possiamo sapere quali saranno le parole che verranno censurate dai server di MSN? Non c\u0026rsquo;√® modo. La lista delle parole censurate √® ovviamente segreta. Cosa succeder√† un giorno se a Microsoft (magari con l\u0026rsquo;appoggio o la spinta di qualche governo) verr√† in mente di iniziare a filtrare altri contenuti ritenuti \u0026ldquo;pericolosi\u0026rdquo;? Questa situazione purtroppo ricorda molto da vicino \u0026ldquo;la grande muraglia\u0026rdquo;, ovvero il firewall con il quale tutti i navigatori residenti in Cina sono costretti a fare i conti durante la navigazione.\nLa soluzione ovviamente esiste: non utilizzare MSN come sistema di instant messaging, ma usare invece una piattaforma completamente aperta e non centralizzata, come ad esempio Jabber dove la comunicazione avviene tra piu\u0026rsquo; server, e dove chiunque puo\u0026rsquo; mettere su un proprio server.\nSpero che questo post abbia aperto un po\u0026rsquo; gli occhi a coloro che fino ad ora erano un po\u0026rsquo; scettici su questo tipo di cose.\n","date":"2008-05-13T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/msn-e-la-censura-delle-conversazioni/","title":"MSN e la censura delle conversazioni"},{"content":"\nIl client di Skype per Linux non supporta al momento l\u0026rsquo;invio degli SMS. Questa puo\u0026rsquo; essere per molti una grossa limitazione, visto che √® molto conveniente come metodo per inviare gli sms (costano 10 centesimi) rispetto a molte tariffe in circolazione al momento, con i principali gestori italiani.La mancanza di questa funzionalit√† √® per√≤ soltanto apparente! Infatti √® stata gi√† implementata a livello di librerie di Skype ed √® gi√† disponibile tramite le API.\nGrazie alla libreria Skype4Py, ufficialmente supportata da Skype e sviluppata da Arkadiusz Wahlig (che ha tenuto un talk proprio su questo argomento nella giornata di ieri del PyCon Due), √® possibile scrivere applicazioni multipiattaforma (Windows, Linux, Mac) che interagiscano con Skype.\nUna volta installata la libreria nel proprio sistema, dobbiamo soltanto avviare il client Skype.\nLe applicazioni che possiamo scrivere, per automatizzare alcune funzioni di Skype, sono moltissime. In questo caso particolare far√≤ vedere un piccolo script Python che invia un SMS utilizzando il client (ed il credito) dell\u0026rsquo;istanza di Skype che sta girando sulla vostra macchina:\n1 2 3 4 5 6 7 8 9 10 11 12 13 import Skype4Py number = \u0026#39;+393*******\u0026#39; text= \u0026#39;Messaggio di prova da PySms4Skype!\u0026#39; skype = Skype4Py.Skype() skype.FriendlyName = \u0026#39;PySms4Skype\u0026#39; skype.Attach() sms = skype.CreateSms(Skype4Py.smsMessageTypeOutgoing, number) sms.Body = text sms.Send() Quando eseguite questo script, Skype vi chiedera\u0026rsquo; la conferma per autorizzare la vostra applicazione ad utilizzare le API, baster√† quindi dare conferma per continuare. Nello script ovviamente dovrete sostituire il numero di telefono con uno valido.\n","date":"2008-05-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/skype-sms-su-linux-grazie-a-skype4py-si-puo/","title":"Skype SMS su Linux: grazie a Skype4Py si puo'!"},{"content":"\nPer chi avesse seguito il mio talk su PyMaemo al PyCon Due a Firenze, metto a disposizione le slide che ho utilizzato. Potete liberamente scaricarle, modificarle e distribuirle.\nSlides ospitate sul sito di Slideshare: http://www.slideshare.net/andy80/conferenza-pymaemo Conferenza Pymaemo from Andrea Grandi Inoltre vi riporto un piccolo abstract del talk:\nIl talk prevede una breve introduzione alla piattaforma Maemo ed ai Nokia Internet Tablet, sia dal punto di vista dell\u0026rsquo;utente comune, sia da quello dello sviluppatore.\nVerr√† poi spiegato come configurare ed installare l\u0026rsquo;ambiente Scratchbox, il principale ambiente utilizzato per sviluppare applicazioni per Maemo.\nInfine verranno presentati due plugin per Eclipse: ESbox e PluThon. Il primo si interfaccia con Eclipse e Scratchbox, permettendo di sviluppare sia applicazione C/C++ che Python e di testarle all\u0026rsquo;interno dell\u0026rsquo;ambiente Scratchbox. Il secondo √® un plugin specifico per Python e permette di eseguire e debuggare le applicazioni direttamente sul dispositivo.\n","date":"2008-05-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/slides-del-talk-su-pymaemo-al-pycon-due/","title":"Slides del talk su PyMaemo al PyCon Due"},{"content":"\nCome da programma, oggi a Palazzo Vecchio\n(Firenze) ci sar√† il talk di apertura del PyCon Italia 2008, tenuto dal leader e fondatore della Free Software Foundation, Richard Stallman.\nRichard Stallman parler√† degli obiettivi e della filosofica del Movimento per il Software Libero, e della storia e stato attuale del sistema operativo GNU che, in combinazione con il kernel Linux, √® usato oggi da decine di milioni di utenti in tutto il mondo.\nL\u0026rsquo;evento di oggi √® completamente gratuito e aperto a tutti (fino ad esaurimento dei posti disponibili). Quelli che si sono registrati per il PyCon avranno ovviamente la precedenza.\nPer ulteriori informazioni sull\u0026rsquo;evento e sul PyCon, potete consultare il sito ufficiale dell\u0026rsquo;evento.\n","date":"2008-05-09T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/inizia-il-pycon-richard-stallman-oggi-a-palazzo-vecchio-firenze-ore-1600/","title":"Inizia il PyCon: Richard Stallman oggi a Palazzo Vecchio (Firenze) ore 16:00"},{"content":"\nDa pochi giorni la Trolltech ha rilasciato la versione 4.4.0 delle proprie librerie multipiattaforma Qt. La versione corrente di Ubuntu (la 8.04) contiene al momento le librerie Qt nella versione 4.3.4.\nGli sviluppatori che utilizzano le Qt potrebbero voler installare l\u0026rsquo;ultima release delle librerie, per testare le nuove funzionalit√† o per verificare il funzionamento di una propria applicazione con questa particolare versione.\nLa buona notizia √® che non c\u0026rsquo;√® bisogno di scaricarsi i sorgenti delle Qt 4.4.0 e ricompilarli, perch√® il team di Ubuntu ha gi√† preparato i pacchetti per la Ubuntu Hardy.\nPer installarli √® necessario abilitare il repository chiamato hardy-backports andando suSystem-\u0026gt;Administration-\u0026gt;Software Sources.\nA questo punto la versione 4.4.0 dovrebbe essere disponibile tra gli aggiornamenti di sistema. Baster√† quindi un apt-get upgrade per procedere all\u0026rsquo;aggiornamento.\n","date":"2008-05-08T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/installare-le-qt-440-su-ubuntu-linux-804/","title":"Installare le Qt 4.4.0 su Ubuntu Linux 8.04"},{"content":"\nQuante volte vi √® capitato di voler ascoltare dal vostro PC la vostra radio preferita e magari il plugin incorporato nel browser non funzionava correttamente? Nel caso di Radio Deejay mi √® capitato molto spesso, a seconda della versione di Firefox che stavo usando o a seconda della distribuzione.\nE\u0026rsquo; possibile ascoltare le radio che trasmettono in streaming anche senza utilizzare il browser. Per fare questo √® necessario un programma che riesce a leggere gli streaming audio/video e nel mio caso ho utilizzato Rhythmbox.\nBisogna aprire il programma ed andare su Radio e cliccare su \u0026ldquo;New Internet Radio Station\u0026rdquo; ed inserire il seguente URL: http://live.mediaserver.kataweb.it/radiodeejay\nA questo punto sar√† possibile ascoltare la nostra radio preferita senza bisogno di utilizzare il browser.\nNota: queste istruzioni potrebbero funzionare benissimo anche nel caso di altre radio e con altre versioni di Ubuntu. Nel mio caso l\u0026rsquo;ho testato con Ubuntu Linux 8.04\n","date":"2008-05-07T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/come-ascoltare-radio-deejay-su-ubuntu-linux-con-rhythmbox/","title":"Come ascoltare Radio Deejay su Ubuntu Linux con Rhythmbox"},{"content":"\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 Il 24 aprile √® uscita la tanto attesa **Ubuntu Hardy 8.04**, sicuramente una tra le distribuzioni piu\u0026#39; utilizzate al momento dagli utenti Linux. Trattandosi di una release LTS (long time support, ovvero supportata per ben 3 anni dal rilascio) ci si aspettava che potesse trattarsi di una distribuzione assai stabile. Dopo circa una decina di giorni di utilizzo (avevo iniziato a fare l\u0026#39;upgrade pochi giorni prima dell\u0026#39;uscita ufficiale), devo purtroppo confermare le lamentele che molti stanno sollevando riguardo a questa versione. Molti fattori, tra cui l\u0026#39;instabilit√† di alcuni applicativi che sono stati distribuiti con questa versione, non ancora pronti al momento del rilascio, hanno fatto si che questa versione risulti una delle piu\u0026#39; instabili tra tutte quelle che sono state rilasciate fino ad ora. Qui di seguito far√≤ una panoramica dei problemi che ho personalmente riscontrato, premettendo che si tratta ovviamente di una lista di problemi non completa e relativa in particolare ai miei due PC sul quale ho avuto modo di testarla. ## Firefox 3 la versione di Firefox distribuita al momento del rilascio della Ubuntu 8.04 √® la versione **3.0 beta 5**. Pur trattandosi di una versione \u0026#34;abbastanza stabile\u0026#34;, non √® del tutto esente da alcuni fastidiosi bug, in particolare si riscontrano [frequenti crash del browser](https://bugs.launchpad.net/ubuntu/+source/pulseaudio/+bug/192888) quando si cerca di visualizzare video tramite il **plugin Flash**. ## PulseAudio il nuovo sistema di gestione audio adottato da Ubuntu, sebbene abbia sulla carta ottime funzionalit√†, non √® ancora compatibile con la maggior parte dei programmi in circolazione. Questo fa si che, ad esempio, anche programmi opensource come il client ufficiale di **Last.Fm** abbiano problemi nel gestire la periferica audio, dando spesso il seguente errore \u0026#34;The Alsa soundsystem is either busy or not present\u0026#34;. ## Bluetooth fino alla versione 7.10 di Ubuntu riuscivo ad inviare correttamente le foto dal mio Nokia N73 al PC. Con la 8.04 non ci riesco piu\u0026#39;. Il [bug](https://bugs.launchpad.net/ubuntu/+source/bluez-utils/+bug/211252) √® gi√† stato segnalato e riguarda anche altre persone oltre a me. ## Clock Applet cliccando sull\u0026#39;orologio per visualizzare il calendario, va in crash gnome-panel. Anche [questo bug](https://bugs.launchpad.net/ubuntu/+source/gnome-panel/+bug/203527) √® stato gi√† segnalato ed era stato \u0026#34;fixato\u0026#34; prima del rilascio della versione definitiva, ma ancora il problema non √® risolto. ## Evolution e Google Calendar una delle funzioni tanto attese sarebbe dovuta essere la possibilit√† di integrare Calendar di Google nel calendario di Evolution. Purtroppo si tratta di un altro [bug](https://bugs.launchpad.net/ubuntu/+source/evolution/+bug/220596) ancora non risolto. ##¬†Nvidia ed il driver proprietario sia a me che ad altre persone, non viene installato correttamente il driver proprietario aggiornato, dopo aver aggiornato ad Ubuntu 8.04. Io ho risolto disattivando il modulo e reinstallandolo da capo. Il problema per√≤ non √® ancora stato risolto. ## Tracker il tool di indicizzazione integrato nella Ubuntu, non indicizza correttamente il contenuto di alcuni file. Cercando ad esempio \u0026#34;Benedetta\u0026#34; vengono fuori anche i documenti che contengono \u0026#34;Benedetto\u0026#34;. Anche questo [bug](https://bugs.launchpad.net/ubuntu/+source/tracker/+bug/222046) √® stato segnalato. In conclusione, non mi sento proprio di consigliare, almeno per il momento, l\u0026#39;aggiornamento alla Ubuntu 8.04 a meno che non si voglia contribuire attivamente alla segnalazione dei bug, in modo che il team di sviluppo di Ubuntu possa correggerli al piu\u0026#39; presto. Non ci resta che attendere la versione **8.04.1** che uscir√† prossimamente e conterr√† i principali fix dei bug che sono stati segnalati in questi giorni. ","date":"2008-04-29T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/i-problemi-della-nuova-ubuntu-hardy-804/","title":"I problemi della nuova Ubuntu Hardy 8.04"},{"content":"\nVorrei segnalarvi un sito web che forse molti di voi conosceranno gi√†: https://launchpad.net/\n√® un sito messo in piedi dalla Canonical (la societ√† che finanzia lo sviluppo di Ubuntu) e presenta alcune funzioni molto interessanti:\nCode √® possibile pubblicare qui una propria patch ad un programma, in modo che gli sviluppatori la possano unire al codice ufficiale.\nBugs un modulo per segnalare i bug della Ubuntu e degli altri progetti che sono registrati su launchpad.\nBlueprints il posto dove pubblicare le proprie idee, proposte di miglioramento, suggerimenti sulle future funzionalit√† ecc\u0026hellip;. della Ubuntu. Se avete un\u0026rsquo;idea originale per una funziona che ancora non √® presente in Ubuntu, potete scriverla qui.\nTranslations consente di visualizzare le stringhe ed i messaggi non ancora tradotti dei programmi di Ubuntu e permette di scrivere la propria traduzione, nella lingua desiderata. La traduzione verr√† poi sottoposta ad approvazione. Un ottimo modo per suddividersi il lavoro di traduzione dei vari programmi.\nAnswers qui √® possibile fare domande (come su un forum) e rispondere alle domande che ancora sono \u0026ldquo;open\u0026rdquo; (cio√® senza risposta).\nTutti i contributi che date in una di queste sezioni, vanno ad aumentare il vostro \u0026ldquo;karma\u0026rdquo;, ovvero la notoriet√†, la popolarit√† e l\u0026rsquo;importanza all\u0026rsquo;interno della community di Ubuntu.\nLa mia pagina ad esempio √® questa: https://launchpad.net/~andy80\nSe non vi sentite ancora dei programmatori esperti, ma volete comunque far qualcosa per migliorare la Ubuntu (o altri progetti registrati in quel sito), quello √® il posto giusto nel quale spendere un po\u0026rsquo; del proprio tempo.\n","date":"2008-04-22T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/diventa-un-ubuntero/","title":"Diventa un Ubuntero!"},{"content":"Yesterday I upgraded from Ubuntu 7.10 to the new 8.04 RC and I \u0026ldquo;broke\u0026rdquo; my Scratchbox installation. I tried to install it again and I had still some problems logging into Scratchbox and installing the SDK.\nThe I found this page: http://suppressingfire.livejournal.com/35277.html\nthat explain how to fix these problems. In particular if you get this kind of error trying to log into Scratchbox:\n1 Inconsistency detected by ld.so: rtld.c: 1192: dl_main: Assertion `(void *) ph-\u0026gt;p_vaddr == _rtld_local._dl_sysinfo_dso\u0026#39; failed! You can fix it in this way:\n1 echo 0 | sudo tee /proc/sys/vm/vdso_enabled You can read the complete fix in my updated wiki: http://www.ptlug.org/wiki/Howto_Installing_Maemo_SDK_4\n","date":"2008-04-21T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/scratchbox-on-ubuntu-hardy-troubleshooting/","title":"Scratchbox on Ubuntu Hardy troubleshooting"},{"content":"I\u0026rsquo;ve updated my previous howto that explain how to install Maemo SDK 4 (Chinook). The other howto was written when Maemo SDK 4 Beta was out, now it\u0026rsquo;s updated to 4.0.1 version of the SDK.\nYou can find it, as usual, on this wiki: http://www.ptlug.org/wiki/Howto_Installing_Maemo_SDK_4\nIf you have any suggestion or if you want to give me any idea to improve this howto, please leave me a comment.\n","date":"2008-04-17T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/installing-maemo-sdk-4-howto-updated/","title":"Installing Maemo SDK 4 HowTo Updated"},{"content":"In these days I was looking for a simple tutorial to understand how to use GtkIconView, but the only thing I was able to find was an example in PHP-Gtk. So I decided to translate it in Python language, thinking it would be useful for other people trying to use that Gtk control. You can find the code here:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 import gtk import gobject DEFAULT_IMAGE_WIDTH = 100 # Main Window setup window = gtk.Window(gtk.WINDOW_TOPLEVEL) window.set_size_request(400, 240) window.connect(\u0026#34;destroy\u0026#34;, gtk.main_quit) window.set_title(\u0026#34;Python GtkIconView Test\u0026#34;) # Add a VBox vbox = gtk.VBox() window.add(vbox) # Setup Scrolled Window scrolled_win = gtk.ScrolledWindow() scrolled_win.set_policy(gtk.POLICY_AUTOMATIC, gtk.POLICY_AUTOMATIC) # Setup ListStore to contain images and description model = gtk.ListStore(gtk.gdk.Pixbuf, gobject.TYPE_STRING) # Create a tuple with image files immagini = ( \u0026#34;BD786-TFR.jpg\u0026#34;, \u0026#34;guido_sottozero.jpg\u0026#34;, \u0026#34;IMG_0056.JPG\u0026#34;, \u0026#34;movies_card.jpg\u0026#34; ) for im in immagini: try: pixbuf = gtk.gdk.pixbuf_new_from_file(im) pix_w = pixbuf.get_width() pix_h = pixbuf.get_height() new_h = (pix_h * DEFAULT_IMAGE_WIDTH) / pix_w # Calculate the scaled height before resizing image scaled_pix = pixbuf.scale_simple( DEFAULT_IMAGE_WIDTH, new_h, gtk.gdk.INTERP_TILES ) model.append((scaled_pix, im)) except: pass # Setup GtkIconView view = gtk.IconView(model) # Pass the model stored in a ListStore to the GtkIconView view.set_pixbuf_column(0) view.set_text_column(1) view.set_selection_mode(gtk.SELECTION_MULTIPLE) view.set_columns(0) view.set_item_width(150) # Pack objects and show them all scrolled_win.add(view) vbox.pack_start(scrolled_win) window.show_all() gtk.main() The important thing to notice is that you have to store all the images in a GtkListStore and pass it to the GtkIconView as \u0026ldquo;model\u0026rdquo; parameter. I hope this example is clear. If you have any question, please comment this post and I\u0026rsquo;ll try to answer.\nThis is a screenshot of this example:\n","date":"2008-04-15T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/using-gtkiconview-in-python-a-small-tutorial/","title":"Using GtkIconView in Python: a small tutorial"},{"content":"PyCon2 is the second edition of the Italian Python Conference and will take place on May 9/10/11, 2008 in Florence.\nThe conference is organized by Python Italia and more than 300 developers, students and researchers will be present for three days of tutorials and other important events.\nPyCon 2008 edition will be opened by Richard Stallman with a keynote on Free Software and Free Ethics. Other famous developers will be presento too: Alex Martelli, Samuele Pedroni, Brian Fitzpatrick and many other.\nI\u0026rsquo;ll partecipate at the conference as speaker on May 10, with a talk on PyMaemo: Python for Nokia Internet Tablets. In particular I\u0026rsquo;ll talk about Maemo platform, Maemo SDK (how to install and configure it) and I\u0026rsquo;ll explain how to use the two Eclipse plugins ESBox and Pluthon.\nIf you want to give me any suggestion or idea for this talk, please leave me a comment on this post, so I\u0026rsquo;ll integrate it with my slides.\n","date":"2008-04-09T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/pymaemo-talk-on-may-10th-in-florence-at-pycon2-conference/","title":"PyMaemo Talk on May 10th in Florence at PyCon2 Conference"},{"content":"\nPyCon Due √® la seconda conferenza italiana dedicata al linguaggio di programmazione Python. La conferenza √® organizzata da un gruppo di appassionati e senza finalit√† di lucro; si prefigge la divulgazione di Python, e di dare visibilit√† agli sviluppatori professionisti, studenti, aziende e semplici interessati al linguaggio.\nDove e quando La conferenza si tiene a Firenze nelle giornate di Venerd√¨ 9, Sabato 10 e Domenica 11 Maggio. L\u0026rsquo;evento di apertura si terr√† a Palazzo Vecchio nel pomeriggio di Venerd√¨, durante il quale terr√† un keynote Richard Stallman. Sabato e Domenica, al Viva Hotel Laurus (Via Cerretani 54/r), nei pressi del Duomo, si svolgeranno 3 track parallele di conferenze.\nGli Interventi Durante la conferenza si terranno due tipi di interventi: i keynote ed i talk.\nI keynote sono interventi di ampio respiro che trattano temi di attualit√† del mondo dell\u0026rsquo;informatica; hanno una durata indicativa di 90' e verranno tenuti in occasione dell\u0026rsquo;evento di apertura di venerd√¨ 9 ed alla chiusura delle due giornate successive.\nI talk sono invece interventi focalizzati su un particolare argomento; hanno una durata indicativa di 45\u0026rsquo;, comprensivi del tempo per le domande del pubblico. I talk di PyCon Due si tengono durante le giornate di sabato 10 e domenica 11, e si dividono in tre track: \u0026ldquo;Scoprire Python\u0026rdquo;, \u0026ldquo;Diffondere Python\u0026rdquo; e \u0026ldquo;Imparare Python\u0026rdquo;:\nScoprire Python √® una track introduttiva su librerie, framework e metodologie, pensata per chi si sta avvicinando al Python o desidera una prima trattazione di un argomento;```\nDiffondere Python √® una track dedicata ad aspetti pi√π avanzati del linguaggio, esempi di integrazione della piattaforma e casi d\u0026rsquo;uso in azienda;```\nImparare Python √® una track interattiva: i talk sono parzialmente guidati dal pubblico, che discute la trattazione dell\u0026rsquo;argomento insieme al relatore, proponendo scenari e commentando le soluzioni proposte.\n1 2 3 4 5 6 7 8 ##¬†Registrazione per partecipare all\u0026#39;evento occorre registrarsi. La registrazione puo\u0026#39; essere fatta direttamente sul [sito ufficiale del PyCon2](http://www.pycon.it). Sempre sul sito ufficiale, potrete trovare a breve l\u0026#39;elenco delle conferenze che verranno fatte, non appena si concluderanno le votazioni per il Call For Paper che sono in corso in questi giorni. ","date":"2008-04-06T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/pycon2-conferenza-italiana-dedicata-al-linguaggio-python/","title":"PyCon2: conferenza italiana dedicata al linguaggio Python"},{"content":"\nNavigando sul sito web di una nota catena di negozi di hardware/software italiana, mi sono imbattuto in un\u0026rsquo;offerta davvero interessante. Vengono proposti due PC apparentemente \u0026ldquo;diversi\u0026rdquo;, ma dalle caratteristiche del tutto simili.\nIl primo PC costa 399 euro e viene venduto con la seguente configurazione hardware:\nCase¬†RAY Midi Tower Black/Aluminium con alimentatore da 500W Scheda Madre¬†ASUS M2N-MX SE AM2 nForce6100 VGA 2SATA Raid PCI-E Processore¬†AMD Athlon64 X2 5000+ (Socket AM2) + ventola RAM¬†2 GB DDR2 667MHz (PC5300) Hard Disk Drive¬†320 GB SATA2 8MB Scheda Video¬†NVIDIA GeForce 6100 GPU integrata nel chipset Scheda Audio¬†integrata Unit√† ottica¬†DVD¬±RW DualLayer black Il secondo PC invece, viene venduto a 339 euro, con le seguenti caratteristiche:\nCase¬†H@L Midi Tower ATX Black con alimentatore da 500W Scheda Madre¬†ASUS M2N-MX SE+ AM2+ nForce6100 VGA 2SATARaidPCI-E Processore¬†AMD Athlon64 X2 5000+ (Socket AM2) + ventola RAM¬†2GB (1.024 MB x 2) DDR2 667MHz (PC5300) Hard Disk Drive¬†320GB SATA2 8MB Scheda Video¬†nForce6100 integrata su M/B Scheda Audio¬†integrata su M/B Unit√† ottica¬†LG H54/5/8N 18X DVD¬±RW DualLayer black Cos\u0026rsquo;√® che vale 60 euro di differenza? La risposta √® molto semplice: il primo PC viene venduto con Windows Vista Home Basic preinstallato, mentre il secondo viene venduto con Kubuntu Linux. Questo per chi crede ancora (purtroppo me lo senti dire spesso \u0026ldquo;ma.. Windows √® gratis\u0026hellip; io l\u0026rsquo;ho trovato insieme al computer!\u0026rdquo; ) che Windows sia gratuito quando lo si trova pre-installato in un nuovo computer.\nNota: non ho voluto citare il nome della catena di computer che ha questi due PC a listino, visto che nessuno mi ha pagato per scrivere questo articolo ;) Al limite posso dirvelo in privato, ma credo che anche altri venditori abbiano ormai offerte simili a questa.\n","date":"2008-03-26T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/il-costo-di-un-computer-senza-windows-vista/","title":"Il costo di un computer senza Windows Vista"},{"content":"\nVenerdi 7 marzo 2008 si √® svolta a Firenze, a Palazzo Vecchio, la prima presentazione ufficiale in Italia dell\u0026rsquo;OLPC, che ha visto la presenza del fondatore stesso del progetto, Nicholas Negroponte.\nLa conferenza √® durata circa 2 ore ed √® iniziata con un intervento dell\u0026rsquo;Assessore alle Politiche Sociali, Lucia De Siervo, che ha manifestato l\u0026rsquo;impegno da parte del Comune di Firenze di aderire al progetto G1G1 di OLPC.\nG1G1 (Give one get one) prevede che con ogni acquisto di un OLPC che viene fatto in una scuola, ne venga acquistato un secondo da donare ad un\u0026rsquo;altra scuola di quelle nel terzo mondo. Il costo di ogni OLPC √® attualmente di 128 euro ciascuno (al prezzo bisogna aggiungere l\u0026rsquo;IVA e le spese di spedizione), anche se la cifra potra\u0026rsquo; subire lievi variazioni a causa del cambio euro/dollaro.\nL\u0026rsquo;intervento di Nicholas Negroponte non √® durato moltissimo purtroppo, perch√® sarebbe dovuto tornare entro il pomeriggio negli Stati uniti. A sentire le sue parole, dobbiamo sentirci onorati. Siamo la prima citt√†, non solo in Italia, ma anche nel resto del mondo, che ha aderito al progetto OLPC a livello di pubblica amministrazione.\nL\u0026rsquo;accordo infatti prevede che l\u0026rsquo;amministrazione comunale di Firenze acquisti qualche centinaio di OLPC da distribuire in alcune scuole. Di questo progetto si occuper√† direttamente OLPC Italia.\nOLPC Italia √® un\u0026rsquo;iniziativa che √® nata per volont√† dell\u0026rsquo;Assessorato allInformatica del Comune di Firenze e prevede la creazione di un centro competenza che faciliti l\u0026rsquo;accesso dei piu\u0026rsquo; piccoli, di qualunque paese, all\u0026rsquo;utilizzo di strumenti informatici e di altre tecnologie dell\u0026rsquo;informazione.\nGli obbiettivi di OLPC Italia sono i seguenti:\ndare un sostegno all\u0026rsquo;iniziativa globale OLPC \u0026ldquo;Give 1 Get 1\u0026rdquo; di Nicholas Negroponte```\nproporsi come unico tramite locale tra la realt√† nazionale, i paesi in via di sviluppo ed il mondo delle tecnologie dell\u0026rsquo;informatica e della comunicazione```\noffrire un supporto tecnico completo all\u0026rsquo;utilizzo dell\u0026rsquo;OLPC grazie al Centro di Competenza e di sviluppare utility ed altro software per il laptop stesso.\n1 2 3 4 5 6 La conferenza si √® conclusa con una dimostrazione pratica del funzionamento degli OLPC e molti bambini di una scuola elementare che aveva partecipato all\u0026#39;evento, hanno potuto provare ad usare direttamente i laptop, senza il bisogno che qualche adulto dovesse spiegare loro il funzionamento. ","date":"2008-03-08T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/conferenza-olpc-a-firenze-con-nicholas-negroponte-la-recensione/","title":"Conferenza OLPC a Firenze con Nicholas Negroponte: la recensione"},{"content":"I report this news from Andrew Jorgensen (Monologue):\nThe Map application for Nokia‚Äôs OS2008 (for N800 and N810) lets you download map data for a number of regions. The USA-West and USA-East regions are very large, though, and I have never been able to download them ‚Äî it always fails about half way through. I know others have dealt with the same problem.\nThis morning I got a reply from Wayfinder Customer Support:\nDear Sir,\nThank you for contacting Wayfinder.\nIf the map download fails through the Internet Tablet, you can download the maps from this address: http://www.navicoretech.com/Consumer/Support/Downloads/tablet/en_GB/wfnavigator/\nBest regards,\nAnnette\nCustomer Support\nWayfinder\nInstructions for installing the map data are on that site. It‚Äôs still a slow download but at least you can use a download manager.\n","date":"2008-03-06T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/maps-for-nokia-os2008/","title":"Maps for Nokia OS2008"},{"content":"\nE\u0026rsquo; appena stato rilasciato il numero 10 di Full Circle Magazine, la rivista elettronica gratuita dedicata a Linux e ad Ubuntu in generale.\nIn questo numero:\nInstallazione di Linux Mint\nHowTo: installare un programma da sorgenti, utilizzare TuxPaint, rippare un DVD con AcidRip, creare il proprio server (parte 2)```\nRecensione dell\u0026rsquo;Asus EeePc con eeeXubuntu\nLettere, domande \u0026amp; risposte, ecc\u0026hellip;\nLa rivista √® interamente in inglese e potete scaricarla da questo indirizzo: http://fullcirclemagazine.org/issue-10/\n","date":"2008-02-29T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/full-circle-magazine-10/","title":"Full Circle Magazine #10"},{"content":"{ width=40% }\nQuando vogliamo connetterci ad un server SSH, solitamente utilizziamo un comando simile al seguente:\n1 ssh user@remotehost.com Una volta connessi ci viene richiesta la password di accesso e subito dopo siamo connessi. Digitare ogni volta la password puo\u0026rsquo; essere scomodo, ed in alcuni casi questo potrebbe addirittura impedirci di creare uno script di automazione per velocizzare alcuni compiti.\nCi vengono in aiuto le chiavi SSH. Generando una coppia di chiavi pubblica/privata di SSH sulla propria macchina, ed esportando la chiave pubblica sul server remoto, possiamo fare in modo di autorizzare la nostra chiave remota, facendo si che le connessioni successive avvengano senza la richiesta di alcuna password.\nSupponiamo (a scopo dimostrativo) che il server remoto si trovi all\u0026rsquo;indirizzo IP 192.168.0.2 e supponiamo inoltre di avere un account chiamato user sulla macchina remota.\nPer prima cosa dobbiamo generare la coppia di chiavi sulla nostra macchina locale (n.b: non utilizzo alcuna passphrase, altrimenti mi verrebbe richiesta comunque al primo login di ogni sessione):\n1 2 3 4 5 6 7 8 9 andy80@noteboontu:~$ ssh-keygen -t dsa Generating public/private dsa key pair. Enter file in which to save the key (/home/andy80/.ssh/id_dsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/andy80/.ssh/id_dsa. Your public key has been saved in /home/andy80/.ssh/id_dsa.pub. The key fingerprint is: 22:99:69:d2:8d:8e:a5:f1:f4:dc:0f:d8:49:52:53:cd andy80@noteboontu A questo punto dobbiamo copiare la chiave pubblica appena generata, sul server remoto:\n1 2 cd ~/.ssh/ scp id_dsa.pub user@192.168.0.2:./id_dsa.pub Ci verr√† chiesta la nostra password remota, per poter effettuare la copia del file. A questo punto dobbiamo connetterci via SSH al server remoto:\n1 ssh user@192.168.0.2 Quando abbiamo effettuato correttamente il login, dobbiamo procedere con i seguenti comandi:\n1 2 3 4 5 cd .ssh touch authorized_keys2 chmod 600 authorized_keys2 cat ../id_dsa.pub \u0026gt;\u0026gt; authorized_keys2 rm ../id_dsa.pub Il gioco √® fatto! Le successive connessioni SSH che effettueremo verso il server remoto, avverranno senza la richiesta di alcuna password.\n","date":"2008-02-29T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/utilizzare-ssh-senza-password-chiavi-ssh/","title":"Utilizzare SSH senza password: chiavi SSH"},{"content":"\nIl 7 marzo 2008, presso il salone De\u0026rsquo;Dugento a Palazzo Vecchio (Firenze), dalle ore 10:00 verr√† presentato il portatile da 100$ One Laptop Per Child dove parteciper√† anche l\u0026rsquo;ideatore del progetto, Nicholas Negroponte.\nQui di seguito il comunicato ufficiale del Comune di Firenze:\nONE LAPTOP FOR CHILD, IL 7 MARZO PRESENTAZIONE A LIVELLO NAZIONALE, DELLA CAMPAGNA DI DIFFUSIONE DEL PRIMO PC ADATTO AI BAMBINI DI TUTTO IL MONDO\nParte da Firenze, per la prima volta in Italia, la presentazione di One Laptop Per Child (OLPC) Italia: il portatile adatto ai bambini e disegnato per imparare a imparare. L\u0026rsquo;importante appuntamento, organizzato dall\u0026rsquo;assessorato all\u0026rsquo;informatica, √® per il 7 marzo nel salone de' Dugento in Palazzo Vecchio. L\u0026rsquo;evento vanta la partecipazione di Nicholas Negroponte, Fondatore del Massachusetts Institute of Technology (MIT) Media Lab di Boston ed ideatore del laptop XO-OLPC.\nIl nuovo portatile verr√† presentato alle 10,30 durante una conferenza stampa nel Salone de\u0026rsquo; Dugento, dove parteciper√† anche Nicholas Negroponte. Seguir√† poi una dimostrazione del laptop OLPC e verranno anche installate anche delle postazioni.\n\u0026ldquo;√à un progetto educativo, non solo un semplice portatile.\u0026rdquo; Come ribadisce Negroponte , il laptop √® una risposta alla sfida globale di combattere l\u0026rsquo;analfabetizzazione, l\u0026rsquo;inclusione sociale ed il divario digitale. \u0026quot; Il laptop XO, un portatile adatto per i bambini e disegnato per imparare a imparare\u0026quot;.\nL\u0026rsquo;XO incorpora le teorie costruzionistiche sviluppate per prime negli anni \u0026lsquo;60 dal professore del MIT Media Lab, Seymour Papert, pi√π tardi rielaborate da Alan Kay e complementate da principi articolati da Nicholas Negroponte nel suo libro, Essere Digitale.\nOLPC Italia nasce dalla sensibilit√† dell\u0026rsquo;assessore all\u0026rsquo;informatica, che ha deciso di aderire all\u0026rsquo;iniziativa globale OLPC Give 1 Get 1 (G1G1) sul territorio locale, promuovendo il laptop XO non solo per i bambini delle scuole fiorentine ma anche per i Paesi in via di sviluppo gemellati con il Comune di Firenze. OLPC Italia si sviluppa sul territorio italiano, partendo dal Comune di Firenze, attraverso modelli sinergetici tra scuole nazionali ed in PVS. Ciascun studente italiano che acquister√† un laptop, doner√† un altro laptop ad un suo coetaneo di un\u0026rsquo; altra citt√† del Sud del mondo. Mobilitando risorse e partner, OLPC Italia tende a creare una rete di solidariet√† civica internazionale, gestendo in prima persona l\u0026rsquo;implementazione ed il monitoraggio di tali progetti nei PVS.\nDurante la giornata sar√† possibile assistere ad una dimostrazione sull\u0026rsquo;utilizzo e le principali funzioni che caratterizzano XO, nonch√© provare il laptop stesso e condividere la rete tra i vari XOs collegati.\nIl progetto OLPC √® stato fondato da Nicholas Negroponte con un nucleo di veterani del Media Lab, e ha presto coinvolto persone di talento e costanza eccezionali, provenienti dall\u0026rsquo;ambiente accademico, dalle belle arti e dalla comunit√† open source.\nOgni individuo che partecipa porta con s√© un insieme di capacit√† uniche, e una profonda passione per il progetto. La campagna G1G1 presentata negli Stati Uniti a novembre, ha venduto sul territorio americano oltre 200.000 macchine in un mese e mezzo.\nPer informazioni rivolgersi a giulia@laptop.org\n","date":"2008-02-27T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/olpc-a-firenze-il-7-marzo-con-nicholas-negroponte/","title":"OLPC a Firenze il 7 marzo con Nicholas Negroponte"},{"content":"Maemo Team has just released a plugin for Maemo Eclipse integration. This tool allows developers to use Eclipse IDE to develop and test Maemo applications.\nThis release includes:\nmaemo PC Connectivity version [0.1] (Beta) maemo ESBox plugin for Eclipse IDE version [1.3.6] (Beta) maemo Pluthon plugin for Eclipse IDE version [0.1.7] (Beta) Maemo PC connectivity packages are tools and other components developer needs to install into his Internet Tablet to enable connectivity between developer PC and Internet Tablet.\nMaemo ESBox plugin for Eclipse IDE integrates maemo SDK Scratchbox based development environment to the Eclipse development environment. ESBox plugin supports application developers using C, C++ or Python programming language.\nDevelopers are able to do all their development work inside Eclipse, from starting the project using template to packaging final application into maemo installation package.\nMaemo Pluthon plugin for Eclipse IDE integrates Eclipse IDE development environment to the Internet Tablet so that maemo Python developers do not need to use maemo SDK and Scratchbox as development environment. Maemo Pluthon plugin fully supports application development process with Python where developer develops and tests his Python application directly with Internet Tablet.\nYou can find more informations on the official plugin websites:\nESbox: http://esbox.garage.maemo.org/ PluThon: http://pluthon.garage.maemo.org/ ","date":"2008-02-26T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/eclipse-plugins-for-maemo-development/","title":"Eclipse plugins for Maemo Development"},{"content":"\nL\u0026rsquo;utilizzo di una unit√† UPS √® certamente una delle cose piu\u0026rsquo; consigliate quando vogliamo proteggere l\u0026rsquo;integrit√† di un computer da sbalzi di corrente o interruzioni dell\u0026rsquo;alimentazione.\nCosa succede per√≤ quando la batteria dell\u0026rsquo;UPS si esaurisce? In casi normali √® molto semplice: la corrente viene a mancare del tutto ed il nostro PC verr√† spento bruscamente.\nAlla mancanza di corrente non c\u0026rsquo;√® modo di porre un rimedio definitivo, per√≤ possiamo almeno fare in modo che il nostro computer venga spento in maniera corretta, prima che la batteria dell\u0026rsquo;UPS si esaurisca del tutto.\nNel caso di una macchina Linux, ci viene in aiuto una utility chiamata apcupsd. Installarla su Ubuntu √® molto semplice:\n1 apt-get install apcupsd A questo punto, dando per scontato che abbiate gi√† connesso l\u0026rsquo;UPS al PC/server, collegate il cavo USB a corredo in modo da far riconoscere l\u0026rsquo;UPS a Linux, in modo da poter proseguire con la configurazione. Il primo file da modificare √® /etc/apcupsd/apcupsd.conf ed impostare i seguenti parametri come segue:\n1 2 3 UPSCABLE usb UPSTYPE usb DEVICE A questo punto non ci resta che modificare il file /etc/default/apcupsd in modo da rendere effettive le modifiche:\n1 ISCONFIGURED=yes Infine dobbiamo soltanto avviare il demone ed il gioco √® fatto:\n1 /etc/init.d/apcupsd start Per default apcupsd effettuer√† lo shutdown nel PC quando la batteria sar√† arrivata al 5% della sua capacit√†, consentendo cos√¨ uno shutdown controllato del sistema, ed evitando quindi possibili perdite di dati.\n","date":"2008-02-15T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/apc-back-ups-500-usb-e-ubuntu-server/","title":"APC Back-UPS 500 USB e Ubuntu Server"},{"content":"\nI laboratori di Google hanno da poco rilasciato una versione aggiornata di Android, l\u0026rsquo;SDK che permette di sviluppare applicazioni per i futuri telefonini Google, si tratta della versione m5-rc14.\nLe principali novit√† di questa release sono le seguenti:\nNuova interfaccia utente: anche se si tratta di una versione ancora in sviluppo, √® stata aggiornata l\u0026rsquo;interfaccia grafica di Android.```\nLayout Animations: √® stata aggiunta la possibilit√† di creare animazioni grazie alle classi presenti nel package android.view.animation. Si consiglia di controllare gli esempi presenti nei file `LayoutAnimation*.java````\nGeo-coding: il package android.location.Geocoder permette di trasformare un indirizzo in coordinate geografiche e viceversa.```\nNuovi codec multimediali: √® stato aggiunto il supporto per i seguenti formati: OGG Vorbis, Midi, XMF, iMelody, RTTL/RTX e OTA.```\nAggiornato il plugin per Eclipse: il plugin per eclipse presente alcune novit√†, in particolare un editor per il Manifesto\n1 2 3 4 5 Ulteriori informazioni sulle modifiche alle API, possono essere trovate su [questa pagina](http://code.google.com/android/migrating/m3-to-m5/m5-api-changes.html). Per tutto il resto si rimanda alla [pagina principale del progetto](http://code.google.com/android/index.html) Android. ","date":"2008-02-14T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/android-rilasciata-la-m5-rc14-dellsdk/","title":"Android: rilasciata la m5-rc14 dell'SDK"},{"content":"\nE\u0026rsquo; stata rilasciata da poche ore la versione 2.3.3 di WordPress. Con questa release viene corretta una falla piuttosto grave che riguarda in particolar modo quei blog che permettono la registrazione di altri utenti.\nA causa di un bug in xmlrpc.php √® infatti possibile per un utente qualsiasi del blog, editare i contenuti scritti da un altro utente.\nOltre a questo bug, sono stati corretti anche altri piccoli problemi che riguardavano la versione 2.3.2 di WordPress.\nE\u0026rsquo; consigliato un tempestivo aggiornamento, seguendo la procedura indicata sul sito ufficiale.\n","date":"2008-02-06T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/rilasciato-wordpress-233-corretta-una-grave-falla-di-sicurezza/","title":"Rilasciato WordPress 2.3.3: corretta una grave falla di sicurezza"},{"content":"\nUna delle domande che mi vengono fatte piu\u0026rsquo; di frequente √® \u0026ldquo;MySQL si paga per uso commerciale?\u0026rdquo;. La risposta non √® delle piu\u0026rsquo; semplici.\nLeggendo direttamente il sito web di MySQL, si possono trovare due pagine dedicate alle licenze: una per chi fa sviluppo di software opensource ed una per chi sviluppa software commerciale.\nDopo una lettura superficiale delle due pagine, potremmo essere tratti in inganno e pensare che sviluppando un\u0026rsquo;applicazione commerciale, si debba per forza acquistare una licenza commerciale di MySQL. Questo non √® vero.\nTutto dipende dal tipo di librerie di interfacciamento che vogliamo utilizzare. MySQL mette a disposizione due modi per interfacciarsi al database: una propria API scritta in linguaggio C ed un socket in ascolto che riceve comandi tramite una normale connessione TCP/IP.\nE\u0026rsquo; chiaro che scrivendo un\u0026rsquo;applicazione che va a fare l\u0026rsquo;include di (faccio un esempio) mysql.h poi io debba rilasciarne i sorgenti. La licenza GPL con il quale √® stato rilasciato MySQL (ed anche le sue librerie client) dice chiaramente che quando si \u0026ldquo;linka\u0026rdquo; codice GPL ad altro codice, il risultato deve essere per forza rilasciato sotto licenza GPL.\nLa licenza GPL per√≤ non impone vincoli di utilizzo dell\u0026rsquo;applicazione stessa. Utilizzare quindi una libreria client che al posto delle API, usa il socket TCP/IP, ci permette di utilizzare MySQL anche da un\u0026rsquo;applicazione closed-source, senza bisogno di ottenere una licenza commerciale.\nE\u0026rsquo; esattamente quello che fa la libreria di interfacciamento di Python oppure di PHP. Esse utilizzando il metodo di connessione al socket, senza fare l\u0026rsquo;include del codice di MySQL.\nRiassumendo: se ci troviamo a scrivere un\u0026rsquo;applicazione commerciale che sappiamo non verr√† distribuita insieme al codice sorgente, dobbiamo preoccuparci solo di utilizzare una libreria client che utilizzi il metodo di connessione tramite socket al database.\nC\u0026rsquo;√® infine da aggiungere una cosa: se si utilizza codice opensource per uso personale oppure interno alla propria azienda, senza distribuirlo in giro, la GPL non ci impone di rilasciare le modifiche che abbiamo fatto ai sorgenti GPL che stiamo utilizzando.\nIl caso piu\u0026rsquo; lampante √® quello di Google: essi utilizzano tonnellate di codice GPL, per√≤ non distribuiscono un programma, offrono un servizio. Questo gli permette di non dover rendere pubbliche le modifiche fatte al codice originale.\nCredits: questo articolo √® stato possibile in gran parte grazie all\u0026rsquo;aiuto ed ai consigli di Giovanni Bajo (che pur chiedendomi di specificare che non √® un avvocato e che quindi potrebbe anche sbagliarsi, ha senz\u0026rsquo;altro fatto un ottimo lavoro) .\n","date":"2008-02-05T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/mysql-quando-si-deve-pagare-la-licenza/","title":"MySQL: quando si deve pagare la licenza?"},{"content":"\nE\u0026rsquo; stata da poco rilasciata la Alpha 4 di Ubuntu 8.04, ovvero la versione di Ubuntu che vedr√† la luce in Aprile. Le novit√† sono molte e si vanno a sommare a quelle gi√† introdotte nelle precedenti release Alpha:\nXorg √® stato aggiornato alla 7.3\nIl kernel √® stato aggiornato alla versione 2.6.24\nIl nuovo server audio predefinito diventa PulseAudio```\nTramite PolicyKit √® possibile configurare le applicazioni da amministratore che pu√≤ far girare anche l\u0026rsquo;utente normale```\nFirefox √® stato aggiornato alla versione 3.0 beta 2 e presenta una migliore integrazione con il layout di sistema```\nTrasmission √® il nuovo client BitTorrent che sostituir√† lo Gnome BitTorrent downloader```\nVinagre sar√† il nuovo client VNC predefinito ed andr√† a sostituire xvnc4viewer```\nBrasero (il programma per masterizzare CD/DVD) √® stato aggiornato e si integra perfettamente con Nautilus, sostituendo anche Serpentine per quanto riguarda la creazione dei CD audio```\nL\u0026rsquo;applet orologio permetter√† di vedere l\u0026rsquo;orario ed il meteo di altre localit√† (configurabili) contemporaneamente```\nPer quanto riguarda il file system virtual usato da Nautilus, GVFS prender√† il posto di GnomeVFS```\nGnome System Monitor √® stato ridisegnato e adesso disegna i grafici tramite le librerie Cairo```\nKVM viene ufficialmente mantenuto all\u0026rsquo;interno dei Kernel di Ubuntu rendendo piu\u0026rsquo; semplice l\u0026rsquo;integrazione con i sistemi di virtualizzazione```\nUfw (Uncomplicated Firewall) √® una nuova applicazione che permetter√† di scrivere regole di firewall senza dover imparare la complicata sintassi di iptables\n1 2 3 4 5 Queste sono solo alcune delle novit√† che vedremo nella prossima versione di Ubuntu. Per visualizzare alcuni screenshot e scaricare questa versione di Ubuntu, vi rimando alla pagina ufficiale: \u0026lt;http://www.ubuntu.com/testing/hardy/alpha4\u0026gt; ","date":"2008-02-03T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/ubuntu-804-alpha-4/","title":"Ubuntu 8.04 Alpha 4"},{"content":"This is the first post from my N810 using MaemoWordpy client. This is very cool! I can blog from everywhere now :)\n","date":"2008-02-01T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/first-post-from-maemowordpy-using-n810/","title":"First post from MaemoWordpy using N810"},{"content":"\nChe lo si voglia o no, acquistando un computer in un qualsiasi negozio si e' costretti a comprare anche il sistema operativo Microsoft Windows gia' installato. Ma non tutti sanno che √® possibile restituire il software non voluto ed ottenere un rimborso. Questo e\u0026rsquo; il tema dell\u0026rsquo;incontro che si terra\u0026rsquo; alla Stazione di Confine in via Attavante a Firenze il 2 Febbraio 2008 alle ore 21:00\nDurante l\u0026rsquo;hacknight organizzata dall\u0026rsquo;Hacklab di Firenze ed Firenze Linux User Group in video conferenza con l\u0026rsquo;Hacklab di Caserta, verrano illustrati i modi con cui far valere il diritto al rimborso e le gravi conseguenze generate dall\u0026rsquo;aggressione alla concorrenza sul mercato mondiale del software, non esclusivamente dei sistemi operativi, e anche a danno dello sviluppo tecnologico.\nAlla serata interverranno l\u0026rsquo;avv. Moretti dell\u0026rsquo;ADUC (Associazione Diritti Utenti e Consumatori) che ha seguito la prima causa italiana vinta da un utente che ha richiesto il rimborso del software preisntallato sul PC, e Marco Pieraccioli, l\u0026rsquo;utente che ha comprato quel computer ed avviato un processo che mira alla liberalizzazione del mercato del software, sar√† presente un rappresentante dell\u0026rsquo;associazione Software Libero. L\u0026rsquo;evento potra\u0026rsquo; essere seguito anche in diretta su Internet.\nPer maggiori informazioni visitate il sito dell\u0026rsquo;ADUC: http://www.aduc.it/dyn/rimborsowindows\nL\u0026rsquo;Hacklab di Firenze: http://hacknight.firenze.linux.it/wiki.php\nFLUG Firenze Linux User Group: http://www.firenze.linux.it\nL\u0026rsquo;Hacklab di Caserta: http://81100.eu.org/\nLa Stazione di Confine: http://www.stazionediconfine.it/\nAssociazione Software Libero: http://www.softwarelibero.it/\nPer contatti: FLUG Firenze Linux User Group (Hacklab Firenze/ FLUG ): info@firenze.linux.it\n","date":"2008-02-01T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/rimborso-windows-come-ottenerlo-e-perche/","title":"Rimborso Windows: come ottenerlo e perche'"},{"content":"Come molti utenti WordPress avranno gi√† notato, esistono svariati client per poter gestire il proprio blog, che possono essere utilizzati invece della normale gestione via web. Gestire WordPress da un client nativo o comunque da remoto, √® possibile grazie ad XML-RPC.Questo semplice script Python vi mostrer√† quanto sia semplice connettersi al proprio blog ed invocare un metodo:\n1 2 3 4 from xmlrpclib import Server server = Server(\u0026#34;http://www.andreagrandi.it/xmlrpc.php\u0026#34;) userinfo = server.blogger.getUserInfo(\u0026#39;\u0026#39;,\u0026#39;admin\u0026#39;,\u0026#39;password\u0026#39;) print userinfo vi stamper√† a video le informazioni sul vostro utente (ovviamente dovrete sostituire l\u0026rsquo;URL con quello del vostro blog e mettere gli user e password corretti.\n","date":"2008-02-01T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/utilizzare-wordpress-da-remoto-grazie-a-xml-rpc/","title":"Utilizzare WordPress da remoto grazie a XML-RPC"},{"content":"Questo codice Python di esempio, genera una lista di numeri primi che vanno da 2 fino al numero passato come parametro.\n1 2 3 4 5 6 7 8 9 10 def eratostene(x): primi = range(3, x + 1, 2) for i in primi: if(pow(i, 2) \u0026gt; x): break for j in primi: if(i != j) and (j % i == 0): primi.remove(j) primi.insert(0, 2) return primi ","date":"2008-01-30T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/il-crivello-di-eratostene/","title":"Il crivello di Eratostene"},{"content":"Pensando di fare una cosa gradita ai futuri lettori di questo blog, uno dei primi problemi di cui mi sono occupato dopo aver installato Wordpress √® stato quello della localizzazione in lingua italiana.\nSono bastate pochissime letture della documentazione ufficiale per approdare finalmente a questa pagina che, con chiarissime istruzioni, spiegava quali erano i semplici passi da compiere.\nPurtroppo le semplici istruzioni non hanno funzionato al primo colpo, in quanto il blog continuava ad essere completamente in inglese. Tramite una breve ricerca nel forum di supporto, ho scoperto che si tratta di una fastidiosa incompatibilit√† con i server a 64 bit che pare verr√† corretta nella prossima release. La patch sembra funzionare molto bene. Una volta applicata (almeno per quanto riguarda la mia installazione di Wordpress, ospitata su un hosting di Bluehost) sembra funzionare tutto correttamente.\nCome mai il blog si trova ancora in lingua inglese? Beh\u0026hellip; qui non si tratta di un bug, ma di una proverbiale incapacit√† di chi ha curato la traduzione in italiano. Installare la localizzazione e poi leggere una frase del genere \u0026ldquo;Grazie per creare utilizando WordPress\u0026rdquo; mi ha lasciato senza speranze ;)\nQuando la qualit√† della localizzazione avr√† raggiunto un livello accettabile, forse torner√≤ a farci un pensierino\u0026hellip; per adesso rimane in inglese!\n","date":"2008-01-30T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/wordpress-e-le-localizzazioni-in-altre-lingue/","title":"Wordpress e le localizzazioni in altre lingue"},{"content":"Reading the official WxWidget blog, I discovered that one of their developer was working to hildonize [WxWidgets]{style=\u0026ldquo;font-weight: bold;\u0026rdquo;}. I wanted to know if that was just a test or if this library could work in Maemo, so I followed his suggestion and I grabbed the latest SVN sources:\n1 svn checkout http://svn.wxwidgets.org/svn/wx/wxWidgets/trunk wxWidgets and I compiled it in this way:\n1 cd wxWidgets ./configure --with-hildon make make install then I grabbed a simple \u0026ldquo;HelloWorld\u0026rdquo; from the official documentation. You can find the complete source code here.\nI compiled the source code in this way:\n1 g++ hworld.cpp wx-config --libs wx-config --cxxflags -o hworld then I ran it in the usual way:\n1 run-standalone.sh ./hworld The result? I think that a screenshoot is better than thousand words :)\nNote: I tested this inside Scratchbox, using CHINOOK_x86 target, so I think it will work fine on Os2008. This could be a good thing to help other developers porting some interesting applications (uhm\u0026hellip; aMule for example ;) ) to Maemo.\n","date":"2007-12-17T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/wxgtk-working-on-maemo/","title":"wxGTK working on Maemo"},{"content":"\nFor the joy of all italian people, the internet tablet Nokia N810 is available in the italian Nokia shop.\nYou can find it here. The price is 459 ‚Ç¨.\nN.B: the discount code doesn\u0026rsquo;t work yet.\n","date":"2007-12-14T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/nokia-n810-available-in-italy/","title":"Nokia N810 available in Italy!"},{"content":"\nI was looking in the Italian Nokia official shop, and I noticed that the N800 price was decreased to 259‚Ç¨ instead of 289‚Ç¨\nYou can verify it on the official website.\nMaybe the N810 is coming closer? Who knows ;)\n","date":"2007-12-13T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/lower-price-for-n800-in-italymaybe-n810-coming-closer/","title":"Lower price for N800 in Italy...maybe N810 coming closer?!"},{"content":"Great news for all N770 users! Someone discovered that is possible to make Skype run on N770 with Os2007 HE.\nAll you have to do is follow these steps:\nInstall skype-ui through Application Manager\nDownload this package in your PC and extract the file named skyhost\nFind a way to copy the file skyhost to your maemo device in /usr/bin\nexecute this from root on your device:\nchown user:users /usr/bin/skyhost\nThat\u0026rsquo;s all! You can find more information on the original post.\n","date":"2007-12-10T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/skype-on-n770-using-os2007-he/","title":"Skype on N770 (using Os2007 HE)"},{"content":"Thanks to Mohammed Hassan now I know an alternative (alternative to the official howto) way to generate a .deb package for Maemo.\nIf the package already exist in the Debian repositories, you can get the .dsc file (for example in an ftp like this: http://ftp.debian.org/debian/pool/non-free/s/spim/ ) and execute the following commands:\n1 dget -x DSC_FILE_URL It will download the package and will unpack it in the current folder. You have to enter in the created folder and edit the debian/* files to personalize settings, mantainer data, add deps ecc\u0026hellip;\nWhen you\u0026rsquo;re done, you can generate the package with the usual command:\n1 dpkg-buildpackage -rfakeroot ","date":"2007-11-20T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/alternative-way-to-generate-deb-packages-for-maemo/","title":"Alternative way to generate .deb packages for Maemo"},{"content":"Using Scratchbox and in particular the Maemo SDK with ARMEL target, very often when we try to execute some application we can get into this kind of errors (for example):\n1 sem_post: Function not implemented This happens because not all the functions have been implemented in the emulated environment.[ Lauro Ven√¢ncio]{style=\u0026ldquo;font-weight: bold;\u0026rdquo;} has created a patched version of qemu-arm called [qemu-arm-eabi].\nThanks to Marcelo Lira, we have a simple howto to install the patch into the Scratchbox environment.\nNote: you have to execute these commands from outside the Scratchbox environment and you should not be logged into the environment at the same time.\nYou need gcc 3.4, SDL dev library andZlib dev:\n1 sudo apt-get install gcc-3.4 libsdl1.2-dev zlib1g-dev Get the patched qemu-arm. Notice that the patches are already applied, everything is here, and you don\u0026rsquo;t need to get the qemu sources.\n1 2 3 svn co https://qemu-arm-eabi.svn.sourceforge.net/svnroot/qemu-arm-eabi qemu-arm-eabi cd qemu-arm-eabi ./configure --target-list=arm-linux-user --static make Copy qemu to the cputransp dir on scratchbox:\n1 sudo cp arm-linux-user/qemu-arm /scratchbox/devkits/cputransp/bin/qemu-arm-eabi-sb2 Add it to the list of cputransp methods. Open the file:\n1 sudo vim /scratchbox/devkits/cputransp/etc/cputransp-methods and add this line:\n1 qemu-arm-eabi-sb2 Configure the target to use the patched qemu as transparency method. Edit the file:\n1 vim /scratchbox/users/USERNAME/targets/CHINOOK_ARMEL.config and change this line:\n1 SBOX_CPUTRANSPARENCY_METHOD=/scratchbox/devkits/cputransp/bin/qemu-arm-eabi-sb2 That\u0026rsquo;s all! You\u0026rsquo;re now ready to log again into your Scratchbox environment.\n","date":"2007-11-16T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/installing-qemu-arm-eabi-patch-into-scratchbox/","title":"Installing qemu-arm-eabi patch into Scratchbox"},{"content":"Since Os2008 for N810 is out, a lot of people were asking about the possibility to install it on their N800. Nokia will relase Os2008 for N800 too, but at the moment they don\u0026rsquo;t offer the possibility to download it since the N810 firmware it\u0026rsquo;s not 100% compatible with the old N800.\nThe only way to download a Nokia tablet firmware is being the owner of a tablet. The user has to enter it\u0026rsquo;s own MAC-address to be able to download the file. To download a N810 firmware you need to have a valid N810 MAC-address.\nA post on News.com describes the exact procedure to follow if you want to try this in your N800:\nGo to the N810 software download page{.external-link}.```\nEnter the serial number for a valid N810 device. To get one of these, pick any number between 001d6e9c0000 to 001d6e9cffff. Pick any random 4 digits (between 0-9 and a-f hex) as the last 4 digits.```\nDownload the file named RX-44_2008SE_1.2007.42-18_PR_COMBINED_MR0_ARM.bin\nDownload the latest firmware-upgrading software, \u0026ldquo;flasher-3.0\u0026rdquo;.\nNow that you have the firmware flasher and the 2008 N800 software update in the same directory, open up a terminal (on a Linux desktop/laptop), and type:\nchmod a+x ./flasher-3.0\n./flasher-3.0 -u -F RX-44_2008SE_1.2007.42-18_PR_COMBINED_MR0_ARM.bin\n1 2 3 4 5 6 7 8 9 10 - That will unpack the software, and it may take a few seconds. Once that is done, plug the N800 into your computer, using the included USB cable, then reboot the Nokia device while holding the home button. Now execute the following commands: - `sudo ./flasher-3.0 --enable-rd-mode` - `sudo ./flasher-3.0 -k zImage -f` - `sudo ./flasher-3.0 -n initfs.jffs2 -f` - `sudo ./flasher-3.0 -r rootfs.jffs2 -f -R` That should be it. Your device should now boot up with the new 2008 version of the Nokia Maemo operating system. 1 2 3 4 **Note:** Nokia **DOESN\u0026#39;T SUPPORT** this procedure in ANY way. You can follow this procedure at your own risk. Neither me or Nokia have the responsability of any damage caused to your device. ","date":"2007-11-16T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/the-unofficial-way-to-get-os2008-into-nokia-n800/","title":"The UNOFFICIAL way to get Os2008 into Nokia N800"},{"content":"The final version of Maemo SDK 4 is out. Like most other people I couldn\u0026rsquo;t wait for the final release and I installed the beta version. The big question, when I did read about the final version was \u0026ldquo;how can I upgrade to the final version without installing it from scratch?!\u0026rdquo;. Luckly one kind person helped me on maemo-developer mailing list, and suggested me to do a dist-upgrade from inside the Scratchbox environment. So, login into tour Scratchbox environment and execute this:\n1 2 [sbox-SDK_BETA_X86: ~] \u0026gt; fakeroot apt-get update [sbox-SDK_BETA_X86: ~] \u0026gt; fakeroot apt-get dist-upgrade That\u0026rsquo;s all! I don\u0026rsquo;t know if this is the official method to do the upgrade, but it worked for me. I checked, after the upgrade, if I had the right packages installed, using this page: http://tablets-dev.nokia.com/4.0/4.0b_vs_4.0_content_comparison.html\nand they were right.\n","date":"2007-11-11T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/upgrading-maemo-sdk-4-beta-to-maemo-sdk-4-final-release/","title":"Upgrading Maemo SDK 4 Beta to Maemo SDK 4 final release"},{"content":"Introduction Maemo is an opensource development platform for Linux based devices. Actually is the base for the operating system installed on Nokia N770, N800 and the upcoming N810 but it could be adopted, with few changes, even by other similar devices.\nIn particular, this version of Maemo SDK is the only one that allow developers to develop new applications for N810 and to start porting old application to this new platform.\nThe SDK is not only a set of libraries and compiler, it gives you a real environment that emulates the Nokia device, so the developer can write applications, debug them and test them. Both command line and gui application are supported in emulator.\nGraphical environment is based on a real X server, a window manager and on GTK libraries, with a particular extension called Hildon.\nWith Maemo SDK you can:\nTest Maemo applications using a normal PC with Linux.\nWrite and debug applications written by you.\nPort existing applications written for Linux/GTK and verify if they work correctly.```\nCompile and build ARMEL package so you can install them in the device.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 ## Requirements These are the minimum requirements to work with Maemo SDK: - Intel compatible processor (x86), at least 500 Mhz - 256 Mb RAM - 2 Gb space on hard disk - A Linux distribution (I suggest Debian or Ubuntu) You need the following software packages: - Scratchbox: a cross-compiling toolkit that allows you to compile applications for different platform``` - Maemo SDK: you can find it at this address: \u0026lt;http://www.maemo.org/downloads/download-sdk.html\u0026gt; - Xephyr Xserver: Starting from **4.x** version, Maemo has a simple installer script, so all you need are these two files: - [maemo-scratchbox-install_4.0beta.sh](http://tabletsdev.maemo.org/unstable/chinook-beta/maemo-scratchbox-install_4.0beta.sh \u0026#34;http://tabletsdev.maemo.org/unstable/chinook-beta/maemo-scratchbox-install_4.0beta.sh\u0026#34;) - [maemo-sdk-install_4.0beta.sh](http://tabletsdev.maemo.org/unstable/chinook-beta/maemo-sdk-install_4.0beta.sh \u0026#34;http://tabletsdev.maemo.org/unstable/chinook-beta/maemo-sdk-install_4.0beta.sh\u0026#34;) ## Installing Scratchbox The first tool you have to install is **Scratchbox**. I suggest you to use the script provided but you could choose also to install it manually (in this case please refer to [this site](http://scratchbox.org/documentation/user/scratchbox-1.0/html/installdoc.html \u0026#34;http://scratchbox.org/documentation/user/scratchbox-1.0/html/installdoc.html\u0026#34;) for detailed instructions). Before beginning the installation of Scratchbox, you have to become **`root`**. First of all set the permission of the script file: ```shell chmod +x maemo-scratchbox-install_4.0beta.sh Then run it with these parameters:\n1 ./maemo-scratchbox-install_4.0beta.sh -d -u andy80 Please note that -d tells the installer to install from Debian dpkg packages while -u specifies your username (in my case is andy80, you have to change it using your local username).\nScratchbox environment will be installed in /scratchbox/\nPlease note that you\u0026rsquo;ll have to logout and login again to be able to log into you new Scratchbox environment. To test it you simply have to start Scratchbox from your local user:\n1 2 3 4 5 6 /scratchbox/login Welcome to Scratchbox, the cross-compilation toolkit! Use \u0026#39;sb-menu\u0026#39; to change your compilation target. See /scratchbox/doc/ for documentation. Installing Maemo SDK When Scratchbox is correctly installed on your system, you can install the Maemo SDK. Please note that you have to do it from normal user (the user you specified in the installation of Scratchbox).\nSimply run this command and follow instructions:\n1 bash maemo-sdk-install_4.0beta.sh At the end you should get this message:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Installation was successful! ---------------------------- IMPORTANT! Please read this. You now have the maemo 4.0beta \u0026#39;chinook\u0026#39; installed on your computer. You can now start your maemo SDK session with /scratchbox/login and then select your target with \u0026#39;sb-conf select SDK\\_BETA\\_ARMEL\u0026#39; for the armel target or \u0026#39;sb-conf select SDK\\_BETA\\_X86\u0026#39; for the i386 target. If you have any problems with targets\u0026#39; package databases, you can try running \u0026#39;fakeroot apt-get -f install\u0026#39; on your scratchbox target. This command will try to fix any problems with the package database. Happy hacking! Installing Xephyr Xephyr is an X11 server that provides a device screen for the developer so that you can see all the maemo application windows and visuals on your computer.\nTo install it in a Debian based distribution, simply execute this (from root):\n1 apt-get install xserver-xephyr Running Xephyr To see if all works fine, you should start Xephyr and Maemo environment. Execute this from outside the Scratchbox environment:\n1 Xephyr :2 -host-cursor -screen 800x480x16 -dpi 96 -ac -extension Composite Now, from another shell, log into Scratchbox and execute this:\n1 2 [sbox-SDK_BETA_X86:~] \u0026gt; export DISPLAY=:2 [sbox-SDK_BETA_X86:~] \u0026gt; af-sb-init.sh start This should start the Hildon Application Framework inside the Xephyr window. That\u0026rsquo;s all!\nReferences Here you can find a list of website where I took information from to write this guide:\nhttp://tabletsdev.maemo.org/unstable/chinook-beta/INSTALL.txt http://www.maemo.org ","date":"2007-10-25T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/installing-maemo-sdk-4-beta/","title":"Installing Maemo SDK 4 Beta"},{"content":"Spim is a self-contained simulator that will run MIPS32 assembly language programs. It reads and executes assembly language programs written for this processor. spim also provides a simple debugger and minimal set of operating system services. spim does not execute binary (compiled) programs.\nI made a port of spim for the Nokia 770/800 device just for fun and to start learning how to do ports.\nDownload You can download spim for N770/800 from here: http://www.ptlug.org/download/packages/spim_7.3-1_armel.deb\nReferences To create the package i followed the guide lines in these websites:\nhttp://www.maemo.org/platform/docs/howtos/howto_making_an_application_package.html http://www.debian.org/doc/maint-guide/index.en.html http://www.cs.wisc.edu/~larus/spim.html ","date":"2007-10-25T00:00:00Z","permalink":"https://www.andreagrandi.it/posts/spim-mips-emulator-for-n770/","title":"Spim - MIPS Emulator for N770"}]