<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hosting on Andrea Grandi</title>
        <link>https://www.andreagrandi.it/tags/hosting/</link>
        <description>Recent content in Hosting on Andrea Grandi</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sat, 20 Jul 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://www.andreagrandi.it/tags/hosting/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Buy or Rent? RaspberryPi vs VPS</title>
        <link>https://www.andreagrandi.it/posts/buy-or-rent-raspberrypi-vs-vps/</link>
        <pubDate>Sat, 20 Jul 2024 00:00:00 +0000</pubDate>
        
        <guid>https://www.andreagrandi.it/posts/buy-or-rent-raspberrypi-vs-vps/</guid>
        <description>&lt;img src="https://www.andreagrandi.it/posts/buy-or-rent-raspberrypi-vs-vps/cover-raspberrypi-vs-vps.png" alt="Featured image of post Buy or Rent? RaspberryPi vs VPS" /&gt;&lt;p&gt;Recently I was planning to self host a service I&amp;rsquo;m using and I was immediately stuck on a decision: &lt;strong&gt;should I just buy a Raspberry Pi 5 or rent a VPS?&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s starts from the basic question: &lt;strong&gt;what specs do I need to run this service?&lt;/strong&gt; Reading around, it seems that something with 4GB of RAM and 20-30 GB of disk could be enough for my needs. Good.&lt;/p&gt;
&lt;h2 id=&#34;costs&#34;&gt;Costs
&lt;/h2&gt;&lt;p&gt;A &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.raspberrypi.com/products/raspberry-pi-5/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Raspberry Pi 5&lt;/a&gt; would cost me around 100â‚¬&lt;/strong&gt; (including accessories) plus the cost of energy, while &lt;strong&gt;renting a VPS&lt;/strong&gt; with similar characteristics, &lt;strong&gt;would cost me around 4,50â‚¬/month&lt;/strong&gt; (I used &lt;a class=&#34;link&#34; href=&#34;https://www.hetzner.com/cloud/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hetzner VPS prices&lt;/a&gt; as reference).&lt;/p&gt;
&lt;p&gt;To compensate costs of purchasing a Raspberry Pi, &lt;strong&gt;I should keep running my service for at least a couple of years&lt;/strong&gt;. After that time, having purchased a Raspberry Pi would come cheaper (if you consider the total cost per month) then keep paying Hetzner.&lt;/p&gt;
&lt;h2 id=&#34;complexity&#34;&gt;Complexity
&lt;/h2&gt;&lt;p&gt;Honestly, both solutions are quite &lt;strong&gt;challenging&lt;/strong&gt; (if you want to do things in the right way) and similar in terms of administration, the main difference would be that in case of a Raspberry Pi, I would have to also include the setup of something like &lt;a class=&#34;link&#34; href=&#34;https://tailscale.com/kb/1223/funnel&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Tailscale Funnel&lt;/a&gt;, to be able to expose my device on the public Internet (my provider, Fastweb, doesn&amp;rsquo;t give public IP addresses to every user and most of them are behind a NAT).&lt;/p&gt;
&lt;p&gt;In addition to this, I would also have to do the initial &lt;strong&gt;installation of the operating system&lt;/strong&gt; and the &lt;strong&gt;network configuration&lt;/strong&gt;, but it&amp;rsquo;s surely not the most difficult part.&lt;/p&gt;
&lt;p&gt;Everything else (installing a web server, a database, configuring them, installing and running the service etc&amp;hellip;) would be exactly the same.&lt;/p&gt;
&lt;h2 id=&#34;the-solution&#34;&gt;The solution
&lt;/h2&gt;&lt;p&gt;Both solutions are valid and both have pros and cons. So, what should one do? The best approach is evaluate both of them and pick the one that suits our needs.&lt;/p&gt;
&lt;h2 id=&#34;raspberry-pi-buy&#34;&gt;Raspberry Pi (buy)
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s analyse the case we buy a &lt;strong&gt;Raspberry Pi&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;pros&#34;&gt;Pros
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;You physically own the hardware&lt;/li&gt;
&lt;li&gt;It can be more fun to own an electronic device&lt;/li&gt;
&lt;li&gt;After a couple of years you basically run your service for free (apart from the electricity)&lt;/li&gt;
&lt;li&gt;Your data is definitely private&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cons&#34;&gt;Cons
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Home connection is less reliable than a VPS network&lt;/li&gt;
&lt;li&gt;If the device breaks after two years, you have to buy it from scratch&lt;/li&gt;
&lt;li&gt;A bit more complexity for the initial setup&lt;/li&gt;
&lt;li&gt;If you don&amp;rsquo;t need the service anymore after a couple of months, you are left with an expensive device collecting dust&lt;/li&gt;
&lt;li&gt;Physical hardware gets old: the same Raspberry Pi is unlikely to serve you for many years and you will need to buy a new one every few years&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;vps-rent&#34;&gt;VPS (rent)
&lt;/h2&gt;&lt;p&gt;What if we rent a &lt;strong&gt;Virtual Private server&lt;/strong&gt;?&lt;/p&gt;
&lt;h3 id=&#34;pros-1&#34;&gt;Pros
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Your service is always up (even when your local ISP fails)&lt;/li&gt;
&lt;li&gt;You don&amp;rsquo;t have an high initial cost&lt;/li&gt;
&lt;li&gt;If you decide to give up after a couple of months, you have only wasted less than 10â‚¬&lt;/li&gt;
&lt;li&gt;Easier initial setup&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cons-1&#34;&gt;Cons
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Your data won&amp;rsquo;t be private&lt;/li&gt;
&lt;li&gt;If you keep running the service after 2 years (or the equivalent considering the cost of the Raspberry Pi) you also keep paying&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;As you can see, &lt;strong&gt;there is no right or wrong solution&lt;/strong&gt;. Depending on our own priorities and preferences, we may choose to buy something or to rent.&lt;/p&gt;
&lt;p&gt;What did I end up choosing for my specific case? Well&amp;hellip; in the end &lt;strong&gt;I found a third solution&lt;/strong&gt; which has some of the benefits of both, it was much easier to configure (I got it up and running in less than 1 hour) and most importantly &lt;strong&gt;costed me 0â‚¬&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;But I will talk about it in another post ðŸ˜‰&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Self hosting a Copilot replacement: my personal experience</title>
        <link>https://www.andreagrandi.it/posts/self-hosting-copilot-replacement/</link>
        <pubDate>Sun, 03 Mar 2024 00:00:00 +0000</pubDate>
        
        <guid>https://www.andreagrandi.it/posts/self-hosting-copilot-replacement/</guid>
        <description>&lt;img src="https://www.andreagrandi.it/posts/self-hosting-copilot-replacement/self-hosting-copilot-cover.webp" alt="Featured image of post Self hosting a Copilot replacement: my personal experience" /&gt;&lt;p&gt;For my job (Software Developer) I make a daily use of tools like &lt;a class=&#34;link&#34; href=&#34;https://github.com/features/copilot&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GitHub Copilot&lt;/a&gt; and &lt;a class=&#34;link&#34; href=&#34;https://chat.openai.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChatGPT&lt;/a&gt;. I want to explore alternative solutions which can be hosted autonomusly, without relying on an external service.&lt;/p&gt;
&lt;h2 id=&#34;disclaimer&#34;&gt;Disclaimer
&lt;/h2&gt;&lt;p&gt;Before I continue, let me clarify that these are &lt;strong&gt;tools&lt;/strong&gt; which makes my job faster, they don&amp;rsquo;t do the job for me: a wrong assumption made by so many people is that AI tools will do the work for you.&lt;/p&gt;
&lt;p&gt;This is quite &lt;strong&gt;not true&lt;/strong&gt;. You are still responsible of knowing what to do, understanding the problem, asking the right questions and knowing what to do with the answers.&lt;/p&gt;
&lt;p&gt;If you regularly search for stuff on Google or any other engine, to find examples in blog posts or Stack Overflow, read someone else example and then adapt the code for your needs, there is nothing wrong automating this: &lt;strong&gt;you are still in charge of the final result&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-experiment&#34;&gt;The experiment
&lt;/h2&gt;&lt;p&gt;After I recently experimented with &lt;a class=&#34;link&#34; href=&#34;https://www.andreagrandi.it/posts/ollama-running-llm-locally/&#34; &gt;local LLMs using Ollama&lt;/a&gt;, I wanted to figure out if I could use some of these models to &lt;strong&gt;replace GitHub Copilot&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;My intent is not to save some money (my company pays for these tools) or for privacy reasons (it would be pointless to keep your code &amp;ldquo;secret&amp;rdquo; from GitHub if you use it to host it), but to &lt;strong&gt;find out how good these alternative tools are&lt;/strong&gt; and&amp;hellip; for fun!&lt;/p&gt;
&lt;h2 id=&#34;setup-and-available-resources&#34;&gt;Setup and available resources
&lt;/h2&gt;&lt;p&gt;The laptop I&amp;rsquo;m using is a MacBook Pro with &lt;strong&gt;M2 Pro&lt;/strong&gt; CPU and &lt;strong&gt;32 GB RAM&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This machine must be able to run my basic &lt;strong&gt;requirements&lt;/strong&gt;, which are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slack&lt;/li&gt;
&lt;li&gt;Docker (running my work containers)&lt;/li&gt;
&lt;li&gt;VSCode&lt;/li&gt;
&lt;li&gt;Safari / Chrome&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s see if it can also run a Copilot replacement.&lt;/p&gt;
&lt;h2 id=&#34;tested-models-and-extensions&#34;&gt;Tested models and extensions
&lt;/h2&gt;&lt;p&gt;Basically, to run a Copilot replacement, you need to be able to run an LLM and use one of the available extensions for VSCode (in my case I use VSCode, but similar extensions exist for other IDEs).&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m running the models locally using &lt;a class=&#34;link&#34; href=&#34;https://ollama.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ollama&lt;/a&gt;. If you need to know how to use it, you can refer to my &lt;a class=&#34;link&#34; href=&#34;https://www.andreagrandi.it/posts/ollama-running-llm-locally/&#34; &gt;previous post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;models&lt;/strong&gt; I tested are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;stable-code:3b-code-q4_0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;codellama:7b-code-q4_K_M&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;codellama:13b-code-q4_K_M&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The number before the &lt;code&gt;b&lt;/code&gt; usually represents the number of parameters (&lt;strong&gt;3 billions&lt;/strong&gt;, &lt;strong&gt;7 billions&lt;/strong&gt;, &lt;strong&gt;13 billions&lt;/strong&gt; etc&amp;hellip;) and you approximately need &lt;strong&gt;4 GB&lt;/strong&gt;, &lt;strong&gt;8 GB&lt;/strong&gt; and &lt;strong&gt;16 GB RAM&lt;/strong&gt; to use them.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://about.meta.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Meta&lt;/a&gt; has released models with &lt;strong&gt;34 billions&lt;/strong&gt; and &lt;strong&gt;70 billions&lt;/strong&gt; parameters, which are even more powerful, and you can find them here: &lt;a class=&#34;link&#34; href=&#34;https://ollama.com/library/codellama&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ollama.com/library/codellama&lt;/a&gt; but you will need &lt;strong&gt;64-128 GB RAM&lt;/strong&gt; to run them properly.&lt;/p&gt;
&lt;p&gt;The extensions I tested are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LLama Coder&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://marketplace.visualstudio.com/items?itemName=ex3ndr.llama-coder&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://marketplace.visualstudio.com/items?itemName=ex3ndr.llama-coder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Code GPT&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://marketplace.visualstudio.com/items?itemName=DanielSanMedium.dscodegpt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://marketplace.visualstudio.com/items?itemName=DanielSanMedium.dscodegpt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;twinny&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://marketplace.visualstudio.com/items?itemName=rjmacarthy.twinny&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://marketplace.visualstudio.com/items?itemName=rjmacarthy.twinny&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results
&lt;/h2&gt;&lt;p&gt;The results I got have been quite mixed and &lt;strong&gt;mostly depending on the LLM model&lt;/strong&gt; I was testing, rather than on the extension I was using.&lt;/p&gt;
&lt;p&gt;A model like &lt;code&gt;stable-code:3b-code-q4_0&lt;/code&gt; was quite &lt;strong&gt;fast&lt;/strong&gt; to complete the code I was typing, &lt;strong&gt;but very often&lt;/strong&gt; giving me &lt;strong&gt;wrong&lt;/strong&gt; code or pure garbage (ie: the model wasn&amp;rsquo;t even able to correctly structure a simple Python method or to maintain the correct indentation)&lt;/p&gt;
&lt;p&gt;Models like &lt;code&gt;codellama:7b-code-q4_K_M&lt;/code&gt; or &lt;code&gt;codellama:13b-code-q4_K_M&lt;/code&gt; were giving me &lt;strong&gt;better results&lt;/strong&gt; but despite having 32 GB RAM available and a quite fast CPU, they were &lt;strong&gt;taking 3-4 seconds&lt;/strong&gt; to complete what I was typing, making themselves useless (at least for my use case).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;None of them was even remotely close to the speed and accuracy of GitHub Copilot&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;While the idea of having a personal and private instance of a code assistant is interesting (and can also be the only available option in certain environments), &lt;strong&gt;the reality is that achieving the same level of performance as GitHub Copilot is quite challenging&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Despite these challenges, I think with time both available models and extensions &lt;strong&gt;will get better&lt;/strong&gt; and better, improving their quality and maybe reducing the amount of required resources.&lt;/p&gt;
&lt;p&gt;In case I missed some better model or extension, please feel free to &lt;strong&gt;let me know&lt;/strong&gt; in the comments. I will be glad to do more tests and update this posts or write a new one in the future.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In the mean time&lt;/strong&gt;, at least for my personale usage, I think I will &lt;strong&gt;stick with GitHub Copilot&lt;/strong&gt;.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
